--------------------Training--------------------
arch_str :: |skip_connect~0|+|lstm_1~0|skip_connect~1|[linear]
model :: 3A
InferCell(
  info :: nodes=3, inC=1, outC=64, [1<-(I0-L0) | 2<-(I0-L1,I1-L2)], genotype_str: skip_connect~0|lstm_1~0|skip_connect~1
  linear_layers: [linear]
  (layers): ModuleList(
    (0): FactorizedReduce(
      C_in=1, C_out=64, stride=1
      (relu): ReLU()
      (conv): Conv1d(1, 64, kernel_size=(1,), stride=(1,), bias=False)
      (bn): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (1): LSTM(
      (lstm): LSTM(1, 64, batch_first=True)
    )
    (2): Identity()
  )
  (linear_layers): ModuleList(
    (0): Linear(in_features=3072, out_features=1, bias=True)
  )
)
tr_params :: epochs = 100, patience = 20, batch_size = 256, window_size = 48, data_size = 100
Model MACs: 866.304K, Model Params: 20.417K
learning rate scheduling :: (optimizer, mode='min', factor=0.1, patience=5, verbose=True)
total_samples :: train_dataset = 2136000, train_dataloader = 2136000
total_samples :: valid_dataset = 283200, valid_dataloader = 283200
Epoch ::  1 || Loss: 0.44109364 || it_count: 8344 || Val Loss: 0.46882804 || Val it_count: 1107 || Current Learning Rate: 0.001 || Time: 00:06:5.51
Epoch ::  2 || Loss: 0.41545175 || it_count: 8344 || Val Loss: 0.46857600 || Val it_count: 1107 || Current Learning Rate: 0.001 || Time: 00:12:12.36
Epoch ::  3 || Loss: 0.41337477 || it_count: 8344 || Val Loss: 0.46695789 || Val it_count: 1107 || Current Learning Rate: 0.001 || Time: 00:18:23.75
Epoch ::  4 || Loss: 0.41292492 || it_count: 8344 || Val Loss: 0.46634505 || Val it_count: 1107 || Current Learning Rate: 0.001 || Time: 00:24:32.78
Epoch ::  5 || Loss: 0.41267623 || it_count: 8344 || Val Loss: 0.46505762 || Val it_count: 1107 || Current Learning Rate: 0.001 || Time: 00:30:38.61
Epoch ::  6 || Loss: 0.41244063 || it_count: 8344 || Val Loss: 0.46727395 || Val it_count: 1107 || Current Learning Rate: 0.001 || Time: 00:36:44.68
Epoch ::  7 || Loss: 0.41231928 || it_count: 8344 || Val Loss: 0.46577302 || Val it_count: 1107 || Current Learning Rate: 0.001 || Time: 00:42:50.62
Epoch ::  8 || Loss: 0.41193200 || it_count: 8344 || Val Loss: 0.46737099 || Val it_count: 1107 || Current Learning Rate: 0.001 || Time: 00:48:56.69
Epoch ::  9 || Loss: 0.41186671 || it_count: 8344 || Val Loss: 0.46493575 || Val it_count: 1107 || Current Learning Rate: 0.001 || Time: 00:55:3.48
Epoch :: 10 || Loss: 0.41180669 || it_count: 8344 || Val Loss: 0.46618897 || Val it_count: 1107 || Current Learning Rate: 0.001 || Time: 01:01:9.17
Epoch :: 11 || Loss: 0.41150803 || it_count: 8344 || Val Loss: 0.46670323 || Val it_count: 1107 || Current Learning Rate: 0.001 || Time: 01:07:15.17
Epoch :: 12 || Loss: 0.41155249 || it_count: 8344 || Val Loss: 0.46623071 || Val it_count: 1107 || Current Learning Rate: 0.001 || Time: 01:13:20.30
Epoch :: 13 || Loss: 0.41135694 || it_count: 8344 || Val Loss: 0.46643820 || Val it_count: 1107 || Current Learning Rate: 0.001 || Time: 01:19:25.54
Epoch :: 14 || Loss: 0.41127532 || it_count: 8344 || Val Loss: 0.46604994 || Val it_count: 1107 || Current Learning Rate: 0.001 || Time: 01:25:31.86
Epoch :: 15 || Loss: 0.41139864 || it_count: 8344 || Val Loss: 0.46707040 || Val it_count: 1107 || Current Learning Rate: 0.001 || Time: 01:31:37.07
Epoch :: 16 || Loss: 0.41111230 || it_count: 8344 || Val Loss: 0.46578144 || Val it_count: 1107 || Current Learning Rate: 0.001 || Time: 01:37:41.28
Epoch :: 17 || Loss: 0.41100649 || it_count: 8344 || Val Loss: 0.46630376 || Val it_count: 1107 || Current Learning Rate: 0.001 || Time: 01:43:46.70
Epoch :: 18 || Loss: 0.41092830 || it_count: 8344 || Val Loss: 0.46516470 || Val it_count: 1107 || Current Learning Rate: 0.001 || Time: 01:49:51.13
Epoch :: 19 || Loss: 0.41102504 || it_count: 8344 || Val Loss: 0.46519965 || Val it_count: 1107 || Current Learning Rate: 0.001 || Time: 01:55:56.79
Epoch :: 20 || Loss: 0.41092569 || it_count: 8344 || Val Loss: 0.46547797 || Val it_count: 1107 || Current Learning Rate: 0.001 || Time: 02:02:1.81
Epoch :: 21 || Loss: 0.41085983 || it_count: 8344 || Val Loss: 0.46390733 || Val it_count: 1107 || Current Learning Rate: 0.001 || Time: 02:08:7.56
Epoch :: 22 || Loss: 0.41070780 || it_count: 8344 || Val Loss: 0.46403333 || Val it_count: 1107 || Current Learning Rate: 0.001 || Time: 02:14:14.99
Epoch :: 23 || Loss: 0.41040049 || it_count: 8344 || Val Loss: 0.46557165 || Val it_count: 1107 || Current Learning Rate: 0.001 || Time: 02:20:22.28
Epoch :: 24 || Loss: 0.41039521 || it_count: 8344 || Val Loss: 0.46530354 || Val it_count: 1107 || Current Learning Rate: 0.001 || Time: 02:26:28.68
Epoch :: 25 || Loss: 0.41027390 || it_count: 8344 || Val Loss: 0.46574069 || Val it_count: 1107 || Current Learning Rate: 0.001 || Time: 02:32:35.76
Epoch :: 26 || Loss: 0.41028599 || it_count: 8344 || Val Loss: 0.46605801 || Val it_count: 1107 || Current Learning Rate: 0.001 || Time: 02:38:42.78
Epoch 00011: reducing learning rate of group 0 to 1.0000e-04.
Epoch :: 27 || Loss: 0.41020715 || it_count: 8344 || Val Loss: 0.46707351 || Val it_count: 1107 || Current Learning Rate: 0.0001 || Time: 02:44:50.05
Epoch :: 28 || Loss: 0.41603318 || it_count: 8344 || Val Loss: 0.45505310 || Val it_count: 1107 || Current Learning Rate: 0.0001 || Time: 02:50:57.03
Epoch :: 29 || Loss: 0.41201009 || it_count: 8344 || Val Loss: 0.45373930 || Val it_count: 1107 || Current Learning Rate: 0.0001 || Time: 02:57:3.17
Epoch :: 30 || Loss: 0.41050209 || it_count: 8344 || Val Loss: 0.45378112 || Val it_count: 1107 || Current Learning Rate: 0.0001 || Time: 03:03:10.08
Epoch :: 31 || Loss: 0.41008651 || it_count: 8344 || Val Loss: 0.45397138 || Val it_count: 1107 || Current Learning Rate: 0.0001 || Time: 03:09:16.72
Epoch :: 32 || Loss: 0.40984817 || it_count: 8344 || Val Loss: 0.45436198 || Val it_count: 1107 || Current Learning Rate: 0.0001 || Time: 03:15:22.76
Epoch :: 33 || Loss: 0.40970755 || it_count: 8344 || Val Loss: 0.45385006 || Val it_count: 1107 || Current Learning Rate: 0.0001 || Time: 03:21:28.83
Epoch :: 34 || Loss: 0.40960930 || it_count: 8344 || Val Loss: 0.45353548 || Val it_count: 1107 || Current Learning Rate: 0.0001 || Time: 03:27:35.02
Epoch :: 35 || Loss: 0.40949127 || it_count: 8344 || Val Loss: 0.45425681 || Val it_count: 1107 || Current Learning Rate: 0.0001 || Time: 03:33:41.63
Epoch :: 36 || Loss: 0.40943460 || it_count: 8344 || Val Loss: 0.45417931 || Val it_count: 1107 || Current Learning Rate: 0.0001 || Time: 03:39:47.33
Epoch :: 37 || Loss: 0.40936240 || it_count: 8344 || Val Loss: 0.45429506 || Val it_count: 1107 || Current Learning Rate: 0.0001 || Time: 03:45:53.37
Epoch :: 38 || Loss: 0.40922179 || it_count: 8344 || Val Loss: 0.45401010 || Val it_count: 1107 || Current Learning Rate: 0.0001 || Time: 03:51:58.72
Epoch :: 39 || Loss: 0.40914618 || it_count: 8344 || Val Loss: 0.45277223 || Val it_count: 1107 || Current Learning Rate: 0.0001 || Time: 03:58:4.08
Epoch :: 40 || Loss: 0.40898492 || it_count: 8344 || Val Loss: 0.45228108 || Val it_count: 1107 || Current Learning Rate: 0.0001 || Time: 04:04:11.79
Epoch :: 41 || Loss: 0.40892271 || it_count: 8344 || Val Loss: 0.45463181 || Val it_count: 1107 || Current Learning Rate: 0.0001 || Time: 04:10:17.90
Epoch :: 42 || Loss: 0.40885637 || it_count: 8344 || Val Loss: 0.45478565 || Val it_count: 1107 || Current Learning Rate: 0.0001 || Time: 04:16:23.89
Epoch :: 43 || Loss: 0.40881533 || it_count: 8344 || Val Loss: 0.45438171 || Val it_count: 1107 || Current Learning Rate: 0.0001 || Time: 04:22:30.47
Epoch :: 44 || Loss: 0.40874990 || it_count: 8344 || Val Loss: 0.45265781 || Val it_count: 1107 || Current Learning Rate: 0.0001 || Time: 04:28:36.29
Epoch :: 45 || Loss: 0.40867990 || it_count: 8344 || Val Loss: 0.45368908 || Val it_count: 1107 || Current Learning Rate: 0.0001 || Time: 04:34:43.38
Epoch :: 46 || Loss: 0.40865957 || it_count: 8344 || Val Loss: 0.45191377 || Val it_count: 1107 || Current Learning Rate: 0.0001 || Time: 04:40:50.65
Epoch :: 47 || Loss: 0.40855037 || it_count: 8344 || Val Loss: 0.45447975 || Val it_count: 1107 || Current Learning Rate: 0.0001 || Time: 04:46:56.71
Epoch :: 48 || Loss: 0.40848553 || it_count: 8344 || Val Loss: 0.45377082 || Val it_count: 1107 || Current Learning Rate: 0.0001 || Time: 04:53:1.19
Epoch :: 49 || Loss: 0.40844774 || it_count: 8344 || Val Loss: 0.45268790 || Val it_count: 1107 || Current Learning Rate: 0.0001 || Time: 04:59:7.87
Epoch :: 50 || Loss: 0.40837222 || it_count: 8344 || Val Loss: 0.45437016 || Val it_count: 1107 || Current Learning Rate: 0.0001 || Time: 05:05:14.28
Epoch :: 51 || Loss: 0.40829531 || it_count: 8344 || Val Loss: 0.45231382 || Val it_count: 1107 || Current Learning Rate: 0.0001 || Time: 05:11:21.19
Epoch 00036: reducing learning rate of group 0 to 1.0000e-05.
Epoch :: 52 || Loss: 0.40829496 || it_count: 8344 || Val Loss: 0.45396597 || Val it_count: 1107 || Current Learning Rate: 1e-05 || Time: 05:17:27.73
Epoch :: 53 || Loss: 0.41004406 || it_count: 8344 || Val Loss: 0.44600545 || Val it_count: 1107 || Current Learning Rate: 1e-05 || Time: 05:23:34.02
Epoch :: 54 || Loss: 0.40890370 || it_count: 8344 || Val Loss: 0.44610176 || Val it_count: 1107 || Current Learning Rate: 1e-05 || Time: 05:29:39.27
Epoch :: 55 || Loss: 0.40868559 || it_count: 8344 || Val Loss: 0.44624230 || Val it_count: 1107 || Current Learning Rate: 1e-05 || Time: 05:35:44.60
Epoch :: 56 || Loss: 0.40861042 || it_count: 8344 || Val Loss: 0.44648453 || Val it_count: 1107 || Current Learning Rate: 1e-05 || Time: 05:41:50.15
Epoch :: 57 || Loss: 0.40856538 || it_count: 8344 || Val Loss: 0.44677521 || Val it_count: 1107 || Current Learning Rate: 1e-05 || Time: 05:47:55.30
Epoch :: 58 || Loss: 0.40853201 || it_count: 8344 || Val Loss: 0.44706535 || Val it_count: 1107 || Current Learning Rate: 1e-05 || Time: 05:54:0.76
Epoch 00043: reducing learning rate of group 0 to 1.0000e-06.
Epoch :: 59 || Loss: 0.40850401 || it_count: 8344 || Val Loss: 0.44725127 || Val it_count: 1107 || Current Learning Rate: 1.0000000000000002e-06 || Time: 06:00:7.48
Epoch :: 60 || Loss: 0.40863949 || it_count: 8344 || Val Loss: 0.44619857 || Val it_count: 1107 || Current Learning Rate: 1.0000000000000002e-06 || Time: 06:06:12.38
Epoch :: 61 || Loss: 0.40854549 || it_count: 8344 || Val Loss: 0.44576739 || Val it_count: 1107 || Current Learning Rate: 1.0000000000000002e-06 || Time: 06:12:17.82
Epoch :: 62 || Loss: 0.40852315 || it_count: 8344 || Val Loss: 0.44557799 || Val it_count: 1107 || Current Learning Rate: 1.0000000000000002e-06 || Time: 06:18:25.61
Epoch :: 63 || Loss: 0.40851234 || it_count: 8344 || Val Loss: 0.44549051 || Val it_count: 1107 || Current Learning Rate: 1.0000000000000002e-06 || Time: 06:24:31.32
Epoch :: 64 || Loss: 0.40850507 || it_count: 8344 || Val Loss: 0.44545046 || Val it_count: 1107 || Current Learning Rate: 1.0000000000000002e-06 || Time: 06:30:37.60
Epoch :: 65 || Loss: 0.40849938 || it_count: 8344 || Val Loss: 0.44543541 || Val it_count: 1107 || Current Learning Rate: 1.0000000000000002e-06 || Time: 06:36:43.37
Epoch :: 66 || Loss: 0.40849457 || it_count: 8344 || Val Loss: 0.44543441 || Val it_count: 1107 || Current Learning Rate: 1.0000000000000002e-06 || Time: 06:42:50.34
Epoch :: 67 || Loss: 0.40849032 || it_count: 8344 || Val Loss: 0.44544168 || Val it_count: 1107 || Current Learning Rate: 1.0000000000000002e-06 || Time: 06:48:55.95
Epoch :: 68 || Loss: 0.40848646 || it_count: 8344 || Val Loss: 0.44545409 || Val it_count: 1107 || Current Learning Rate: 1.0000000000000002e-06 || Time: 06:55:1.58
Epoch :: 69 || Loss: 0.40848289 || it_count: 8344 || Val Loss: 0.44546986 || Val it_count: 1107 || Current Learning Rate: 1.0000000000000002e-06 || Time: 07:01:7.89
Epoch :: 70 || Loss: 0.40847954 || it_count: 8344 || Val Loss: 0.44548789 || Val it_count: 1107 || Current Learning Rate: 1.0000000000000002e-06 || Time: 07:07:14.17
Epoch 00055: reducing learning rate of group 0 to 1.0000e-07.
Epoch :: 71 || Loss: 0.40847635 || it_count: 8344 || Val Loss: 0.44550744 || Val it_count: 1107 || Current Learning Rate: 1.0000000000000002e-07 || Time: 07:13:20.92
Epoch :: 72 || Loss: 0.40847813 || it_count: 8344 || Val Loss: 0.44543769 || Val it_count: 1107 || Current Learning Rate: 1.0000000000000002e-07 || Time: 07:19:27.54
Epoch :: 73 || Loss: 0.40847265 || it_count: 8344 || Val Loss: 0.44539897 || Val it_count: 1107 || Current Learning Rate: 1.0000000000000002e-07 || Time: 07:25:33.90
Epoch :: 74 || Loss: 0.40846931 || it_count: 8344 || Val Loss: 0.44537161 || Val it_count: 1107 || Current Learning Rate: 1.0000000000000002e-07 || Time: 07:31:38.37
Epoch :: 75 || Loss: 0.40846712 || it_count: 8344 || Val Loss: 0.44535045 || Val it_count: 1107 || Current Learning Rate: 1.0000000000000002e-07 || Time: 07:37:43.92
Epoch :: 76 || Loss: 0.40846557 || it_count: 8344 || Val Loss: 0.44533342 || Val it_count: 1107 || Current Learning Rate: 1.0000000000000002e-07 || Time: 07:43:51.65
Epoch :: 77 || Loss: 0.40846441 || it_count: 8344 || Val Loss: 0.44531948 || Val it_count: 1107 || Current Learning Rate: 1.0000000000000002e-07 || Time: 07:49:56.87
Epoch :: 78 || Loss: 0.40846350 || it_count: 8344 || Val Loss: 0.44530796 || Val it_count: 1107 || Current Learning Rate: 1.0000000000000002e-07 || Time: 07:56:2.77
Epoch :: 79 || Loss: 0.40846275 || it_count: 8344 || Val Loss: 0.44529842 || Val it_count: 1107 || Current Learning Rate: 1.0000000000000002e-07 || Time: 08:02:9.76
Epoch :: 80 || Loss: 0.40846211 || it_count: 8344 || Val Loss: 0.44529050 || Val it_count: 1107 || Current Learning Rate: 1.0000000000000002e-07 || Time: 08:08:15.94
Epoch :: 81 || Loss: 0.40846154 || it_count: 8344 || Val Loss: 0.44528393 || Val it_count: 1107 || Current Learning Rate: 1.0000000000000002e-07 || Time: 08:14:22.23
Epoch :: 82 || Loss: 0.40846103 || it_count: 8344 || Val Loss: 0.44527848 || Val it_count: 1107 || Current Learning Rate: 1.0000000000000002e-07 || Time: 08:20:27.87
Epoch :: 83 || Loss: 0.40846056 || it_count: 8344 || Val Loss: 0.44527397 || Val it_count: 1107 || Current Learning Rate: 1.0000000000000002e-07 || Time: 08:26:33.09
Epoch :: 84 || Loss: 0.40846012 || it_count: 8344 || Val Loss: 0.44527026 || Val it_count: 1107 || Current Learning Rate: 1.0000000000000002e-07 || Time: 08:32:39.82
Epoch :: 85 || Loss: 0.40845971 || it_count: 8344 || Val Loss: 0.44526722 || Val it_count: 1107 || Current Learning Rate: 1.0000000000000002e-07 || Time: 08:38:46.40
Epoch :: 86 || Loss: 0.40845931 || it_count: 8344 || Val Loss: 0.44526476 || Val it_count: 1107 || Current Learning Rate: 1.0000000000000002e-07 || Time: 08:44:53.23
Epoch :: 87 || Loss: 0.40845893 || it_count: 8344 || Val Loss: 0.44526279 || Val it_count: 1107 || Current Learning Rate: 1.0000000000000002e-07 || Time: 08:51:0.61
Epoch :: 88 || Loss: 0.40845856 || it_count: 8344 || Val Loss: 0.44526124 || Val it_count: 1107 || Current Learning Rate: 1.0000000000000002e-07 || Time: 08:57:7.35
Epoch 00073: reducing learning rate of group 0 to 1.0000e-08.
Early stopping triggered due to learning rate below threshold.
Done Total time: 09:03:13.47
best_loss: 0.44526124256228855

--------------------Testing--------------------

total_samples :: test_dataset = 139200, test_dataloader = 139200
Epoch ::  1 || Loss: 0.29818564 || it_count: 544 || Time: 00:00:19.44
MAE:  0.29315534
MSE:  0.2982341
RMSE:  0.48391685

--------------------Training--------------------
arch_str :: |lstm_1~0|+|lstm_3~0|lstm_1~1|[linear]
model :: 3A
InferCell(
  info :: nodes=3, inC=1, outC=64, [1<-(I0-L0) | 2<-(I0-L1,I1-L2)], genotype_str: lstm_1~0|lstm_3~0|lstm_1~1
  linear_layers: [linear]
  (layers): ModuleList(
    (0): LSTM(
      (lstm): LSTM(1, 64, batch_first=True)
    )
    (1): LSTM(
      (lstm): LSTM(1, 64, num_layers=3, batch_first=True)
    )
    (2): LSTM(
      (lstm): LSTM(64, 64, batch_first=True)
    )
  )
  (linear_layers): ModuleList(
    (0): Linear(in_features=3072, out_features=1, bias=True)
  )
)
tr_params :: epochs = 100, patience = 20, batch_size = 256, window_size = 48, data_size = 100
Model MACs: 6.565M, Model Params: 137.217K
learning rate scheduling :: (optimizer, mode='min', factor=0.1, patience=5, verbose=True)
total_samples :: train_dataset = 2136000, train_dataloader = 2136000
total_samples :: valid_dataset = 283200, valid_dataloader = 283200
Epoch ::  1 || Loss: 0.42132584 || it_count: 8344 || Val Loss: 0.44983474 || Val it_count: 1107 || Current Learning Rate: 0.001 || Time: 00:12:11.23
Epoch ::  2 || Loss: 0.41832819 || it_count: 8344 || Val Loss: 0.44927831 || Val it_count: 1107 || Current Learning Rate: 0.001 || Time: 00:24:28.00
Epoch ::  3 || Loss: 0.41771180 || it_count: 8344 || Val Loss: 0.44991253 || Val it_count: 1107 || Current Learning Rate: 0.001 || Time: 00:36:47.11
Epoch ::  4 || Loss: 0.41759796 || it_count: 8344 || Val Loss: 0.44913809 || Val it_count: 1107 || Current Learning Rate: 0.001 || Time: 00:49:6.15
Epoch ::  5 || Loss: 0.41715602 || it_count: 8344 || Val Loss: 0.44879234 || Val it_count: 1107 || Current Learning Rate: 0.001 || Time: 01:01:26.13
Epoch ::  6 || Loss: 0.41667959 || it_count: 8344 || Val Loss: 0.44815259 || Val it_count: 1107 || Current Learning Rate: 0.001 || Time: 01:13:45.12
Epoch ::  7 || Loss: 0.41716621 || it_count: 8344 || Val Loss: 0.44706558 || Val it_count: 1107 || Current Learning Rate: 0.001 || Time: 01:26:4.94
Epoch ::  8 || Loss: 0.41691614 || it_count: 8344 || Val Loss: 0.44649171 || Val it_count: 1107 || Current Learning Rate: 0.001 || Time: 01:38:24.33
Epoch ::  9 || Loss: 0.41690769 || it_count: 8344 || Val Loss: 0.44567970 || Val it_count: 1107 || Current Learning Rate: 0.001 || Time: 01:50:45.08
Epoch :: 10 || Loss: 0.41644867 || it_count: 8344 || Val Loss: 0.44516869 || Val it_count: 1107 || Current Learning Rate: 0.001 || Time: 02:03:4.51
Epoch :: 11 || Loss: 0.41602841 || it_count: 8344 || Val Loss: 0.44512699 || Val it_count: 1107 || Current Learning Rate: 0.001 || Time: 02:15:25.41
Epoch :: 12 || Loss: 0.41588104 || it_count: 8344 || Val Loss: 0.44458266 || Val it_count: 1107 || Current Learning Rate: 0.001 || Time: 02:27:45.42
Epoch :: 13 || Loss: 0.41581037 || it_count: 8344 || Val Loss: 0.44487364 || Val it_count: 1107 || Current Learning Rate: 0.001 || Time: 02:40:7.87
Epoch :: 14 || Loss: 0.41551762 || it_count: 8344 || Val Loss: 0.44410089 || Val it_count: 1107 || Current Learning Rate: 0.001 || Time: 02:52:27.21
Epoch :: 15 || Loss: 0.41508734 || it_count: 8344 || Val Loss: 0.44251537 || Val it_count: 1107 || Current Learning Rate: 0.001 || Time: 03:04:49.04
Epoch :: 16 || Loss: 0.41468200 || it_count: 8344 || Val Loss: 0.44245125 || Val it_count: 1107 || Current Learning Rate: 0.001 || Time: 03:17:10.11
Epoch :: 17 || Loss: 0.41442456 || it_count: 8344 || Val Loss: 0.44342917 || Val it_count: 1107 || Current Learning Rate: 0.001 || Time: 03:29:32.77
Epoch :: 18 || Loss: 0.41410905 || it_count: 8344 || Val Loss: 0.44446050 || Val it_count: 1107 || Current Learning Rate: 0.001 || Time: 03:41:53.20
Epoch :: 19 || Loss: 0.41383290 || it_count: 8344 || Val Loss: 0.44474040 || Val it_count: 1107 || Current Learning Rate: 0.001 || Time: 03:54:15.08
Epoch :: 20 || Loss: 0.41383617 || it_count: 8344 || Val Loss: 0.44425200 || Val it_count: 1107 || Current Learning Rate: 0.001 || Time: 04:06:36.36
Epoch :: 21 || Loss: 0.41387121 || it_count: 8344 || Val Loss: 0.44538578 || Val it_count: 1107 || Current Learning Rate: 0.001 || Time: 04:18:59.13
Epoch :: 22 || Loss: 0.41421126 || it_count: 8344 || Val Loss: 0.44861819 || Val it_count: 1107 || Current Learning Rate: 0.001 || Time: 04:31:19.12
Epoch 00007: reducing learning rate of group 0 to 1.0000e-04.
Epoch :: 23 || Loss: 0.41393649 || it_count: 8344 || Val Loss: 0.44822429 || Val it_count: 1107 || Current Learning Rate: 0.0001 || Time: 04:43:41.23
Epoch :: 24 || Loss: 0.41998074 || it_count: 8344 || Val Loss: 0.42531387 || Val it_count: 1107 || Current Learning Rate: 0.0001 || Time: 04:56:1.58
Epoch :: 25 || Loss: 0.41425457 || it_count: 8344 || Val Loss: 0.42352681 || Val it_count: 1107 || Current Learning Rate: 0.0001 || Time: 05:08:23.46
Epoch :: 26 || Loss: 0.41309258 || it_count: 8344 || Val Loss: 0.42279661 || Val it_count: 1107 || Current Learning Rate: 0.0001 || Time: 05:20:44.08
Epoch :: 27 || Loss: 0.41249216 || it_count: 8344 || Val Loss: 0.42239548 || Val it_count: 1107 || Current Learning Rate: 0.0001 || Time: 05:33:4.91
Epoch :: 28 || Loss: 0.41205155 || it_count: 8344 || Val Loss: 0.42213628 || Val it_count: 1107 || Current Learning Rate: 0.0001 || Time: 05:45:25.93
Epoch :: 29 || Loss: 0.41165959 || it_count: 8344 || Val Loss: 0.42194171 || Val it_count: 1107 || Current Learning Rate: 0.0001 || Time: 05:57:48.22
Epoch :: 30 || Loss: 0.41132985 || it_count: 8344 || Val Loss: 0.42171503 || Val it_count: 1107 || Current Learning Rate: 0.0001 || Time: 06:10:7.81
Epoch :: 31 || Loss: 0.41102671 || it_count: 8344 || Val Loss: 0.42145561 || Val it_count: 1107 || Current Learning Rate: 0.0001 || Time: 06:22:29.07
Epoch :: 32 || Loss: 0.41075932 || it_count: 8344 || Val Loss: 0.42123118 || Val it_count: 1107 || Current Learning Rate: 0.0001 || Time: 06:34:49.38
Epoch :: 33 || Loss: 0.41055087 || it_count: 8344 || Val Loss: 0.42105202 || Val it_count: 1107 || Current Learning Rate: 0.0001 || Time: 06:47:9.80
Epoch :: 34 || Loss: 0.41037928 || it_count: 8344 || Val Loss: 0.42091339 || Val it_count: 1107 || Current Learning Rate: 0.0001 || Time: 06:59:29.26
Epoch :: 35 || Loss: 0.41023646 || it_count: 8344 || Val Loss: 0.42081893 || Val it_count: 1107 || Current Learning Rate: 0.0001 || Time: 07:11:50.00
Epoch :: 36 || Loss: 0.41010096 || it_count: 8344 || Val Loss: 0.42076846 || Val it_count: 1107 || Current Learning Rate: 0.0001 || Time: 07:24:9.63
Epoch :: 37 || Loss: 0.40995155 || it_count: 8344 || Val Loss: 0.42073161 || Val it_count: 1107 || Current Learning Rate: 0.0001 || Time: 07:36:30.05
Epoch :: 38 || Loss: 0.40984016 || it_count: 8344 || Val Loss: 0.42073489 || Val it_count: 1107 || Current Learning Rate: 0.0001 || Time: 07:48:48.86
Epoch :: 39 || Loss: 0.40971013 || it_count: 8344 || Val Loss: 0.42076951 || Val it_count: 1107 || Current Learning Rate: 0.0001 || Time: 08:01:10.54
Epoch :: 40 || Loss: 0.40955550 || it_count: 8344 || Val Loss: 0.42083736 || Val it_count: 1107 || Current Learning Rate: 0.0001 || Time: 08:13:31.63
Epoch :: 41 || Loss: 0.40944621 || it_count: 8344 || Val Loss: 0.42093563 || Val it_count: 1107 || Current Learning Rate: 0.0001 || Time: 08:25:53.40
Epoch 00026: reducing learning rate of group 0 to 1.0000e-05.
Epoch :: 42 || Loss: 0.40929696 || it_count: 8344 || Val Loss: 0.42104326 || Val it_count: 1107 || Current Learning Rate: 1e-05 || Time: 08:38:14.18
Epoch :: 43 || Loss: 0.41130840 || it_count: 8344 || Val Loss: 0.41577804 || Val it_count: 1107 || Current Learning Rate: 1e-05 || Time: 08:50:35.21
Epoch :: 44 || Loss: 0.41009493 || it_count: 8344 || Val Loss: 0.41563622 || Val it_count: 1107 || Current Learning Rate: 1e-05 || Time: 09:02:55.97
Epoch :: 45 || Loss: 0.40994775 || it_count: 8344 || Val Loss: 0.41557172 || Val it_count: 1107 || Current Learning Rate: 1e-05 || Time: 09:15:18.56
Epoch :: 46 || Loss: 0.40988069 || it_count: 8344 || Val Loss: 0.41552612 || Val it_count: 1107 || Current Learning Rate: 1e-05 || Time: 09:27:39.16
Epoch :: 47 || Loss: 0.40983240 || it_count: 8344 || Val Loss: 0.41549009 || Val it_count: 1107 || Current Learning Rate: 1e-05 || Time: 09:40:1.75
Epoch :: 48 || Loss: 0.40979296 || it_count: 8344 || Val Loss: 0.41545848 || Val it_count: 1107 || Current Learning Rate: 1e-05 || Time: 09:52:23.07
Epoch :: 49 || Loss: 0.40975891 || it_count: 8344 || Val Loss: 0.41542887 || Val it_count: 1107 || Current Learning Rate: 1e-05 || Time: 10:04:45.85
Epoch :: 50 || Loss: 0.40972832 || it_count: 8344 || Val Loss: 0.41540040 || Val it_count: 1107 || Current Learning Rate: 1e-05 || Time: 10:17:6.83
Epoch :: 51 || Loss: 0.40969999 || it_count: 8344 || Val Loss: 0.41537282 || Val it_count: 1107 || Current Learning Rate: 1e-05 || Time: 10:29:27.98
Epoch :: 52 || Loss: 0.40967327 || it_count: 8344 || Val Loss: 0.41534581 || Val it_count: 1107 || Current Learning Rate: 1e-05 || Time: 10:41:49.18
Epoch :: 53 || Loss: 0.40964780 || it_count: 8344 || Val Loss: 0.41531877 || Val it_count: 1107 || Current Learning Rate: 1e-05 || Time: 10:54:11.03
Epoch :: 54 || Loss: 0.40962324 || it_count: 8344 || Val Loss: 0.41529351 || Val it_count: 1107 || Current Learning Rate: 1e-05 || Time: 11:06:32.33
Epoch :: 55 || Loss: 0.40959937 || it_count: 8344 || Val Loss: 0.41527431 || Val it_count: 1107 || Current Learning Rate: 1e-05 || Time: 11:18:54.28
Epoch :: 56 || Loss: 0.40957622 || it_count: 8344 || Val Loss: 0.41525984 || Val it_count: 1107 || Current Learning Rate: 1e-05 || Time: 11:31:15.61
Epoch :: 57 || Loss: 0.40955264 || it_count: 8344 || Val Loss: 0.41524767 || Val it_count: 1107 || Current Learning Rate: 1e-05 || Time: 11:43:38.34
Epoch :: 58 || Loss: 0.40952992 || it_count: 8344 || Val Loss: 0.41523430 || Val it_count: 1107 || Current Learning Rate: 1e-05 || Time: 11:55:58.82
Epoch :: 59 || Loss: 0.40950844 || it_count: 8344 || Val Loss: 0.41522008 || Val it_count: 1107 || Current Learning Rate: 1e-05 || Time: 12:08:20.53
Epoch :: 60 || Loss: 0.40948776 || it_count: 8344 || Val Loss: 0.41520639 || Val it_count: 1107 || Current Learning Rate: 1e-05 || Time: 12:20:41.68
Epoch :: 61 || Loss: 0.40946765 || it_count: 8344 || Val Loss: 0.41519334 || Val it_count: 1107 || Current Learning Rate: 1e-05 || Time: 12:33:3.37
Epoch :: 62 || Loss: 0.40944802 || it_count: 8344 || Val Loss: 0.41518107 || Val it_count: 1107 || Current Learning Rate: 1e-05 || Time: 12:45:23.94
Epoch :: 63 || Loss: 0.40942880 || it_count: 8344 || Val Loss: 0.41516970 || Val it_count: 1107 || Current Learning Rate: 1e-05 || Time: 12:57:46.26
Epoch :: 64 || Loss: 0.40940997 || it_count: 8344 || Val Loss: 0.41515927 || Val it_count: 1107 || Current Learning Rate: 1e-05 || Time: 13:10:6.74
Epoch :: 65 || Loss: 0.40939151 || it_count: 8344 || Val Loss: 0.41514949 || Val it_count: 1107 || Current Learning Rate: 1e-05 || Time: 13:22:29.26
Epoch :: 66 || Loss: 0.40937339 || it_count: 8344 || Val Loss: 0.41513977 || Val it_count: 1107 || Current Learning Rate: 1e-05 || Time: 13:34:50.02
Epoch :: 67 || Loss: 0.40935563 || it_count: 8344 || Val Loss: 0.41512985 || Val it_count: 1107 || Current Learning Rate: 1e-05 || Time: 13:47:11.30
Epoch :: 68 || Loss: 0.40933818 || it_count: 8344 || Val Loss: 0.41512004 || Val it_count: 1107 || Current Learning Rate: 1e-05 || Time: 13:59:32.24
Epoch :: 69 || Loss: 0.40932104 || it_count: 8344 || Val Loss: 0.41511060 || Val it_count: 1107 || Current Learning Rate: 1e-05 || Time: 14:11:54.06
Epoch :: 70 || Loss: 0.40930417 || it_count: 8344 || Val Loss: 0.41510165 || Val it_count: 1107 || Current Learning Rate: 1e-05 || Time: 14:24:14.30
Epoch :: 71 || Loss: 0.40928755 || it_count: 8344 || Val Loss: 0.41509319 || Val it_count: 1107 || Current Learning Rate: 1e-05 || Time: 14:36:36.22
Epoch :: 72 || Loss: 0.40927117 || it_count: 8344 || Val Loss: 0.41508519 || Val it_count: 1107 || Current Learning Rate: 1e-05 || Time: 14:48:57.82
Epoch :: 73 || Loss: 0.40925500 || it_count: 8344 || Val Loss: 0.41507760 || Val it_count: 1107 || Current Learning Rate: 1e-05 || Time: 15:01:19.39
Epoch :: 74 || Loss: 0.40923903 || it_count: 8344 || Val Loss: 0.41507035 || Val it_count: 1107 || Current Learning Rate: 1e-05 || Time: 15:13:39.91
Epoch :: 75 || Loss: 0.40922325 || it_count: 8344 || Val Loss: 0.41506339 || Val it_count: 1107 || Current Learning Rate: 1e-05 || Time: 15:26:1.64
Epoch :: 76 || Loss: 0.40920766 || it_count: 8344 || Val Loss: 0.41505669 || Val it_count: 1107 || Current Learning Rate: 1e-05 || Time: 15:38:22.56
Epoch :: 77 || Loss: 0.40919226 || it_count: 8344 || Val Loss: 0.41505021 || Val it_count: 1107 || Current Learning Rate: 1e-05 || Time: 15:50:44.87
Epoch :: 78 || Loss: 0.40917702 || it_count: 8344 || Val Loss: 0.41504391 || Val it_count: 1107 || Current Learning Rate: 1e-05 || Time: 16:03:5.06
Epoch :: 79 || Loss: 0.40916196 || it_count: 8344 || Val Loss: 0.41503778 || Val it_count: 1107 || Current Learning Rate: 1e-05 || Time: 16:15:25.99
Epoch :: 80 || Loss: 0.40914706 || it_count: 8344 || Val Loss: 0.41503180 || Val it_count: 1107 || Current Learning Rate: 1e-05 || Time: 16:27:47.42
Epoch :: 81 || Loss: 0.40913232 || it_count: 8344 || Val Loss: 0.41502597 || Val it_count: 1107 || Current Learning Rate: 1e-05 || Time: 16:40:9.85
Epoch 00066: reducing learning rate of group 0 to 1.0000e-06.
Epoch :: 82 || Loss: 0.40911773 || it_count: 8344 || Val Loss: 0.41502029 || Val it_count: 1107 || Current Learning Rate: 1.0000000000000002e-06 || Time: 16:52:29.81
Epoch :: 83 || Loss: 0.40928840 || it_count: 8344 || Val Loss: 0.41470848 || Val it_count: 1107 || Current Learning Rate: 1.0000000000000002e-06 || Time: 17:04:51.80
Epoch :: 84 || Loss: 0.40919044 || it_count: 8344 || Val Loss: 0.41463440 || Val it_count: 1107 || Current Learning Rate: 1.0000000000000002e-06 || Time: 17:17:12.46
Epoch :: 85 || Loss: 0.40915544 || it_count: 8344 || Val Loss: 0.41459818 || Val it_count: 1107 || Current Learning Rate: 1.0000000000000002e-06 || Time: 17:29:34.74
Epoch :: 86 || Loss: 0.40913850 || it_count: 8344 || Val Loss: 0.41457923 || Val it_count: 1107 || Current Learning Rate: 1.0000000000000002e-06 || Time: 17:41:54.56
Epoch :: 87 || Loss: 0.40912871 || it_count: 8344 || Val Loss: 0.41456870 || Val it_count: 1107 || Current Learning Rate: 1.0000000000000002e-06 || Time: 17:54:16.06
Epoch :: 88 || Loss: 0.40912227 || it_count: 8344 || Val Loss: 0.41456254 || Val it_count: 1107 || Current Learning Rate: 1.0000000000000002e-06 || Time: 18:06:37.02
Epoch :: 89 || Loss: 0.40911759 || it_count: 8344 || Val Loss: 0.41455878 || Val it_count: 1107 || Current Learning Rate: 1.0000000000000002e-06 || Time: 18:19:0.73
Epoch :: 90 || Loss: 0.40911390 || it_count: 8344 || Val Loss: 0.41455641 || Val it_count: 1107 || Current Learning Rate: 1.0000000000000002e-06 || Time: 18:31:21.49
Epoch :: 91 || Loss: 0.40911082 || it_count: 8344 || Val Loss: 0.41455490 || Val it_count: 1107 || Current Learning Rate: 1.0000000000000002e-06 || Time: 18:43:42.51
Epoch 00076: reducing learning rate of group 0 to 1.0000e-07.
Early stopping triggered due to learning rate below threshold.
Done Total time: 18:56:2.83
best_loss: 0.4145549006687793

--------------------Testing--------------------

total_samples :: test_dataset = 139200, test_dataloader = 139200
Epoch ::  1 || Loss: 0.23575839 || it_count: 544 || Time: 00:00:25.81
MAE:  0.25258315
MSE:  0.23577693
RMSE:  0.44150648

--------------------Training--------------------
arch_str :: |none~0|+|none~0|lstm_3~1|[relu->dropout->linear]
model :: 3D
InferCell(
  info :: nodes=3, inC=1, outC=64, [1<-(I0-L0) | 2<-(I0-L1,I1-L2)], genotype_str: none~0|none~0|lstm_3~1
  linear_layers: [relu->dropout->linear]
  (layers): ModuleList(
    (0-1): 2 x Zero(C_in=1, C_out=64, stride=1)
    (2): LSTM(
      (lstm): LSTM(64, 64, num_layers=3, batch_first=True)
    )
  )
  (linear_layers): ModuleList(
    (0): ReLU()
    (1): Dropout(p=0.1, inplace=False)
    (2): Linear(in_features=3072, out_features=1, bias=True)
  )
)
tr_params :: epochs = 100, patience = 20, batch_size = 256, window_size = 48, data_size = 100
Model MACs: 4.869M, Model Params: 102.913K
learning rate scheduling :: (optimizer, mode='min', factor=0.1, patience=5, verbose=True)
total_samples :: train_dataset = 2136000, train_dataloader = 2136000
total_samples :: valid_dataset = 283200, valid_dataloader = 283200
Epoch ::  1 || Loss: 0.58165864 || it_count: 8344 || Val Loss: 0.65314595 || Val it_count: 1107 || Current Learning Rate: 0.001 || Time: 00:03:40.72
Epoch ::  2 || Loss: 0.58981519 || it_count: 8344 || Val Loss: 0.65348587 || Val it_count: 1107 || Current Learning Rate: 0.001 || Time: 00:07:19.88
Epoch ::  3 || Loss: 0.59475376 || it_count: 8344 || Val Loss: 0.65614533 || Val it_count: 1107 || Current Learning Rate: 0.001 || Time: 00:11:0.15
Epoch ::  4 || Loss: 0.60664023 || it_count: 8344 || Val Loss: 0.65308809 || Val it_count: 1107 || Current Learning Rate: 0.001 || Time: 00:14:41.18
Epoch ::  5 || Loss: 0.60787370 || it_count: 8344 || Val Loss: 0.65310208 || Val it_count: 1107 || Current Learning Rate: 0.001 || Time: 00:18:20.68
Epoch ::  6 || Loss: 0.61005918 || it_count: 8344 || Val Loss: 0.65377647 || Val it_count: 1107 || Current Learning Rate: 0.001 || Time: 00:22:1.00
Epoch ::  7 || Loss: 0.61027552 || it_count: 8344 || Val Loss: 0.65318977 || Val it_count: 1107 || Current Learning Rate: 0.001 || Time: 00:25:41.46
Epoch ::  8 || Loss: 0.60510313 || it_count: 8344 || Val Loss: 0.65310134 || Val it_count: 1107 || Current Learning Rate: 0.001 || Time: 00:29:22.02
Epoch ::  9 || Loss: 0.60717773 || it_count: 8344 || Val Loss: 0.65310724 || Val it_count: 1107 || Current Learning Rate: 0.001 || Time: 00:33:4.98
Epoch :: 10 || Loss: 0.60742898 || it_count: 8344 || Val Loss: 0.65309660 || Val it_count: 1107 || Current Learning Rate: 0.001 || Time: 00:36:44.70
Epoch :: 11 || Loss: 0.60954080 || it_count: 8344 || Val Loss: 0.65331342 || Val it_count: 1107 || Current Learning Rate: 0.001 || Time: 00:40:26.04
Epoch :: 12 || Loss: 0.60704378 || it_count: 8344 || Val Loss: 0.65314578 || Val it_count: 1107 || Current Learning Rate: 0.001 || Time: 00:44:5.87
Epoch :: 13 || Loss: 0.61028189 || it_count: 8344 || Val Loss: 0.65307613 || Val it_count: 1107 || Current Learning Rate: 0.001 || Time: 00:47:46.76
Epoch :: 14 || Loss: 0.60477661 || it_count: 8344 || Val Loss: 0.65316885 || Val it_count: 1107 || Current Learning Rate: 0.001 || Time: 00:51:27.98
Epoch :: 15 || Loss: 0.61084859 || it_count: 8344 || Val Loss: 0.65333069 || Val it_count: 1107 || Current Learning Rate: 0.001 || Time: 00:55:10.46
Epoch :: 16 || Loss: 0.60701928 || it_count: 8344 || Val Loss: 0.65326046 || Val it_count: 1107 || Current Learning Rate: 0.001 || Time: 00:58:52.28
Epoch :: 17 || Loss: 0.60668226 || it_count: 8344 || Val Loss: 0.65307813 || Val it_count: 1107 || Current Learning Rate: 0.001 || Time: 01:02:33.20
Epoch :: 18 || Loss: 0.61171852 || it_count: 8344 || Val Loss: 0.65335041 || Val it_count: 1107 || Current Learning Rate: 0.001 || Time: 01:06:14.04
Epoch :: 19 || Loss: 0.60994985 || it_count: 8344 || Val Loss: 0.65345627 || Val it_count: 1107 || Current Learning Rate: 0.001 || Time: 01:09:55.75
Epoch :: 20 || Loss: 0.60440885 || it_count: 8344 || Val Loss: 0.65331642 || Val it_count: 1107 || Current Learning Rate: 0.001 || Time: 01:13:35.49
Epoch :: 21 || Loss: 0.60912165 || it_count: 8344 || Val Loss: 0.65402410 || Val it_count: 1107 || Current Learning Rate: 0.001 || Time: 01:17:16.17
Epoch :: 22 || Loss: 0.60831656 || it_count: 8344 || Val Loss: 0.65308624 || Val it_count: 1107 || Current Learning Rate: 0.001 || Time: 01:20:57.68
Epoch :: 23 || Loss: 0.60562543 || it_count: 8344 || Val Loss: 0.65312742 || Val it_count: 1107 || Current Learning Rate: 0.0001 || Time: 01:24:36.66
Epoch :: 24 || Loss: 0.61905536 || it_count: 8344 || Val Loss: 0.65308375 || Val it_count: 1107 || Current Learning Rate: 0.0001 || Time: 01:28:17.68
Epoch :: 25 || Loss: 0.61832647 || it_count: 8344 || Val Loss: 0.65306135 || Val it_count: 1107 || Current Learning Rate: 0.0001 || Time: 01:31:57.95
Epoch :: 26 || Loss: 0.61775845 || it_count: 8344 || Val Loss: 0.65306116 || Val it_count: 1107 || Current Learning Rate: 0.0001 || Time: 01:35:39.48
Epoch :: 27 || Loss: 0.61578452 || it_count: 8344 || Val Loss: 0.65309553 || Val it_count: 1107 || Current Learning Rate: 0.0001 || Time: 01:39:19.18
Epoch :: 28 || Loss: 0.61729446 || it_count: 8344 || Val Loss: 0.65308080 || Val it_count: 1107 || Current Learning Rate: 0.0001 || Time: 01:43:0.01
Epoch :: 29 || Loss: 0.61717776 || it_count: 8344 || Val Loss: 0.65307078 || Val it_count: 1107 || Current Learning Rate: 1e-05 || Time: 01:46:42.09
Epoch :: 30 || Loss: 0.61992419 || it_count: 8344 || Val Loss: 0.65362826 || Val it_count: 1107 || Current Learning Rate: 1e-05 || Time: 01:50:21.78
Epoch :: 31 || Loss: 0.61971591 || it_count: 8344 || Val Loss: 0.65380981 || Val it_count: 1107 || Current Learning Rate: 1e-05 || Time: 01:54:2.16
Epoch :: 32 || Loss: 0.61971900 || it_count: 8344 || Val Loss: 0.65379533 || Val it_count: 1107 || Current Learning Rate: 1e-05 || Time: 01:57:42.47
Epoch :: 33 || Loss: 0.61970166 || it_count: 8344 || Val Loss: 0.65373678 || Val it_count: 1107 || Current Learning Rate: 1e-05 || Time: 02:01:23.25
Epoch :: 34 || Loss: 0.61969840 || it_count: 8344 || Val Loss: 0.65364451 || Val it_count: 1107 || Current Learning Rate: 1e-05 || Time: 02:05:5.00
Epoch :: 35 || Loss: 0.61960732 || it_count: 8344 || Val Loss: 0.65353340 || Val it_count: 1107 || Current Learning Rate: 1.0000000000000002e-06 || Time: 02:08:47.79
Epoch :: 36 || Loss: 0.61974695 || it_count: 8344 || Val Loss: 0.65364780 || Val it_count: 1107 || Current Learning Rate: 1.0000000000000002e-06 || Time: 02:12:26.68
Epoch :: 37 || Loss: 0.61971189 || it_count: 8344 || Val Loss: 0.65372492 || Val it_count: 1107 || Current Learning Rate: 1.0000000000000002e-06 || Time: 02:16:6.74
Epoch :: 38 || Loss: 0.61970907 || it_count: 8344 || Val Loss: 0.65377771 || Val it_count: 1107 || Current Learning Rate: 1.0000000000000002e-06 || Time: 02:19:48.07
Epoch :: 39 || Loss: 0.61969004 || it_count: 8344 || Val Loss: 0.65381324 || Val it_count: 1107 || Current Learning Rate: 1.0000000000000002e-06 || Time: 02:23:30.51
Epoch :: 40 || Loss: 0.61970953 || it_count: 8344 || Val Loss: 0.65383785 || Val it_count: 1107 || Current Learning Rate: 1.0000000000000002e-06 || Time: 02:27:12.06
Early stopping triggered due to learning rate below threshold.
Done Total time: 02:30:52.79
best_loss: 0.653061163550829

--------------------Testing--------------------

total_samples :: test_dataset = 139200, test_dataloader = 139200
Epoch ::  1 || Loss: 1.03385495 || it_count: 544 || Time: 00:00:11.78
MAE:  0.5476347
MSE:  1.0341576
RMSE:  0.8080835

--------------------Training--------------------
arch_str :: |skip_connect~0|+|skip_connect~0|lstm_2~1|[relu->dropout->linear]
model :: 3D
InferCell(
  info :: nodes=3, inC=1, outC=64, [1<-(I0-L0) | 2<-(I0-L1,I1-L2)], genotype_str: skip_connect~0|skip_connect~0|lstm_2~1
  linear_layers: [relu->dropout->linear]
  (layers): ModuleList(
    (0): FactorizedReduce(
      C_in=1, C_out=64, stride=1
      (relu): ReLU()
      (conv): Conv1d(1, 64, kernel_size=(1,), stride=(1,), bias=False)
      (bn): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (1): FactorizedReduce(
      C_in=1, C_out=64, stride=1
      (relu): ReLU()
      (conv): Conv1d(1, 64, kernel_size=(1,), stride=(1,), bias=False)
      (bn): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (2): LSTM(
      (lstm): LSTM(64, 64, num_layers=2, batch_first=True)
    )
  )
  (linear_layers): ModuleList(
    (0): ReLU()
    (1): Dropout(p=0.1, inplace=False)
    (2): Linear(in_features=3072, out_features=1, bias=True)
  )
)
tr_params :: epochs = 100, patience = 20, batch_size = 256, window_size = 48, data_size = 100
Model MACs: 3.278M, Model Params: 70.017K
learning rate scheduling :: (optimizer, mode='min', factor=0.1, patience=5, verbose=True)
total_samples :: train_dataset = 2136000, train_dataloader = 2136000
total_samples :: valid_dataset = 283200, valid_dataloader = 283200
Epoch ::  1 || Loss: 0.46745530 || it_count: 8344 || Val Loss: 0.50777032 || Val it_count: 1107 || Current Learning Rate: 0.001 || Time: 00:06:53.27
Epoch ::  2 || Loss: 0.47186038 || it_count: 8344 || Val Loss: 0.49862688 || Val it_count: 1107 || Current Learning Rate: 0.001 || Time: 00:13:44.96
Epoch ::  3 || Loss: 0.47096188 || it_count: 8344 || Val Loss: 0.53176674 || Val it_count: 1107 || Current Learning Rate: 0.001 || Time: 00:20:36.70
Epoch ::  4 || Loss: 0.47630663 || it_count: 8344 || Val Loss: 0.50045510 || Val it_count: 1107 || Current Learning Rate: 0.001 || Time: 00:27:27.98
Epoch ::  5 || Loss: 0.47333800 || it_count: 8344 || Val Loss: 0.50624177 || Val it_count: 1107 || Current Learning Rate: 0.001 || Time: 00:34:19.64
Epoch ::  6 || Loss: 0.47574706 || it_count: 8344 || Val Loss: 0.65305432 || Val it_count: 1107 || Current Learning Rate: 0.001 || Time: 00:41:11.30
Epoch ::  7 || Loss: 0.47884082 || it_count: 8344 || Val Loss: 0.50562766 || Val it_count: 1107 || Current Learning Rate: 0.001 || Time: 00:48:3.51
Epoch ::  8 || Loss: 0.47257852 || it_count: 8344 || Val Loss: 0.49079400 || Val it_count: 1107 || Current Learning Rate: 0.001 || Time: 00:54:56.06
Epoch ::  9 || Loss: 0.48627652 || it_count: 8344 || Val Loss: 0.48585541 || Val it_count: 1107 || Current Learning Rate: 0.001 || Time: 01:01:47.53
Epoch :: 10 || Loss: 0.47582242 || it_count: 8344 || Val Loss: 0.49282659 || Val it_count: 1107 || Current Learning Rate: 0.001 || Time: 01:08:39.31
Epoch :: 11 || Loss: 0.47105293 || it_count: 8344 || Val Loss: 0.48949317 || Val it_count: 1107 || Current Learning Rate: 0.001 || Time: 01:15:30.15
Epoch :: 12 || Loss: 0.48487842 || it_count: 8344 || Val Loss: 0.52632138 || Val it_count: 1107 || Current Learning Rate: 0.001 || Time: 01:22:21.88
Epoch :: 13 || Loss: 0.48271800 || it_count: 8344 || Val Loss: 0.51623061 || Val it_count: 1107 || Current Learning Rate: 0.001 || Time: 01:29:12.94
Epoch :: 14 || Loss: 0.47874723 || it_count: 8344 || Val Loss: 0.53439258 || Val it_count: 1107 || Current Learning Rate: 0.001 || Time: 01:36:4.09
Epoch :: 15 || Loss: 0.47567006 || it_count: 8344 || Val Loss: 0.50919450 || Val it_count: 1107 || Current Learning Rate: 0.001 || Time: 01:42:55.01
Epoch :: 16 || Loss: 0.47904120 || it_count: 8344 || Val Loss: 0.51982964 || Val it_count: 1107 || Current Learning Rate: 0.001 || Time: 01:49:47.26
Epoch :: 17 || Loss: 0.48750399 || it_count: 8344 || Val Loss: 0.52289864 || Val it_count: 1107 || Current Learning Rate: 0.001 || Time: 01:56:39.05
Epoch :: 18 || Loss: 0.49000531 || it_count: 8344 || Val Loss: 0.50696646 || Val it_count: 1107 || Current Learning Rate: 0.001 || Time: 02:03:31.00
Epoch :: 19 || Loss: 0.48618218 || it_count: 8344 || Val Loss: 0.60210480 || Val it_count: 1107 || Current Learning Rate: 0.001 || Time: 02:10:22.17
Epoch :: 20 || Loss: 0.49203242 || it_count: 8344 || Val Loss: 0.51523306 || Val it_count: 1107 || Current Learning Rate: 0.001 || Time: 02:17:13.55
Epoch :: 21 || Loss: 0.49284170 || it_count: 8344 || Val Loss: 0.52850260 || Val it_count: 1107 || Current Learning Rate: 0.001 || Time: 02:24:5.16
Epoch :: 22 || Loss: 0.49337728 || it_count: 8344 || Val Loss: 0.49721402 || Val it_count: 1107 || Current Learning Rate: 0.001 || Time: 02:30:55.61
Epoch :: 23 || Loss: 0.48097246 || it_count: 8344 || Val Loss: 0.51717573 || Val it_count: 1107 || Current Learning Rate: 0.001 || Time: 02:37:47.10
Epoch :: 24 || Loss: 0.48877049 || it_count: 8344 || Val Loss: 0.48932928 || Val it_count: 1107 || Current Learning Rate: 0.001 || Time: 02:44:39.48
Epoch :: 25 || Loss: 0.48556819 || it_count: 8344 || Val Loss: 0.59001974 || Val it_count: 1107 || Current Learning Rate: 0.001 || Time: 02:51:30.58
Epoch :: 26 || Loss: 0.48555898 || it_count: 8344 || Val Loss: 0.53488583 || Val it_count: 1107 || Current Learning Rate: 0.001 || Time: 02:58:22.81
Epoch :: 27 || Loss: 0.48496362 || it_count: 8344 || Val Loss: 0.51331449 || Val it_count: 1107 || Current Learning Rate: 0.001 || Time: 03:05:15.03
Epoch :: 28 || Loss: 0.49045166 || it_count: 8344 || Val Loss: 0.51835206 || Val it_count: 1107 || Current Learning Rate: 0.001 || Time: 03:12:6.30
Epoch :: 29 || Loss: 0.49002884 || it_count: 8344 || Val Loss: 0.56985187 || Val it_count: 1107 || Current Learning Rate: 0.001 || Time: 03:18:57.33
Early stopping triggered due to patience exceeded.
Done Total time: 03:18:57.33
best_loss: 0.485855405728274

--------------------Testing--------------------

total_samples :: test_dataset = 139200, test_dataloader = 139200
Epoch ::  1 || Loss: 0.39755916 || it_count: 544 || Time: 00:00:21.57
MAE:  0.34205145
MSE:  0.39764813
RMSE:  0.5385418

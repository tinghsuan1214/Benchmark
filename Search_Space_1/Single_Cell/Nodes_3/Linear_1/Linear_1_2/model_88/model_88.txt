--------------------Training--------------------
arch_str :: |none~0|+|lstm_3~0|lstm_3~1|[dropout->linear]
model :: 3B
InferCell(
  info :: nodes=3, inC=1, outC=64, [1<-(I0-L0) | 2<-(I0-L1,I1-L2)], genotype_str: none~0|lstm_3~0|lstm_3~1
  linear_layers: [dropout->linear]
  (layers): ModuleList(
    (0): Zero(C_in=1, C_out=64, stride=1)
    (1): LSTM(
      (lstm): LSTM(1, 64, num_layers=3, batch_first=True)
    )
    (2): LSTM(
      (lstm): LSTM(64, 64, num_layers=3, batch_first=True)
    )
  )
  (linear_layers): ModuleList(
    (0): Dropout(p=0.1, inplace=False)
    (1): Linear(in_features=3072, out_features=1, bias=True)
  )
)
tr_params :: epochs = 100, patience = 20, batch_size = 256, window_size = 48, data_size = 100
Model MACs: 8.961M, Model Params: 186.625K
learning rate scheduling :: (optimizer, mode='min', factor=0.1, patience=5, verbose=True)
total_samples :: train_dataset = 2136000, train_dataloader = 2136000
total_samples :: valid_dataset = 283200, valid_dataloader = 283200
Epoch ::  1 || Loss: 0.42482278 || it_count: 8344 || Val Loss: 0.44936945 || Val it_count: 1107 || Current Learning Rate: 0.001 || Time: 00:08:53.66
Epoch ::  2 || Loss: 0.41959662 || it_count: 8344 || Val Loss: 0.44802256 || Val it_count: 1107 || Current Learning Rate: 0.001 || Time: 00:17:45.99
Epoch ::  3 || Loss: 0.41946883 || it_count: 8344 || Val Loss: 0.44887938 || Val it_count: 1107 || Current Learning Rate: 0.001 || Time: 00:26:38.82
Epoch ::  4 || Loss: 0.41911381 || it_count: 8344 || Val Loss: 0.44948982 || Val it_count: 1107 || Current Learning Rate: 0.001 || Time: 00:35:33.76
Epoch ::  5 || Loss: 0.41870191 || it_count: 8344 || Val Loss: 0.44995391 || Val it_count: 1107 || Current Learning Rate: 0.001 || Time: 00:44:28.00
Epoch ::  6 || Loss: 0.41838778 || it_count: 8344 || Val Loss: 0.45008299 || Val it_count: 1107 || Current Learning Rate: 0.001 || Time: 00:53:22.38
Epoch ::  7 || Loss: 0.41788460 || it_count: 8344 || Val Loss: 0.45016693 || Val it_count: 1107 || Current Learning Rate: 0.001 || Time: 01:02:17.98
Epoch ::  8 || Loss: 0.41755942 || it_count: 8344 || Val Loss: 0.45112855 || Val it_count: 1107 || Current Learning Rate: 0.001 || Time: 01:11:12.69
Epoch ::  9 || Loss: 0.41727586 || it_count: 8344 || Val Loss: 0.45095257 || Val it_count: 1107 || Current Learning Rate: 0.001 || Time: 01:20:7.72
Epoch :: 10 || Loss: 0.41688447 || it_count: 8344 || Val Loss: 0.45090664 || Val it_count: 1107 || Current Learning Rate: 0.001 || Time: 01:29:3.49
Epoch :: 11 || Loss: 0.41655395 || it_count: 8344 || Val Loss: 0.45166120 || Val it_count: 1107 || Current Learning Rate: 0.001 || Time: 01:37:59.13
Epoch :: 12 || Loss: 0.41616662 || it_count: 8344 || Val Loss: 0.45045574 || Val it_count: 1107 || Current Learning Rate: 0.001 || Time: 01:46:56.11
Epoch :: 13 || Loss: 0.41583307 || it_count: 8344 || Val Loss: 0.44936029 || Val it_count: 1107 || Current Learning Rate: 0.001 || Time: 01:55:52.38
Epoch :: 14 || Loss: 0.41550497 || it_count: 8344 || Val Loss: 0.44823424 || Val it_count: 1107 || Current Learning Rate: 0.001 || Time: 02:04:38.68
Epoch :: 15 || Loss: 0.41457075 || it_count: 8344 || Val Loss: 0.44657590 || Val it_count: 1107 || Current Learning Rate: 0.001 || Time: 02:13:21.78
Epoch :: 16 || Loss: 0.41393681 || it_count: 8344 || Val Loss: 0.44625052 || Val it_count: 1107 || Current Learning Rate: 0.001 || Time: 02:22:4.96
Epoch :: 17 || Loss: 0.41366096 || it_count: 8344 || Val Loss: 0.44710105 || Val it_count: 1107 || Current Learning Rate: 0.001 || Time: 02:30:48.17
Epoch :: 18 || Loss: 0.41354053 || it_count: 8344 || Val Loss: 0.44723439 || Val it_count: 1107 || Current Learning Rate: 0.001 || Time: 02:39:32.11
Epoch :: 19 || Loss: 0.41328056 || it_count: 8344 || Val Loss: 0.44838517 || Val it_count: 1107 || Current Learning Rate: 0.001 || Time: 02:48:15.70
Epoch :: 20 || Loss: 0.41329987 || it_count: 8344 || Val Loss: 0.45318982 || Val it_count: 1107 || Current Learning Rate: 0.001 || Time: 02:56:59.16
Epoch :: 21 || Loss: 0.41249626 || it_count: 8344 || Val Loss: 0.45517175 || Val it_count: 1107 || Current Learning Rate: 0.001 || Time: 03:05:43.48
Epoch :: 22 || Loss: 0.41232382 || it_count: 8344 || Val Loss: 0.45183879 || Val it_count: 1107 || Current Learning Rate: 0.001 || Time: 03:14:27.63
Epoch 00007: reducing learning rate of group 0 to 1.0000e-04.
Epoch :: 23 || Loss: 0.41163500 || it_count: 8344 || Val Loss: 0.44902825 || Val it_count: 1107 || Current Learning Rate: 0.0001 || Time: 03:23:10.59
Epoch :: 24 || Loss: 0.41592219 || it_count: 8344 || Val Loss: 0.42393853 || Val it_count: 1107 || Current Learning Rate: 0.0001 || Time: 03:31:53.76
Epoch :: 25 || Loss: 0.41232473 || it_count: 8344 || Val Loss: 0.42308223 || Val it_count: 1107 || Current Learning Rate: 0.0001 || Time: 03:40:36.95
Epoch :: 26 || Loss: 0.41144051 || it_count: 8344 || Val Loss: 0.42296810 || Val it_count: 1107 || Current Learning Rate: 0.0001 || Time: 03:49:20.28
Epoch :: 27 || Loss: 0.41098409 || it_count: 8344 || Val Loss: 0.42287472 || Val it_count: 1107 || Current Learning Rate: 0.0001 || Time: 03:58:4.44
Epoch :: 28 || Loss: 0.41062216 || it_count: 8344 || Val Loss: 0.42271027 || Val it_count: 1107 || Current Learning Rate: 0.0001 || Time: 04:06:48.45
Epoch :: 29 || Loss: 0.41030262 || it_count: 8344 || Val Loss: 0.42243218 || Val it_count: 1107 || Current Learning Rate: 0.0001 || Time: 04:15:31.46
Epoch :: 30 || Loss: 0.41004318 || it_count: 8344 || Val Loss: 0.42218124 || Val it_count: 1107 || Current Learning Rate: 0.0001 || Time: 04:24:15.39
Epoch :: 31 || Loss: 0.40982527 || it_count: 8344 || Val Loss: 0.42208807 || Val it_count: 1107 || Current Learning Rate: 0.0001 || Time: 04:32:58.59
Epoch :: 32 || Loss: 0.40956786 || it_count: 8344 || Val Loss: 0.42197291 || Val it_count: 1107 || Current Learning Rate: 0.0001 || Time: 04:41:42.74
Epoch :: 33 || Loss: 0.40934092 || it_count: 8344 || Val Loss: 0.42180714 || Val it_count: 1107 || Current Learning Rate: 0.0001 || Time: 04:50:26.72
Epoch :: 34 || Loss: 0.40910882 || it_count: 8344 || Val Loss: 0.42162750 || Val it_count: 1107 || Current Learning Rate: 0.0001 || Time: 04:59:10.27
Epoch :: 35 || Loss: 0.40890047 || it_count: 8344 || Val Loss: 0.42156806 || Val it_count: 1107 || Current Learning Rate: 0.0001 || Time: 05:07:54.53
Epoch :: 36 || Loss: 0.40864848 || it_count: 8344 || Val Loss: 0.42147943 || Val it_count: 1107 || Current Learning Rate: 0.0001 || Time: 05:16:37.85
Epoch :: 37 || Loss: 0.40852533 || it_count: 8344 || Val Loss: 0.42127536 || Val it_count: 1107 || Current Learning Rate: 0.0001 || Time: 05:25:22.21
Epoch :: 38 || Loss: 0.40829586 || it_count: 8344 || Val Loss: 0.42125814 || Val it_count: 1107 || Current Learning Rate: 0.0001 || Time: 05:34:6.34
Epoch :: 39 || Loss: 0.40810292 || it_count: 8344 || Val Loss: 0.42136945 || Val it_count: 1107 || Current Learning Rate: 0.0001 || Time: 05:42:49.82
Epoch :: 40 || Loss: 0.40794560 || it_count: 8344 || Val Loss: 0.42107583 || Val it_count: 1107 || Current Learning Rate: 0.0001 || Time: 05:51:33.61
Epoch :: 41 || Loss: 0.40773220 || it_count: 8344 || Val Loss: 0.42111824 || Val it_count: 1107 || Current Learning Rate: 0.0001 || Time: 06:00:17.95
Epoch :: 42 || Loss: 0.40755551 || it_count: 8344 || Val Loss: 0.42111967 || Val it_count: 1107 || Current Learning Rate: 0.0001 || Time: 06:09:2.10
Epoch :: 43 || Loss: 0.40739360 || it_count: 8344 || Val Loss: 0.42109939 || Val it_count: 1107 || Current Learning Rate: 0.0001 || Time: 06:17:46.05
Epoch :: 44 || Loss: 0.40722433 || it_count: 8344 || Val Loss: 0.42105517 || Val it_count: 1107 || Current Learning Rate: 0.0001 || Time: 06:26:29.49
Epoch :: 45 || Loss: 0.40705652 || it_count: 8344 || Val Loss: 0.42082641 || Val it_count: 1107 || Current Learning Rate: 0.0001 || Time: 06:35:13.01
Epoch :: 46 || Loss: 0.40694020 || it_count: 8344 || Val Loss: 0.42086431 || Val it_count: 1107 || Current Learning Rate: 0.0001 || Time: 06:43:56.99
Epoch :: 47 || Loss: 0.40681213 || it_count: 8344 || Val Loss: 0.42087081 || Val it_count: 1107 || Current Learning Rate: 0.0001 || Time: 06:52:41.60
Epoch :: 48 || Loss: 0.40663748 || it_count: 8344 || Val Loss: 0.42075644 || Val it_count: 1107 || Current Learning Rate: 0.0001 || Time: 07:01:26.23
Epoch :: 49 || Loss: 0.40653642 || it_count: 8344 || Val Loss: 0.42056832 || Val it_count: 1107 || Current Learning Rate: 0.0001 || Time: 07:10:9.51
Epoch :: 50 || Loss: 0.40639143 || it_count: 8344 || Val Loss: 0.42058107 || Val it_count: 1107 || Current Learning Rate: 0.0001 || Time: 07:18:53.86
Epoch :: 51 || Loss: 0.40622800 || it_count: 8344 || Val Loss: 0.42039236 || Val it_count: 1107 || Current Learning Rate: 0.0001 || Time: 07:27:38.34
Epoch :: 52 || Loss: 0.40613052 || it_count: 8344 || Val Loss: 0.42069576 || Val it_count: 1107 || Current Learning Rate: 0.0001 || Time: 07:36:22.76
Epoch :: 53 || Loss: 0.40603183 || it_count: 8344 || Val Loss: 0.42070265 || Val it_count: 1107 || Current Learning Rate: 0.0001 || Time: 07:45:5.78
Epoch :: 54 || Loss: 0.40583396 || it_count: 8344 || Val Loss: 0.42097817 || Val it_count: 1107 || Current Learning Rate: 0.0001 || Time: 07:53:49.98
Epoch :: 55 || Loss: 0.40577195 || it_count: 8344 || Val Loss: 0.42090280 || Val it_count: 1107 || Current Learning Rate: 0.0001 || Time: 08:02:34.54
Epoch :: 56 || Loss: 0.40552746 || it_count: 8344 || Val Loss: 0.42092408 || Val it_count: 1107 || Current Learning Rate: 0.0001 || Time: 08:11:18.30
Epoch 00041: reducing learning rate of group 0 to 1.0000e-05.
Epoch :: 57 || Loss: 0.40547475 || it_count: 8344 || Val Loss: 0.42126860 || Val it_count: 1107 || Current Learning Rate: 1e-05 || Time: 08:20:3.69
Epoch :: 58 || Loss: 0.40855129 || it_count: 8344 || Val Loss: 0.41210707 || Val it_count: 1107 || Current Learning Rate: 1e-05 || Time: 08:28:47.81
Epoch :: 59 || Loss: 0.40718181 || it_count: 8344 || Val Loss: 0.41181767 || Val it_count: 1107 || Current Learning Rate: 1e-05 || Time: 08:37:31.07
Epoch :: 60 || Loss: 0.40695833 || it_count: 8344 || Val Loss: 0.41175397 || Val it_count: 1107 || Current Learning Rate: 1e-05 || Time: 08:46:15.09
Epoch :: 61 || Loss: 0.40685357 || it_count: 8344 || Val Loss: 0.41170495 || Val it_count: 1107 || Current Learning Rate: 1e-05 || Time: 08:54:58.53
Epoch :: 62 || Loss: 0.40675630 || it_count: 8344 || Val Loss: 0.41167361 || Val it_count: 1107 || Current Learning Rate: 1e-05 || Time: 09:03:42.43
Epoch :: 63 || Loss: 0.40670016 || it_count: 8344 || Val Loss: 0.41163610 || Val it_count: 1107 || Current Learning Rate: 1e-05 || Time: 09:12:27.08
Epoch :: 64 || Loss: 0.40664832 || it_count: 8344 || Val Loss: 0.41162963 || Val it_count: 1107 || Current Learning Rate: 1e-05 || Time: 09:21:10.73
Epoch :: 65 || Loss: 0.40657734 || it_count: 8344 || Val Loss: 0.41161522 || Val it_count: 1107 || Current Learning Rate: 1e-05 || Time: 09:29:55.17
Epoch :: 66 || Loss: 0.40652371 || it_count: 8344 || Val Loss: 0.41158940 || Val it_count: 1107 || Current Learning Rate: 1e-05 || Time: 09:38:39.25
Epoch :: 67 || Loss: 0.40651096 || it_count: 8344 || Val Loss: 0.41158975 || Val it_count: 1107 || Current Learning Rate: 1e-05 || Time: 09:47:23.79
Epoch :: 68 || Loss: 0.40638805 || it_count: 8344 || Val Loss: 0.41157459 || Val it_count: 1107 || Current Learning Rate: 1e-05 || Time: 09:56:7.90
Epoch :: 69 || Loss: 0.40638995 || it_count: 8344 || Val Loss: 0.41158294 || Val it_count: 1107 || Current Learning Rate: 1e-05 || Time: 10:04:52.54
Epoch :: 70 || Loss: 0.40636583 || it_count: 8344 || Val Loss: 0.41159070 || Val it_count: 1107 || Current Learning Rate: 1e-05 || Time: 10:13:36.52
Epoch :: 71 || Loss: 0.40632794 || it_count: 8344 || Val Loss: 0.41159432 || Val it_count: 1107 || Current Learning Rate: 1e-05 || Time: 10:22:21.33
Epoch 00056: reducing learning rate of group 0 to 1.0000e-06.
Epoch :: 72 || Loss: 0.40626033 || it_count: 8344 || Val Loss: 0.41157093 || Val it_count: 1107 || Current Learning Rate: 1.0000000000000002e-06 || Time: 10:31:4.64
Epoch :: 73 || Loss: 0.40664317 || it_count: 8344 || Val Loss: 0.41123128 || Val it_count: 1107 || Current Learning Rate: 1.0000000000000002e-06 || Time: 10:39:48.69
Epoch :: 74 || Loss: 0.40653928 || it_count: 8344 || Val Loss: 0.41115986 || Val it_count: 1107 || Current Learning Rate: 1.0000000000000002e-06 || Time: 10:48:32.53
Epoch :: 75 || Loss: 0.40644181 || it_count: 8344 || Val Loss: 0.41112196 || Val it_count: 1107 || Current Learning Rate: 1.0000000000000002e-06 || Time: 10:57:16.68
Epoch :: 76 || Loss: 0.40643559 || it_count: 8344 || Val Loss: 0.41109888 || Val it_count: 1107 || Current Learning Rate: 1.0000000000000002e-06 || Time: 11:06:0.36
Epoch :: 77 || Loss: 0.40640866 || it_count: 8344 || Val Loss: 0.41108060 || Val it_count: 1107 || Current Learning Rate: 1.0000000000000002e-06 || Time: 11:14:43.52
Epoch :: 78 || Loss: 0.40639029 || it_count: 8344 || Val Loss: 0.41106638 || Val it_count: 1107 || Current Learning Rate: 1.0000000000000002e-06 || Time: 11:23:27.27
Epoch :: 79 || Loss: 0.40639881 || it_count: 8344 || Val Loss: 0.41105455 || Val it_count: 1107 || Current Learning Rate: 1.0000000000000002e-06 || Time: 11:32:10.80
Epoch :: 80 || Loss: 0.40638448 || it_count: 8344 || Val Loss: 0.41104889 || Val it_count: 1107 || Current Learning Rate: 1.0000000000000002e-06 || Time: 11:40:57.47
Epoch :: 81 || Loss: 0.40634775 || it_count: 8344 || Val Loss: 0.41104217 || Val it_count: 1107 || Current Learning Rate: 1.0000000000000002e-06 || Time: 11:50:38.69
Epoch :: 82 || Loss: 0.40636453 || it_count: 8344 || Val Loss: 0.41103718 || Val it_count: 1107 || Current Learning Rate: 1.0000000000000002e-06 || Time: 12:02:16.63
Epoch :: 83 || Loss: 0.40637997 || it_count: 8344 || Val Loss: 0.41103277 || Val it_count: 1107 || Current Learning Rate: 1.0000000000000002e-06 || Time: 12:11:54.71
Epoch :: 84 || Loss: 0.40630862 || it_count: 8344 || Val Loss: 0.41102940 || Val it_count: 1107 || Current Learning Rate: 1.0000000000000002e-06 || Time: 12:20:40.28
Epoch 00069: reducing learning rate of group 0 to 1.0000e-07.
Early stopping triggered due to learning rate below threshold.
Done Total time: 12:30:22.17
best_loss: 0.41102939791920684

--------------------Testing--------------------

total_samples :: test_dataset = 139200, test_dataloader = 139200
Epoch ::  1 || Loss: 0.23487658 || it_count: 544 || Time: 00:00:22.28
MAE:  0.2512923
MSE:  0.23489718
RMSE:  0.44062546

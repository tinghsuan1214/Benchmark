--------------------Training--------------------
arch_str :: |lstm_1~0|+|none~0|skip_connect~1|[relu->linear->dropout->linear]
model :: 3N
InferCell(
  info :: nodes=3, inC=1, outC=64, [1<-(I0-L0) | 2<-(I0-L1,I1-L2)], genotype_str: lstm_1~0|none~0|skip_connect~1
  linear_layers: [relu->linear->dropout->linear]
  (layers): ModuleList(
    (0): LSTM(
      (lstm): LSTM(1, 64, batch_first=True)
    )
    (1): Zero(C_in=1, C_out=64, stride=1)
    (2): Identity()
  )
  (linear_layers): ModuleList(
    (0): ReLU()
    (1): Linear(in_features=3072, out_features=1536, bias=True)
    (2): Dropout(p=0.1, inplace=False)
    (3): Linear(in_features=1536, out_features=1, bias=True)
  )
)
tr_params :: epochs = 100, patience = 20, batch_size = 256, window_size = 48, data_size = 100
Model MACs: 5.568M, Model Params: 4.739M
learning rate scheduling :: (optimizer, mode='min', factor=0.1, patience=5, verbose=True)
total_samples :: train_dataset = 2136000, train_dataloader = 2136000
total_samples :: valid_dataset = 283200, valid_dataloader = 283200
Epoch ::  1 || Loss: 0.42098252 || it_count: 8344 || Val Loss: 0.45546333 || Val it_count: 1107 || Current Learning Rate: 0.001 || Time: 00:06:1.83
Epoch ::  2 || Loss: 0.41840833 || it_count: 8344 || Val Loss: 0.45045620 || Val it_count: 1107 || Current Learning Rate: 0.001 || Time: 00:12:1.55
Epoch ::  3 || Loss: 0.41816153 || it_count: 8344 || Val Loss: 0.45121352 || Val it_count: 1107 || Current Learning Rate: 0.001 || Time: 00:18:0.93
Epoch ::  4 || Loss: 0.41721497 || it_count: 8344 || Val Loss: 0.44740988 || Val it_count: 1107 || Current Learning Rate: 0.001 || Time: 00:23:59.82
Epoch ::  5 || Loss: 0.41679141 || it_count: 8344 || Val Loss: 0.44951535 || Val it_count: 1107 || Current Learning Rate: 0.001 || Time: 00:29:59.07
Epoch ::  6 || Loss: 0.41670647 || it_count: 8344 || Val Loss: 0.44726842 || Val it_count: 1107 || Current Learning Rate: 0.001 || Time: 00:35:57.69
Epoch ::  7 || Loss: 0.41677119 || it_count: 8344 || Val Loss: 0.44734634 || Val it_count: 1107 || Current Learning Rate: 0.001 || Time: 00:41:57.20
Epoch ::  8 || Loss: 0.41641423 || it_count: 8344 || Val Loss: 0.44726704 || Val it_count: 1107 || Current Learning Rate: 0.001 || Time: 00:47:57.01
Epoch ::  9 || Loss: 0.41623735 || it_count: 8344 || Val Loss: 0.44661909 || Val it_count: 1107 || Current Learning Rate: 0.001 || Time: 00:53:58.77
Epoch :: 10 || Loss: 0.41605149 || it_count: 8344 || Val Loss: 0.44569409 || Val it_count: 1107 || Current Learning Rate: 0.001 || Time: 00:59:58.69
Epoch :: 11 || Loss: 0.41578214 || it_count: 8344 || Val Loss: 0.44612104 || Val it_count: 1107 || Current Learning Rate: 0.001 || Time: 01:05:59.76
Epoch :: 12 || Loss: 0.41554064 || it_count: 8344 || Val Loss: 0.44525411 || Val it_count: 1107 || Current Learning Rate: 0.001 || Time: 01:12:0.50
Epoch :: 13 || Loss: 0.41533969 || it_count: 8344 || Val Loss: 0.44562241 || Val it_count: 1107 || Current Learning Rate: 0.001 || Time: 01:18:1.56
Epoch :: 14 || Loss: 0.41534695 || it_count: 8344 || Val Loss: 0.44551779 || Val it_count: 1107 || Current Learning Rate: 0.001 || Time: 01:24:1.81
Epoch :: 15 || Loss: 0.41517670 || it_count: 8344 || Val Loss: 0.44510368 || Val it_count: 1107 || Current Learning Rate: 0.001 || Time: 01:30:2.40
Epoch :: 16 || Loss: 0.41503032 || it_count: 8344 || Val Loss: 0.44540189 || Val it_count: 1107 || Current Learning Rate: 0.001 || Time: 01:36:3.43
Epoch :: 17 || Loss: 0.41468933 || it_count: 8344 || Val Loss: 0.44564687 || Val it_count: 1107 || Current Learning Rate: 0.001 || Time: 01:42:2.69
Epoch :: 18 || Loss: 0.41453270 || it_count: 8344 || Val Loss: 0.44543498 || Val it_count: 1107 || Current Learning Rate: 0.001 || Time: 01:48:3.08
Epoch :: 19 || Loss: 0.41447057 || it_count: 8344 || Val Loss: 0.44551394 || Val it_count: 1107 || Current Learning Rate: 0.001 || Time: 01:54:2.28
Epoch :: 20 || Loss: 0.41426055 || it_count: 8344 || Val Loss: 0.44553223 || Val it_count: 1107 || Current Learning Rate: 0.001 || Time: 02:00:0.86
Epoch :: 21 || Loss: 0.41411166 || it_count: 8344 || Val Loss: 0.44615377 || Val it_count: 1107 || Current Learning Rate: 0.001 || Time: 02:06:0.57
Epoch :: 22 || Loss: 0.41435146 || it_count: 8344 || Val Loss: 0.44538576 || Val it_count: 1107 || Current Learning Rate: 0.001 || Time: 02:11:58.79
Epoch :: 23 || Loss: 0.41381791 || it_count: 8344 || Val Loss: 0.44653673 || Val it_count: 1107 || Current Learning Rate: 0.001 || Time: 02:17:58.91
Epoch :: 24 || Loss: 0.41369857 || it_count: 8344 || Val Loss: 0.44528018 || Val it_count: 1107 || Current Learning Rate: 0.001 || Time: 02:24:0.57
Epoch :: 25 || Loss: 0.41349112 || it_count: 8344 || Val Loss: 0.44470104 || Val it_count: 1107 || Current Learning Rate: 0.001 || Time: 02:30:1.08
Epoch :: 26 || Loss: 0.41347272 || it_count: 8344 || Val Loss: 0.44355312 || Val it_count: 1107 || Current Learning Rate: 0.001 || Time: 02:36:2.28
Epoch :: 27 || Loss: 0.41303931 || it_count: 8344 || Val Loss: 0.44320680 || Val it_count: 1107 || Current Learning Rate: 0.001 || Time: 02:42:4.26
Epoch :: 28 || Loss: 0.41277716 || it_count: 8344 || Val Loss: 0.44306402 || Val it_count: 1107 || Current Learning Rate: 0.001 || Time: 02:48:5.12
Epoch :: 29 || Loss: 0.41237081 || it_count: 8344 || Val Loss: 0.44487031 || Val it_count: 1107 || Current Learning Rate: 0.001 || Time: 02:54:5.65
Epoch :: 30 || Loss: 0.41228623 || it_count: 8344 || Val Loss: 0.44609483 || Val it_count: 1107 || Current Learning Rate: 0.001 || Time: 03:00:6.09
Epoch :: 31 || Loss: 0.41236784 || it_count: 8344 || Val Loss: 0.44623244 || Val it_count: 1107 || Current Learning Rate: 0.001 || Time: 03:06:7.90
Epoch :: 32 || Loss: 0.41193698 || it_count: 8344 || Val Loss: 0.44678085 || Val it_count: 1107 || Current Learning Rate: 0.001 || Time: 03:12:9.01
Epoch :: 33 || Loss: 0.41212876 || it_count: 8344 || Val Loss: 0.44754889 || Val it_count: 1107 || Current Learning Rate: 0.001 || Time: 03:18:10.13
Epoch 00018: reducing learning rate of group 0 to 1.0000e-04.
Epoch :: 34 || Loss: 0.41186407 || it_count: 8344 || Val Loss: 0.44679249 || Val it_count: 1107 || Current Learning Rate: 0.0001 || Time: 03:24:12.19
Epoch :: 35 || Loss: 0.41857605 || it_count: 8344 || Val Loss: 0.43578249 || Val it_count: 1107 || Current Learning Rate: 0.0001 || Time: 03:30:12.93
Epoch :: 36 || Loss: 0.41645960 || it_count: 8344 || Val Loss: 0.43489096 || Val it_count: 1107 || Current Learning Rate: 0.0001 || Time: 03:36:12.54
Epoch :: 37 || Loss: 0.41592361 || it_count: 8344 || Val Loss: 0.43403219 || Val it_count: 1107 || Current Learning Rate: 0.0001 || Time: 03:42:14.69
Epoch :: 38 || Loss: 0.41548037 || it_count: 8344 || Val Loss: 0.43358812 || Val it_count: 1107 || Current Learning Rate: 0.0001 || Time: 03:48:15.86
Epoch :: 39 || Loss: 0.41517609 || it_count: 8344 || Val Loss: 0.43303767 || Val it_count: 1107 || Current Learning Rate: 0.0001 || Time: 03:54:17.25
Epoch :: 40 || Loss: 0.41485924 || it_count: 8344 || Val Loss: 0.43261391 || Val it_count: 1107 || Current Learning Rate: 0.0001 || Time: 04:00:18.41
Epoch :: 41 || Loss: 0.41456008 || it_count: 8344 || Val Loss: 0.43223392 || Val it_count: 1107 || Current Learning Rate: 0.0001 || Time: 04:06:20.31
Epoch :: 42 || Loss: 0.41432086 || it_count: 8344 || Val Loss: 0.43197505 || Val it_count: 1107 || Current Learning Rate: 0.0001 || Time: 04:12:21.27
Epoch :: 43 || Loss: 0.41412520 || it_count: 8344 || Val Loss: 0.43200793 || Val it_count: 1107 || Current Learning Rate: 0.0001 || Time: 04:18:22.89
Epoch :: 44 || Loss: 0.41390622 || it_count: 8344 || Val Loss: 0.43172409 || Val it_count: 1107 || Current Learning Rate: 0.0001 || Time: 04:24:23.95
Epoch :: 45 || Loss: 0.41372754 || it_count: 8344 || Val Loss: 0.43172584 || Val it_count: 1107 || Current Learning Rate: 0.0001 || Time: 04:30:26.39
Epoch :: 46 || Loss: 0.41354762 || it_count: 8344 || Val Loss: 0.43176855 || Val it_count: 1107 || Current Learning Rate: 0.0001 || Time: 04:36:27.57
Epoch :: 47 || Loss: 0.41339067 || it_count: 8344 || Val Loss: 0.43154707 || Val it_count: 1107 || Current Learning Rate: 0.0001 || Time: 04:42:28.68
Epoch :: 48 || Loss: 0.41326261 || it_count: 8344 || Val Loss: 0.43144752 || Val it_count: 1107 || Current Learning Rate: 0.0001 || Time: 04:48:30.66
Epoch :: 49 || Loss: 0.41316788 || it_count: 8344 || Val Loss: 0.43105094 || Val it_count: 1107 || Current Learning Rate: 0.0001 || Time: 04:54:32.18
Epoch :: 50 || Loss: 0.41296657 || it_count: 8344 || Val Loss: 0.43089552 || Val it_count: 1107 || Current Learning Rate: 0.0001 || Time: 05:00:33.26
Epoch :: 51 || Loss: 0.41285039 || it_count: 8344 || Val Loss: 0.43077349 || Val it_count: 1107 || Current Learning Rate: 0.0001 || Time: 05:06:34.58
Epoch :: 52 || Loss: 0.41277356 || it_count: 8344 || Val Loss: 0.43057668 || Val it_count: 1107 || Current Learning Rate: 0.0001 || Time: 05:12:36.74
Epoch :: 53 || Loss: 0.41263405 || it_count: 8344 || Val Loss: 0.43049454 || Val it_count: 1107 || Current Learning Rate: 0.0001 || Time: 05:18:39.01
Epoch :: 54 || Loss: 0.41252067 || it_count: 8344 || Val Loss: 0.43032868 || Val it_count: 1107 || Current Learning Rate: 0.0001 || Time: 05:24:41.09
Epoch :: 55 || Loss: 0.41240852 || it_count: 8344 || Val Loss: 0.43033519 || Val it_count: 1107 || Current Learning Rate: 0.0001 || Time: 05:30:41.83
Epoch :: 56 || Loss: 0.41230295 || it_count: 8344 || Val Loss: 0.43048631 || Val it_count: 1107 || Current Learning Rate: 0.0001 || Time: 05:36:43.20
Epoch :: 57 || Loss: 0.41224778 || it_count: 8344 || Val Loss: 0.43026288 || Val it_count: 1107 || Current Learning Rate: 0.0001 || Time: 05:42:45.93
Epoch :: 58 || Loss: 0.41213780 || it_count: 8344 || Val Loss: 0.43017101 || Val it_count: 1107 || Current Learning Rate: 0.0001 || Time: 05:48:47.52
Epoch :: 59 || Loss: 0.41206777 || it_count: 8344 || Val Loss: 0.43016922 || Val it_count: 1107 || Current Learning Rate: 0.0001 || Time: 05:54:48.97
Epoch :: 60 || Loss: 0.41201180 || it_count: 8344 || Val Loss: 0.42986211 || Val it_count: 1107 || Current Learning Rate: 0.0001 || Time: 06:00:50.94
Epoch :: 61 || Loss: 0.41193361 || it_count: 8344 || Val Loss: 0.42975854 || Val it_count: 1107 || Current Learning Rate: 0.0001 || Time: 06:06:51.48
Epoch :: 62 || Loss: 0.41185009 || it_count: 8344 || Val Loss: 0.42989917 || Val it_count: 1107 || Current Learning Rate: 0.0001 || Time: 06:12:52.64
Epoch :: 63 || Loss: 0.41174944 || it_count: 8344 || Val Loss: 0.42966321 || Val it_count: 1107 || Current Learning Rate: 0.0001 || Time: 06:18:53.99
Epoch :: 64 || Loss: 0.41167027 || it_count: 8344 || Val Loss: 0.42985455 || Val it_count: 1107 || Current Learning Rate: 0.0001 || Time: 06:24:55.93
Epoch :: 65 || Loss: 0.41165365 || it_count: 8344 || Val Loss: 0.42978895 || Val it_count: 1107 || Current Learning Rate: 0.0001 || Time: 06:30:56.86
Epoch :: 66 || Loss: 0.41158590 || it_count: 8344 || Val Loss: 0.42973001 || Val it_count: 1107 || Current Learning Rate: 0.0001 || Time: 06:36:58.10
Epoch :: 67 || Loss: 0.41151366 || it_count: 8344 || Val Loss: 0.42974860 || Val it_count: 1107 || Current Learning Rate: 0.0001 || Time: 06:42:58.21
Epoch :: 68 || Loss: 0.41150255 || it_count: 8344 || Val Loss: 0.42975585 || Val it_count: 1107 || Current Learning Rate: 0.0001 || Time: 06:48:58.23
Epoch 00053: reducing learning rate of group 0 to 1.0000e-05.
Epoch :: 69 || Loss: 0.41142682 || it_count: 8344 || Val Loss: 0.42988745 || Val it_count: 1107 || Current Learning Rate: 1e-05 || Time: 06:55:0.23
Epoch :: 70 || Loss: 0.41513080 || it_count: 8344 || Val Loss: 0.41719435 || Val it_count: 1107 || Current Learning Rate: 1e-05 || Time: 07:01:2.63
Epoch :: 71 || Loss: 0.41289893 || it_count: 8344 || Val Loss: 0.41649704 || Val it_count: 1107 || Current Learning Rate: 1e-05 || Time: 07:07:3.84
Epoch :: 72 || Loss: 0.41264004 || it_count: 8344 || Val Loss: 0.41631926 || Val it_count: 1107 || Current Learning Rate: 1e-05 || Time: 07:13:6.07
Epoch :: 73 || Loss: 0.41252422 || it_count: 8344 || Val Loss: 0.41625739 || Val it_count: 1107 || Current Learning Rate: 1e-05 || Time: 07:19:7.61
Epoch :: 74 || Loss: 0.41244362 || it_count: 8344 || Val Loss: 0.41622815 || Val it_count: 1107 || Current Learning Rate: 1e-05 || Time: 07:25:9.62
Epoch :: 75 || Loss: 0.41236288 || it_count: 8344 || Val Loss: 0.41620202 || Val it_count: 1107 || Current Learning Rate: 1e-05 || Time: 07:31:11.32
Epoch :: 76 || Loss: 0.41235033 || it_count: 8344 || Val Loss: 0.41617881 || Val it_count: 1107 || Current Learning Rate: 1e-05 || Time: 07:37:11.96
Epoch :: 77 || Loss: 0.41231910 || it_count: 8344 || Val Loss: 0.41615368 || Val it_count: 1107 || Current Learning Rate: 1e-05 || Time: 07:43:12.50
Epoch :: 78 || Loss: 0.41225381 || it_count: 8344 || Val Loss: 0.41617616 || Val it_count: 1107 || Current Learning Rate: 1e-05 || Time: 07:49:13.15
Epoch :: 79 || Loss: 0.41225812 || it_count: 8344 || Val Loss: 0.41617779 || Val it_count: 1107 || Current Learning Rate: 1e-05 || Time: 07:55:14.10
Epoch :: 80 || Loss: 0.41222283 || it_count: 8344 || Val Loss: 0.41620198 || Val it_count: 1107 || Current Learning Rate: 1e-05 || Time: 08:01:18.80
Epoch :: 81 || Loss: 0.41218847 || it_count: 8344 || Val Loss: 0.41621365 || Val it_count: 1107 || Current Learning Rate: 1e-05 || Time: 08:07:19.68
Epoch :: 82 || Loss: 0.41216927 || it_count: 8344 || Val Loss: 0.41620874 || Val it_count: 1107 || Current Learning Rate: 1e-05 || Time: 08:13:20.51
Epoch 00067: reducing learning rate of group 0 to 1.0000e-06.
Epoch :: 83 || Loss: 0.41212022 || it_count: 8344 || Val Loss: 0.41623042 || Val it_count: 1107 || Current Learning Rate: 1.0000000000000002e-06 || Time: 08:19:20.66
Epoch :: 84 || Loss: 0.41244930 || it_count: 8344 || Val Loss: 0.41505711 || Val it_count: 1107 || Current Learning Rate: 1.0000000000000002e-06 || Time: 08:25:20.83
Epoch :: 85 || Loss: 0.41233117 || it_count: 8344 || Val Loss: 0.41498530 || Val it_count: 1107 || Current Learning Rate: 1.0000000000000002e-06 || Time: 08:31:21.00
Epoch :: 86 || Loss: 0.41228209 || it_count: 8344 || Val Loss: 0.41494889 || Val it_count: 1107 || Current Learning Rate: 1.0000000000000002e-06 || Time: 08:37:21.83
Epoch :: 87 || Loss: 0.41224936 || it_count: 8344 || Val Loss: 0.41492399 || Val it_count: 1107 || Current Learning Rate: 1.0000000000000002e-06 || Time: 08:43:21.80
Epoch :: 88 || Loss: 0.41224937 || it_count: 8344 || Val Loss: 0.41491154 || Val it_count: 1107 || Current Learning Rate: 1.0000000000000002e-06 || Time: 08:49:22.76
Epoch :: 89 || Loss: 0.41225359 || it_count: 8344 || Val Loss: 0.41489969 || Val it_count: 1107 || Current Learning Rate: 1.0000000000000002e-06 || Time: 08:55:22.85
Epoch :: 90 || Loss: 0.41222309 || it_count: 8344 || Val Loss: 0.41489085 || Val it_count: 1107 || Current Learning Rate: 1.0000000000000002e-06 || Time: 09:01:23.14
Epoch :: 91 || Loss: 0.41221001 || it_count: 8344 || Val Loss: 0.41488018 || Val it_count: 1107 || Current Learning Rate: 1.0000000000000002e-06 || Time: 09:07:23.14
Epoch :: 92 || Loss: 0.41220869 || it_count: 8344 || Val Loss: 0.41487416 || Val it_count: 1107 || Current Learning Rate: 1.0000000000000002e-06 || Time: 09:13:24.11
Epoch :: 93 || Loss: 0.41217618 || it_count: 8344 || Val Loss: 0.41486711 || Val it_count: 1107 || Current Learning Rate: 1.0000000000000002e-06 || Time: 09:19:23.52
Epoch :: 94 || Loss: 0.41217645 || it_count: 8344 || Val Loss: 0.41486076 || Val it_count: 1107 || Current Learning Rate: 1.0000000000000002e-06 || Time: 09:25:24.63
Epoch :: 95 || Loss: 0.41219263 || it_count: 8344 || Val Loss: 0.41485778 || Val it_count: 1107 || Current Learning Rate: 1.0000000000000002e-06 || Time: 09:31:25.58
Epoch :: 96 || Loss: 0.41217418 || it_count: 8344 || Val Loss: 0.41485367 || Val it_count: 1107 || Current Learning Rate: 1.0000000000000002e-06 || Time: 09:37:26.48
Epoch 00081: reducing learning rate of group 0 to 1.0000e-07.
Early stopping triggered due to learning rate below threshold.
Done Total time: 09:43:28.21
best_loss: 0.41485366723259276

--------------------Testing--------------------

total_samples :: test_dataset = 139200, test_dataloader = 139200
Epoch ::  1 || Loss: 0.23984347 || it_count: 544 || Time: 00:00:19.98
MAE:  0.25784627
MSE:  0.23986334
RMSE:  0.44483054

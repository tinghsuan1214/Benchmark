--------------------Training--------------------
arch_str :: |lstm_2~0|+|lstm_2~0|none~1|[relu->linear->dropout->linear]
model :: 3N
InferCell(
  info :: nodes=3, inC=1, outC=64, [1<-(I0-L0) | 2<-(I0-L1,I1-L2)], genotype_str: lstm_2~0|lstm_2~0|none~1
  linear_layers: [relu->linear->dropout->linear]
  (layers): ModuleList(
    (0-1): 2 x LSTM(
      (lstm): LSTM(1, 64, num_layers=2, batch_first=True)
    )
    (2): Zero(C_in=64, C_out=64, stride=1)
  )
  (linear_layers): ModuleList(
    (0): ReLU()
    (1): Linear(in_features=3072, out_features=1536, bias=True)
    (2): Dropout(p=0.1, inplace=False)
    (3): Linear(in_features=1536, out_features=1, bias=True)
  )
)
tr_params :: epochs = 100, patience = 20, batch_size = 256, window_size = 48, data_size = 100
Model MACs: 9.660M, Model Params: 4.823M
learning rate scheduling :: (optimizer, mode='min', factor=0.1, patience=5, verbose=True)
total_samples :: train_dataset = 2136000, train_dataloader = 2136000
total_samples :: valid_dataset = 283200, valid_dataloader = 283200
Epoch ::  1 || Loss: 0.42249950 || it_count: 8344 || Val Loss: 0.45790816 || Val it_count: 1107 || Current Learning Rate: 0.001 || Time: 00:08:29.75
Epoch ::  2 || Loss: 0.41766565 || it_count: 8344 || Val Loss: 0.45591517 || Val it_count: 1107 || Current Learning Rate: 0.001 || Time: 00:16:56.72
Epoch ::  3 || Loss: 0.41670802 || it_count: 8344 || Val Loss: 0.45242286 || Val it_count: 1107 || Current Learning Rate: 0.001 || Time: 00:25:23.40
Epoch ::  4 || Loss: 0.41660908 || it_count: 8344 || Val Loss: 0.45082329 || Val it_count: 1107 || Current Learning Rate: 0.001 || Time: 00:33:50.21
Epoch ::  5 || Loss: 0.41616546 || it_count: 8344 || Val Loss: 0.45160296 || Val it_count: 1107 || Current Learning Rate: 0.001 || Time: 00:42:17.98
Epoch ::  6 || Loss: 0.41590529 || it_count: 8344 || Val Loss: 0.45099872 || Val it_count: 1107 || Current Learning Rate: 0.001 || Time: 00:50:43.81
Epoch ::  7 || Loss: 0.41566303 || it_count: 8344 || Val Loss: 0.44957257 || Val it_count: 1107 || Current Learning Rate: 0.001 || Time: 00:59:12.48
Epoch ::  8 || Loss: 0.41546678 || it_count: 8344 || Val Loss: 0.44805066 || Val it_count: 1107 || Current Learning Rate: 0.001 || Time: 01:07:42.83
Epoch ::  9 || Loss: 0.41536243 || it_count: 8344 || Val Loss: 0.44979331 || Val it_count: 1107 || Current Learning Rate: 0.001 || Time: 01:16:14.45
Epoch :: 10 || Loss: 0.41504332 || it_count: 8344 || Val Loss: 0.45044566 || Val it_count: 1107 || Current Learning Rate: 0.001 || Time: 01:24:47.12
Epoch :: 11 || Loss: 0.41504590 || it_count: 8344 || Val Loss: 0.45007706 || Val it_count: 1107 || Current Learning Rate: 0.001 || Time: 01:33:22.51
Epoch :: 12 || Loss: 0.41475272 || it_count: 8344 || Val Loss: 0.44932058 || Val it_count: 1107 || Current Learning Rate: 0.001 || Time: 01:41:57.12
Epoch :: 13 || Loss: 0.41439011 || it_count: 8344 || Val Loss: 0.44967032 || Val it_count: 1107 || Current Learning Rate: 0.001 || Time: 01:50:31.72
Epoch :: 14 || Loss: 0.41408320 || it_count: 8344 || Val Loss: 0.44859983 || Val it_count: 1107 || Current Learning Rate: 0.001 || Time: 01:59:5.60
Epoch :: 15 || Loss: 0.41387311 || it_count: 8344 || Val Loss: 0.44930044 || Val it_count: 1107 || Current Learning Rate: 0.001 || Time: 02:07:39.85
Epoch :: 16 || Loss: 0.41368836 || it_count: 8344 || Val Loss: 0.44934395 || Val it_count: 1107 || Current Learning Rate: 0.001 || Time: 02:16:15.36
Epoch :: 17 || Loss: 0.41335317 || it_count: 8344 || Val Loss: 0.44922843 || Val it_count: 1107 || Current Learning Rate: 0.001 || Time: 02:24:50.17
Epoch :: 18 || Loss: 0.41297073 || it_count: 8344 || Val Loss: 0.44956321 || Val it_count: 1107 || Current Learning Rate: 0.001 || Time: 02:33:25.55
Epoch :: 19 || Loss: 0.41276339 || it_count: 8344 || Val Loss: 0.44991834 || Val it_count: 1107 || Current Learning Rate: 0.001 || Time: 02:42:0.36
Epoch :: 20 || Loss: 0.41272378 || it_count: 8344 || Val Loss: 0.45055818 || Val it_count: 1107 || Current Learning Rate: 0.001 || Time: 02:50:33.90
Epoch :: 21 || Loss: 0.41225209 || it_count: 8344 || Val Loss: 0.45072506 || Val it_count: 1107 || Current Learning Rate: 0.001 || Time: 02:59:8.81
Epoch :: 22 || Loss: 0.41185864 || it_count: 8344 || Val Loss: 0.45052292 || Val it_count: 1107 || Current Learning Rate: 0.001 || Time: 03:07:43.46
Epoch :: 23 || Loss: 0.41186810 || it_count: 8344 || Val Loss: 0.44912794 || Val it_count: 1107 || Current Learning Rate: 0.001 || Time: 03:16:19.42
Epoch :: 24 || Loss: 0.41127682 || it_count: 8344 || Val Loss: 0.44857388 || Val it_count: 1107 || Current Learning Rate: 0.001 || Time: 03:24:54.51
Epoch :: 25 || Loss: 0.41116591 || it_count: 8344 || Val Loss: 0.44831419 || Val it_count: 1107 || Current Learning Rate: 0.001 || Time: 03:33:29.58
Epoch :: 26 || Loss: 0.41054555 || it_count: 8344 || Val Loss: 0.44870333 || Val it_count: 1107 || Current Learning Rate: 0.001 || Time: 03:42:4.73
Epoch :: 27 || Loss: 0.40994585 || it_count: 8344 || Val Loss: 0.44830810 || Val it_count: 1107 || Current Learning Rate: 0.001 || Time: 03:50:38.47
Epoch :: 28 || Loss: 0.40916237 || it_count: 8344 || Val Loss: 0.44730425 || Val it_count: 1107 || Current Learning Rate: 0.001 || Time: 03:59:12.36
Epoch :: 29 || Loss: 0.40849334 || it_count: 8344 || Val Loss: 0.44556314 || Val it_count: 1107 || Current Learning Rate: 0.001 || Time: 04:07:46.73
Epoch :: 30 || Loss: 0.40792458 || it_count: 8344 || Val Loss: 0.44428418 || Val it_count: 1107 || Current Learning Rate: 0.001 || Time: 04:16:20.70
Epoch :: 31 || Loss: 0.40750205 || it_count: 8344 || Val Loss: 0.44416586 || Val it_count: 1107 || Current Learning Rate: 0.001 || Time: 04:24:55.68
Epoch :: 32 || Loss: 0.40711723 || it_count: 8344 || Val Loss: 0.44436699 || Val it_count: 1107 || Current Learning Rate: 0.001 || Time: 04:33:29.62
Epoch :: 33 || Loss: 0.40662705 || it_count: 8344 || Val Loss: 0.44604516 || Val it_count: 1107 || Current Learning Rate: 0.001 || Time: 04:42:2.91
Epoch :: 34 || Loss: 0.40610904 || it_count: 8344 || Val Loss: 0.44581450 || Val it_count: 1107 || Current Learning Rate: 0.001 || Time: 04:50:36.62
Epoch :: 35 || Loss: 0.40552354 || it_count: 8344 || Val Loss: 0.44588138 || Val it_count: 1107 || Current Learning Rate: 0.001 || Time: 04:59:11.28
Epoch :: 36 || Loss: 0.40528416 || it_count: 8344 || Val Loss: 0.44697314 || Val it_count: 1107 || Current Learning Rate: 0.001 || Time: 05:07:46.31
Epoch 00021: reducing learning rate of group 0 to 1.0000e-04.
Epoch :: 37 || Loss: 0.40494784 || it_count: 8344 || Val Loss: 0.44860184 || Val it_count: 1107 || Current Learning Rate: 0.0001 || Time: 05:16:18.94
Epoch :: 38 || Loss: 0.41414115 || it_count: 8344 || Val Loss: 0.43527220 || Val it_count: 1107 || Current Learning Rate: 0.0001 || Time: 05:24:52.55
Epoch :: 39 || Loss: 0.41177655 || it_count: 8344 || Val Loss: 0.43404905 || Val it_count: 1107 || Current Learning Rate: 0.0001 || Time: 05:33:27.63
Epoch :: 40 || Loss: 0.41077973 || it_count: 8344 || Val Loss: 0.43287376 || Val it_count: 1107 || Current Learning Rate: 0.0001 || Time: 05:42:2.13
Epoch :: 41 || Loss: 0.41014351 || it_count: 8344 || Val Loss: 0.43238651 || Val it_count: 1107 || Current Learning Rate: 0.0001 || Time: 05:50:37.02
Epoch :: 42 || Loss: 0.40966337 || it_count: 8344 || Val Loss: 0.43159266 || Val it_count: 1107 || Current Learning Rate: 0.0001 || Time: 05:59:10.61
Epoch :: 43 || Loss: 0.40925200 || it_count: 8344 || Val Loss: 0.43153408 || Val it_count: 1107 || Current Learning Rate: 0.0001 || Time: 06:07:45.57
Epoch :: 44 || Loss: 0.40894207 || it_count: 8344 || Val Loss: 0.43145898 || Val it_count: 1107 || Current Learning Rate: 0.0001 || Time: 06:16:20.04
Epoch :: 45 || Loss: 0.40855342 || it_count: 8344 || Val Loss: 0.43142288 || Val it_count: 1107 || Current Learning Rate: 0.0001 || Time: 06:24:53.52
Epoch :: 46 || Loss: 0.40833501 || it_count: 8344 || Val Loss: 0.43174235 || Val it_count: 1107 || Current Learning Rate: 0.0001 || Time: 06:33:28.06
Epoch :: 47 || Loss: 0.40808855 || it_count: 8344 || Val Loss: 0.43159195 || Val it_count: 1107 || Current Learning Rate: 0.0001 || Time: 06:42:1.54
Epoch :: 48 || Loss: 0.40785095 || it_count: 8344 || Val Loss: 0.43171721 || Val it_count: 1107 || Current Learning Rate: 0.0001 || Time: 06:50:35.52
Epoch :: 49 || Loss: 0.40765234 || it_count: 8344 || Val Loss: 0.43141936 || Val it_count: 1107 || Current Learning Rate: 0.0001 || Time: 06:59:8.93
Epoch 00034: reducing learning rate of group 0 to 1.0000e-05.
Epoch :: 50 || Loss: 0.40742142 || it_count: 8344 || Val Loss: 0.43148573 || Val it_count: 1107 || Current Learning Rate: 1e-05 || Time: 07:07:43.34
Epoch :: 51 || Loss: 0.41355619 || it_count: 8344 || Val Loss: 0.41595718 || Val it_count: 1107 || Current Learning Rate: 1e-05 || Time: 07:16:16.77
Epoch :: 52 || Loss: 0.40975425 || it_count: 8344 || Val Loss: 0.41465929 || Val it_count: 1107 || Current Learning Rate: 1e-05 || Time: 07:24:51.50
Epoch :: 53 || Loss: 0.40931139 || it_count: 8344 || Val Loss: 0.41450021 || Val it_count: 1107 || Current Learning Rate: 1e-05 || Time: 07:33:25.89
Epoch :: 54 || Loss: 0.40913964 || it_count: 8344 || Val Loss: 0.41442832 || Val it_count: 1107 || Current Learning Rate: 1e-05 || Time: 07:41:59.40
Epoch :: 55 || Loss: 0.40903372 || it_count: 8344 || Val Loss: 0.41436105 || Val it_count: 1107 || Current Learning Rate: 1e-05 || Time: 07:50:34.31
Epoch :: 56 || Loss: 0.40894055 || it_count: 8344 || Val Loss: 0.41432452 || Val it_count: 1107 || Current Learning Rate: 1e-05 || Time: 07:59:8.00
Epoch :: 57 || Loss: 0.40887887 || it_count: 8344 || Val Loss: 0.41433648 || Val it_count: 1107 || Current Learning Rate: 1e-05 || Time: 08:07:41.76
Epoch :: 58 || Loss: 0.40885883 || it_count: 8344 || Val Loss: 0.41435053 || Val it_count: 1107 || Current Learning Rate: 1e-05 || Time: 08:16:16.54
Epoch :: 59 || Loss: 0.40880179 || it_count: 8344 || Val Loss: 0.41431464 || Val it_count: 1107 || Current Learning Rate: 1e-05 || Time: 08:24:49.81
Epoch :: 60 || Loss: 0.40874569 || it_count: 8344 || Val Loss: 0.41429987 || Val it_count: 1107 || Current Learning Rate: 1e-05 || Time: 08:33:23.63
Epoch :: 61 || Loss: 0.40869061 || it_count: 8344 || Val Loss: 0.41433444 || Val it_count: 1107 || Current Learning Rate: 1e-05 || Time: 08:41:57.47
Epoch :: 62 || Loss: 0.40863693 || it_count: 8344 || Val Loss: 0.41430975 || Val it_count: 1107 || Current Learning Rate: 1e-05 || Time: 08:50:32.18
Epoch :: 63 || Loss: 0.40858451 || it_count: 8344 || Val Loss: 0.41433242 || Val it_count: 1107 || Current Learning Rate: 1e-05 || Time: 08:59:5.56
Epoch :: 64 || Loss: 0.40857309 || it_count: 8344 || Val Loss: 0.41433865 || Val it_count: 1107 || Current Learning Rate: 1e-05 || Time: 09:07:39.48
Epoch 00049: reducing learning rate of group 0 to 1.0000e-06.
Epoch :: 65 || Loss: 0.40851967 || it_count: 8344 || Val Loss: 0.41438285 || Val it_count: 1107 || Current Learning Rate: 1.0000000000000002e-06 || Time: 09:16:14.41
Epoch :: 66 || Loss: 0.40896696 || it_count: 8344 || Val Loss: 0.41304764 || Val it_count: 1107 || Current Learning Rate: 1.0000000000000002e-06 || Time: 09:24:48.59
Epoch :: 67 || Loss: 0.40877403 || it_count: 8344 || Val Loss: 0.41287754 || Val it_count: 1107 || Current Learning Rate: 1.0000000000000002e-06 || Time: 09:33:24.12
Epoch :: 68 || Loss: 0.40874255 || it_count: 8344 || Val Loss: 0.41285496 || Val it_count: 1107 || Current Learning Rate: 1.0000000000000002e-06 || Time: 09:41:59.26
Epoch :: 69 || Loss: 0.40870477 || it_count: 8344 || Val Loss: 0.41282788 || Val it_count: 1107 || Current Learning Rate: 1.0000000000000002e-06 || Time: 09:50:32.56
Epoch :: 70 || Loss: 0.40869546 || it_count: 8344 || Val Loss: 0.41281130 || Val it_count: 1107 || Current Learning Rate: 1.0000000000000002e-06 || Time: 09:59:6.89
Epoch :: 71 || Loss: 0.40870455 || it_count: 8344 || Val Loss: 0.41280087 || Val it_count: 1107 || Current Learning Rate: 1.0000000000000002e-06 || Time: 10:07:41.66
Epoch :: 72 || Loss: 0.40868939 || it_count: 8344 || Val Loss: 0.41278676 || Val it_count: 1107 || Current Learning Rate: 1.0000000000000002e-06 || Time: 10:16:15.64
Epoch :: 73 || Loss: 0.40867163 || it_count: 8344 || Val Loss: 0.41277343 || Val it_count: 1107 || Current Learning Rate: 1.0000000000000002e-06 || Time: 10:24:50.39
Epoch :: 74 || Loss: 0.40865465 || it_count: 8344 || Val Loss: 0.41276856 || Val it_count: 1107 || Current Learning Rate: 1.0000000000000002e-06 || Time: 10:33:24.07
Epoch :: 75 || Loss: 0.40863430 || it_count: 8344 || Val Loss: 0.41275614 || Val it_count: 1107 || Current Learning Rate: 1.0000000000000002e-06 || Time: 10:41:57.95
Epoch :: 76 || Loss: 0.40860098 || it_count: 8344 || Val Loss: 0.41274202 || Val it_count: 1107 || Current Learning Rate: 1.0000000000000002e-06 || Time: 10:50:31.46
Epoch :: 77 || Loss: 0.40860021 || it_count: 8344 || Val Loss: 0.41273673 || Val it_count: 1107 || Current Learning Rate: 1.0000000000000002e-06 || Time: 10:59:5.79
Epoch :: 78 || Loss: 0.40863353 || it_count: 8344 || Val Loss: 0.41272881 || Val it_count: 1107 || Current Learning Rate: 1.0000000000000002e-06 || Time: 11:07:40.26
Epoch :: 79 || Loss: 0.40860070 || it_count: 8344 || Val Loss: 0.41272859 || Val it_count: 1107 || Current Learning Rate: 1.0000000000000002e-06 || Time: 11:16:15.41
Epoch :: 80 || Loss: 0.40858840 || it_count: 8344 || Val Loss: 0.41272565 || Val it_count: 1107 || Current Learning Rate: 1.0000000000000002e-06 || Time: 11:24:49.83
Epoch :: 81 || Loss: 0.40858320 || it_count: 8344 || Val Loss: 0.41271407 || Val it_count: 1107 || Current Learning Rate: 1.0000000000000002e-06 || Time: 11:33:24.00
Epoch :: 82 || Loss: 0.40857552 || it_count: 8344 || Val Loss: 0.41270736 || Val it_count: 1107 || Current Learning Rate: 1.0000000000000002e-06 || Time: 11:41:59.09
Epoch :: 83 || Loss: 0.40856599 || it_count: 8344 || Val Loss: 0.41270661 || Val it_count: 1107 || Current Learning Rate: 1.0000000000000002e-06 || Time: 11:50:32.10
Epoch 00068: reducing learning rate of group 0 to 1.0000e-07.
Early stopping triggered due to learning rate below threshold.
Done Total time: 11:59:6.52
best_loss: 0.4127066078101552

--------------------Testing--------------------

total_samples :: test_dataset = 139200, test_dataloader = 139200
Epoch ::  1 || Loss: 0.23586412 || it_count: 544 || Time: 00:00:23.12
MAE:  0.2536083
MSE:  0.23588188
RMSE:  0.44161853

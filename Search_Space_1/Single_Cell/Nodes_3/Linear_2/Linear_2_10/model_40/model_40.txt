--------------------Training--------------------
arch_str :: |lstm_2~0|+|lstm_3~0|skip_connect~1|[relu->linear->dropout->linear]
model :: 3N
InferCell(
  info :: nodes=3, inC=1, outC=64, [1<-(I0-L0) | 2<-(I0-L1,I1-L2)], genotype_str: lstm_2~0|lstm_3~0|skip_connect~1
  linear_layers: [relu->linear->dropout->linear]
  (layers): ModuleList(
    (0): LSTM(
      (lstm): LSTM(1, 64, num_layers=2, batch_first=True)
    )
    (1): LSTM(
      (lstm): LSTM(1, 64, num_layers=3, batch_first=True)
    )
    (2): Identity()
  )
  (linear_layers): ModuleList(
    (0): ReLU()
    (1): Linear(in_features=3072, out_features=1536, bias=True)
    (2): Dropout(p=0.1, inplace=False)
    (3): Linear(in_features=1536, out_features=1, bias=True)
  )
)
tr_params :: epochs = 100, patience = 20, batch_size = 256, window_size = 48, data_size = 100
Model MACs: 11.282M, Model Params: 4.856M
learning rate scheduling :: (optimizer, mode='min', factor=0.1, patience=5, verbose=True)
total_samples :: train_dataset = 2136000, train_dataloader = 2136000
total_samples :: valid_dataset = 283200, valid_dataloader = 283200
Epoch ::  1 || Loss: 0.42382841 || it_count: 8344 || Val Loss: 0.46229394 || Val it_count: 1107 || Current Learning Rate: 0.001 || Time: 00:09:16.42
Epoch ::  2 || Loss: 0.41841518 || it_count: 8344 || Val Loss: 0.45283459 || Val it_count: 1107 || Current Learning Rate: 0.001 || Time: 00:18:35.81
Epoch ::  3 || Loss: 0.41770780 || it_count: 8344 || Val Loss: 0.45171926 || Val it_count: 1107 || Current Learning Rate: 0.001 || Time: 00:28:1.19
Epoch ::  4 || Loss: 0.41705187 || it_count: 8344 || Val Loss: 0.45086016 || Val it_count: 1107 || Current Learning Rate: 0.001 || Time: 00:37:33.13
Epoch ::  5 || Loss: 0.41632656 || it_count: 8344 || Val Loss: 0.45116784 || Val it_count: 1107 || Current Learning Rate: 0.001 || Time: 00:47:4.42
Epoch ::  6 || Loss: 0.41655797 || it_count: 8344 || Val Loss: 0.45129926 || Val it_count: 1107 || Current Learning Rate: 0.001 || Time: 00:56:37.53
Epoch ::  7 || Loss: 0.41592468 || it_count: 8344 || Val Loss: 0.45066074 || Val it_count: 1107 || Current Learning Rate: 0.001 || Time: 01:06:13.73
Epoch ::  8 || Loss: 0.41536423 || it_count: 8344 || Val Loss: 0.45052113 || Val it_count: 1107 || Current Learning Rate: 0.001 || Time: 01:15:49.98
Epoch ::  9 || Loss: 0.41493365 || it_count: 8344 || Val Loss: 0.45125229 || Val it_count: 1107 || Current Learning Rate: 0.001 || Time: 01:25:26.52
Epoch :: 10 || Loss: 0.41517617 || it_count: 8344 || Val Loss: 0.45196887 || Val it_count: 1107 || Current Learning Rate: 0.001 || Time: 01:35:3.24
Epoch :: 11 || Loss: 0.41543816 || it_count: 8344 || Val Loss: 0.45205655 || Val it_count: 1107 || Current Learning Rate: 0.001 || Time: 01:44:41.69
Epoch :: 12 || Loss: 0.41512245 || it_count: 8344 || Val Loss: 0.45105916 || Val it_count: 1107 || Current Learning Rate: 0.001 || Time: 01:54:20.35
Epoch :: 13 || Loss: 0.41490853 || it_count: 8344 || Val Loss: 0.44941487 || Val it_count: 1107 || Current Learning Rate: 0.001 || Time: 02:03:59.09
Epoch :: 14 || Loss: 0.41445841 || it_count: 8344 || Val Loss: 0.44855811 || Val it_count: 1107 || Current Learning Rate: 0.001 || Time: 02:13:38.86
Epoch :: 15 || Loss: 0.41381375 || it_count: 8344 || Val Loss: 0.44824978 || Val it_count: 1107 || Current Learning Rate: 0.001 || Time: 02:23:18.38
Epoch :: 16 || Loss: 0.41346903 || it_count: 8344 || Val Loss: 0.44761943 || Val it_count: 1107 || Current Learning Rate: 0.001 || Time: 02:32:57.67
Epoch :: 17 || Loss: 0.41284468 || it_count: 8344 || Val Loss: 0.44725661 || Val it_count: 1107 || Current Learning Rate: 0.001 || Time: 02:42:36.66
Epoch :: 18 || Loss: 0.41235104 || it_count: 8344 || Val Loss: 0.44636546 || Val it_count: 1107 || Current Learning Rate: 0.001 || Time: 02:52:16.48
Epoch :: 19 || Loss: 0.41208402 || it_count: 8344 || Val Loss: 0.44540078 || Val it_count: 1107 || Current Learning Rate: 0.001 || Time: 03:01:55.91
Epoch :: 20 || Loss: 0.41174418 || it_count: 8344 || Val Loss: 0.44535080 || Val it_count: 1107 || Current Learning Rate: 0.001 || Time: 03:11:35.04
Epoch :: 21 || Loss: 0.41129378 || it_count: 8344 || Val Loss: 0.44477412 || Val it_count: 1107 || Current Learning Rate: 0.001 || Time: 03:21:14.53
Epoch :: 22 || Loss: 0.41117324 || it_count: 8344 || Val Loss: 0.44464592 || Val it_count: 1107 || Current Learning Rate: 0.001 || Time: 03:30:53.92
Epoch :: 23 || Loss: 0.41086499 || it_count: 8344 || Val Loss: 0.44663109 || Val it_count: 1107 || Current Learning Rate: 0.001 || Time: 03:40:33.26
Epoch :: 24 || Loss: 0.41068062 || it_count: 8344 || Val Loss: 0.44705193 || Val it_count: 1107 || Current Learning Rate: 0.001 || Time: 03:50:12.79
Epoch :: 25 || Loss: 0.41061494 || it_count: 8344 || Val Loss: 0.44514792 || Val it_count: 1107 || Current Learning Rate: 0.001 || Time: 03:59:51.55
Epoch :: 26 || Loss: 0.41014438 || it_count: 8344 || Val Loss: 0.44602879 || Val it_count: 1107 || Current Learning Rate: 0.001 || Time: 04:09:31.71
Epoch :: 27 || Loss: 0.40999693 || it_count: 8344 || Val Loss: 0.44754895 || Val it_count: 1107 || Current Learning Rate: 0.001 || Time: 04:19:11.88
Epoch 00012: reducing learning rate of group 0 to 1.0000e-04.
Epoch :: 28 || Loss: 0.40976560 || it_count: 8344 || Val Loss: 0.44616916 || Val it_count: 1107 || Current Learning Rate: 0.0001 || Time: 04:28:52.20
Epoch :: 29 || Loss: 0.41660036 || it_count: 8344 || Val Loss: 0.43267114 || Val it_count: 1107 || Current Learning Rate: 0.0001 || Time: 04:38:32.10
Epoch :: 30 || Loss: 0.41387033 || it_count: 8344 || Val Loss: 0.43060392 || Val it_count: 1107 || Current Learning Rate: 0.0001 || Time: 04:48:12.55
Epoch :: 31 || Loss: 0.41319293 || it_count: 8344 || Val Loss: 0.42939958 || Val it_count: 1107 || Current Learning Rate: 0.0001 || Time: 04:57:53.17
Epoch :: 32 || Loss: 0.41272783 || it_count: 8344 || Val Loss: 0.42841798 || Val it_count: 1107 || Current Learning Rate: 0.0001 || Time: 05:07:33.54
Epoch :: 33 || Loss: 0.41236053 || it_count: 8344 || Val Loss: 0.42804375 || Val it_count: 1107 || Current Learning Rate: 0.0001 || Time: 05:17:14.36
Epoch :: 34 || Loss: 0.41204589 || it_count: 8344 || Val Loss: 0.42758870 || Val it_count: 1107 || Current Learning Rate: 0.0001 || Time: 05:26:55.03
Epoch :: 35 || Loss: 0.41167407 || it_count: 8344 || Val Loss: 0.42760544 || Val it_count: 1107 || Current Learning Rate: 0.0001 || Time: 05:36:35.49
Epoch :: 36 || Loss: 0.41141705 || it_count: 8344 || Val Loss: 0.42746521 || Val it_count: 1107 || Current Learning Rate: 0.0001 || Time: 05:46:15.71
Epoch :: 37 || Loss: 0.41113747 || it_count: 8344 || Val Loss: 0.42775628 || Val it_count: 1107 || Current Learning Rate: 0.0001 || Time: 05:55:56.66
Epoch :: 38 || Loss: 0.41094514 || it_count: 8344 || Val Loss: 0.42801140 || Val it_count: 1107 || Current Learning Rate: 0.0001 || Time: 06:05:36.98
Epoch :: 39 || Loss: 0.41065776 || it_count: 8344 || Val Loss: 0.42862255 || Val it_count: 1107 || Current Learning Rate: 0.0001 || Time: 06:15:17.56
Epoch :: 40 || Loss: 0.41052236 || it_count: 8344 || Val Loss: 0.42868931 || Val it_count: 1107 || Current Learning Rate: 0.0001 || Time: 06:24:57.72
Epoch :: 41 || Loss: 0.41032357 || it_count: 8344 || Val Loss: 0.42912502 || Val it_count: 1107 || Current Learning Rate: 0.0001 || Time: 06:34:38.08
Epoch 00026: reducing learning rate of group 0 to 1.0000e-05.
Epoch :: 42 || Loss: 0.41017161 || it_count: 8344 || Val Loss: 0.42915560 || Val it_count: 1107 || Current Learning Rate: 1e-05 || Time: 06:44:18.13
Epoch :: 43 || Loss: 0.41388924 || it_count: 8344 || Val Loss: 0.41635722 || Val it_count: 1107 || Current Learning Rate: 1e-05 || Time: 06:53:59.26
Epoch :: 44 || Loss: 0.41134524 || it_count: 8344 || Val Loss: 0.41570149 || Val it_count: 1107 || Current Learning Rate: 1e-05 || Time: 07:03:40.05
Epoch :: 45 || Loss: 0.41113337 || it_count: 8344 || Val Loss: 0.41558827 || Val it_count: 1107 || Current Learning Rate: 1e-05 || Time: 07:13:20.31
Epoch :: 46 || Loss: 0.41106475 || it_count: 8344 || Val Loss: 0.41553174 || Val it_count: 1107 || Current Learning Rate: 1e-05 || Time: 07:23:0.93
Epoch :: 47 || Loss: 0.41098768 || it_count: 8344 || Val Loss: 0.41552298 || Val it_count: 1107 || Current Learning Rate: 1e-05 || Time: 07:32:41.96
Epoch :: 48 || Loss: 0.41090508 || it_count: 8344 || Val Loss: 0.41546878 || Val it_count: 1107 || Current Learning Rate: 1e-05 || Time: 07:42:22.67
Epoch :: 49 || Loss: 0.41085702 || it_count: 8344 || Val Loss: 0.41544712 || Val it_count: 1107 || Current Learning Rate: 1e-05 || Time: 07:52:3.16
Epoch :: 50 || Loss: 0.41082125 || it_count: 8344 || Val Loss: 0.41541821 || Val it_count: 1107 || Current Learning Rate: 1e-05 || Time: 08:01:44.30
Epoch :: 51 || Loss: 0.41073063 || it_count: 8344 || Val Loss: 0.41537867 || Val it_count: 1107 || Current Learning Rate: 1e-05 || Time: 08:11:25.35
Epoch :: 52 || Loss: 0.41073062 || it_count: 8344 || Val Loss: 0.41538183 || Val it_count: 1107 || Current Learning Rate: 1e-05 || Time: 08:21:5.67
Epoch :: 53 || Loss: 0.41066320 || it_count: 8344 || Val Loss: 0.41533991 || Val it_count: 1107 || Current Learning Rate: 1e-05 || Time: 08:30:46.92
Epoch :: 54 || Loss: 0.41064028 || it_count: 8344 || Val Loss: 0.41533101 || Val it_count: 1107 || Current Learning Rate: 1e-05 || Time: 08:40:27.88
Epoch :: 55 || Loss: 0.41055369 || it_count: 8344 || Val Loss: 0.41530607 || Val it_count: 1107 || Current Learning Rate: 1e-05 || Time: 08:50:8.71
Epoch :: 56 || Loss: 0.41052307 || it_count: 8344 || Val Loss: 0.41528243 || Val it_count: 1107 || Current Learning Rate: 1e-05 || Time: 08:59:50.09
Epoch :: 57 || Loss: 0.41049891 || it_count: 8344 || Val Loss: 0.41529504 || Val it_count: 1107 || Current Learning Rate: 1e-05 || Time: 09:09:30.99
Epoch :: 58 || Loss: 0.41047847 || it_count: 8344 || Val Loss: 0.41526438 || Val it_count: 1107 || Current Learning Rate: 1e-05 || Time: 09:19:11.39
Epoch :: 59 || Loss: 0.41045829 || it_count: 8344 || Val Loss: 0.41520488 || Val it_count: 1107 || Current Learning Rate: 1e-05 || Time: 09:28:52.56
Epoch :: 60 || Loss: 0.41042141 || it_count: 8344 || Val Loss: 0.41522348 || Val it_count: 1107 || Current Learning Rate: 1e-05 || Time: 09:38:33.55
Epoch :: 61 || Loss: 0.41037043 || it_count: 8344 || Val Loss: 0.41516628 || Val it_count: 1107 || Current Learning Rate: 1e-05 || Time: 09:48:14.01
Epoch :: 62 || Loss: 0.41033900 || it_count: 8344 || Val Loss: 0.41513222 || Val it_count: 1107 || Current Learning Rate: 1e-05 || Time: 09:57:53.94
Epoch :: 63 || Loss: 0.41031777 || it_count: 8344 || Val Loss: 0.41512759 || Val it_count: 1107 || Current Learning Rate: 1e-05 || Time: 10:07:34.35
Epoch :: 64 || Loss: 0.41028263 || it_count: 8344 || Val Loss: 0.41508131 || Val it_count: 1107 || Current Learning Rate: 1e-05 || Time: 10:17:15.20
Epoch :: 65 || Loss: 0.41028611 || it_count: 8344 || Val Loss: 0.41511478 || Val it_count: 1107 || Current Learning Rate: 1e-05 || Time: 10:26:56.11
Epoch :: 66 || Loss: 0.41027365 || it_count: 8344 || Val Loss: 0.41507481 || Val it_count: 1107 || Current Learning Rate: 1e-05 || Time: 10:36:37.17
Epoch :: 67 || Loss: 0.41020284 || it_count: 8344 || Val Loss: 0.41507954 || Val it_count: 1107 || Current Learning Rate: 1e-05 || Time: 10:46:18.06
Epoch :: 68 || Loss: 0.41019669 || it_count: 8344 || Val Loss: 0.41502070 || Val it_count: 1107 || Current Learning Rate: 1e-05 || Time: 10:55:59.70
Epoch :: 69 || Loss: 0.41019765 || it_count: 8344 || Val Loss: 0.41499156 || Val it_count: 1107 || Current Learning Rate: 1e-05 || Time: 11:05:41.34
Epoch :: 70 || Loss: 0.41012416 || it_count: 8344 || Val Loss: 0.41495480 || Val it_count: 1107 || Current Learning Rate: 1e-05 || Time: 11:15:22.70
Epoch :: 71 || Loss: 0.41015272 || it_count: 8344 || Val Loss: 0.41501726 || Val it_count: 1107 || Current Learning Rate: 1e-05 || Time: 11:25:3.53
Epoch :: 72 || Loss: 0.41009142 || it_count: 8344 || Val Loss: 0.41499698 || Val it_count: 1107 || Current Learning Rate: 1e-05 || Time: 11:34:44.14
Epoch :: 73 || Loss: 0.41005936 || it_count: 8344 || Val Loss: 0.41503376 || Val it_count: 1107 || Current Learning Rate: 1e-05 || Time: 11:44:25.59
Epoch :: 74 || Loss: 0.41005283 || it_count: 8344 || Val Loss: 0.41501102 || Val it_count: 1107 || Current Learning Rate: 1e-05 || Time: 11:54:5.98
Epoch :: 75 || Loss: 0.41006065 || it_count: 8344 || Val Loss: 0.41496514 || Val it_count: 1107 || Current Learning Rate: 1e-05 || Time: 12:03:46.97
Epoch 00060: reducing learning rate of group 0 to 1.0000e-06.
Epoch :: 76 || Loss: 0.41000831 || it_count: 8344 || Val Loss: 0.41493253 || Val it_count: 1107 || Current Learning Rate: 1.0000000000000002e-06 || Time: 12:13:27.64
Epoch :: 77 || Loss: 0.41032453 || it_count: 8344 || Val Loss: 0.41381520 || Val it_count: 1107 || Current Learning Rate: 1.0000000000000002e-06 || Time: 12:23:8.71
Epoch :: 78 || Loss: 0.41020893 || it_count: 8344 || Val Loss: 0.41380133 || Val it_count: 1107 || Current Learning Rate: 1.0000000000000002e-06 || Time: 12:32:49.79
Epoch :: 79 || Loss: 0.41013831 || it_count: 8344 || Val Loss: 0.41382348 || Val it_count: 1107 || Current Learning Rate: 1.0000000000000002e-06 || Time: 12:42:30.76
Epoch :: 80 || Loss: 0.41012900 || it_count: 8344 || Val Loss: 0.41383063 || Val it_count: 1107 || Current Learning Rate: 1.0000000000000002e-06 || Time: 12:52:11.00
Epoch :: 81 || Loss: 0.41010775 || it_count: 8344 || Val Loss: 0.41383186 || Val it_count: 1107 || Current Learning Rate: 1.0000000000000002e-06 || Time: 13:01:51.83
Epoch :: 82 || Loss: 0.41013219 || it_count: 8344 || Val Loss: 0.41382551 || Val it_count: 1107 || Current Learning Rate: 1.0000000000000002e-06 || Time: 13:11:32.88
Epoch 00067: reducing learning rate of group 0 to 1.0000e-07.
Early stopping triggered due to learning rate below threshold.
Done Total time: 13:21:13.95
best_loss: 0.41380133018544074

--------------------Testing--------------------

total_samples :: test_dataset = 139200, test_dataloader = 139200
Epoch ::  1 || Loss: 0.23626222 || it_count: 544 || Time: 00:00:24.47
MAE:  0.25433564
MSE:  0.23628065
RMSE:  0.44236848

--------------------Training--------------------
arch_str :: |none~0|+|skip_connect~0|lstm_2~1|[relu->dropout->linear->relu->dropout->linear]
model :: 3T
InferCell(
  info :: nodes=3, inC=1, outC=64, [1<-(I0-L0) | 2<-(I0-L1,I1-L2)], genotype_str: none~0|skip_connect~0|lstm_2~1
  linear_layers: [relu->dropout->linear->relu->dropout->linear]
  (layers): ModuleList(
    (0): Zero(C_in=1, C_out=64, stride=1)
    (1): FactorizedReduce(
      C_in=1, C_out=64, stride=1
      (relu): ReLU()
      (conv): Conv1d(1, 64, kernel_size=(1,), stride=(1,), bias=False)
      (bn): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (2): LSTM(
      (lstm): LSTM(64, 64, num_layers=2, batch_first=True)
    )
  )
  (linear_layers): ModuleList(
    (0): ReLU()
    (1): Dropout(p=0.1, inplace=False)
    (2): Linear(in_features=3072, out_features=1536, bias=True)
    (3): ReLU()
    (4): Dropout(p=0.1, inplace=False)
    (5): Linear(in_features=1536, out_features=1, bias=True)
  )
)
tr_params :: epochs = 100, patience = 20, batch_size = 256, window_size = 48, data_size = 100
Model MACs: 7.980M, Model Params: 4.788M
learning rate scheduling :: (optimizer, mode='min', factor=0.1, patience=5, verbose=True)
total_samples :: train_dataset = 2136000, train_dataloader = 2136000
total_samples :: valid_dataset = 283200, valid_dataloader = 283200
Epoch ::  1 || Loss: 0.51404667 || it_count: 8344 || Val Loss: 0.47467074 || Val it_count: 1107 || Current Learning Rate: 0.001 || Time: 00:04:13.59
Epoch ::  2 || Loss: 0.47922219 || it_count: 8344 || Val Loss: 0.50442960 || Val it_count: 1107 || Current Learning Rate: 0.001 || Time: 00:08:23.59
Epoch ::  3 || Loss: 0.47043871 || it_count: 8344 || Val Loss: 0.50918503 || Val it_count: 1107 || Current Learning Rate: 0.001 || Time: 00:12:34.87
Epoch ::  4 || Loss: 0.46418855 || it_count: 8344 || Val Loss: 0.56208514 || Val it_count: 1107 || Current Learning Rate: 0.001 || Time: 00:16:45.79
Epoch ::  5 || Loss: 0.46467575 || it_count: 8344 || Val Loss: 0.48691069 || Val it_count: 1107 || Current Learning Rate: 0.001 || Time: 00:20:57.44
Epoch ::  6 || Loss: 0.46376864 || it_count: 8344 || Val Loss: 0.48565370 || Val it_count: 1107 || Current Learning Rate: 0.001 || Time: 00:25:8.38
Epoch ::  7 || Loss: 0.46420270 || it_count: 8344 || Val Loss: 0.52146903 || Val it_count: 1107 || Current Learning Rate: 0.001 || Time: 00:29:18.47
Epoch ::  8 || Loss: 0.46380097 || it_count: 8344 || Val Loss: 0.53722717 || Val it_count: 1107 || Current Learning Rate: 0.001 || Time: 00:33:27.34
Epoch ::  9 || Loss: 0.46316412 || it_count: 8344 || Val Loss: 0.53459992 || Val it_count: 1107 || Current Learning Rate: 0.001 || Time: 00:37:35.57
Epoch :: 10 || Loss: 0.46069105 || it_count: 8344 || Val Loss: 0.52899968 || Val it_count: 1107 || Current Learning Rate: 0.001 || Time: 00:41:45.55
Epoch :: 11 || Loss: 0.45841350 || it_count: 8344 || Val Loss: 0.52070129 || Val it_count: 1107 || Current Learning Rate: 0.001 || Time: 00:45:58.46
Epoch :: 12 || Loss: 0.46314953 || it_count: 8344 || Val Loss: 0.53219487 || Val it_count: 1107 || Current Learning Rate: 0.001 || Time: 00:50:9.30
Epoch :: 13 || Loss: 0.46094632 || it_count: 8344 || Val Loss: 0.51205234 || Val it_count: 1107 || Current Learning Rate: 0.001 || Time: 00:54:22.12
Epoch :: 14 || Loss: 0.46000188 || it_count: 8344 || Val Loss: 0.52845709 || Val it_count: 1107 || Current Learning Rate: 0.001 || Time: 00:58:32.80
Epoch :: 15 || Loss: 0.45893797 || it_count: 8344 || Val Loss: 0.51145942 || Val it_count: 1107 || Current Learning Rate: 0.001 || Time: 01:02:47.61
Epoch :: 16 || Loss: 0.45986463 || it_count: 8344 || Val Loss: 0.47462066 || Val it_count: 1107 || Current Learning Rate: 0.001 || Time: 01:07:0.52
Epoch :: 17 || Loss: 0.45751555 || it_count: 8344 || Val Loss: 0.51605620 || Val it_count: 1107 || Current Learning Rate: 0.001 || Time: 01:11:11.73
Epoch :: 18 || Loss: 0.45853544 || it_count: 8344 || Val Loss: 0.50547923 || Val it_count: 1107 || Current Learning Rate: 0.001 || Time: 01:15:19.16
Epoch :: 19 || Loss: 0.45761465 || it_count: 8344 || Val Loss: 0.51679314 || Val it_count: 1107 || Current Learning Rate: 0.001 || Time: 01:19:27.97
Epoch :: 20 || Loss: 0.46139334 || it_count: 8344 || Val Loss: 0.50344412 || Val it_count: 1107 || Current Learning Rate: 0.001 || Time: 01:23:36.67
Epoch :: 21 || Loss: 0.45885193 || it_count: 8344 || Val Loss: 0.48856883 || Val it_count: 1107 || Current Learning Rate: 0.001 || Time: 01:27:42.72
Epoch :: 22 || Loss: 0.45895883 || it_count: 8344 || Val Loss: 0.51058829 || Val it_count: 1107 || Current Learning Rate: 0.001 || Time: 01:31:51.48
Epoch :: 23 || Loss: 0.45768872 || it_count: 8344 || Val Loss: 0.51350913 || Val it_count: 1107 || Current Learning Rate: 0.001 || Time: 01:35:59.98
Epoch :: 24 || Loss: 0.46270958 || it_count: 8344 || Val Loss: 0.50429393 || Val it_count: 1107 || Current Learning Rate: 0.001 || Time: 01:40:7.66
Epoch :: 25 || Loss: 0.46113676 || it_count: 8344 || Val Loss: 0.50395606 || Val it_count: 1107 || Current Learning Rate: 0.001 || Time: 01:44:16.13
Epoch :: 26 || Loss: 0.45814309 || it_count: 8344 || Val Loss: 0.50957598 || Val it_count: 1107 || Current Learning Rate: 0.001 || Time: 01:48:24.75
Epoch :: 27 || Loss: 0.45877037 || it_count: 8344 || Val Loss: 0.50212029 || Val it_count: 1107 || Current Learning Rate: 0.0001 || Time: 01:52:33.63
Epoch :: 28 || Loss: 0.46044611 || it_count: 8344 || Val Loss: 0.50803415 || Val it_count: 1107 || Current Learning Rate: 0.0001 || Time: 01:56:42.87
Epoch :: 29 || Loss: 0.45028185 || it_count: 8344 || Val Loss: 0.51223188 || Val it_count: 1107 || Current Learning Rate: 0.0001 || Time: 02:00:58.94
Epoch :: 30 || Loss: 0.44783338 || it_count: 8344 || Val Loss: 0.48611737 || Val it_count: 1107 || Current Learning Rate: 0.0001 || Time: 02:05:21.69
Epoch :: 31 || Loss: 0.44669945 || it_count: 8344 || Val Loss: 0.51261091 || Val it_count: 1107 || Current Learning Rate: 0.0001 || Time: 02:09:32.62
Epoch :: 32 || Loss: 0.44555714 || it_count: 8344 || Val Loss: 0.50622528 || Val it_count: 1107 || Current Learning Rate: 0.0001 || Time: 02:13:30.95
Epoch :: 33 || Loss: 0.44374740 || it_count: 8344 || Val Loss: 0.48128702 || Val it_count: 1107 || Current Learning Rate: 0.0001 || Time: 02:17:30.49
Epoch :: 34 || Loss: 0.44385223 || it_count: 8344 || Val Loss: 0.50295146 || Val it_count: 1107 || Current Learning Rate: 0.0001 || Time: 02:21:27.54
Epoch :: 35 || Loss: 0.44265451 || it_count: 8344 || Val Loss: 0.50400871 || Val it_count: 1107 || Current Learning Rate: 0.0001 || Time: 02:25:25.11
Epoch :: 36 || Loss: 0.44254677 || it_count: 8344 || Val Loss: 0.49450530 || Val it_count: 1107 || Current Learning Rate: 0.0001 || Time: 02:29:22.07
Early stopping triggered due to patience exceeded.
Done Total time: 02:29:22.07
best_loss: 0.4746206576323897

--------------------Testing--------------------

total_samples :: test_dataset = 139200, test_dataloader = 139200
Epoch ::  1 || Loss: 0.43185037 || it_count: 544 || Time: 00:00:12.49
MAE:  0.33309972
MSE:  0.43196058
RMSE:  0.5303434

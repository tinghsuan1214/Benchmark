--------------------Training--------------------
arch_str :: |lstm_3~0|+|lstm_3~0|lstm_1~1|[linear->dropout->linear]
model :: 3F
InferCell(
  info :: nodes=3, inC=1, outC=64, [1<-(I0-L0) | 2<-(I0-L1,I1-L2)], genotype_str: lstm_3~0|lstm_3~0|lstm_1~1
  linear_layers: [linear->dropout->linear]
  (layers): ModuleList(
    (0-1): 2 x LSTM(
      (lstm): LSTM(1, 64, num_layers=3, batch_first=True)
    )
    (2): LSTM(
      (lstm): LSTM(64, 64, batch_first=True)
    )
  )
  (linear_layers): ModuleList(
    (0): Linear(in_features=3072, out_features=1536, bias=True)
    (1): Dropout(p=0.1, inplace=False)
    (2): Linear(in_features=1536, out_features=1, bias=True)
  )
)
tr_params :: epochs = 100, patience = 20, batch_size = 256, window_size = 48, data_size = 100
Model MACs: 14.526M, Model Params: 4.922M
learning rate scheduling :: (optimizer, mode='min', factor=0.1, patience=5, verbose=True)
total_samples :: train_dataset = 2136000, train_dataloader = 2136000
total_samples :: valid_dataset = 283200, valid_dataloader = 283200
Epoch ::  1 || Loss: 0.42763532 || it_count: 8344 || Val Loss: 0.46240251 || Val it_count: 1107 || Current Learning Rate: 0.001 || Time: 00:09:16.12
Epoch ::  2 || Loss: 0.41762121 || it_count: 8344 || Val Loss: 0.45173981 || Val it_count: 1107 || Current Learning Rate: 0.001 || Time: 00:18:25.57
Epoch ::  3 || Loss: 0.41630554 || it_count: 8344 || Val Loss: 0.44860590 || Val it_count: 1107 || Current Learning Rate: 0.001 || Time: 00:27:37.15
Epoch ::  4 || Loss: 0.41629230 || it_count: 8344 || Val Loss: 0.44961604 || Val it_count: 1107 || Current Learning Rate: 0.001 || Time: 00:36:18.11
Epoch ::  5 || Loss: 0.41658903 || it_count: 8344 || Val Loss: 0.45052469 || Val it_count: 1107 || Current Learning Rate: 0.001 || Time: 00:45:1.93
Epoch ::  6 || Loss: 0.41654087 || it_count: 8344 || Val Loss: 0.45119684 || Val it_count: 1107 || Current Learning Rate: 0.001 || Time: 00:53:28.16
Epoch ::  7 || Loss: 0.41652916 || it_count: 8344 || Val Loss: 0.45051552 || Val it_count: 1107 || Current Learning Rate: 0.001 || Time: 01:02:19.81
Epoch ::  8 || Loss: 0.41619146 || it_count: 8344 || Val Loss: 0.45073973 || Val it_count: 1107 || Current Learning Rate: 0.001 || Time: 01:11:8.86
Epoch ::  9 || Loss: 0.41597813 || it_count: 8344 || Val Loss: 0.45044790 || Val it_count: 1107 || Current Learning Rate: 0.001 || Time: 01:20:0.92
Epoch :: 10 || Loss: 0.41568781 || it_count: 8344 || Val Loss: 0.45054605 || Val it_count: 1107 || Current Learning Rate: 0.001 || Time: 01:28:53.48
Epoch :: 11 || Loss: 0.41534622 || it_count: 8344 || Val Loss: 0.45164523 || Val it_count: 1107 || Current Learning Rate: 0.001 || Time: 01:37:24.50
Epoch :: 12 || Loss: 0.41503166 || it_count: 8344 || Val Loss: 0.45122170 || Val it_count: 1107 || Current Learning Rate: 0.001 || Time: 01:46:18.65
Epoch :: 13 || Loss: 0.41524419 || it_count: 8344 || Val Loss: 0.44949545 || Val it_count: 1107 || Current Learning Rate: 0.001 || Time: 01:54:55.54
Epoch :: 14 || Loss: 0.41479433 || it_count: 8344 || Val Loss: 0.45097608 || Val it_count: 1107 || Current Learning Rate: 0.001 || Time: 02:03:49.57
Epoch :: 15 || Loss: 0.41442668 || it_count: 8344 || Val Loss: 0.44988197 || Val it_count: 1107 || Current Learning Rate: 0.001 || Time: 02:12:45.03
Epoch :: 16 || Loss: 0.41425376 || it_count: 8344 || Val Loss: 0.45019354 || Val it_count: 1107 || Current Learning Rate: 0.001 || Time: 02:21:31.66
Epoch :: 17 || Loss: 0.41385302 || it_count: 8344 || Val Loss: 0.44958049 || Val it_count: 1107 || Current Learning Rate: 0.001 || Time: 02:30:26.22
Epoch :: 18 || Loss: 0.41360391 || it_count: 8344 || Val Loss: 0.44985145 || Val it_count: 1107 || Current Learning Rate: 0.001 || Time: 02:39:1.14
Epoch :: 19 || Loss: 0.41344415 || it_count: 8344 || Val Loss: 0.44918470 || Val it_count: 1107 || Current Learning Rate: 0.001 || Time: 02:47:55.96
Epoch :: 20 || Loss: 0.41309733 || it_count: 8344 || Val Loss: 0.44897169 || Val it_count: 1107 || Current Learning Rate: 0.001 || Time: 02:56:43.14
Epoch :: 21 || Loss: 0.41258569 || it_count: 8344 || Val Loss: 0.44740983 || Val it_count: 1107 || Current Learning Rate: 0.001 || Time: 03:05:38.34
Epoch :: 22 || Loss: 0.41207914 || it_count: 8344 || Val Loss: 0.44593822 || Val it_count: 1107 || Current Learning Rate: 0.001 || Time: 03:14:35.17
Epoch :: 23 || Loss: 0.41177939 || it_count: 8344 || Val Loss: 0.44625636 || Val it_count: 1107 || Current Learning Rate: 0.001 || Time: 03:23:16.79
Epoch :: 24 || Loss: 0.41078590 || it_count: 8344 || Val Loss: 0.44634253 || Val it_count: 1107 || Current Learning Rate: 0.001 || Time: 03:32:13.11
Epoch :: 25 || Loss: 0.41037822 || it_count: 8344 || Val Loss: 0.44705121 || Val it_count: 1107 || Current Learning Rate: 0.001 || Time: 03:40:47.32
Epoch :: 26 || Loss: 0.40975233 || it_count: 8344 || Val Loss: 0.44679271 || Val it_count: 1107 || Current Learning Rate: 0.001 || Time: 03:49:42.83
Epoch :: 27 || Loss: 0.40929769 || it_count: 8344 || Val Loss: 0.44655013 || Val it_count: 1107 || Current Learning Rate: 0.001 || Time: 03:58:36.13
Epoch 00012: reducing learning rate of group 0 to 1.0000e-04.
Epoch :: 28 || Loss: 0.40896757 || it_count: 8344 || Val Loss: 0.44608781 || Val it_count: 1107 || Current Learning Rate: 0.0001 || Time: 04:07:31.77
Epoch :: 29 || Loss: 0.41475610 || it_count: 8344 || Val Loss: 0.43135385 || Val it_count: 1107 || Current Learning Rate: 0.0001 || Time: 04:16:27.02
Epoch :: 30 || Loss: 0.41222773 || it_count: 8344 || Val Loss: 0.42985877 || Val it_count: 1107 || Current Learning Rate: 0.0001 || Time: 04:25:2.00
Epoch :: 31 || Loss: 0.41128849 || it_count: 8344 || Val Loss: 0.42923442 || Val it_count: 1107 || Current Learning Rate: 0.0001 || Time: 04:33:57.04
Epoch :: 32 || Loss: 0.41058769 || it_count: 8344 || Val Loss: 0.42881556 || Val it_count: 1107 || Current Learning Rate: 0.0001 || Time: 04:42:30.16
Epoch :: 33 || Loss: 0.41018116 || it_count: 8344 || Val Loss: 0.42903591 || Val it_count: 1107 || Current Learning Rate: 0.0001 || Time: 04:51:25.87
Epoch :: 34 || Loss: 0.40985089 || it_count: 8344 || Val Loss: 0.42877822 || Val it_count: 1107 || Current Learning Rate: 0.0001 || Time: 05:00:23.73
Epoch :: 35 || Loss: 0.40953901 || it_count: 8344 || Val Loss: 0.42852344 || Val it_count: 1107 || Current Learning Rate: 0.0001 || Time: 05:09:18.62
Epoch :: 36 || Loss: 0.40923644 || it_count: 8344 || Val Loss: 0.42830153 || Val it_count: 1107 || Current Learning Rate: 0.0001 || Time: 05:18:13.30
Epoch :: 37 || Loss: 0.40892884 || it_count: 8344 || Val Loss: 0.42800453 || Val it_count: 1107 || Current Learning Rate: 0.0001 || Time: 05:26:46.63
Epoch :: 38 || Loss: 0.40868804 || it_count: 8344 || Val Loss: 0.42761105 || Val it_count: 1107 || Current Learning Rate: 0.0001 || Time: 05:35:41.44
Epoch :: 39 || Loss: 0.40842804 || it_count: 8344 || Val Loss: 0.42754903 || Val it_count: 1107 || Current Learning Rate: 0.0001 || Time: 05:44:18.56
Epoch :: 40 || Loss: 0.40816495 || it_count: 8344 || Val Loss: 0.42748262 || Val it_count: 1107 || Current Learning Rate: 0.0001 || Time: 05:53:13.41
Epoch :: 41 || Loss: 0.40788286 || it_count: 8344 || Val Loss: 0.42717316 || Val it_count: 1107 || Current Learning Rate: 0.0001 || Time: 06:02:10.01
Epoch :: 42 || Loss: 0.40766210 || it_count: 8344 || Val Loss: 0.42710657 || Val it_count: 1107 || Current Learning Rate: 0.0001 || Time: 06:10:58.49
Epoch :: 43 || Loss: 0.40744979 || it_count: 8344 || Val Loss: 0.42747599 || Val it_count: 1107 || Current Learning Rate: 0.0001 || Time: 06:19:53.56
Epoch :: 44 || Loss: 0.40725492 || it_count: 8344 || Val Loss: 0.42779505 || Val it_count: 1107 || Current Learning Rate: 0.0001 || Time: 06:28:27.07
Epoch :: 45 || Loss: 0.40698583 || it_count: 8344 || Val Loss: 0.42807759 || Val it_count: 1107 || Current Learning Rate: 0.0001 || Time: 06:37:22.20
Epoch :: 46 || Loss: 0.40685734 || it_count: 8344 || Val Loss: 0.42842528 || Val it_count: 1107 || Current Learning Rate: 0.0001 || Time: 06:46:6.76
Epoch :: 47 || Loss: 0.40665853 || it_count: 8344 || Val Loss: 0.42853483 || Val it_count: 1107 || Current Learning Rate: 0.0001 || Time: 06:55:2.89
Epoch 00032: reducing learning rate of group 0 to 1.0000e-05.
Epoch :: 48 || Loss: 0.40650043 || it_count: 8344 || Val Loss: 0.42860261 || Val it_count: 1107 || Current Learning Rate: 1e-05 || Time: 07:03:58.57
Epoch :: 49 || Loss: 0.41134418 || it_count: 8344 || Val Loss: 0.41498187 || Val it_count: 1107 || Current Learning Rate: 1e-05 || Time: 07:12:42.18
Epoch :: 50 || Loss: 0.40875444 || it_count: 8344 || Val Loss: 0.41491967 || Val it_count: 1107 || Current Learning Rate: 1e-05 || Time: 07:21:38.26
Epoch :: 51 || Loss: 0.40844260 || it_count: 8344 || Val Loss: 0.41495615 || Val it_count: 1107 || Current Learning Rate: 1e-05 || Time: 07:30:11.50
Epoch :: 52 || Loss: 0.40822716 || it_count: 8344 || Val Loss: 0.41495998 || Val it_count: 1107 || Current Learning Rate: 1e-05 || Time: 07:39:5.72
Epoch :: 53 || Loss: 0.40815896 || it_count: 8344 || Val Loss: 0.41493434 || Val it_count: 1107 || Current Learning Rate: 1e-05 || Time: 07:47:55.84
Epoch :: 54 || Loss: 0.40806792 || it_count: 8344 || Val Loss: 0.41500010 || Val it_count: 1107 || Current Learning Rate: 1e-05 || Time: 07:56:49.44
Epoch :: 55 || Loss: 0.40799435 || it_count: 8344 || Val Loss: 0.41503354 || Val it_count: 1107 || Current Learning Rate: 1e-05 || Time: 08:05:42.97
Epoch 00040: reducing learning rate of group 0 to 1.0000e-06.
Epoch :: 56 || Loss: 0.40794609 || it_count: 8344 || Val Loss: 0.41511953 || Val it_count: 1107 || Current Learning Rate: 1.0000000000000002e-06 || Time: 08:14:17.39
Epoch :: 57 || Loss: 0.40849746 || it_count: 8344 || Val Loss: 0.41380918 || Val it_count: 1107 || Current Learning Rate: 1.0000000000000002e-06 || Time: 08:23:10.77
Epoch :: 58 || Loss: 0.40813050 || it_count: 8344 || Val Loss: 0.41352214 || Val it_count: 1107 || Current Learning Rate: 1.0000000000000002e-06 || Time: 08:31:43.45
Epoch :: 59 || Loss: 0.40802402 || it_count: 8344 || Val Loss: 0.41343376 || Val it_count: 1107 || Current Learning Rate: 1.0000000000000002e-06 || Time: 08:40:37.53
Epoch :: 60 || Loss: 0.40802602 || it_count: 8344 || Val Loss: 0.41341040 || Val it_count: 1107 || Current Learning Rate: 1.0000000000000002e-06 || Time: 08:49:33.60
Epoch :: 61 || Loss: 0.40797843 || it_count: 8344 || Val Loss: 0.41339857 || Val it_count: 1107 || Current Learning Rate: 1.0000000000000002e-06 || Time: 08:58:27.43
Epoch :: 62 || Loss: 0.40798206 || it_count: 8344 || Val Loss: 0.41338828 || Val it_count: 1107 || Current Learning Rate: 1.0000000000000002e-06 || Time: 09:07:21.16
Epoch :: 63 || Loss: 0.40796242 || it_count: 8344 || Val Loss: 0.41338317 || Val it_count: 1107 || Current Learning Rate: 1.0000000000000002e-06 || Time: 09:15:53.64
Epoch :: 64 || Loss: 0.40797165 || it_count: 8344 || Val Loss: 0.41338214 || Val it_count: 1107 || Current Learning Rate: 1.0000000000000002e-06 || Time: 09:24:47.78
Epoch :: 65 || Loss: 0.40787901 || it_count: 8344 || Val Loss: 0.41336802 || Val it_count: 1107 || Current Learning Rate: 1.0000000000000002e-06 || Time: 09:33:28.31
Epoch :: 66 || Loss: 0.40791547 || it_count: 8344 || Val Loss: 0.41336098 || Val it_count: 1107 || Current Learning Rate: 1.0000000000000002e-06 || Time: 09:42:36.68
Epoch :: 67 || Loss: 0.40791900 || it_count: 8344 || Val Loss: 0.41335883 || Val it_count: 1107 || Current Learning Rate: 1.0000000000000002e-06 || Time: 09:51:43.01
Epoch 00052: reducing learning rate of group 0 to 1.0000e-07.
Early stopping triggered due to learning rate below threshold.
Done Total time: 10:00:31.71
best_loss: 0.41335883031007253

--------------------Testing--------------------

total_samples :: test_dataset = 139200, test_dataloader = 139200
Epoch ::  1 || Loss: 0.23600750 || it_count: 544 || Time: 00:00:18.17
MAE:  0.25326386
MSE:  0.23602578
RMSE:  0.44160157

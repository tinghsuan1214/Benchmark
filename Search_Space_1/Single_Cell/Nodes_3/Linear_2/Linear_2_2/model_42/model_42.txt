--------------------Training--------------------
arch_str :: |lstm_2~0|+|none~0|lstm_2~1|[linear->dropout->linear]
model :: 3F
InferCell(
  info :: nodes=3, inC=1, outC=64, [1<-(I0-L0) | 2<-(I0-L1,I1-L2)], genotype_str: lstm_2~0|none~0|lstm_2~1
  linear_layers: [linear->dropout->linear]
  (layers): ModuleList(
    (0): LSTM(
      (lstm): LSTM(1, 64, num_layers=2, batch_first=True)
    )
    (1): Zero(C_in=1, C_out=64, stride=1)
    (2): LSTM(
      (lstm): LSTM(64, 64, num_layers=2, batch_first=True)
    )
  )
  (linear_layers): ModuleList(
    (0): Linear(in_features=3072, out_features=1536, bias=True)
    (1): Dropout(p=0.1, inplace=False)
    (2): Linear(in_features=1536, out_features=1, bias=True)
  )
)
tr_params :: epochs = 100, patience = 20, batch_size = 256, window_size = 48, data_size = 100
Model MACs: 10.434M, Model Params: 4.839M
learning rate scheduling :: (optimizer, mode='min', factor=0.1, patience=5, verbose=True)
total_samples :: train_dataset = 2136000, train_dataloader = 2136000
total_samples :: valid_dataset = 283200, valid_dataloader = 283200
Epoch ::  1 || Loss: 0.43190961 || it_count: 8344 || Val Loss: 0.45422612 || Val it_count: 1107 || Current Learning Rate: 0.001 || Time: 00:04:35.48
Epoch ::  2 || Loss: 0.41872460 || it_count: 8344 || Val Loss: 0.45083623 || Val it_count: 1107 || Current Learning Rate: 0.001 || Time: 00:09:6.42
Epoch ::  3 || Loss: 0.41808904 || it_count: 8344 || Val Loss: 0.45406777 || Val it_count: 1107 || Current Learning Rate: 0.001 || Time: 00:13:40.04
Epoch ::  4 || Loss: 0.41747745 || it_count: 8344 || Val Loss: 0.45475601 || Val it_count: 1107 || Current Learning Rate: 0.001 || Time: 00:18:11.61
Epoch ::  5 || Loss: 0.41705321 || it_count: 8344 || Val Loss: 0.45434928 || Val it_count: 1107 || Current Learning Rate: 0.001 || Time: 00:22:43.76
Epoch ::  6 || Loss: 0.41676511 || it_count: 8344 || Val Loss: 0.45339244 || Val it_count: 1107 || Current Learning Rate: 0.001 || Time: 00:27:15.31
Epoch ::  7 || Loss: 0.41671945 || it_count: 8344 || Val Loss: 0.45293184 || Val it_count: 1107 || Current Learning Rate: 0.001 || Time: 00:31:46.68
Epoch ::  8 || Loss: 0.41624392 || it_count: 8344 || Val Loss: 0.45277754 || Val it_count: 1107 || Current Learning Rate: 0.001 || Time: 00:36:26.94
Epoch ::  9 || Loss: 0.42472528 || it_count: 8344 || Val Loss: 0.45023815 || Val it_count: 1107 || Current Learning Rate: 0.001 || Time: 00:41:6.56
Epoch :: 10 || Loss: 0.41579848 || it_count: 8344 || Val Loss: 0.45133916 || Val it_count: 1107 || Current Learning Rate: 0.001 || Time: 00:45:42.57
Epoch :: 11 || Loss: 0.41555197 || it_count: 8344 || Val Loss: 0.45190611 || Val it_count: 1107 || Current Learning Rate: 0.001 || Time: 00:50:17.71
Epoch :: 12 || Loss: 0.41784305 || it_count: 8344 || Val Loss: 0.44935353 || Val it_count: 1107 || Current Learning Rate: 0.001 || Time: 00:54:51.80
Epoch :: 13 || Loss: 0.41452901 || it_count: 8344 || Val Loss: 0.45203070 || Val it_count: 1107 || Current Learning Rate: 0.001 || Time: 00:59:24.59
Epoch :: 14 || Loss: 0.41370342 || it_count: 8344 || Val Loss: 0.45229318 || Val it_count: 1107 || Current Learning Rate: 0.001 || Time: 01:03:56.82
Epoch :: 15 || Loss: 0.41338947 || it_count: 8344 || Val Loss: 0.44957344 || Val it_count: 1107 || Current Learning Rate: 0.001 || Time: 01:08:29.52
Epoch :: 16 || Loss: 0.41277169 || it_count: 8344 || Val Loss: 0.45204951 || Val it_count: 1107 || Current Learning Rate: 0.001 || Time: 01:13:5.24
Epoch :: 17 || Loss: 0.41245846 || it_count: 8344 || Val Loss: 0.45042306 || Val it_count: 1107 || Current Learning Rate: 0.001 || Time: 01:17:41.42
Epoch :: 18 || Loss: 0.41217921 || it_count: 8344 || Val Loss: 0.44972743 || Val it_count: 1107 || Current Learning Rate: 0.001 || Time: 01:22:15.20
Epoch :: 19 || Loss: 0.41155204 || it_count: 8344 || Val Loss: 0.45018996 || Val it_count: 1107 || Current Learning Rate: 0.001 || Time: 01:26:47.97
Epoch :: 20 || Loss: 0.41143589 || it_count: 8344 || Val Loss: 0.44969970 || Val it_count: 1107 || Current Learning Rate: 0.001 || Time: 01:31:22.87
Epoch :: 21 || Loss: 0.41102040 || it_count: 8344 || Val Loss: 0.44984013 || Val it_count: 1107 || Current Learning Rate: 0.001 || Time: 01:35:55.88
Epoch :: 22 || Loss: 0.41080677 || it_count: 8344 || Val Loss: 0.44996145 || Val it_count: 1107 || Current Learning Rate: 0.001 || Time: 01:40:31.97
Epoch :: 23 || Loss: 0.41015611 || it_count: 8344 || Val Loss: 0.44976454 || Val it_count: 1107 || Current Learning Rate: 0.001 || Time: 01:45:5.28
Epoch 00008: reducing learning rate of group 0 to 1.0000e-04.
Epoch :: 24 || Loss: 0.40967186 || it_count: 8344 || Val Loss: 0.45066801 || Val it_count: 1107 || Current Learning Rate: 0.0001 || Time: 01:49:39.32
Epoch :: 25 || Loss: 0.41572075 || it_count: 8344 || Val Loss: 0.43142537 || Val it_count: 1107 || Current Learning Rate: 0.0001 || Time: 01:54:12.20
Epoch :: 26 || Loss: 0.41227932 || it_count: 8344 || Val Loss: 0.43131276 || Val it_count: 1107 || Current Learning Rate: 0.0001 || Time: 01:58:47.13
Epoch :: 27 || Loss: 0.41134338 || it_count: 8344 || Val Loss: 0.43112924 || Val it_count: 1107 || Current Learning Rate: 0.0001 || Time: 02:03:18.84
Epoch :: 28 || Loss: 0.41071691 || it_count: 8344 || Val Loss: 0.43128771 || Val it_count: 1107 || Current Learning Rate: 0.0001 || Time: 02:07:51.04
Epoch :: 29 || Loss: 0.41028440 || it_count: 8344 || Val Loss: 0.43135294 || Val it_count: 1107 || Current Learning Rate: 0.0001 || Time: 02:12:26.22
Epoch :: 30 || Loss: 0.40983340 || it_count: 8344 || Val Loss: 0.43124088 || Val it_count: 1107 || Current Learning Rate: 0.0001 || Time: 02:17:4.07
Epoch :: 31 || Loss: 0.40944638 || it_count: 8344 || Val Loss: 0.43120873 || Val it_count: 1107 || Current Learning Rate: 0.0001 || Time: 02:21:37.58
Epoch :: 32 || Loss: 0.40911398 || it_count: 8344 || Val Loss: 0.43093815 || Val it_count: 1107 || Current Learning Rate: 0.0001 || Time: 02:26:13.93
Epoch :: 33 || Loss: 0.40874276 || it_count: 8344 || Val Loss: 0.43115661 || Val it_count: 1107 || Current Learning Rate: 0.0001 || Time: 02:30:45.56
Epoch :: 34 || Loss: 0.40839309 || it_count: 8344 || Val Loss: 0.43105697 || Val it_count: 1107 || Current Learning Rate: 0.0001 || Time: 02:35:20.08
Epoch :: 35 || Loss: 0.40812838 || it_count: 8344 || Val Loss: 0.43102701 || Val it_count: 1107 || Current Learning Rate: 0.0001 || Time: 02:39:58.84
Epoch :: 36 || Loss: 0.40779981 || it_count: 8344 || Val Loss: 0.43163621 || Val it_count: 1107 || Current Learning Rate: 0.0001 || Time: 02:44:34.03
Epoch :: 37 || Loss: 0.40759902 || it_count: 8344 || Val Loss: 0.43155560 || Val it_count: 1107 || Current Learning Rate: 0.0001 || Time: 02:49:7.54
Epoch 00022: reducing learning rate of group 0 to 1.0000e-05.
Epoch :: 38 || Loss: 0.40726921 || it_count: 8344 || Val Loss: 0.43167096 || Val it_count: 1107 || Current Learning Rate: 1e-05 || Time: 02:53:45.67
Epoch :: 39 || Loss: 0.41177308 || it_count: 8344 || Val Loss: 0.41523230 || Val it_count: 1107 || Current Learning Rate: 1e-05 || Time: 02:58:22.69
Epoch :: 40 || Loss: 0.40896841 || it_count: 8344 || Val Loss: 0.41512111 || Val it_count: 1107 || Current Learning Rate: 1e-05 || Time: 03:02:58.54
Epoch :: 41 || Loss: 0.40859066 || it_count: 8344 || Val Loss: 0.41475989 || Val it_count: 1107 || Current Learning Rate: 1e-05 || Time: 03:07:35.27
Epoch :: 42 || Loss: 0.40843837 || it_count: 8344 || Val Loss: 0.41469601 || Val it_count: 1107 || Current Learning Rate: 1e-05 || Time: 03:12:12.19
Epoch :: 43 || Loss: 0.40834151 || it_count: 8344 || Val Loss: 0.41460228 || Val it_count: 1107 || Current Learning Rate: 1e-05 || Time: 03:16:47.37
Epoch :: 44 || Loss: 0.40821888 || it_count: 8344 || Val Loss: 0.41460735 || Val it_count: 1107 || Current Learning Rate: 1e-05 || Time: 03:21:21.64
Epoch :: 45 || Loss: 0.40816964 || it_count: 8344 || Val Loss: 0.41454202 || Val it_count: 1107 || Current Learning Rate: 1e-05 || Time: 03:25:53.92
Epoch :: 46 || Loss: 0.40809733 || it_count: 8344 || Val Loss: 0.41451913 || Val it_count: 1107 || Current Learning Rate: 1e-05 || Time: 03:30:29.83
Epoch :: 47 || Loss: 0.40805607 || it_count: 8344 || Val Loss: 0.41443216 || Val it_count: 1107 || Current Learning Rate: 1e-05 || Time: 03:35:4.15
Epoch :: 48 || Loss: 0.40797647 || it_count: 8344 || Val Loss: 0.41447427 || Val it_count: 1107 || Current Learning Rate: 1e-05 || Time: 03:39:43.27
Epoch :: 49 || Loss: 0.40794761 || it_count: 8344 || Val Loss: 0.41442418 || Val it_count: 1107 || Current Learning Rate: 1e-05 || Time: 03:44:21.81
Epoch :: 50 || Loss: 0.40785716 || it_count: 8344 || Val Loss: 0.41442051 || Val it_count: 1107 || Current Learning Rate: 1e-05 || Time: 03:48:56.55
Epoch :: 51 || Loss: 0.40780389 || it_count: 8344 || Val Loss: 0.41439499 || Val it_count: 1107 || Current Learning Rate: 1e-05 || Time: 03:53:29.79
Epoch :: 52 || Loss: 0.40774973 || it_count: 8344 || Val Loss: 0.41440197 || Val it_count: 1107 || Current Learning Rate: 1e-05 || Time: 03:58:2.43
Epoch :: 53 || Loss: 0.40773990 || it_count: 8344 || Val Loss: 0.41436200 || Val it_count: 1107 || Current Learning Rate: 1e-05 || Time: 04:02:37.67
Epoch :: 54 || Loss: 0.40768957 || it_count: 8344 || Val Loss: 0.41436109 || Val it_count: 1107 || Current Learning Rate: 1e-05 || Time: 04:07:11.02
Epoch :: 55 || Loss: 0.40766582 || it_count: 8344 || Val Loss: 0.41426839 || Val it_count: 1107 || Current Learning Rate: 1e-05 || Time: 04:11:45.15
Epoch :: 56 || Loss: 0.40758940 || it_count: 8344 || Val Loss: 0.41430352 || Val it_count: 1107 || Current Learning Rate: 1e-05 || Time: 04:16:18.49
Epoch :: 57 || Loss: 0.40758127 || it_count: 8344 || Val Loss: 0.41432684 || Val it_count: 1107 || Current Learning Rate: 1e-05 || Time: 04:20:51.27
Epoch :: 58 || Loss: 0.40749872 || it_count: 8344 || Val Loss: 0.41427967 || Val it_count: 1107 || Current Learning Rate: 1e-05 || Time: 04:25:23.89
Epoch :: 59 || Loss: 0.40748638 || it_count: 8344 || Val Loss: 0.41427742 || Val it_count: 1107 || Current Learning Rate: 1e-05 || Time: 04:29:56.65
Epoch :: 60 || Loss: 0.40745070 || it_count: 8344 || Val Loss: 0.41421182 || Val it_count: 1107 || Current Learning Rate: 1e-05 || Time: 04:34:28.69
Epoch :: 61 || Loss: 0.40742433 || it_count: 8344 || Val Loss: 0.41418644 || Val it_count: 1107 || Current Learning Rate: 1e-05 || Time: 04:38:58.94
Epoch :: 62 || Loss: 0.40738581 || it_count: 8344 || Val Loss: 0.41426495 || Val it_count: 1107 || Current Learning Rate: 1e-05 || Time: 04:43:30.52
Epoch :: 63 || Loss: 0.40730827 || it_count: 8344 || Val Loss: 0.41423879 || Val it_count: 1107 || Current Learning Rate: 1e-05 || Time: 04:48:6.56
Epoch :: 64 || Loss: 0.40728266 || it_count: 8344 || Val Loss: 0.41427399 || Val it_count: 1107 || Current Learning Rate: 1e-05 || Time: 04:52:40.27
Epoch :: 65 || Loss: 0.40729385 || it_count: 8344 || Val Loss: 0.41420549 || Val it_count: 1107 || Current Learning Rate: 1e-05 || Time: 04:57:14.77
Epoch 00050: reducing learning rate of group 0 to 1.0000e-06.
Epoch :: 66 || Loss: 0.40720469 || it_count: 8344 || Val Loss: 0.41422397 || Val it_count: 1107 || Current Learning Rate: 1.0000000000000002e-06 || Time: 05:01:49.14
Epoch :: 67 || Loss: 0.40766992 || it_count: 8344 || Val Loss: 0.41273901 || Val it_count: 1107 || Current Learning Rate: 1.0000000000000002e-06 || Time: 05:06:23.25
Epoch :: 68 || Loss: 0.40747004 || it_count: 8344 || Val Loss: 0.41268061 || Val it_count: 1107 || Current Learning Rate: 1.0000000000000002e-06 || Time: 05:10:56.31
Epoch :: 69 || Loss: 0.40740047 || it_count: 8344 || Val Loss: 0.41263420 || Val it_count: 1107 || Current Learning Rate: 1.0000000000000002e-06 || Time: 05:15:31.26
Epoch :: 70 || Loss: 0.40738247 || it_count: 8344 || Val Loss: 0.41261053 || Val it_count: 1107 || Current Learning Rate: 1.0000000000000002e-06 || Time: 05:20:4.61
Epoch :: 71 || Loss: 0.40731131 || it_count: 8344 || Val Loss: 0.41258545 || Val it_count: 1107 || Current Learning Rate: 1.0000000000000002e-06 || Time: 05:24:39.21
Epoch :: 72 || Loss: 0.40729563 || it_count: 8344 || Val Loss: 0.41255845 || Val it_count: 1107 || Current Learning Rate: 1.0000000000000002e-06 || Time: 05:29:12.45
Epoch :: 73 || Loss: 0.40733049 || it_count: 8344 || Val Loss: 0.41253822 || Val it_count: 1107 || Current Learning Rate: 1.0000000000000002e-06 || Time: 05:33:46.42
Epoch :: 74 || Loss: 0.40729808 || it_count: 8344 || Val Loss: 0.41252344 || Val it_count: 1107 || Current Learning Rate: 1.0000000000000002e-06 || Time: 05:38:19.89
Epoch :: 75 || Loss: 0.40724444 || it_count: 8344 || Val Loss: 0.41250070 || Val it_count: 1107 || Current Learning Rate: 1.0000000000000002e-06 || Time: 05:42:51.54
Epoch :: 76 || Loss: 0.40727590 || it_count: 8344 || Val Loss: 0.41248532 || Val it_count: 1107 || Current Learning Rate: 1.0000000000000002e-06 || Time: 05:47:24.53
Epoch :: 77 || Loss: 0.40725556 || it_count: 8344 || Val Loss: 0.41248742 || Val it_count: 1107 || Current Learning Rate: 1.0000000000000002e-06 || Time: 05:51:57.11
Epoch :: 78 || Loss: 0.40723457 || it_count: 8344 || Val Loss: 0.41246913 || Val it_count: 1107 || Current Learning Rate: 1.0000000000000002e-06 || Time: 05:56:32.34
Epoch :: 79 || Loss: 0.40721127 || it_count: 8344 || Val Loss: 0.41245476 || Val it_count: 1107 || Current Learning Rate: 1.0000000000000002e-06 || Time: 06:01:5.03
Epoch :: 80 || Loss: 0.40723176 || it_count: 8344 || Val Loss: 0.41242338 || Val it_count: 1107 || Current Learning Rate: 1.0000000000000002e-06 || Time: 06:05:40.69
Epoch :: 81 || Loss: 0.40719581 || it_count: 8344 || Val Loss: 0.41241978 || Val it_count: 1107 || Current Learning Rate: 1.0000000000000002e-06 || Time: 06:10:21.34
Epoch :: 82 || Loss: 0.40721381 || it_count: 8344 || Val Loss: 0.41241435 || Val it_count: 1107 || Current Learning Rate: 1.0000000000000002e-06 || Time: 06:14:57.53
Epoch :: 83 || Loss: 0.40720753 || it_count: 8344 || Val Loss: 0.41239963 || Val it_count: 1107 || Current Learning Rate: 1.0000000000000002e-06 || Time: 06:19:33.25
Epoch :: 84 || Loss: 0.40720461 || it_count: 8344 || Val Loss: 0.41238738 || Val it_count: 1107 || Current Learning Rate: 1.0000000000000002e-06 || Time: 06:24:8.04
Epoch :: 85 || Loss: 0.40720102 || it_count: 8344 || Val Loss: 0.41240440 || Val it_count: 1107 || Current Learning Rate: 1.0000000000000002e-06 || Time: 06:28:42.47
Epoch :: 86 || Loss: 0.40718171 || it_count: 8344 || Val Loss: 0.41237782 || Val it_count: 1107 || Current Learning Rate: 1.0000000000000002e-06 || Time: 06:33:14.70
Epoch :: 87 || Loss: 0.40720510 || it_count: 8344 || Val Loss: 0.41236888 || Val it_count: 1107 || Current Learning Rate: 1.0000000000000002e-06 || Time: 06:37:50.57
Epoch :: 88 || Loss: 0.40717910 || it_count: 8344 || Val Loss: 0.41237875 || Val it_count: 1107 || Current Learning Rate: 1.0000000000000002e-06 || Time: 06:42:25.43
Epoch :: 89 || Loss: 0.40717735 || it_count: 8344 || Val Loss: 0.41235825 || Val it_count: 1107 || Current Learning Rate: 1.0000000000000002e-06 || Time: 06:46:59.74
Epoch :: 90 || Loss: 0.40714595 || it_count: 8344 || Val Loss: 0.41235564 || Val it_count: 1107 || Current Learning Rate: 1.0000000000000002e-06 || Time: 06:51:35.75
Epoch :: 91 || Loss: 0.40717348 || it_count: 8344 || Val Loss: 0.41233940 || Val it_count: 1107 || Current Learning Rate: 1.0000000000000002e-06 || Time: 06:56:11.48
Epoch 00076: reducing learning rate of group 0 to 1.0000e-07.
Early stopping triggered due to learning rate below threshold.
Done Total time: 07:00:49.61
best_loss: 0.4123394049379955

--------------------Testing--------------------

total_samples :: test_dataset = 139200, test_dataloader = 139200
Epoch ::  1 || Loss: 0.23550066 || it_count: 544 || Time: 00:00:14.41
MAE:  0.25279272
MSE:  0.23552081
RMSE:  0.44102898

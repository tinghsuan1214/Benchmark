--------------------Training--------------------
arch_str :: |none~0|+|lstm_2~0|none~1|[linear->dropout->linear]
model :: 3F
InferCell(
  info :: nodes=3, inC=1, outC=64, [1<-(I0-L0) | 2<-(I0-L1,I1-L2)], genotype_str: none~0|lstm_2~0|none~1
  linear_layers: [linear->dropout->linear]
  (layers): ModuleList(
    (0): Zero(C_in=1, C_out=64, stride=1)
    (1): LSTM(
      (lstm): LSTM(1, 64, num_layers=2, batch_first=True)
    )
    (2): Zero(C_in=64, C_out=64, stride=1)
  )
  (linear_layers): ModuleList(
    (0): Linear(in_features=3072, out_features=1536, bias=True)
    (1): Dropout(p=0.1, inplace=False)
    (2): Linear(in_features=1536, out_features=1, bias=True)
  )
)
tr_params :: epochs = 100, patience = 20, batch_size = 256, window_size = 48, data_size = 100
Model MACs: 7.190M, Model Params: 4.772M
learning rate scheduling :: (optimizer, mode='min', factor=0.1, patience=5, verbose=True)
total_samples :: train_dataset = 2136000, train_dataloader = 2136000
total_samples :: valid_dataset = 283200, valid_dataloader = 283200
Epoch ::  1 || Loss: 0.42435911 || it_count: 8344 || Val Loss: 0.45095133 || Val it_count: 1107 || Current Learning Rate: 0.001 || Time: 00:07:48.64
Epoch ::  2 || Loss: 0.41724094 || it_count: 8344 || Val Loss: 0.44903792 || Val it_count: 1107 || Current Learning Rate: 0.001 || Time: 00:15:34.64
Epoch ::  3 || Loss: 0.41671482 || it_count: 8344 || Val Loss: 0.44780321 || Val it_count: 1107 || Current Learning Rate: 0.001 || Time: 00:23:19.22
Epoch ::  4 || Loss: 0.41646405 || it_count: 8344 || Val Loss: 0.44693502 || Val it_count: 1107 || Current Learning Rate: 0.001 || Time: 00:31:4.98
Epoch ::  5 || Loss: 0.41644900 || it_count: 8344 || Val Loss: 0.44780523 || Val it_count: 1107 || Current Learning Rate: 0.001 || Time: 00:38:53.07
Epoch ::  6 || Loss: 0.41612008 || it_count: 8344 || Val Loss: 0.44796577 || Val it_count: 1107 || Current Learning Rate: 0.001 || Time: 00:46:40.03
Epoch ::  7 || Loss: 0.41584360 || it_count: 8344 || Val Loss: 0.44765194 || Val it_count: 1107 || Current Learning Rate: 0.001 || Time: 00:54:26.87
Epoch ::  8 || Loss: 0.41572393 || it_count: 8344 || Val Loss: 0.44706559 || Val it_count: 1107 || Current Learning Rate: 0.001 || Time: 01:02:15.67
Epoch ::  9 || Loss: 0.41533286 || it_count: 8344 || Val Loss: 0.44715801 || Val it_count: 1107 || Current Learning Rate: 0.001 || Time: 01:10:5.32
Epoch :: 10 || Loss: 0.41516373 || it_count: 8344 || Val Loss: 0.44682912 || Val it_count: 1107 || Current Learning Rate: 0.001 || Time: 01:17:55.03
Epoch :: 11 || Loss: 0.41502261 || it_count: 8344 || Val Loss: 0.44681692 || Val it_count: 1107 || Current Learning Rate: 0.001 || Time: 01:25:44.32
Epoch :: 12 || Loss: 0.41483352 || it_count: 8344 || Val Loss: 0.44621654 || Val it_count: 1107 || Current Learning Rate: 0.001 || Time: 01:33:34.00
Epoch :: 13 || Loss: 0.41443627 || it_count: 8344 || Val Loss: 0.44638042 || Val it_count: 1107 || Current Learning Rate: 0.001 || Time: 01:41:24.51
Epoch :: 14 || Loss: 0.41414364 || it_count: 8344 || Val Loss: 0.44701023 || Val it_count: 1107 || Current Learning Rate: 0.001 || Time: 01:49:14.11
Epoch :: 15 || Loss: 0.41391966 || it_count: 8344 || Val Loss: 0.44698855 || Val it_count: 1107 || Current Learning Rate: 0.001 || Time: 01:57:4.19
Epoch :: 16 || Loss: 0.41374067 || it_count: 8344 || Val Loss: 0.44711082 || Val it_count: 1107 || Current Learning Rate: 0.001 || Time: 02:04:54.47
Epoch :: 17 || Loss: 0.41332704 || it_count: 8344 || Val Loss: 0.44664970 || Val it_count: 1107 || Current Learning Rate: 0.001 || Time: 02:12:44.15
Epoch :: 18 || Loss: 0.41297078 || it_count: 8344 || Val Loss: 0.44609317 || Val it_count: 1107 || Current Learning Rate: 0.001 || Time: 02:20:33.84
Epoch :: 19 || Loss: 0.41252806 || it_count: 8344 || Val Loss: 0.44522339 || Val it_count: 1107 || Current Learning Rate: 0.001 || Time: 02:28:24.05
Epoch :: 20 || Loss: 0.41208840 || it_count: 8344 || Val Loss: 0.44481784 || Val it_count: 1107 || Current Learning Rate: 0.001 || Time: 02:36:14.57
Epoch :: 21 || Loss: 0.41178615 || it_count: 8344 || Val Loss: 0.44458900 || Val it_count: 1107 || Current Learning Rate: 0.001 || Time: 02:44:4.49
Epoch :: 22 || Loss: 0.41144070 || it_count: 8344 || Val Loss: 0.44427140 || Val it_count: 1107 || Current Learning Rate: 0.001 || Time: 02:51:54.49
Epoch :: 23 || Loss: 0.41099527 || it_count: 8344 || Val Loss: 0.44458753 || Val it_count: 1107 || Current Learning Rate: 0.001 || Time: 02:59:45.54
Epoch :: 24 || Loss: 0.41050035 || it_count: 8344 || Val Loss: 0.44429800 || Val it_count: 1107 || Current Learning Rate: 0.001 || Time: 03:07:37.05
Epoch :: 25 || Loss: 0.40984564 || it_count: 8344 || Val Loss: 0.44606020 || Val it_count: 1107 || Current Learning Rate: 0.001 || Time: 03:15:28.22
Epoch :: 26 || Loss: 0.40909773 || it_count: 8344 || Val Loss: 0.44719210 || Val it_count: 1107 || Current Learning Rate: 0.001 || Time: 03:23:19.02
Epoch :: 27 || Loss: 0.40856591 || it_count: 8344 || Val Loss: 0.44674122 || Val it_count: 1107 || Current Learning Rate: 0.001 || Time: 03:31:10.46
Epoch 00012: reducing learning rate of group 0 to 1.0000e-04.
Epoch :: 28 || Loss: 0.40800320 || it_count: 8344 || Val Loss: 0.44596645 || Val it_count: 1107 || Current Learning Rate: 0.0001 || Time: 03:39:1.06
Epoch :: 29 || Loss: 0.41557472 || it_count: 8344 || Val Loss: 0.43168669 || Val it_count: 1107 || Current Learning Rate: 0.0001 || Time: 03:46:51.88
Epoch :: 30 || Loss: 0.41292955 || it_count: 8344 || Val Loss: 0.43078027 || Val it_count: 1107 || Current Learning Rate: 0.0001 || Time: 03:54:42.39
Epoch :: 31 || Loss: 0.41197689 || it_count: 8344 || Val Loss: 0.43001502 || Val it_count: 1107 || Current Learning Rate: 0.0001 || Time: 04:02:35.33
Epoch :: 32 || Loss: 0.41127003 || it_count: 8344 || Val Loss: 0.42956389 || Val it_count: 1107 || Current Learning Rate: 0.0001 || Time: 04:10:25.77
Epoch :: 33 || Loss: 0.41074774 || it_count: 8344 || Val Loss: 0.42922431 || Val it_count: 1107 || Current Learning Rate: 0.0001 || Time: 04:18:16.84
Epoch :: 34 || Loss: 0.41032201 || it_count: 8344 || Val Loss: 0.42889149 || Val it_count: 1107 || Current Learning Rate: 0.0001 || Time: 04:26:7.60
Epoch :: 35 || Loss: 0.41003407 || it_count: 8344 || Val Loss: 0.42857741 || Val it_count: 1107 || Current Learning Rate: 0.0001 || Time: 04:33:58.76
Epoch :: 36 || Loss: 0.40971829 || it_count: 8344 || Val Loss: 0.42837129 || Val it_count: 1107 || Current Learning Rate: 0.0001 || Time: 04:41:49.76
Epoch :: 37 || Loss: 0.40949453 || it_count: 8344 || Val Loss: 0.42807730 || Val it_count: 1107 || Current Learning Rate: 0.0001 || Time: 04:49:41.64
Epoch :: 38 || Loss: 0.40930095 || it_count: 8344 || Val Loss: 0.42798379 || Val it_count: 1107 || Current Learning Rate: 0.0001 || Time: 04:57:33.62
Epoch :: 39 || Loss: 0.40908613 || it_count: 8344 || Val Loss: 0.42772254 || Val it_count: 1107 || Current Learning Rate: 0.0001 || Time: 05:05:25.00
Epoch :: 40 || Loss: 0.40890958 || it_count: 8344 || Val Loss: 0.42777474 || Val it_count: 1107 || Current Learning Rate: 0.0001 || Time: 05:13:16.24
Epoch :: 41 || Loss: 0.40868624 || it_count: 8344 || Val Loss: 0.42780890 || Val it_count: 1107 || Current Learning Rate: 0.0001 || Time: 05:21:7.29
Epoch :: 42 || Loss: 0.40854914 || it_count: 8344 || Val Loss: 0.42779804 || Val it_count: 1107 || Current Learning Rate: 0.0001 || Time: 05:28:59.64
Epoch :: 43 || Loss: 0.40833925 || it_count: 8344 || Val Loss: 0.42781673 || Val it_count: 1107 || Current Learning Rate: 0.0001 || Time: 05:36:50.67
Epoch :: 44 || Loss: 0.40817237 || it_count: 8344 || Val Loss: 0.42788045 || Val it_count: 1107 || Current Learning Rate: 0.0001 || Time: 05:44:42.50
Epoch 00029: reducing learning rate of group 0 to 1.0000e-05.
Epoch :: 45 || Loss: 0.40800292 || it_count: 8344 || Val Loss: 0.42790039 || Val it_count: 1107 || Current Learning Rate: 1e-05 || Time: 05:52:33.36
Epoch :: 46 || Loss: 0.41254412 || it_count: 8344 || Val Loss: 0.41723673 || Val it_count: 1107 || Current Learning Rate: 1e-05 || Time: 06:00:25.67
Epoch :: 47 || Loss: 0.41023065 || it_count: 8344 || Val Loss: 0.41654187 || Val it_count: 1107 || Current Learning Rate: 1e-05 || Time: 06:08:15.58
Epoch :: 48 || Loss: 0.40992381 || it_count: 8344 || Val Loss: 0.41626804 || Val it_count: 1107 || Current Learning Rate: 1e-05 || Time: 06:16:5.89
Epoch :: 49 || Loss: 0.40969435 || it_count: 8344 || Val Loss: 0.41610430 || Val it_count: 1107 || Current Learning Rate: 1e-05 || Time: 06:23:57.35
Epoch :: 50 || Loss: 0.40955941 || it_count: 8344 || Val Loss: 0.41603436 || Val it_count: 1107 || Current Learning Rate: 1e-05 || Time: 06:31:48.58
Epoch :: 51 || Loss: 0.40947101 || it_count: 8344 || Val Loss: 0.41597063 || Val it_count: 1107 || Current Learning Rate: 1e-05 || Time: 06:39:39.83
Epoch :: 52 || Loss: 0.40938424 || it_count: 8344 || Val Loss: 0.41589838 || Val it_count: 1107 || Current Learning Rate: 1e-05 || Time: 06:47:31.41
Epoch :: 53 || Loss: 0.40933567 || it_count: 8344 || Val Loss: 0.41592944 || Val it_count: 1107 || Current Learning Rate: 1e-05 || Time: 06:55:24.54
Epoch :: 54 || Loss: 0.40929043 || it_count: 8344 || Val Loss: 0.41585744 || Val it_count: 1107 || Current Learning Rate: 1e-05 || Time: 07:03:15.93
Epoch :: 55 || Loss: 0.40920681 || it_count: 8344 || Val Loss: 0.41585536 || Val it_count: 1107 || Current Learning Rate: 1e-05 || Time: 07:11:7.60
Epoch :: 56 || Loss: 0.40913855 || it_count: 8344 || Val Loss: 0.41585681 || Val it_count: 1107 || Current Learning Rate: 1e-05 || Time: 07:18:59.53
Epoch :: 57 || Loss: 0.40907315 || it_count: 8344 || Val Loss: 0.41584697 || Val it_count: 1107 || Current Learning Rate: 1e-05 || Time: 07:26:51.66
Epoch :: 58 || Loss: 0.40907131 || it_count: 8344 || Val Loss: 0.41587008 || Val it_count: 1107 || Current Learning Rate: 1e-05 || Time: 07:34:42.81
Epoch :: 59 || Loss: 0.40900942 || it_count: 8344 || Val Loss: 0.41585420 || Val it_count: 1107 || Current Learning Rate: 1e-05 || Time: 07:42:33.17
Epoch :: 60 || Loss: 0.40901500 || it_count: 8344 || Val Loss: 0.41586536 || Val it_count: 1107 || Current Learning Rate: 1e-05 || Time: 07:50:24.16
Epoch 00045: reducing learning rate of group 0 to 1.0000e-06.
Epoch :: 61 || Loss: 0.40893976 || it_count: 8344 || Val Loss: 0.41584392 || Val it_count: 1107 || Current Learning Rate: 1.0000000000000002e-06 || Time: 07:58:14.37
Epoch :: 62 || Loss: 0.40929841 || it_count: 8344 || Val Loss: 0.41456239 || Val it_count: 1107 || Current Learning Rate: 1.0000000000000002e-06 || Time: 08:06:5.56
Epoch :: 63 || Loss: 0.40917336 || it_count: 8344 || Val Loss: 0.41443654 || Val it_count: 1107 || Current Learning Rate: 1.0000000000000002e-06 || Time: 08:13:56.51
Epoch :: 64 || Loss: 0.40911399 || it_count: 8344 || Val Loss: 0.41440109 || Val it_count: 1107 || Current Learning Rate: 1.0000000000000002e-06 || Time: 08:21:46.66
Epoch :: 65 || Loss: 0.40910430 || it_count: 8344 || Val Loss: 0.41437979 || Val it_count: 1107 || Current Learning Rate: 1.0000000000000002e-06 || Time: 08:29:38.44
Epoch :: 66 || Loss: 0.40909089 || it_count: 8344 || Val Loss: 0.41437248 || Val it_count: 1107 || Current Learning Rate: 1.0000000000000002e-06 || Time: 08:37:30.06
Epoch :: 67 || Loss: 0.40908558 || it_count: 8344 || Val Loss: 0.41435756 || Val it_count: 1107 || Current Learning Rate: 1.0000000000000002e-06 || Time: 08:45:21.67
Epoch :: 68 || Loss: 0.40905864 || it_count: 8344 || Val Loss: 0.41434713 || Val it_count: 1107 || Current Learning Rate: 1.0000000000000002e-06 || Time: 08:53:11.70
Epoch :: 69 || Loss: 0.40901506 || it_count: 8344 || Val Loss: 0.41434126 || Val it_count: 1107 || Current Learning Rate: 1.0000000000000002e-06 || Time: 09:01:1.47
Epoch :: 70 || Loss: 0.40902565 || it_count: 8344 || Val Loss: 0.41433413 || Val it_count: 1107 || Current Learning Rate: 1.0000000000000002e-06 || Time: 09:08:52.48
Epoch :: 71 || Loss: 0.40904246 || it_count: 8344 || Val Loss: 0.41432908 || Val it_count: 1107 || Current Learning Rate: 1.0000000000000002e-06 || Time: 09:16:44.27
Epoch :: 72 || Loss: 0.40900583 || it_count: 8344 || Val Loss: 0.41432052 || Val it_count: 1107 || Current Learning Rate: 1.0000000000000002e-06 || Time: 09:24:35.73
Epoch :: 73 || Loss: 0.40901484 || it_count: 8344 || Val Loss: 0.41431369 || Val it_count: 1107 || Current Learning Rate: 1.0000000000000002e-06 || Time: 09:32:27.04
Epoch :: 74 || Loss: 0.40897633 || it_count: 8344 || Val Loss: 0.41430956 || Val it_count: 1107 || Current Learning Rate: 1.0000000000000002e-06 || Time: 09:40:18.95
Epoch :: 75 || Loss: 0.40898966 || it_count: 8344 || Val Loss: 0.41430090 || Val it_count: 1107 || Current Learning Rate: 1.0000000000000002e-06 || Time: 09:48:10.24
Epoch 00060: reducing learning rate of group 0 to 1.0000e-07.
Early stopping triggered due to learning rate below threshold.
Done Total time: 09:56:2.64
best_loss: 0.4143008968318539

--------------------Testing--------------------

total_samples :: test_dataset = 139200, test_dataloader = 139200
Epoch ::  1 || Loss: 0.23752547 || it_count: 544 || Time: 00:00:24.60
MAE:  0.25458744
MSE:  0.2375454
RMSE:  0.442534

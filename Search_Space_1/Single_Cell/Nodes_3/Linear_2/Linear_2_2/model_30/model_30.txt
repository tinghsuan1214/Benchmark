--------------------Training--------------------
arch_str :: |lstm_2~0|+|lstm_1~0|skip_connect~1|[linear->dropout->linear]
model :: 3F
InferCell(
  info :: nodes=3, inC=1, outC=64, [1<-(I0-L0) | 2<-(I0-L1,I1-L2)], genotype_str: lstm_2~0|lstm_1~0|skip_connect~1
  linear_layers: [linear->dropout->linear]
  (layers): ModuleList(
    (0): LSTM(
      (lstm): LSTM(1, 64, num_layers=2, batch_first=True)
    )
    (1): LSTM(
      (lstm): LSTM(1, 64, batch_first=True)
    )
    (2): Identity()
  )
  (linear_layers): ModuleList(
    (0): Linear(in_features=3072, out_features=1536, bias=True)
    (1): Dropout(p=0.1, inplace=False)
    (2): Linear(in_features=1536, out_features=1, bias=True)
  )
)
tr_params :: epochs = 100, patience = 20, batch_size = 256, window_size = 48, data_size = 100
Model MACs: 8.038M, Model Params: 4.789M
learning rate scheduling :: (optimizer, mode='min', factor=0.1, patience=5, verbose=True)
total_samples :: train_dataset = 2136000, train_dataloader = 2136000
total_samples :: valid_dataset = 283200, valid_dataloader = 283200
Epoch ::  1 || Loss: 0.42251964 || it_count: 8344 || Val Loss: 0.46211437 || Val it_count: 1107 || Current Learning Rate: 0.001 || Time: 00:06:9.97
Epoch ::  2 || Loss: 0.41768970 || it_count: 8344 || Val Loss: 0.44952013 || Val it_count: 1107 || Current Learning Rate: 0.001 || Time: 00:12:14.41
Epoch ::  3 || Loss: 0.41728685 || it_count: 8344 || Val Loss: 0.44887694 || Val it_count: 1107 || Current Learning Rate: 0.001 || Time: 00:18:34.18
Epoch ::  4 || Loss: 0.41713858 || it_count: 8344 || Val Loss: 0.44964381 || Val it_count: 1107 || Current Learning Rate: 0.001 || Time: 00:24:42.78
Epoch ::  5 || Loss: 0.41773164 || it_count: 8344 || Val Loss: 0.44893034 || Val it_count: 1107 || Current Learning Rate: 0.001 || Time: 00:30:50.66
Epoch ::  6 || Loss: 0.41741114 || it_count: 8344 || Val Loss: 0.44808667 || Val it_count: 1107 || Current Learning Rate: 0.001 || Time: 00:37:7.45
Epoch ::  7 || Loss: 0.41748776 || it_count: 8344 || Val Loss: 0.44812932 || Val it_count: 1107 || Current Learning Rate: 0.001 || Time: 00:43:24.37
Epoch ::  8 || Loss: 0.41729567 || it_count: 8344 || Val Loss: 0.44778847 || Val it_count: 1107 || Current Learning Rate: 0.001 || Time: 00:49:32.61
Epoch ::  9 || Loss: 0.41720144 || it_count: 8344 || Val Loss: 0.44777443 || Val it_count: 1107 || Current Learning Rate: 0.001 || Time: 00:55:40.43
Epoch :: 10 || Loss: 0.41726707 || it_count: 8344 || Val Loss: 0.44738227 || Val it_count: 1107 || Current Learning Rate: 0.001 || Time: 01:02:1.02
Epoch :: 11 || Loss: 0.41712160 || it_count: 8344 || Val Loss: 0.44799290 || Val it_count: 1107 || Current Learning Rate: 0.001 || Time: 01:08:8.56
Epoch :: 12 || Loss: 0.41707284 || it_count: 8344 || Val Loss: 0.44757372 || Val it_count: 1107 || Current Learning Rate: 0.001 || Time: 01:14:16.57
Epoch :: 13 || Loss: 0.41711483 || it_count: 8344 || Val Loss: 0.44767832 || Val it_count: 1107 || Current Learning Rate: 0.001 || Time: 01:20:36.02
Epoch :: 14 || Loss: 0.41703685 || it_count: 8344 || Val Loss: 0.44785619 || Val it_count: 1107 || Current Learning Rate: 0.001 || Time: 01:26:45.66
Epoch :: 15 || Loss: 0.41699026 || it_count: 8344 || Val Loss: 0.44781173 || Val it_count: 1107 || Current Learning Rate: 0.001 || Time: 01:32:53.23
Epoch :: 16 || Loss: 0.41691633 || it_count: 8344 || Val Loss: 0.44773202 || Val it_count: 1107 || Current Learning Rate: 0.001 || Time: 01:39:5.44
Epoch :: 17 || Loss: 0.41691018 || it_count: 8344 || Val Loss: 0.44782173 || Val it_count: 1107 || Current Learning Rate: 0.001 || Time: 01:45:26.17
Epoch :: 18 || Loss: 0.41685044 || it_count: 8344 || Val Loss: 0.44770344 || Val it_count: 1107 || Current Learning Rate: 0.001 || Time: 01:51:34.04
Epoch :: 19 || Loss: 0.41675144 || it_count: 8344 || Val Loss: 0.44729628 || Val it_count: 1107 || Current Learning Rate: 0.001 || Time: 01:57:41.92
Epoch :: 20 || Loss: 0.41663304 || it_count: 8344 || Val Loss: 0.44765167 || Val it_count: 1107 || Current Learning Rate: 0.001 || Time: 02:04:2.38
Epoch :: 21 || Loss: 0.41657741 || it_count: 8344 || Val Loss: 0.44729513 || Val it_count: 1107 || Current Learning Rate: 0.001 || Time: 02:10:10.92
Epoch :: 22 || Loss: 0.41650938 || it_count: 8344 || Val Loss: 0.44731207 || Val it_count: 1107 || Current Learning Rate: 0.001 || Time: 02:16:19.28
Epoch :: 23 || Loss: 0.41648011 || it_count: 8344 || Val Loss: 0.44744173 || Val it_count: 1107 || Current Learning Rate: 0.001 || Time: 02:22:36.72
Epoch :: 24 || Loss: 0.41642647 || it_count: 8344 || Val Loss: 0.44716309 || Val it_count: 1107 || Current Learning Rate: 0.001 || Time: 02:28:51.28
Epoch :: 25 || Loss: 0.41649281 || it_count: 8344 || Val Loss: 0.44641479 || Val it_count: 1107 || Current Learning Rate: 0.001 || Time: 02:34:58.96
Epoch :: 26 || Loss: 0.41648115 || it_count: 8344 || Val Loss: 0.44650499 || Val it_count: 1107 || Current Learning Rate: 0.001 || Time: 02:41:8.50
Epoch :: 27 || Loss: 0.41643738 || it_count: 8344 || Val Loss: 0.44637337 || Val it_count: 1107 || Current Learning Rate: 0.001 || Time: 02:47:28.66
Epoch :: 28 || Loss: 0.41638528 || it_count: 8344 || Val Loss: 0.44701749 || Val it_count: 1107 || Current Learning Rate: 0.001 || Time: 02:53:36.66
Epoch :: 29 || Loss: 0.41641340 || it_count: 8344 || Val Loss: 0.44655619 || Val it_count: 1107 || Current Learning Rate: 0.001 || Time: 02:59:43.88
Epoch :: 30 || Loss: 0.41650367 || it_count: 8344 || Val Loss: 0.44647093 || Val it_count: 1107 || Current Learning Rate: 0.001 || Time: 03:06:4.41
Epoch 00015: reducing learning rate of group 0 to 1.0000e-04.
Epoch :: 31 || Loss: 0.41654493 || it_count: 8344 || Val Loss: 0.44678614 || Val it_count: 1107 || Current Learning Rate: 0.0001 || Time: 03:12:12.11
Epoch :: 32 || Loss: 0.42358917 || it_count: 8344 || Val Loss: 0.43805526 || Val it_count: 1107 || Current Learning Rate: 0.0001 || Time: 03:18:19.51
Epoch :: 33 || Loss: 0.42081855 || it_count: 8344 || Val Loss: 0.43670794 || Val it_count: 1107 || Current Learning Rate: 0.0001 || Time: 03:24:35.35
Epoch :: 34 || Loss: 0.42039115 || it_count: 8344 || Val Loss: 0.43537905 || Val it_count: 1107 || Current Learning Rate: 0.0001 || Time: 03:30:51.89
Epoch :: 35 || Loss: 0.42005636 || it_count: 8344 || Val Loss: 0.43435259 || Val it_count: 1107 || Current Learning Rate: 0.0001 || Time: 03:36:59.48
Epoch :: 36 || Loss: 0.41979845 || it_count: 8344 || Val Loss: 0.43367548 || Val it_count: 1107 || Current Learning Rate: 0.0001 || Time: 03:43:7.73
Epoch :: 37 || Loss: 0.41960611 || it_count: 8344 || Val Loss: 0.43328592 || Val it_count: 1107 || Current Learning Rate: 0.0001 || Time: 03:49:28.59
Epoch :: 38 || Loss: 0.41940686 || it_count: 8344 || Val Loss: 0.43306983 || Val it_count: 1107 || Current Learning Rate: 0.0001 || Time: 03:55:37.03
Epoch :: 39 || Loss: 0.41923335 || it_count: 8344 || Val Loss: 0.43294247 || Val it_count: 1107 || Current Learning Rate: 0.0001 || Time: 04:01:45.18
Epoch :: 40 || Loss: 0.41905775 || it_count: 8344 || Val Loss: 0.43277816 || Val it_count: 1107 || Current Learning Rate: 0.0001 || Time: 04:08:5.93
Epoch :: 41 || Loss: 0.41889366 || it_count: 8344 || Val Loss: 0.43259019 || Val it_count: 1107 || Current Learning Rate: 0.0001 || Time: 04:14:13.81
Epoch :: 42 || Loss: 0.41873407 || it_count: 8344 || Val Loss: 0.43255625 || Val it_count: 1107 || Current Learning Rate: 0.0001 || Time: 04:20:20.92
Epoch :: 43 || Loss: 0.41861909 || it_count: 8344 || Val Loss: 0.43255659 || Val it_count: 1107 || Current Learning Rate: 0.0001 || Time: 04:26:33.76
Epoch :: 44 || Loss: 0.41850407 || it_count: 8344 || Val Loss: 0.43245676 || Val it_count: 1107 || Current Learning Rate: 0.0001 || Time: 04:32:53.33
Epoch :: 45 || Loss: 0.41836917 || it_count: 8344 || Val Loss: 0.43242376 || Val it_count: 1107 || Current Learning Rate: 0.0001 || Time: 04:39:0.47
Epoch :: 46 || Loss: 0.41830084 || it_count: 8344 || Val Loss: 0.43233341 || Val it_count: 1107 || Current Learning Rate: 0.0001 || Time: 04:45:7.24
Epoch :: 47 || Loss: 0.41818398 || it_count: 8344 || Val Loss: 0.43235786 || Val it_count: 1107 || Current Learning Rate: 0.0001 || Time: 04:51:27.05
Epoch :: 48 || Loss: 0.41810165 || it_count: 8344 || Val Loss: 0.43240033 || Val it_count: 1107 || Current Learning Rate: 0.0001 || Time: 04:57:33.99
Epoch :: 49 || Loss: 0.41802182 || it_count: 8344 || Val Loss: 0.43242629 || Val it_count: 1107 || Current Learning Rate: 0.0001 || Time: 05:03:40.86
Epoch :: 50 || Loss: 0.41794443 || it_count: 8344 || Val Loss: 0.43249429 || Val it_count: 1107 || Current Learning Rate: 0.0001 || Time: 05:10:0.09
Epoch :: 51 || Loss: 0.41787983 || it_count: 8344 || Val Loss: 0.43242357 || Val it_count: 1107 || Current Learning Rate: 0.0001 || Time: 05:16:9.46
Epoch 00036: reducing learning rate of group 0 to 1.0000e-05.
Epoch :: 52 || Loss: 0.41782022 || it_count: 8344 || Val Loss: 0.43245098 || Val it_count: 1107 || Current Learning Rate: 1e-05 || Time: 05:22:16.89
Epoch :: 53 || Loss: 0.42063640 || it_count: 8344 || Val Loss: 0.42366013 || Val it_count: 1107 || Current Learning Rate: 1e-05 || Time: 05:28:28.68
Epoch :: 54 || Loss: 0.41904592 || it_count: 8344 || Val Loss: 0.42295090 || Val it_count: 1107 || Current Learning Rate: 1e-05 || Time: 05:34:49.16
Epoch :: 55 || Loss: 0.41864342 || it_count: 8344 || Val Loss: 0.42266275 || Val it_count: 1107 || Current Learning Rate: 1e-05 || Time: 05:40:56.69
Epoch :: 56 || Loss: 0.41849639 || it_count: 8344 || Val Loss: 0.42252802 || Val it_count: 1107 || Current Learning Rate: 1e-05 || Time: 05:47:4.46
Epoch :: 57 || Loss: 0.41837503 || it_count: 8344 || Val Loss: 0.42242645 || Val it_count: 1107 || Current Learning Rate: 1e-05 || Time: 05:53:24.21
Epoch :: 58 || Loss: 0.41831660 || it_count: 8344 || Val Loss: 0.42237289 || Val it_count: 1107 || Current Learning Rate: 1e-05 || Time: 05:59:31.87
Epoch :: 59 || Loss: 0.41827911 || it_count: 8344 || Val Loss: 0.42232022 || Val it_count: 1107 || Current Learning Rate: 1e-05 || Time: 06:05:38.77
Epoch :: 60 || Loss: 0.41824785 || it_count: 8344 || Val Loss: 0.42225613 || Val it_count: 1107 || Current Learning Rate: 1e-05 || Time: 06:11:56.30
Epoch :: 61 || Loss: 0.41822572 || it_count: 8344 || Val Loss: 0.42224045 || Val it_count: 1107 || Current Learning Rate: 1e-05 || Time: 06:18:8.65
Epoch :: 62 || Loss: 0.41816528 || it_count: 8344 || Val Loss: 0.42219919 || Val it_count: 1107 || Current Learning Rate: 1e-05 || Time: 06:24:16.86
Epoch :: 63 || Loss: 0.41816038 || it_count: 8344 || Val Loss: 0.42217428 || Val it_count: 1107 || Current Learning Rate: 1e-05 || Time: 06:30:26.87
Epoch :: 64 || Loss: 0.41809576 || it_count: 8344 || Val Loss: 0.42216428 || Val it_count: 1107 || Current Learning Rate: 1e-05 || Time: 06:36:46.64
Epoch :: 65 || Loss: 0.41811205 || it_count: 8344 || Val Loss: 0.42214090 || Val it_count: 1107 || Current Learning Rate: 1e-05 || Time: 06:42:53.33
Epoch :: 66 || Loss: 0.41808377 || it_count: 8344 || Val Loss: 0.42211263 || Val it_count: 1107 || Current Learning Rate: 1e-05 || Time: 06:49:0.79
Epoch :: 67 || Loss: 0.41805768 || it_count: 8344 || Val Loss: 0.42209435 || Val it_count: 1107 || Current Learning Rate: 1e-05 || Time: 06:55:20.88
Epoch :: 68 || Loss: 0.41803959 || it_count: 8344 || Val Loss: 0.42209430 || Val it_count: 1107 || Current Learning Rate: 1e-05 || Time: 07:01:28.94
Epoch :: 69 || Loss: 0.41804038 || it_count: 8344 || Val Loss: 0.42208900 || Val it_count: 1107 || Current Learning Rate: 1e-05 || Time: 07:07:36.44
Epoch :: 70 || Loss: 0.41799285 || it_count: 8344 || Val Loss: 0.42207946 || Val it_count: 1107 || Current Learning Rate: 1e-05 || Time: 07:13:53.22
Epoch :: 71 || Loss: 0.41799704 || it_count: 8344 || Val Loss: 0.42208721 || Val it_count: 1107 || Current Learning Rate: 1e-05 || Time: 07:20:9.15
Epoch :: 72 || Loss: 0.41798040 || it_count: 8344 || Val Loss: 0.42208694 || Val it_count: 1107 || Current Learning Rate: 1e-05 || Time: 07:26:16.19
Epoch 00057: reducing learning rate of group 0 to 1.0000e-06.
Epoch :: 73 || Loss: 0.41796815 || it_count: 8344 || Val Loss: 0.42207442 || Val it_count: 1107 || Current Learning Rate: 1.0000000000000002e-06 || Time: 07:32:23.23
Epoch :: 74 || Loss: 0.41827134 || it_count: 8344 || Val Loss: 0.42123090 || Val it_count: 1107 || Current Learning Rate: 1.0000000000000002e-06 || Time: 07:38:42.76
Epoch :: 75 || Loss: 0.41809654 || it_count: 8344 || Val Loss: 0.42113768 || Val it_count: 1107 || Current Learning Rate: 1.0000000000000002e-06 || Time: 07:44:49.27
Epoch :: 76 || Loss: 0.41808831 || it_count: 8344 || Val Loss: 0.42108505 || Val it_count: 1107 || Current Learning Rate: 1.0000000000000002e-06 || Time: 07:50:55.85
Epoch :: 77 || Loss: 0.41807319 || it_count: 8344 || Val Loss: 0.42105135 || Val it_count: 1107 || Current Learning Rate: 1.0000000000000002e-06 || Time: 07:57:15.01
Epoch :: 78 || Loss: 0.41807526 || it_count: 8344 || Val Loss: 0.42103293 || Val it_count: 1107 || Current Learning Rate: 1.0000000000000002e-06 || Time: 08:03:22.14
Epoch :: 79 || Loss: 0.41805727 || it_count: 8344 || Val Loss: 0.42101271 || Val it_count: 1107 || Current Learning Rate: 1.0000000000000002e-06 || Time: 08:09:28.93
Epoch :: 80 || Loss: 0.41804972 || it_count: 8344 || Val Loss: 0.42100087 || Val it_count: 1107 || Current Learning Rate: 1.0000000000000002e-06 || Time: 08:15:42.11
Epoch :: 81 || Loss: 0.41803853 || it_count: 8344 || Val Loss: 0.42098812 || Val it_count: 1107 || Current Learning Rate: 1.0000000000000002e-06 || Time: 08:22:1.27
Epoch :: 82 || Loss: 0.41801640 || it_count: 8344 || Val Loss: 0.42097994 || Val it_count: 1107 || Current Learning Rate: 1.0000000000000002e-06 || Time: 08:28:7.68
Epoch :: 83 || Loss: 0.41802096 || it_count: 8344 || Val Loss: 0.42096820 || Val it_count: 1107 || Current Learning Rate: 1.0000000000000002e-06 || Time: 08:34:14.12
Epoch :: 84 || Loss: 0.41799267 || it_count: 8344 || Val Loss: 0.42095982 || Val it_count: 1107 || Current Learning Rate: 1.0000000000000002e-06 || Time: 08:40:33.66
Epoch :: 85 || Loss: 0.41800516 || it_count: 8344 || Val Loss: 0.42095695 || Val it_count: 1107 || Current Learning Rate: 1.0000000000000002e-06 || Time: 08:46:39.89
Epoch :: 86 || Loss: 0.41800946 || it_count: 8344 || Val Loss: 0.42095193 || Val it_count: 1107 || Current Learning Rate: 1.0000000000000002e-06 || Time: 08:52:45.90
Epoch 00071: reducing learning rate of group 0 to 1.0000e-07.
Early stopping triggered due to learning rate below threshold.
Done Total time: 08:59:4.34
best_loss: 0.4209519284415029

--------------------Testing--------------------

total_samples :: test_dataset = 139200, test_dataloader = 139200
Epoch ::  1 || Loss: 0.24925843 || it_count: 544 || Time: 00:00:18.55
MAE:  0.26194805
MSE:  0.24928245
RMSE:  0.45140275

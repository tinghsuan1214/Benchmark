--------------------Training--------------------
arch_str :: |skip_connect~0|+|lstm_1~0|lstm_2~1|[linear->linear]
model :: 3E
InferCell(
  info :: nodes=3, inC=1, outC=64, [1<-(I0-L0) | 2<-(I0-L1,I1-L2)], genotype_str: skip_connect~0|lstm_1~0|lstm_2~1
  linear_layers: [linear->linear]
  (layers): ModuleList(
    (0): FactorizedReduce(
      C_in=1, C_out=64, stride=1
      (relu): ReLU()
      (conv): Conv1d(1, 64, kernel_size=(1,), stride=(1,), bias=False)
      (bn): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (1): LSTM(
      (lstm): LSTM(1, 64, batch_first=True)
    )
    (2): LSTM(
      (lstm): LSTM(64, 64, num_layers=2, batch_first=True)
    )
  )
  (linear_layers): ModuleList(
    (0): Linear(in_features=3072, out_features=1536, bias=True)
    (1): Linear(in_features=1536, out_features=1, bias=True)
  )
)
tr_params :: epochs = 100, patience = 20, batch_size = 256, window_size = 48, data_size = 100
Model MACs: 8.827M, Model Params: 4.806M
learning rate scheduling :: (optimizer, mode='min', factor=0.1, patience=5, verbose=True)
total_samples :: train_dataset = 2136000, train_dataloader = 2136000
total_samples :: valid_dataset = 283200, valid_dataloader = 283200
Epoch ::  1 || Loss: 0.41846063 || it_count: 8344 || Val Loss: 0.46062166 || Val it_count: 1107 || Current Learning Rate: 0.001 || Time: 00:10:57.23
Epoch ::  2 || Loss: 0.41368706 || it_count: 8344 || Val Loss: 0.45199960 || Val it_count: 1107 || Current Learning Rate: 0.001 || Time: 00:21:53.03
Epoch ::  3 || Loss: 0.41213660 || it_count: 8344 || Val Loss: 0.45552154 || Val it_count: 1107 || Current Learning Rate: 0.001 || Time: 00:32:49.04
Epoch ::  4 || Loss: 0.41205378 || it_count: 8344 || Val Loss: 0.45599268 || Val it_count: 1107 || Current Learning Rate: 0.001 || Time: 00:43:44.72
Epoch ::  5 || Loss: 0.41101735 || it_count: 8344 || Val Loss: 0.45459129 || Val it_count: 1107 || Current Learning Rate: 0.001 || Time: 00:54:42.54
Epoch ::  6 || Loss: 0.41466460 || it_count: 8344 || Val Loss: 0.45139842 || Val it_count: 1107 || Current Learning Rate: 0.001 || Time: 01:05:39.10
Epoch ::  7 || Loss: 0.41144127 || it_count: 8344 || Val Loss: 0.45283073 || Val it_count: 1107 || Current Learning Rate: 0.001 || Time: 01:16:37.73
Epoch ::  8 || Loss: 0.40997764 || it_count: 8344 || Val Loss: 0.45696531 || Val it_count: 1107 || Current Learning Rate: 0.001 || Time: 01:27:38.04
Epoch ::  9 || Loss: 0.40928847 || it_count: 8344 || Val Loss: 0.45535958 || Val it_count: 1107 || Current Learning Rate: 0.001 || Time: 01:38:38.54
Epoch :: 10 || Loss: 0.41021831 || it_count: 8344 || Val Loss: 0.45292334 || Val it_count: 1107 || Current Learning Rate: 0.001 || Time: 01:49:38.41
Epoch :: 11 || Loss: 0.40942384 || it_count: 8344 || Val Loss: 0.45240640 || Val it_count: 1107 || Current Learning Rate: 0.001 || Time: 02:00:39.20
Epoch :: 12 || Loss: 0.41004625 || it_count: 8344 || Val Loss: 0.45194966 || Val it_count: 1107 || Current Learning Rate: 0.001 || Time: 02:11:39.60
Epoch :: 13 || Loss: 0.40817152 || it_count: 8344 || Val Loss: 0.45204607 || Val it_count: 1107 || Current Learning Rate: 0.001 || Time: 02:22:40.29
Epoch :: 14 || Loss: 0.41126032 || it_count: 8344 || Val Loss: 0.45470165 || Val it_count: 1107 || Current Learning Rate: 0.001 || Time: 02:33:39.62
Epoch :: 15 || Loss: 0.40911102 || it_count: 8344 || Val Loss: 0.45497027 || Val it_count: 1107 || Current Learning Rate: 0.001 || Time: 02:44:40.25
Epoch :: 16 || Loss: 0.40927217 || it_count: 8344 || Val Loss: 0.45573375 || Val it_count: 1107 || Current Learning Rate: 0.001 || Time: 02:55:40.44
Epoch :: 17 || Loss: 0.40821426 || it_count: 8344 || Val Loss: 0.45570249 || Val it_count: 1107 || Current Learning Rate: 0.001 || Time: 03:06:40.87
Epoch :: 18 || Loss: 0.40772072 || it_count: 8344 || Val Loss: 0.45562449 || Val it_count: 1107 || Current Learning Rate: 0.001 || Time: 03:17:41.66
Epoch :: 19 || Loss: 0.40729106 || it_count: 8344 || Val Loss: 0.45019226 || Val it_count: 1107 || Current Learning Rate: 0.001 || Time: 03:28:41.94
Epoch :: 20 || Loss: 0.40936610 || it_count: 8344 || Val Loss: 0.45297162 || Val it_count: 1107 || Current Learning Rate: 0.001 || Time: 03:39:42.46
Epoch :: 21 || Loss: 0.40810894 || it_count: 8344 || Val Loss: 0.45321892 || Val it_count: 1107 || Current Learning Rate: 0.001 || Time: 03:50:43.76
Epoch :: 22 || Loss: 0.40756815 || it_count: 8344 || Val Loss: 0.45107287 || Val it_count: 1107 || Current Learning Rate: 0.001 || Time: 04:01:44.65
Epoch :: 23 || Loss: 0.40791029 || it_count: 8344 || Val Loss: 0.45389780 || Val it_count: 1107 || Current Learning Rate: 0.001 || Time: 04:12:45.12
Epoch :: 24 || Loss: 0.40737145 || it_count: 8344 || Val Loss: 0.45183511 || Val it_count: 1107 || Current Learning Rate: 0.001 || Time: 04:23:46.14
Epoch :: 25 || Loss: 0.40790712 || it_count: 8344 || Val Loss: 0.45007130 || Val it_count: 1107 || Current Learning Rate: 0.001 || Time: 04:34:46.95
Epoch :: 26 || Loss: 0.40721165 || it_count: 8344 || Val Loss: 0.45935165 || Val it_count: 1107 || Current Learning Rate: 0.001 || Time: 04:45:48.22
Epoch :: 27 || Loss: 0.40780379 || it_count: 8344 || Val Loss: 0.45519050 || Val it_count: 1107 || Current Learning Rate: 0.001 || Time: 04:56:49.39
Epoch :: 28 || Loss: 0.40653933 || it_count: 8344 || Val Loss: 0.45607769 || Val it_count: 1107 || Current Learning Rate: 0.001 || Time: 05:07:50.32
Epoch :: 29 || Loss: 0.40645176 || it_count: 8344 || Val Loss: 0.45105724 || Val it_count: 1107 || Current Learning Rate: 0.001 || Time: 05:18:51.76
Epoch :: 30 || Loss: 0.40622153 || it_count: 8344 || Val Loss: 0.45906468 || Val it_count: 1107 || Current Learning Rate: 0.001 || Time: 05:29:53.36
Epoch :: 31 || Loss: 0.40540678 || it_count: 8344 || Val Loss: 0.44955831 || Val it_count: 1107 || Current Learning Rate: 0.001 || Time: 05:40:54.66
Epoch :: 32 || Loss: 0.40612845 || it_count: 8344 || Val Loss: 0.46141585 || Val it_count: 1107 || Current Learning Rate: 0.001 || Time: 05:51:55.96
Epoch :: 33 || Loss: 0.40556156 || it_count: 8344 || Val Loss: 0.45028316 || Val it_count: 1107 || Current Learning Rate: 0.001 || Time: 06:02:57.91
Epoch :: 34 || Loss: 0.40503787 || it_count: 8344 || Val Loss: 0.45212899 || Val it_count: 1107 || Current Learning Rate: 0.001 || Time: 06:13:59.27
Epoch :: 35 || Loss: 0.40497881 || it_count: 8344 || Val Loss: 0.46463595 || Val it_count: 1107 || Current Learning Rate: 0.001 || Time: 06:25:0.21
Epoch :: 36 || Loss: 0.40501533 || it_count: 8344 || Val Loss: 0.45258876 || Val it_count: 1107 || Current Learning Rate: 0.001 || Time: 06:36:1.57
Epoch 00021: reducing learning rate of group 0 to 1.0000e-04.
Epoch :: 37 || Loss: 0.40588660 || it_count: 8344 || Val Loss: 0.45706186 || Val it_count: 1107 || Current Learning Rate: 0.0001 || Time: 06:47:2.69
Epoch :: 38 || Loss: 0.41022625 || it_count: 8344 || Val Loss: 0.44883339 || Val it_count: 1107 || Current Learning Rate: 0.0001 || Time: 06:58:4.13
Epoch :: 39 || Loss: 0.40872325 || it_count: 8344 || Val Loss: 0.44602746 || Val it_count: 1107 || Current Learning Rate: 0.0001 || Time: 07:09:5.57
Epoch :: 40 || Loss: 0.40755211 || it_count: 8344 || Val Loss: 0.44586580 || Val it_count: 1107 || Current Learning Rate: 0.0001 || Time: 07:20:6.69
Epoch :: 41 || Loss: 0.40694720 || it_count: 8344 || Val Loss: 0.44497578 || Val it_count: 1107 || Current Learning Rate: 0.0001 || Time: 07:31:7.94
Epoch :: 42 || Loss: 0.40651098 || it_count: 8344 || Val Loss: 0.44487432 || Val it_count: 1107 || Current Learning Rate: 0.0001 || Time: 07:42:9.30
Epoch :: 43 || Loss: 0.40611151 || it_count: 8344 || Val Loss: 0.44532028 || Val it_count: 1107 || Current Learning Rate: 0.0001 || Time: 07:53:10.27
Epoch :: 44 || Loss: 0.40577110 || it_count: 8344 || Val Loss: 0.44591891 || Val it_count: 1107 || Current Learning Rate: 0.0001 || Time: 08:04:11.05
Epoch :: 45 || Loss: 0.40544011 || it_count: 8344 || Val Loss: 0.44562274 || Val it_count: 1107 || Current Learning Rate: 0.0001 || Time: 08:15:12.68
Epoch :: 46 || Loss: 0.40515671 || it_count: 8344 || Val Loss: 0.44581524 || Val it_count: 1107 || Current Learning Rate: 0.0001 || Time: 08:26:13.83
Epoch :: 47 || Loss: 0.40486198 || it_count: 8344 || Val Loss: 0.44618069 || Val it_count: 1107 || Current Learning Rate: 0.0001 || Time: 08:37:14.80
Epoch 00032: reducing learning rate of group 0 to 1.0000e-05.
Epoch :: 48 || Loss: 0.40456608 || it_count: 8344 || Val Loss: 0.44640659 || Val it_count: 1107 || Current Learning Rate: 1e-05 || Time: 08:48:16.02
Epoch :: 49 || Loss: 0.40831257 || it_count: 8344 || Val Loss: 0.44973382 || Val it_count: 1107 || Current Learning Rate: 1e-05 || Time: 08:59:17.21
Epoch :: 50 || Loss: 0.40710388 || it_count: 8344 || Val Loss: 0.44918538 || Val it_count: 1107 || Current Learning Rate: 1e-05 || Time: 09:10:18.65
Epoch :: 51 || Loss: 0.40678406 || it_count: 8344 || Val Loss: 0.44880287 || Val it_count: 1107 || Current Learning Rate: 1e-05 || Time: 09:21:20.01
Epoch :: 52 || Loss: 0.40659263 || it_count: 8344 || Val Loss: 0.44861398 || Val it_count: 1107 || Current Learning Rate: 1e-05 || Time: 09:32:20.84
Epoch :: 53 || Loss: 0.40645602 || it_count: 8344 || Val Loss: 0.44853151 || Val it_count: 1107 || Current Learning Rate: 1e-05 || Time: 09:43:21.89
Epoch 00038: reducing learning rate of group 0 to 1.0000e-06.
Epoch :: 54 || Loss: 0.40634704 || it_count: 8344 || Val Loss: 0.44851095 || Val it_count: 1107 || Current Learning Rate: 1.0000000000000002e-06 || Time: 09:54:23.53
Epoch :: 55 || Loss: 0.40682392 || it_count: 8344 || Val Loss: 0.45069025 || Val it_count: 1107 || Current Learning Rate: 1.0000000000000002e-06 || Time: 10:05:24.55
Epoch :: 56 || Loss: 0.40664070 || it_count: 8344 || Val Loss: 0.45055487 || Val it_count: 1107 || Current Learning Rate: 1.0000000000000002e-06 || Time: 10:16:25.48
Epoch :: 57 || Loss: 0.40657866 || it_count: 8344 || Val Loss: 0.45047412 || Val it_count: 1107 || Current Learning Rate: 1.0000000000000002e-06 || Time: 10:27:26.99
Epoch :: 58 || Loss: 0.40654624 || it_count: 8344 || Val Loss: 0.45045744 || Val it_count: 1107 || Current Learning Rate: 1.0000000000000002e-06 || Time: 10:38:27.97
Epoch :: 59 || Loss: 0.40652425 || it_count: 8344 || Val Loss: 0.45047731 || Val it_count: 1107 || Current Learning Rate: 1.0000000000000002e-06 || Time: 10:49:28.92
Epoch 00044: reducing learning rate of group 0 to 1.0000e-07.
Early stopping triggered due to learning rate below threshold.
Done Total time: 11:00:30.45
best_loss: 0.4448743157692659

--------------------Testing--------------------

total_samples :: test_dataset = 139200, test_dataloader = 139200
Epoch ::  1 || Loss: 0.32002652 || it_count: 544 || Time: 00:00:25.84
MAE:  0.28372234
MSE:  0.32009262
RMSE:  0.48272312

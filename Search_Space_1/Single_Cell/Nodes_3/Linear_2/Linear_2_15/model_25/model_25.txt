--------------------Training--------------------
arch_str :: |lstm_1~0|+|skip_connect~0|skip_connect~1|[relu->dropout->linear->relu->linear]
model :: 3S
InferCell(
  info :: nodes=3, inC=1, outC=64, [1<-(I0-L0) | 2<-(I0-L1,I1-L2)], genotype_str: lstm_1~0|skip_connect~0|skip_connect~1
  linear_layers: [relu->dropout->linear->relu->linear]
  (layers): ModuleList(
    (0): LSTM(
      (lstm): LSTM(1, 64, batch_first=True)
    )
    (1): FactorizedReduce(
      C_in=1, C_out=64, stride=1
      (relu): ReLU()
      (conv): Conv1d(1, 64, kernel_size=(1,), stride=(1,), bias=False)
      (bn): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (2): Identity()
  )
  (linear_layers): ModuleList(
    (0): ReLU()
    (1): Dropout(p=0.1, inplace=False)
    (2): Linear(in_features=3072, out_features=1536, bias=True)
    (3): ReLU()
    (4): Linear(in_features=1536, out_features=1, bias=True)
  )
)
tr_params :: epochs = 100, patience = 20, batch_size = 256, window_size = 48, data_size = 100
Model MACs: 5.583M, Model Params: 4.739M
learning rate scheduling :: (optimizer, mode='min', factor=0.1, patience=5, verbose=True)
total_samples :: train_dataset = 2136000, train_dataloader = 2136000
total_samples :: valid_dataset = 283200, valid_dataloader = 283200
Epoch ::  1 || Loss: 0.51043525 || it_count: 8344 || Val Loss: 0.47907540 || Val it_count: 1107 || Current Learning Rate: 0.001 || Time: 00:03:31.85
Epoch ::  2 || Loss: 0.43848919 || it_count: 8344 || Val Loss: 0.48243561 || Val it_count: 1107 || Current Learning Rate: 0.001 || Time: 00:07:1.36
Epoch ::  3 || Loss: 0.42853445 || it_count: 8344 || Val Loss: 0.47830238 || Val it_count: 1107 || Current Learning Rate: 0.001 || Time: 00:10:31.18
Epoch ::  4 || Loss: 0.42333206 || it_count: 8344 || Val Loss: 0.47742357 || Val it_count: 1107 || Current Learning Rate: 0.001 || Time: 00:14:2.17
Epoch ::  5 || Loss: 0.42004893 || it_count: 8344 || Val Loss: 0.46792828 || Val it_count: 1107 || Current Learning Rate: 0.001 || Time: 00:17:30.61
Epoch ::  6 || Loss: 0.41765531 || it_count: 8344 || Val Loss: 0.46712158 || Val it_count: 1107 || Current Learning Rate: 0.001 || Time: 00:21:1.32
Epoch ::  7 || Loss: 0.41598811 || it_count: 8344 || Val Loss: 0.46602003 || Val it_count: 1107 || Current Learning Rate: 0.001 || Time: 00:24:30.76
Epoch ::  8 || Loss: 0.41517174 || it_count: 8344 || Val Loss: 0.46804083 || Val it_count: 1107 || Current Learning Rate: 0.001 || Time: 00:28:1.92
Epoch ::  9 || Loss: 0.41399584 || it_count: 8344 || Val Loss: 0.46559660 || Val it_count: 1107 || Current Learning Rate: 0.001 || Time: 00:31:30.56
Epoch :: 10 || Loss: 0.41311958 || it_count: 8344 || Val Loss: 0.46405537 || Val it_count: 1107 || Current Learning Rate: 0.001 || Time: 00:34:59.24
Epoch :: 11 || Loss: 0.41205699 || it_count: 8344 || Val Loss: 0.46399050 || Val it_count: 1107 || Current Learning Rate: 0.001 || Time: 00:38:25.92
Epoch :: 12 || Loss: 0.41230315 || it_count: 8344 || Val Loss: 0.46396222 || Val it_count: 1107 || Current Learning Rate: 0.001 || Time: 00:41:56.67
Epoch :: 13 || Loss: 0.41212048 || it_count: 8344 || Val Loss: 0.45899053 || Val it_count: 1107 || Current Learning Rate: 0.001 || Time: 00:45:24.88
Epoch :: 14 || Loss: 0.41099108 || it_count: 8344 || Val Loss: 0.46395123 || Val it_count: 1107 || Current Learning Rate: 0.001 || Time: 00:48:52.67
Epoch :: 15 || Loss: 0.41283758 || it_count: 8344 || Val Loss: 0.45894632 || Val it_count: 1107 || Current Learning Rate: 0.001 || Time: 00:52:20.10
Epoch :: 16 || Loss: 0.41149171 || it_count: 8344 || Val Loss: 0.45945789 || Val it_count: 1107 || Current Learning Rate: 0.001 || Time: 00:55:47.83
Epoch :: 17 || Loss: 0.41268190 || it_count: 8344 || Val Loss: 0.46301219 || Val it_count: 1107 || Current Learning Rate: 0.001 || Time: 00:59:18.02
Epoch :: 18 || Loss: 0.41116333 || it_count: 8344 || Val Loss: 0.46464900 || Val it_count: 1107 || Current Learning Rate: 0.001 || Time: 01:02:46.20
Epoch :: 19 || Loss: 0.41100756 || it_count: 8344 || Val Loss: 0.45880542 || Val it_count: 1107 || Current Learning Rate: 0.001 || Time: 01:06:21.52
Epoch :: 20 || Loss: 0.41004763 || it_count: 8344 || Val Loss: 0.46013016 || Val it_count: 1107 || Current Learning Rate: 0.001 || Time: 01:09:49.69
Epoch :: 21 || Loss: 0.40964121 || it_count: 8344 || Val Loss: 0.46341791 || Val it_count: 1107 || Current Learning Rate: 0.001 || Time: 01:13:18.40
Epoch :: 22 || Loss: 0.41008301 || it_count: 8344 || Val Loss: 0.46837555 || Val it_count: 1107 || Current Learning Rate: 0.001 || Time: 01:16:47.35
Epoch :: 23 || Loss: 0.41016106 || it_count: 8344 || Val Loss: 0.47178614 || Val it_count: 1107 || Current Learning Rate: 0.001 || Time: 01:20:16.33
Epoch :: 24 || Loss: 0.41241960 || it_count: 8344 || Val Loss: 0.46566913 || Val it_count: 1107 || Current Learning Rate: 0.001 || Time: 01:23:45.90
Epoch :: 25 || Loss: 0.40926960 || it_count: 8344 || Val Loss: 0.46685961 || Val it_count: 1107 || Current Learning Rate: 0.0001 || Time: 01:27:19.40
Epoch :: 26 || Loss: 0.41178893 || it_count: 8344 || Val Loss: 0.45917628 || Val it_count: 1107 || Current Learning Rate: 0.0001 || Time: 01:30:47.98
Epoch :: 27 || Loss: 0.40901387 || it_count: 8344 || Val Loss: 0.46019131 || Val it_count: 1107 || Current Learning Rate: 0.0001 || Time: 01:34:18.99
Epoch :: 28 || Loss: 0.40849050 || it_count: 8344 || Val Loss: 0.46020216 || Val it_count: 1107 || Current Learning Rate: 0.0001 || Time: 01:37:47.85
Epoch :: 29 || Loss: 0.40799860 || it_count: 8344 || Val Loss: 0.46270744 || Val it_count: 1107 || Current Learning Rate: 0.0001 || Time: 01:41:16.53
Epoch :: 30 || Loss: 0.40767932 || it_count: 8344 || Val Loss: 0.46300095 || Val it_count: 1107 || Current Learning Rate: 0.0001 || Time: 01:44:44.63
Epoch :: 31 || Loss: 0.40760978 || it_count: 8344 || Val Loss: 0.46555193 || Val it_count: 1107 || Current Learning Rate: 1e-05 || Time: 01:48:12.51
Epoch :: 32 || Loss: 0.40858894 || it_count: 8344 || Val Loss: 0.45655564 || Val it_count: 1107 || Current Learning Rate: 1e-05 || Time: 01:51:40.41
Epoch :: 33 || Loss: 0.40784949 || it_count: 8344 || Val Loss: 0.45697874 || Val it_count: 1107 || Current Learning Rate: 1e-05 || Time: 01:55:9.88
Epoch :: 34 || Loss: 0.40770599 || it_count: 8344 || Val Loss: 0.45684920 || Val it_count: 1107 || Current Learning Rate: 1e-05 || Time: 01:58:38.70
Epoch :: 35 || Loss: 0.40761917 || it_count: 8344 || Val Loss: 0.45682694 || Val it_count: 1107 || Current Learning Rate: 1e-05 || Time: 02:02:7.47
Epoch :: 36 || Loss: 0.40757347 || it_count: 8344 || Val Loss: 0.45685371 || Val it_count: 1107 || Current Learning Rate: 1e-05 || Time: 02:05:35.35
Epoch :: 37 || Loss: 0.40741219 || it_count: 8344 || Val Loss: 0.45714983 || Val it_count: 1107 || Current Learning Rate: 1e-05 || Time: 02:09:3.35
Epoch :: 38 || Loss: 0.40744081 || it_count: 8344 || Val Loss: 0.45734651 || Val it_count: 1107 || Current Learning Rate: 1.0000000000000002e-06 || Time: 02:12:34.00
Epoch :: 39 || Loss: 0.40753885 || it_count: 8344 || Val Loss: 0.45541483 || Val it_count: 1107 || Current Learning Rate: 1.0000000000000002e-06 || Time: 02:16:2.30
Epoch :: 40 || Loss: 0.40750105 || it_count: 8344 || Val Loss: 0.45462410 || Val it_count: 1107 || Current Learning Rate: 1.0000000000000002e-06 || Time: 02:19:31.61
Epoch :: 41 || Loss: 0.40741618 || it_count: 8344 || Val Loss: 0.45422388 || Val it_count: 1107 || Current Learning Rate: 1.0000000000000002e-06 || Time: 02:22:59.63
Epoch :: 42 || Loss: 0.40729696 || it_count: 8344 || Val Loss: 0.45410513 || Val it_count: 1107 || Current Learning Rate: 1.0000000000000002e-06 || Time: 02:26:27.66
Epoch :: 43 || Loss: 0.40735647 || it_count: 8344 || Val Loss: 0.45394327 || Val it_count: 1107 || Current Learning Rate: 1.0000000000000002e-06 || Time: 02:29:56.26
Epoch :: 44 || Loss: 0.40735519 || it_count: 8344 || Val Loss: 0.45394148 || Val it_count: 1107 || Current Learning Rate: 1.0000000000000002e-06 || Time: 02:33:23.65
Epoch :: 45 || Loss: 0.40735925 || it_count: 8344 || Val Loss: 0.45393932 || Val it_count: 1107 || Current Learning Rate: 1.0000000000000002e-06 || Time: 02:36:50.34
Epoch :: 46 || Loss: 0.40735448 || it_count: 8344 || Val Loss: 0.45392005 || Val it_count: 1107 || Current Learning Rate: 1.0000000000000002e-06 || Time: 02:40:18.24
Epoch :: 47 || Loss: 0.40729856 || it_count: 8344 || Val Loss: 0.45381093 || Val it_count: 1107 || Current Learning Rate: 1.0000000000000002e-06 || Time: 02:43:46.93
Epoch :: 48 || Loss: 0.40741947 || it_count: 8344 || Val Loss: 0.45377060 || Val it_count: 1107 || Current Learning Rate: 1.0000000000000002e-06 || Time: 02:47:15.34
Epoch :: 49 || Loss: 0.40737224 || it_count: 8344 || Val Loss: 0.45383184 || Val it_count: 1107 || Current Learning Rate: 1.0000000000000002e-06 || Time: 02:50:44.12
Epoch :: 50 || Loss: 0.40736013 || it_count: 8344 || Val Loss: 0.45389714 || Val it_count: 1107 || Current Learning Rate: 1.0000000000000002e-06 || Time: 02:54:12.90
Epoch :: 51 || Loss: 0.40742837 || it_count: 8344 || Val Loss: 0.45387609 || Val it_count: 1107 || Current Learning Rate: 1.0000000000000002e-06 || Time: 02:57:42.73
Epoch :: 52 || Loss: 0.40733941 || it_count: 8344 || Val Loss: 0.45379669 || Val it_count: 1107 || Current Learning Rate: 1.0000000000000002e-06 || Time: 03:01:9.70
Early stopping triggered due to learning rate below threshold.
Done Total time: 03:04:37.93
best_loss: 0.4537706040685042

--------------------Testing--------------------

total_samples :: test_dataset = 139200, test_dataloader = 139200
Epoch ::  1 || Loss: 0.43717502 || it_count: 544 || Time: 00:00:11.39
MAE:  0.30529812
MSE:  0.43728215
RMSE:  0.5112869

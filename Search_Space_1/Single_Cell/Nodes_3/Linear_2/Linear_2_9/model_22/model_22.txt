--------------------Training--------------------
arch_str :: |lstm_1~0|+|skip_connect~0|lstm_2~1|[relu->linear->linear]
model :: 3M
InferCell(
  info :: nodes=3, inC=1, outC=64, [1<-(I0-L0) | 2<-(I0-L1,I1-L2)], genotype_str: lstm_1~0|skip_connect~0|lstm_2~1
  linear_layers: [relu->linear->linear]
  (layers): ModuleList(
    (0): LSTM(
      (lstm): LSTM(1, 64, batch_first=True)
    )
    (1): FactorizedReduce(
      C_in=1, C_out=64, stride=1
      (relu): ReLU()
      (conv): Conv1d(1, 64, kernel_size=(1,), stride=(1,), bias=False)
      (bn): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (2): LSTM(
      (lstm): LSTM(64, 64, num_layers=2, batch_first=True)
    )
  )
  (linear_layers): ModuleList(
    (0): ReLU()
    (1): Linear(in_features=3072, out_features=1536, bias=True)
    (2): Linear(in_features=1536, out_features=1, bias=True)
  )
)
tr_params :: epochs = 100, patience = 20, batch_size = 256, window_size = 48, data_size = 100
Model MACs: 8.827M, Model Params: 4.806M
learning rate scheduling :: (optimizer, mode='min', factor=0.1, patience=5, verbose=True)
total_samples :: train_dataset = 2136000, train_dataloader = 2136000
total_samples :: valid_dataset = 283200, valid_dataloader = 283200
Epoch ::  1 || Loss: 0.46478940 || it_count: 8344 || Val Loss: 0.51858674 || Val it_count: 1107 || Current Learning Rate: 0.001 || Time: 00:08:28.77
Epoch ::  2 || Loss: 0.46371311 || it_count: 8344 || Val Loss: 0.49195973 || Val it_count: 1107 || Current Learning Rate: 0.001 || Time: 00:16:50.00
Epoch ::  3 || Loss: 0.45590442 || it_count: 8344 || Val Loss: 0.48216234 || Val it_count: 1107 || Current Learning Rate: 0.001 || Time: 00:25:13.90
Epoch ::  4 || Loss: 0.45933864 || it_count: 8344 || Val Loss: 0.47435657 || Val it_count: 1107 || Current Learning Rate: 0.001 || Time: 00:33:39.48
Epoch ::  5 || Loss: 0.44386121 || it_count: 8344 || Val Loss: 0.49648437 || Val it_count: 1107 || Current Learning Rate: 0.001 || Time: 00:42:4.87
Epoch ::  6 || Loss: 0.43647978 || it_count: 8344 || Val Loss: 0.48873172 || Val it_count: 1107 || Current Learning Rate: 0.001 || Time: 00:50:30.73
Epoch ::  7 || Loss: 0.43399270 || it_count: 8344 || Val Loss: 0.49447536 || Val it_count: 1107 || Current Learning Rate: 0.001 || Time: 00:58:56.40
Epoch ::  8 || Loss: 0.43137873 || it_count: 8344 || Val Loss: 0.49707864 || Val it_count: 1107 || Current Learning Rate: 0.001 || Time: 01:07:26.58
Epoch ::  9 || Loss: 0.42956979 || it_count: 8344 || Val Loss: 0.49487029 || Val it_count: 1107 || Current Learning Rate: 0.001 || Time: 01:15:51.24
Epoch :: 10 || Loss: 0.42906178 || it_count: 8344 || Val Loss: 0.48796124 || Val it_count: 1107 || Current Learning Rate: 0.001 || Time: 01:24:15.64
Epoch :: 11 || Loss: 0.42543358 || it_count: 8344 || Val Loss: 0.48660696 || Val it_count: 1107 || Current Learning Rate: 0.001 || Time: 01:32:39.65
Epoch :: 12 || Loss: 0.42389980 || it_count: 8344 || Val Loss: 0.48668318 || Val it_count: 1107 || Current Learning Rate: 0.001 || Time: 01:41:4.07
Epoch :: 13 || Loss: 0.41761568 || it_count: 8344 || Val Loss: 0.48849677 || Val it_count: 1107 || Current Learning Rate: 0.001 || Time: 01:49:28.60
Epoch :: 14 || Loss: 0.41578961 || it_count: 8344 || Val Loss: 0.47027366 || Val it_count: 1107 || Current Learning Rate: 0.001 || Time: 01:57:52.69
Epoch :: 15 || Loss: 0.41806790 || it_count: 8344 || Val Loss: 0.47301693 || Val it_count: 1107 || Current Learning Rate: 0.001 || Time: 02:06:17.18
Epoch :: 16 || Loss: 0.41205005 || it_count: 8344 || Val Loss: 0.46188007 || Val it_count: 1107 || Current Learning Rate: 0.001 || Time: 02:14:41.32
Epoch :: 17 || Loss: 0.41131555 || it_count: 8344 || Val Loss: 0.45729182 || Val it_count: 1107 || Current Learning Rate: 0.001 || Time: 02:23:6.58
Epoch :: 18 || Loss: 0.41119818 || it_count: 8344 || Val Loss: 0.45924290 || Val it_count: 1107 || Current Learning Rate: 0.001 || Time: 02:31:32.28
Epoch :: 19 || Loss: 0.41103328 || it_count: 8344 || Val Loss: 0.45892510 || Val it_count: 1107 || Current Learning Rate: 0.001 || Time: 02:39:56.12
Epoch :: 20 || Loss: 0.41141378 || it_count: 8344 || Val Loss: 0.45812615 || Val it_count: 1107 || Current Learning Rate: 0.001 || Time: 02:48:22.36
Epoch :: 21 || Loss: 0.41051200 || it_count: 8344 || Val Loss: 0.45914723 || Val it_count: 1107 || Current Learning Rate: 0.001 || Time: 02:56:47.15
Epoch :: 22 || Loss: 0.41159992 || it_count: 8344 || Val Loss: 0.46107973 || Val it_count: 1107 || Current Learning Rate: 0.001 || Time: 03:05:11.76
Epoch :: 23 || Loss: 0.41046219 || it_count: 8344 || Val Loss: 0.45690036 || Val it_count: 1107 || Current Learning Rate: 0.001 || Time: 03:13:36.61
Epoch :: 24 || Loss: 0.40932926 || it_count: 8344 || Val Loss: 0.45814413 || Val it_count: 1107 || Current Learning Rate: 0.001 || Time: 03:22:0.61
Epoch :: 25 || Loss: 0.40954294 || it_count: 8344 || Val Loss: 0.45719832 || Val it_count: 1107 || Current Learning Rate: 0.001 || Time: 03:30:24.96
Epoch :: 26 || Loss: 0.40830826 || it_count: 8344 || Val Loss: 0.45917656 || Val it_count: 1107 || Current Learning Rate: 0.001 || Time: 03:38:49.01
Epoch :: 27 || Loss: 0.40910426 || it_count: 8344 || Val Loss: 0.45884227 || Val it_count: 1107 || Current Learning Rate: 0.001 || Time: 03:47:12.82
Epoch :: 28 || Loss: 0.40841931 || it_count: 8344 || Val Loss: 0.45849875 || Val it_count: 1107 || Current Learning Rate: 0.001 || Time: 03:55:36.20
Epoch 00013: reducing learning rate of group 0 to 1.0000e-04.
Epoch :: 29 || Loss: 0.40873143 || it_count: 8344 || Val Loss: 0.46006952 || Val it_count: 1107 || Current Learning Rate: 0.0001 || Time: 04:03:59.01
Epoch :: 30 || Loss: 0.41177076 || it_count: 8344 || Val Loss: 0.45606933 || Val it_count: 1107 || Current Learning Rate: 0.0001 || Time: 04:12:24.67
Epoch :: 31 || Loss: 0.40901268 || it_count: 8344 || Val Loss: 0.45587153 || Val it_count: 1107 || Current Learning Rate: 0.0001 || Time: 04:20:54.78
Epoch :: 32 || Loss: 0.40796821 || it_count: 8344 || Val Loss: 0.45508051 || Val it_count: 1107 || Current Learning Rate: 0.0001 || Time: 04:29:25.45
Epoch :: 33 || Loss: 0.40701680 || it_count: 8344 || Val Loss: 0.45346681 || Val it_count: 1107 || Current Learning Rate: 0.0001 || Time: 04:37:56.96
Epoch :: 34 || Loss: 0.40649962 || it_count: 8344 || Val Loss: 0.45594268 || Val it_count: 1107 || Current Learning Rate: 0.0001 || Time: 04:46:29.02
Epoch :: 35 || Loss: 0.40621983 || it_count: 8344 || Val Loss: 0.45570917 || Val it_count: 1107 || Current Learning Rate: 0.0001 || Time: 04:55:0.77
Epoch :: 36 || Loss: 0.40586922 || it_count: 8344 || Val Loss: 0.45651534 || Val it_count: 1107 || Current Learning Rate: 0.0001 || Time: 05:03:32.12
Epoch :: 37 || Loss: 0.40551208 || it_count: 8344 || Val Loss: 0.45579262 || Val it_count: 1107 || Current Learning Rate: 0.0001 || Time: 05:12:3.39
Epoch :: 38 || Loss: 0.40539756 || it_count: 8344 || Val Loss: 0.45515672 || Val it_count: 1107 || Current Learning Rate: 0.0001 || Time: 05:20:35.82
Epoch 00023: reducing learning rate of group 0 to 1.0000e-05.
Epoch :: 39 || Loss: 0.40525956 || it_count: 8344 || Val Loss: 0.45598305 || Val it_count: 1107 || Current Learning Rate: 1e-05 || Time: 05:29:8.32
Epoch :: 40 || Loss: 0.40687952 || it_count: 8344 || Val Loss: 0.44593775 || Val it_count: 1107 || Current Learning Rate: 1e-05 || Time: 05:37:41.22
Epoch :: 41 || Loss: 0.40582683 || it_count: 8344 || Val Loss: 0.44675302 || Val it_count: 1107 || Current Learning Rate: 1e-05 || Time: 05:46:13.14
Epoch :: 42 || Loss: 0.40564370 || it_count: 8344 || Val Loss: 0.44694455 || Val it_count: 1107 || Current Learning Rate: 1e-05 || Time: 05:54:47.38
Epoch :: 43 || Loss: 0.40553381 || it_count: 8344 || Val Loss: 0.44725011 || Val it_count: 1107 || Current Learning Rate: 1e-05 || Time: 06:03:20.27
Epoch :: 44 || Loss: 0.40545287 || it_count: 8344 || Val Loss: 0.44762024 || Val it_count: 1107 || Current Learning Rate: 1e-05 || Time: 06:11:53.71
Epoch :: 45 || Loss: 0.40539185 || it_count: 8344 || Val Loss: 0.44787639 || Val it_count: 1107 || Current Learning Rate: 1e-05 || Time: 06:20:28.07
Epoch 00030: reducing learning rate of group 0 to 1.0000e-06.
Epoch :: 46 || Loss: 0.40532865 || it_count: 8344 || Val Loss: 0.44814276 || Val it_count: 1107 || Current Learning Rate: 1.0000000000000002e-06 || Time: 06:29:2.56
Epoch :: 47 || Loss: 0.40557580 || it_count: 8344 || Val Loss: 0.44554927 || Val it_count: 1107 || Current Learning Rate: 1.0000000000000002e-06 || Time: 06:37:36.79
Epoch :: 48 || Loss: 0.40538774 || it_count: 8344 || Val Loss: 0.44465397 || Val it_count: 1107 || Current Learning Rate: 1.0000000000000002e-06 || Time: 06:46:8.53
Epoch :: 49 || Loss: 0.40533829 || it_count: 8344 || Val Loss: 0.44433500 || Val it_count: 1107 || Current Learning Rate: 1.0000000000000002e-06 || Time: 06:54:40.90
Epoch :: 50 || Loss: 0.40531739 || it_count: 8344 || Val Loss: 0.44422726 || Val it_count: 1107 || Current Learning Rate: 1.0000000000000002e-06 || Time: 07:03:14.08
Epoch :: 51 || Loss: 0.40530425 || it_count: 8344 || Val Loss: 0.44420173 || Val it_count: 1107 || Current Learning Rate: 1.0000000000000002e-06 || Time: 07:11:46.95
Epoch :: 52 || Loss: 0.40529447 || it_count: 8344 || Val Loss: 0.44420507 || Val it_count: 1107 || Current Learning Rate: 1.0000000000000002e-06 || Time: 07:20:22.09
Epoch :: 53 || Loss: 0.40528593 || it_count: 8344 || Val Loss: 0.44422254 || Val it_count: 1107 || Current Learning Rate: 1.0000000000000002e-06 || Time: 07:28:55.08
Epoch :: 54 || Loss: 0.40527831 || it_count: 8344 || Val Loss: 0.44424762 || Val it_count: 1107 || Current Learning Rate: 1.0000000000000002e-06 || Time: 07:37:27.52
Epoch :: 55 || Loss: 0.40527131 || it_count: 8344 || Val Loss: 0.44427732 || Val it_count: 1107 || Current Learning Rate: 1.0000000000000002e-06 || Time: 07:46:0.51
Epoch 00040: reducing learning rate of group 0 to 1.0000e-07.
Early stopping triggered due to learning rate below threshold.
Done Total time: 07:54:33.42
best_loss: 0.4442017283976018

--------------------Testing--------------------

total_samples :: test_dataset = 139200, test_dataloader = 139200
Epoch ::  1 || Loss: 0.41604107 || it_count: 544 || Time: 00:00:22.57
MAE:  0.29311615
MSE:  0.41614538
RMSE:  0.49749166

--------------------Training--------------------
arch_str :: |lstm_3~0|+|lstm_1~0|none~1|[relu->linear->linear]
model :: 3M
InferCell(
  info :: nodes=3, inC=1, outC=64, [1<-(I0-L0) | 2<-(I0-L1,I1-L2)], genotype_str: lstm_3~0|lstm_1~0|none~1
  linear_layers: [relu->linear->linear]
  (layers): ModuleList(
    (0): LSTM(
      (lstm): LSTM(1, 64, num_layers=3, batch_first=True)
    )
    (1): LSTM(
      (lstm): LSTM(1, 64, batch_first=True)
    )
    (2): Zero(C_in=64, C_out=64, stride=1)
  )
  (linear_layers): ModuleList(
    (0): ReLU()
    (1): Linear(in_features=3072, out_features=1536, bias=True)
    (2): Linear(in_features=1536, out_features=1, bias=True)
  )
)
tr_params :: epochs = 100, patience = 20, batch_size = 256, window_size = 48, data_size = 100
Model MACs: 9.660M, Model Params: 4.823M
learning rate scheduling :: (optimizer, mode='min', factor=0.1, patience=5, verbose=True)
total_samples :: train_dataset = 2136000, train_dataloader = 2136000
total_samples :: valid_dataset = 283200, valid_dataloader = 283200
Epoch ::  1 || Loss: 0.42004563 || it_count: 8344 || Val Loss: 0.46309088 || Val it_count: 1107 || Current Learning Rate: 0.001 || Time: 00:08:59.82
Epoch ::  2 || Loss: 0.41828592 || it_count: 8344 || Val Loss: 0.45068837 || Val it_count: 1107 || Current Learning Rate: 0.001 || Time: 00:17:55.41
Epoch ::  3 || Loss: 0.41720715 || it_count: 8344 || Val Loss: 0.44773929 || Val it_count: 1107 || Current Learning Rate: 0.001 || Time: 00:26:47.44
Epoch ::  4 || Loss: 0.41708420 || it_count: 8344 || Val Loss: 0.44711700 || Val it_count: 1107 || Current Learning Rate: 0.001 || Time: 00:35:40.48
Epoch ::  5 || Loss: 0.41628961 || it_count: 8344 || Val Loss: 0.44532593 || Val it_count: 1107 || Current Learning Rate: 0.001 || Time: 00:44:35.57
Epoch ::  6 || Loss: 0.41660497 || it_count: 8344 || Val Loss: 0.44474860 || Val it_count: 1107 || Current Learning Rate: 0.001 || Time: 00:53:31.37
Epoch ::  7 || Loss: 0.41612120 || it_count: 8344 || Val Loss: 0.44490765 || Val it_count: 1107 || Current Learning Rate: 0.001 || Time: 01:02:27.75
Epoch ::  8 || Loss: 0.41564131 || it_count: 8344 || Val Loss: 0.44596694 || Val it_count: 1107 || Current Learning Rate: 0.001 || Time: 01:11:21.62
Epoch ::  9 || Loss: 0.41535751 || it_count: 8344 || Val Loss: 0.44571170 || Val it_count: 1107 || Current Learning Rate: 0.001 || Time: 01:20:16.08
Epoch :: 10 || Loss: 0.41530252 || it_count: 8344 || Val Loss: 0.44641855 || Val it_count: 1107 || Current Learning Rate: 0.001 || Time: 01:29:10.07
Epoch :: 11 || Loss: 0.41505731 || it_count: 8344 || Val Loss: 0.44510041 || Val it_count: 1107 || Current Learning Rate: 0.001 || Time: 01:38:4.63
Epoch :: 12 || Loss: 0.41473291 || it_count: 8344 || Val Loss: 0.44671375 || Val it_count: 1107 || Current Learning Rate: 0.001 || Time: 01:46:57.28
Epoch :: 13 || Loss: 0.41453395 || it_count: 8344 || Val Loss: 0.44823542 || Val it_count: 1107 || Current Learning Rate: 0.001 || Time: 01:55:52.03
Epoch :: 14 || Loss: 0.41399813 || it_count: 8344 || Val Loss: 0.44531930 || Val it_count: 1107 || Current Learning Rate: 0.001 || Time: 02:04:47.40
Epoch :: 15 || Loss: 0.41412453 || it_count: 8344 || Val Loss: 0.44527276 || Val it_count: 1107 || Current Learning Rate: 0.001 || Time: 02:13:44.76
Epoch :: 16 || Loss: 0.41372932 || it_count: 8344 || Val Loss: 0.44663253 || Val it_count: 1107 || Current Learning Rate: 0.001 || Time: 02:22:41.38
Epoch :: 17 || Loss: 0.41363386 || it_count: 8344 || Val Loss: 0.44568336 || Val it_count: 1107 || Current Learning Rate: 0.001 || Time: 02:31:40.60
Epoch :: 18 || Loss: 0.41345620 || it_count: 8344 || Val Loss: 0.44483545 || Val it_count: 1107 || Current Learning Rate: 0.001 || Time: 02:40:36.75
Epoch :: 19 || Loss: 0.41339622 || it_count: 8344 || Val Loss: 0.44375729 || Val it_count: 1107 || Current Learning Rate: 0.001 || Time: 02:49:33.71
Epoch :: 20 || Loss: 0.41316308 || it_count: 8344 || Val Loss: 0.44329235 || Val it_count: 1107 || Current Learning Rate: 0.001 || Time: 02:58:25.60
Epoch :: 21 || Loss: 0.41330064 || it_count: 8344 || Val Loss: 0.44262106 || Val it_count: 1107 || Current Learning Rate: 0.001 || Time: 03:07:9.84
Epoch :: 22 || Loss: 0.41289108 || it_count: 8344 || Val Loss: 0.44292996 || Val it_count: 1107 || Current Learning Rate: 0.001 || Time: 03:15:53.17
Epoch :: 23 || Loss: 0.41266621 || it_count: 8344 || Val Loss: 0.44339828 || Val it_count: 1107 || Current Learning Rate: 0.001 || Time: 03:24:36.63
Epoch :: 24 || Loss: 0.41256090 || it_count: 8344 || Val Loss: 0.44364590 || Val it_count: 1107 || Current Learning Rate: 0.001 || Time: 03:33:25.08
Epoch :: 25 || Loss: 0.41224876 || it_count: 8344 || Val Loss: 0.44443970 || Val it_count: 1107 || Current Learning Rate: 0.001 || Time: 03:42:8.65
Epoch :: 26 || Loss: 0.41213467 || it_count: 8344 || Val Loss: 0.44461086 || Val it_count: 1107 || Current Learning Rate: 0.001 || Time: 03:50:53.05
Epoch 00011: reducing learning rate of group 0 to 1.0000e-04.
Epoch :: 27 || Loss: 0.41189404 || it_count: 8344 || Val Loss: 0.44364444 || Val it_count: 1107 || Current Learning Rate: 0.0001 || Time: 03:59:35.46
Epoch :: 28 || Loss: 0.41873839 || it_count: 8344 || Val Loss: 0.43519247 || Val it_count: 1107 || Current Learning Rate: 0.0001 || Time: 04:08:20.47
Epoch :: 29 || Loss: 0.41705356 || it_count: 8344 || Val Loss: 0.43372263 || Val it_count: 1107 || Current Learning Rate: 0.0001 || Time: 04:17:6.49
Epoch :: 30 || Loss: 0.41639316 || it_count: 8344 || Val Loss: 0.43288202 || Val it_count: 1107 || Current Learning Rate: 0.0001 || Time: 04:25:57.96
Epoch :: 31 || Loss: 0.41593621 || it_count: 8344 || Val Loss: 0.43247614 || Val it_count: 1107 || Current Learning Rate: 0.0001 || Time: 04:34:44.76
Epoch :: 32 || Loss: 0.41559158 || it_count: 8344 || Val Loss: 0.43222662 || Val it_count: 1107 || Current Learning Rate: 0.0001 || Time: 04:43:32.53
Epoch :: 33 || Loss: 0.41532126 || it_count: 8344 || Val Loss: 0.43220161 || Val it_count: 1107 || Current Learning Rate: 0.0001 || Time: 04:52:22.67
Epoch :: 34 || Loss: 0.41506506 || it_count: 8344 || Val Loss: 0.43237289 || Val it_count: 1107 || Current Learning Rate: 0.0001 || Time: 05:01:24.33
Epoch :: 35 || Loss: 0.41493683 || it_count: 8344 || Val Loss: 0.43217707 || Val it_count: 1107 || Current Learning Rate: 0.0001 || Time: 05:10:19.50
Epoch :: 36 || Loss: 0.41476852 || it_count: 8344 || Val Loss: 0.43208354 || Val it_count: 1107 || Current Learning Rate: 0.0001 || Time: 05:19:5.86
Epoch :: 37 || Loss: 0.41459347 || it_count: 8344 || Val Loss: 0.43217136 || Val it_count: 1107 || Current Learning Rate: 0.0001 || Time: 05:27:53.98
Epoch :: 38 || Loss: 0.41451148 || it_count: 8344 || Val Loss: 0.43189352 || Val it_count: 1107 || Current Learning Rate: 0.0001 || Time: 05:36:42.37
Epoch :: 39 || Loss: 0.41440351 || it_count: 8344 || Val Loss: 0.43170833 || Val it_count: 1107 || Current Learning Rate: 0.0001 || Time: 05:45:31.86
Epoch :: 40 || Loss: 0.41428559 || it_count: 8344 || Val Loss: 0.43150212 || Val it_count: 1107 || Current Learning Rate: 0.0001 || Time: 05:54:19.03
Epoch :: 41 || Loss: 0.41419493 || it_count: 8344 || Val Loss: 0.43149040 || Val it_count: 1107 || Current Learning Rate: 0.0001 || Time: 06:03:8.64
Epoch :: 42 || Loss: 0.41411300 || it_count: 8344 || Val Loss: 0.43142316 || Val it_count: 1107 || Current Learning Rate: 0.0001 || Time: 06:11:57.63
Epoch :: 43 || Loss: 0.41398627 || it_count: 8344 || Val Loss: 0.43157855 || Val it_count: 1107 || Current Learning Rate: 0.0001 || Time: 06:20:50.68
Epoch :: 44 || Loss: 0.41395572 || it_count: 8344 || Val Loss: 0.43156970 || Val it_count: 1107 || Current Learning Rate: 0.0001 || Time: 06:29:51.19
Epoch :: 45 || Loss: 0.41389453 || it_count: 8344 || Val Loss: 0.43155757 || Val it_count: 1107 || Current Learning Rate: 0.0001 || Time: 06:38:45.00
Epoch :: 46 || Loss: 0.41382055 || it_count: 8344 || Val Loss: 0.43157312 || Val it_count: 1107 || Current Learning Rate: 0.0001 || Time: 06:47:36.16
Epoch :: 47 || Loss: 0.41376351 || it_count: 8344 || Val Loss: 0.43149714 || Val it_count: 1107 || Current Learning Rate: 0.0001 || Time: 06:56:26.10
Epoch 00032: reducing learning rate of group 0 to 1.0000e-05.
Epoch :: 48 || Loss: 0.41370786 || it_count: 8344 || Val Loss: 0.43153503 || Val it_count: 1107 || Current Learning Rate: 1e-05 || Time: 07:05:13.60
Epoch :: 49 || Loss: 0.41747314 || it_count: 8344 || Val Loss: 0.42062705 || Val it_count: 1107 || Current Learning Rate: 1e-05 || Time: 07:13:59.00
Epoch :: 50 || Loss: 0.41581267 || it_count: 8344 || Val Loss: 0.41999769 || Val it_count: 1107 || Current Learning Rate: 1e-05 || Time: 07:22:47.34
Epoch :: 51 || Loss: 0.41549611 || it_count: 8344 || Val Loss: 0.41968204 || Val it_count: 1107 || Current Learning Rate: 1e-05 || Time: 07:31:34.76
Epoch :: 52 || Loss: 0.41531237 || it_count: 8344 || Val Loss: 0.41949084 || Val it_count: 1107 || Current Learning Rate: 1e-05 || Time: 07:40:20.73
Epoch :: 53 || Loss: 0.41518975 || it_count: 8344 || Val Loss: 0.41937755 || Val it_count: 1107 || Current Learning Rate: 1e-05 || Time: 07:49:6.03
Epoch :: 54 || Loss: 0.41510590 || it_count: 8344 || Val Loss: 0.41931067 || Val it_count: 1107 || Current Learning Rate: 1e-05 || Time: 07:57:54.44
Epoch :: 55 || Loss: 0.41504416 || it_count: 8344 || Val Loss: 0.41927329 || Val it_count: 1107 || Current Learning Rate: 1e-05 || Time: 08:06:41.91
Epoch :: 56 || Loss: 0.41499637 || it_count: 8344 || Val Loss: 0.41925601 || Val it_count: 1107 || Current Learning Rate: 1e-05 || Time: 08:15:30.58
Epoch :: 57 || Loss: 0.41495752 || it_count: 8344 || Val Loss: 0.41923775 || Val it_count: 1107 || Current Learning Rate: 1e-05 || Time: 08:24:21.29
Epoch :: 58 || Loss: 0.41492415 || it_count: 8344 || Val Loss: 0.41923878 || Val it_count: 1107 || Current Learning Rate: 1e-05 || Time: 08:33:6.47
Epoch :: 59 || Loss: 0.41489491 || it_count: 8344 || Val Loss: 0.41924113 || Val it_count: 1107 || Current Learning Rate: 1e-05 || Time: 08:41:51.37
Epoch :: 60 || Loss: 0.41486928 || it_count: 8344 || Val Loss: 0.41924765 || Val it_count: 1107 || Current Learning Rate: 1e-05 || Time: 08:50:41.45
Epoch :: 61 || Loss: 0.41484608 || it_count: 8344 || Val Loss: 0.41925864 || Val it_count: 1107 || Current Learning Rate: 1e-05 || Time: 08:59:28.05
Epoch 00046: reducing learning rate of group 0 to 1.0000e-06.
Epoch :: 62 || Loss: 0.41482449 || it_count: 8344 || Val Loss: 0.41927084 || Val it_count: 1107 || Current Learning Rate: 1.0000000000000002e-06 || Time: 09:08:11.89
Epoch :: 63 || Loss: 0.41521636 || it_count: 8344 || Val Loss: 0.41844022 || Val it_count: 1107 || Current Learning Rate: 1.0000000000000002e-06 || Time: 09:16:55.54
Epoch :: 64 || Loss: 0.41505498 || it_count: 8344 || Val Loss: 0.41826590 || Val it_count: 1107 || Current Learning Rate: 1.0000000000000002e-06 || Time: 09:25:40.25
Epoch :: 65 || Loss: 0.41499820 || it_count: 8344 || Val Loss: 0.41818511 || Val it_count: 1107 || Current Learning Rate: 1.0000000000000002e-06 || Time: 09:34:25.66
Epoch :: 66 || Loss: 0.41496921 || it_count: 8344 || Val Loss: 0.41814217 || Val it_count: 1107 || Current Learning Rate: 1.0000000000000002e-06 || Time: 09:43:10.02
Epoch :: 67 || Loss: 0.41495150 || it_count: 8344 || Val Loss: 0.41811694 || Val it_count: 1107 || Current Learning Rate: 1.0000000000000002e-06 || Time: 09:51:57.02
Epoch :: 68 || Loss: 0.41493930 || it_count: 8344 || Val Loss: 0.41810032 || Val it_count: 1107 || Current Learning Rate: 1.0000000000000002e-06 || Time: 10:00:47.49
Epoch :: 69 || Loss: 0.41492998 || it_count: 8344 || Val Loss: 0.41808837 || Val it_count: 1107 || Current Learning Rate: 1.0000000000000002e-06 || Time: 10:09:36.55
Epoch :: 70 || Loss: 0.41492257 || it_count: 8344 || Val Loss: 0.41807898 || Val it_count: 1107 || Current Learning Rate: 1.0000000000000002e-06 || Time: 10:18:27.06
Epoch :: 71 || Loss: 0.41491637 || it_count: 8344 || Val Loss: 0.41807106 || Val it_count: 1107 || Current Learning Rate: 1.0000000000000002e-06 || Time: 10:27:17.74
Epoch :: 72 || Loss: 0.41491090 || it_count: 8344 || Val Loss: 0.41806392 || Val it_count: 1107 || Current Learning Rate: 1.0000000000000002e-06 || Time: 10:36:7.01
Epoch :: 73 || Loss: 0.41490603 || it_count: 8344 || Val Loss: 0.41805712 || Val it_count: 1107 || Current Learning Rate: 1.0000000000000002e-06 || Time: 10:44:56.42
Epoch :: 74 || Loss: 0.41490165 || it_count: 8344 || Val Loss: 0.41805064 || Val it_count: 1107 || Current Learning Rate: 1.0000000000000002e-06 || Time: 10:53:46.92
Epoch :: 75 || Loss: 0.41489758 || it_count: 8344 || Val Loss: 0.41804445 || Val it_count: 1107 || Current Learning Rate: 1.0000000000000002e-06 || Time: 11:02:38.71
Epoch :: 76 || Loss: 0.41489368 || it_count: 8344 || Val Loss: 0.41803850 || Val it_count: 1107 || Current Learning Rate: 1.0000000000000002e-06 || Time: 11:11:30.14
Epoch :: 77 || Loss: 0.41489003 || it_count: 8344 || Val Loss: 0.41803230 || Val it_count: 1107 || Current Learning Rate: 1.0000000000000002e-06 || Time: 11:20:22.13
Epoch :: 78 || Loss: 0.41488670 || it_count: 8344 || Val Loss: 0.41802619 || Val it_count: 1107 || Current Learning Rate: 1.0000000000000002e-06 || Time: 11:29:17.87
Epoch 00063: reducing learning rate of group 0 to 1.0000e-07.
Early stopping triggered due to learning rate below threshold.
Done Total time: 11:38:11.51
best_loss: 0.41802618620768517

--------------------Testing--------------------

total_samples :: test_dataset = 139200, test_dataloader = 139200
Epoch ::  1 || Loss: 0.24324669 || it_count: 544 || Time: 00:00:23.08
MAE:  0.259405
MSE:  0.2432692
RMSE:  0.44769794

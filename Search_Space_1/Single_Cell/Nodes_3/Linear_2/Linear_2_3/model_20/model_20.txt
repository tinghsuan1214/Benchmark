--------------------Training--------------------
arch_str :: |lstm_1~0|+|none~0|skip_connect~1|[linear->relu->linear]
model :: 3G
InferCell(
  info :: nodes=3, inC=1, outC=64, [1<-(I0-L0) | 2<-(I0-L1,I1-L2)], genotype_str: lstm_1~0|none~0|skip_connect~1
  linear_layers: [linear->relu->linear]
  (layers): ModuleList(
    (0): LSTM(
      (lstm): LSTM(1, 64, batch_first=True)
    )
    (1): Zero(C_in=1, C_out=64, stride=1)
    (2): Identity()
  )
  (linear_layers): ModuleList(
    (0): Linear(in_features=3072, out_features=1536, bias=True)
    (1): ReLU()
    (2): Linear(in_features=1536, out_features=1, bias=True)
  )
)
tr_params :: epochs = 100, patience = 20, batch_size = 256, window_size = 48, data_size = 100
Model MACs: 5.568M, Model Params: 4.739M
learning rate scheduling :: (optimizer, mode='min', factor=0.1, patience=5, verbose=True)
total_samples :: train_dataset = 2136000, train_dataloader = 2136000
total_samples :: valid_dataset = 283200, valid_dataloader = 283200
Epoch ::  1 || Loss: 0.41528892 || it_count: 8344 || Val Loss: 0.44635011 || Val it_count: 1107 || Current Learning Rate: 0.001 || Time: 00:03:46.16
Epoch ::  2 || Loss: 0.41284743 || it_count: 8344 || Val Loss: 0.44650109 || Val it_count: 1107 || Current Learning Rate: 0.001 || Time: 00:07:26.65
Epoch ::  3 || Loss: 0.41169182 || it_count: 8344 || Val Loss: 0.44562641 || Val it_count: 1107 || Current Learning Rate: 0.001 || Time: 00:11:7.15
Epoch ::  4 || Loss: 0.41070610 || it_count: 8344 || Val Loss: 0.44963261 || Val it_count: 1107 || Current Learning Rate: 0.001 || Time: 00:14:46.43
Epoch ::  5 || Loss: 0.41006797 || it_count: 8344 || Val Loss: 0.44865798 || Val it_count: 1107 || Current Learning Rate: 0.001 || Time: 00:18:25.45
Epoch ::  6 || Loss: 0.40904509 || it_count: 8344 || Val Loss: 0.45612089 || Val it_count: 1107 || Current Learning Rate: 0.001 || Time: 00:22:6.73
Epoch ::  7 || Loss: 0.40801805 || it_count: 8344 || Val Loss: 0.45198978 || Val it_count: 1107 || Current Learning Rate: 0.001 || Time: 00:25:46.37
Epoch ::  8 || Loss: 0.40707789 || it_count: 8344 || Val Loss: 0.45119999 || Val it_count: 1107 || Current Learning Rate: 0.001 || Time: 00:29:24.93
Epoch ::  9 || Loss: 0.40615986 || it_count: 8344 || Val Loss: 0.45267553 || Val it_count: 1107 || Current Learning Rate: 0.001 || Time: 00:33:4.27
Epoch :: 10 || Loss: 0.40541195 || it_count: 8344 || Val Loss: 0.44563144 || Val it_count: 1107 || Current Learning Rate: 0.001 || Time: 00:36:43.99
Epoch :: 11 || Loss: 0.40457187 || it_count: 8344 || Val Loss: 0.45230641 || Val it_count: 1107 || Current Learning Rate: 0.001 || Time: 00:40:24.16
Epoch :: 12 || Loss: 0.40378012 || it_count: 8344 || Val Loss: 0.45756123 || Val it_count: 1107 || Current Learning Rate: 0.001 || Time: 00:44:4.86
Epoch :: 13 || Loss: 0.40291509 || it_count: 8344 || Val Loss: 0.44592347 || Val it_count: 1107 || Current Learning Rate: 0.001 || Time: 00:47:45.04
Epoch :: 14 || Loss: 0.40191795 || it_count: 8344 || Val Loss: 0.44465615 || Val it_count: 1107 || Current Learning Rate: 0.001 || Time: 00:51:24.83
Epoch :: 15 || Loss: 0.40082109 || it_count: 8344 || Val Loss: 0.45163234 || Val it_count: 1107 || Current Learning Rate: 0.001 || Time: 00:55:5.02
Epoch :: 16 || Loss: 0.40014580 || it_count: 8344 || Val Loss: 0.44572541 || Val it_count: 1107 || Current Learning Rate: 0.001 || Time: 00:58:44.16
Epoch :: 17 || Loss: 0.39900826 || it_count: 8344 || Val Loss: 0.45039096 || Val it_count: 1107 || Current Learning Rate: 0.001 || Time: 01:02:24.32
Epoch :: 18 || Loss: 0.39801072 || it_count: 8344 || Val Loss: 0.45043652 || Val it_count: 1107 || Current Learning Rate: 0.001 || Time: 01:06:4.21
Epoch :: 19 || Loss: 0.39658243 || it_count: 8344 || Val Loss: 0.44535709 || Val it_count: 1107 || Current Learning Rate: 0.001 || Time: 01:09:43.91
Epoch :: 20 || Loss: 0.39529822 || it_count: 8344 || Val Loss: 0.44509916 || Val it_count: 1107 || Current Learning Rate: 0.001 || Time: 01:13:24.58
Epoch :: 21 || Loss: 0.39387303 || it_count: 8344 || Val Loss: 0.44687421 || Val it_count: 1107 || Current Learning Rate: 0.001 || Time: 01:17:4.35
Epoch :: 22 || Loss: 0.39241496 || it_count: 8344 || Val Loss: 0.44885243 || Val it_count: 1107 || Current Learning Rate: 0.001 || Time: 01:20:44.36
Epoch :: 23 || Loss: 0.39105589 || it_count: 8344 || Val Loss: 0.45097028 || Val it_count: 1107 || Current Learning Rate: 0.001 || Time: 01:24:25.14
Epoch :: 24 || Loss: 0.38914752 || it_count: 8344 || Val Loss: 0.45211849 || Val it_count: 1107 || Current Learning Rate: 0.001 || Time: 01:28:4.69
Epoch :: 25 || Loss: 0.38743859 || it_count: 8344 || Val Loss: 0.45403711 || Val it_count: 1107 || Current Learning Rate: 0.001 || Time: 01:31:44.80
Epoch 00010: reducing learning rate of group 0 to 1.0000e-04.
Epoch :: 26 || Loss: 0.38508104 || it_count: 8344 || Val Loss: 0.45962803 || Val it_count: 1107 || Current Learning Rate: 0.0001 || Time: 01:35:25.28
Epoch :: 27 || Loss: 0.39706401 || it_count: 8344 || Val Loss: 0.42937792 || Val it_count: 1107 || Current Learning Rate: 0.0001 || Time: 01:39:4.91
Epoch :: 28 || Loss: 0.39196058 || it_count: 8344 || Val Loss: 0.42887421 || Val it_count: 1107 || Current Learning Rate: 0.0001 || Time: 01:42:45.96
Epoch :: 29 || Loss: 0.38911660 || it_count: 8344 || Val Loss: 0.42988134 || Val it_count: 1107 || Current Learning Rate: 0.0001 || Time: 01:46:26.08
Epoch :: 30 || Loss: 0.38686562 || it_count: 8344 || Val Loss: 0.43145556 || Val it_count: 1107 || Current Learning Rate: 0.0001 || Time: 01:50:7.40
Epoch :: 31 || Loss: 0.38488220 || it_count: 8344 || Val Loss: 0.43271868 || Val it_count: 1107 || Current Learning Rate: 0.0001 || Time: 01:53:47.20
Epoch :: 32 || Loss: 0.38304403 || it_count: 8344 || Val Loss: 0.43411541 || Val it_count: 1107 || Current Learning Rate: 0.0001 || Time: 01:57:27.63
Epoch :: 33 || Loss: 0.38131684 || it_count: 8344 || Val Loss: 0.43572923 || Val it_count: 1107 || Current Learning Rate: 0.0001 || Time: 02:01:7.41
Epoch 00018: reducing learning rate of group 0 to 1.0000e-05.
Epoch :: 34 || Loss: 0.37969030 || it_count: 8344 || Val Loss: 0.43711719 || Val it_count: 1107 || Current Learning Rate: 1e-05 || Time: 02:04:46.16
Epoch :: 35 || Loss: 0.39235255 || it_count: 8344 || Val Loss: 0.42616803 || Val it_count: 1107 || Current Learning Rate: 1e-05 || Time: 02:08:26.18
Epoch :: 36 || Loss: 0.38814444 || it_count: 8344 || Val Loss: 0.42577028 || Val it_count: 1107 || Current Learning Rate: 1e-05 || Time: 02:12:6.67
Epoch :: 37 || Loss: 0.38728946 || it_count: 8344 || Val Loss: 0.42556615 || Val it_count: 1107 || Current Learning Rate: 1e-05 || Time: 02:15:46.87
Epoch :: 38 || Loss: 0.38678206 || it_count: 8344 || Val Loss: 0.42546240 || Val it_count: 1107 || Current Learning Rate: 1e-05 || Time: 02:19:27.68
Epoch :: 39 || Loss: 0.38638038 || it_count: 8344 || Val Loss: 0.42545033 || Val it_count: 1107 || Current Learning Rate: 1e-05 || Time: 02:23:8.48
Epoch :: 40 || Loss: 0.38602400 || it_count: 8344 || Val Loss: 0.42541127 || Val it_count: 1107 || Current Learning Rate: 1e-05 || Time: 02:26:51.81
Epoch :: 41 || Loss: 0.38568922 || it_count: 8344 || Val Loss: 0.42539864 || Val it_count: 1107 || Current Learning Rate: 1e-05 || Time: 02:30:34.07
Epoch :: 42 || Loss: 0.38537198 || it_count: 8344 || Val Loss: 0.42541219 || Val it_count: 1107 || Current Learning Rate: 1e-05 || Time: 02:34:15.69
Epoch :: 43 || Loss: 0.38507344 || it_count: 8344 || Val Loss: 0.42543251 || Val it_count: 1107 || Current Learning Rate: 1e-05 || Time: 02:37:55.30
Epoch :: 44 || Loss: 0.38477930 || it_count: 8344 || Val Loss: 0.42544541 || Val it_count: 1107 || Current Learning Rate: 1e-05 || Time: 02:41:35.02
Epoch :: 45 || Loss: 0.38450036 || it_count: 8344 || Val Loss: 0.42548852 || Val it_count: 1107 || Current Learning Rate: 1e-05 || Time: 02:45:16.36
Epoch 00030: reducing learning rate of group 0 to 1.0000e-06.
Epoch :: 46 || Loss: 0.38422867 || it_count: 8344 || Val Loss: 0.42553232 || Val it_count: 1107 || Current Learning Rate: 1.0000000000000002e-06 || Time: 02:48:57.27
Epoch :: 47 || Loss: 0.38490625 || it_count: 8344 || Val Loss: 0.42603837 || Val it_count: 1107 || Current Learning Rate: 1.0000000000000002e-06 || Time: 02:52:38.53
Epoch :: 48 || Loss: 0.38472764 || it_count: 8344 || Val Loss: 0.42620111 || Val it_count: 1107 || Current Learning Rate: 1.0000000000000002e-06 || Time: 02:56:19.05
Epoch :: 49 || Loss: 0.38463259 || it_count: 8344 || Val Loss: 0.42623476 || Val it_count: 1107 || Current Learning Rate: 1.0000000000000002e-06 || Time: 03:00:1.66
Epoch :: 50 || Loss: 0.38456342 || it_count: 8344 || Val Loss: 0.42623242 || Val it_count: 1107 || Current Learning Rate: 1.0000000000000002e-06 || Time: 03:03:44.58
Epoch :: 51 || Loss: 0.38450943 || it_count: 8344 || Val Loss: 0.42622095 || Val it_count: 1107 || Current Learning Rate: 1.0000000000000002e-06 || Time: 03:07:25.96
Epoch 00036: reducing learning rate of group 0 to 1.0000e-07.
Early stopping triggered due to learning rate below threshold.
Done Total time: 03:11:6.29
best_loss: 0.4253986422783746

--------------------Testing--------------------

total_samples :: test_dataset = 139200, test_dataloader = 139200
Epoch ::  1 || Loss: 0.25203776 || it_count: 544 || Time: 00:00:12.23
MAE:  0.26021603
MSE:  0.2520595
RMSE:  0.45480958

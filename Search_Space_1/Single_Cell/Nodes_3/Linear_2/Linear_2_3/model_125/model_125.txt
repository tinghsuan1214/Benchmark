--------------------Training--------------------
arch_str :: |skip_connect~0|+|skip_connect~0|skip_connect~1|[linear->relu->linear]
model :: 3G
InferCell(
  info :: nodes=3, inC=1, outC=64, [1<-(I0-L0) | 2<-(I0-L1,I1-L2)], genotype_str: skip_connect~0|skip_connect~0|skip_connect~1
  linear_layers: [linear->relu->linear]
  (layers): ModuleList(
    (0-1): 2 x FactorizedReduce(
      C_in=1, C_out=64, stride=1
      (relu): ReLU()
      (conv): Conv1d(1, 64, kernel_size=(1,), stride=(1,), bias=False)
      (bn): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (2): Identity()
  )
  (linear_layers): ModuleList(
    (0): Linear(in_features=3072, out_features=1536, bias=True)
    (1): ReLU()
    (2): Linear(in_features=1536, out_features=1, bias=True)
  )
)
tr_params :: epochs = 100, patience = 20, batch_size = 256, window_size = 48, data_size = 100
Model MACs: 4.751M, Model Params: 4.722M
learning rate scheduling :: (optimizer, mode='min', factor=0.1, patience=5, verbose=True)
total_samples :: train_dataset = 2136000, train_dataloader = 2136000
total_samples :: valid_dataset = 283200, valid_dataloader = 283200
Epoch ::  1 || Loss: 0.47810294 || it_count: 8344 || Val Loss: 0.49779334 || Val it_count: 1107 || Current Learning Rate: 0.001 || Time: 00:03:39.55
Epoch ::  2 || Loss: 0.46322989 || it_count: 8344 || Val Loss: 0.48898553 || Val it_count: 1107 || Current Learning Rate: 0.001 || Time: 00:07:15.36
Epoch ::  3 || Loss: 0.46246568 || it_count: 8344 || Val Loss: 0.50893907 || Val it_count: 1107 || Current Learning Rate: 0.001 || Time: 00:10:50.42
Epoch ::  4 || Loss: 0.45993655 || it_count: 8344 || Val Loss: 0.49888760 || Val it_count: 1107 || Current Learning Rate: 0.001 || Time: 00:14:26.28
Epoch ::  5 || Loss: 0.45280105 || it_count: 8344 || Val Loss: 0.48786269 || Val it_count: 1107 || Current Learning Rate: 0.001 || Time: 00:18:1.42
Epoch ::  6 || Loss: 0.44917061 || it_count: 8344 || Val Loss: 0.49205282 || Val it_count: 1107 || Current Learning Rate: 0.001 || Time: 00:21:35.93
Epoch ::  7 || Loss: 0.44582847 || it_count: 8344 || Val Loss: 0.48639265 || Val it_count: 1107 || Current Learning Rate: 0.001 || Time: 00:25:11.26
Epoch ::  8 || Loss: 0.44801487 || it_count: 8344 || Val Loss: 0.49114698 || Val it_count: 1107 || Current Learning Rate: 0.001 || Time: 00:28:47.69
Epoch ::  9 || Loss: 0.44637954 || it_count: 8344 || Val Loss: 0.48433689 || Val it_count: 1107 || Current Learning Rate: 0.001 || Time: 00:32:22.19
Epoch :: 10 || Loss: 0.44703274 || it_count: 8344 || Val Loss: 0.48787274 || Val it_count: 1107 || Current Learning Rate: 0.001 || Time: 00:35:57.74
Epoch :: 11 || Loss: 0.44509367 || it_count: 8344 || Val Loss: 0.50034629 || Val it_count: 1107 || Current Learning Rate: 0.001 || Time: 00:39:32.62
Epoch :: 12 || Loss: 0.44505897 || it_count: 8344 || Val Loss: 0.50055449 || Val it_count: 1107 || Current Learning Rate: 0.001 || Time: 00:43:8.53
Epoch :: 13 || Loss: 0.44383858 || it_count: 8344 || Val Loss: 0.49238684 || Val it_count: 1107 || Current Learning Rate: 0.001 || Time: 00:46:44.36
Epoch :: 14 || Loss: 0.44447230 || it_count: 8344 || Val Loss: 0.49776926 || Val it_count: 1107 || Current Learning Rate: 0.001 || Time: 00:50:20.45
Epoch :: 15 || Loss: 0.44549238 || it_count: 8344 || Val Loss: 0.49607372 || Val it_count: 1107 || Current Learning Rate: 0.001 || Time: 00:53:55.79
Epoch :: 16 || Loss: 0.44186500 || it_count: 8344 || Val Loss: 0.49073141 || Val it_count: 1107 || Current Learning Rate: 0.001 || Time: 00:57:33.06
Epoch :: 17 || Loss: 0.44210789 || it_count: 8344 || Val Loss: 0.49741700 || Val it_count: 1107 || Current Learning Rate: 0.001 || Time: 01:01:7.69
Epoch :: 18 || Loss: 0.44216175 || it_count: 8344 || Val Loss: 0.48996016 || Val it_count: 1107 || Current Learning Rate: 0.001 || Time: 01:04:42.29
Epoch :: 19 || Loss: 0.44273402 || it_count: 8344 || Val Loss: 0.53136687 || Val it_count: 1107 || Current Learning Rate: 0.001 || Time: 01:08:17.22
Epoch :: 20 || Loss: 0.44127487 || it_count: 8344 || Val Loss: 0.52176843 || Val it_count: 1107 || Current Learning Rate: 0.001 || Time: 01:11:53.36
Epoch :: 21 || Loss: 0.44145454 || it_count: 8344 || Val Loss: 0.51959074 || Val it_count: 1107 || Current Learning Rate: 0.001 || Time: 01:15:28.17
Epoch :: 22 || Loss: 0.44293706 || it_count: 8344 || Val Loss: 0.52111255 || Val it_count: 1107 || Current Learning Rate: 0.001 || Time: 01:19:2.54
Epoch :: 23 || Loss: 0.44326108 || it_count: 8344 || Val Loss: 0.51654360 || Val it_count: 1107 || Current Learning Rate: 0.001 || Time: 01:22:39.17
Epoch 00008: reducing learning rate of group 0 to 1.0000e-04.
Epoch :: 24 || Loss: 0.44140985 || it_count: 8344 || Val Loss: 0.49901941 || Val it_count: 1107 || Current Learning Rate: 0.0001 || Time: 01:26:14.67
Epoch :: 25 || Loss: 0.45555214 || it_count: 8344 || Val Loss: 0.46800582 || Val it_count: 1107 || Current Learning Rate: 0.0001 || Time: 01:29:50.15
Epoch :: 26 || Loss: 0.44356524 || it_count: 8344 || Val Loss: 0.47150453 || Val it_count: 1107 || Current Learning Rate: 0.0001 || Time: 01:33:24.85
Epoch :: 27 || Loss: 0.43973349 || it_count: 8344 || Val Loss: 0.47059537 || Val it_count: 1107 || Current Learning Rate: 0.0001 || Time: 01:36:59.61
Epoch :: 28 || Loss: 0.43739875 || it_count: 8344 || Val Loss: 0.47248399 || Val it_count: 1107 || Current Learning Rate: 0.0001 || Time: 01:40:34.70
Epoch :: 29 || Loss: 0.43521877 || it_count: 8344 || Val Loss: 0.46714293 || Val it_count: 1107 || Current Learning Rate: 0.0001 || Time: 01:44:9.86
Epoch :: 30 || Loss: 0.43316869 || it_count: 8344 || Val Loss: 0.46618992 || Val it_count: 1107 || Current Learning Rate: 0.0001 || Time: 01:47:45.15
Epoch :: 31 || Loss: 0.43130961 || it_count: 8344 || Val Loss: 0.46634075 || Val it_count: 1107 || Current Learning Rate: 0.0001 || Time: 01:51:23.36
Epoch :: 32 || Loss: 0.42999636 || it_count: 8344 || Val Loss: 0.46790638 || Val it_count: 1107 || Current Learning Rate: 0.0001 || Time: 01:55:0.53
Epoch :: 33 || Loss: 0.42928402 || it_count: 8344 || Val Loss: 0.46818930 || Val it_count: 1107 || Current Learning Rate: 0.0001 || Time: 01:58:35.97
Epoch :: 34 || Loss: 0.42790688 || it_count: 8344 || Val Loss: 0.47301518 || Val it_count: 1107 || Current Learning Rate: 0.0001 || Time: 02:02:10.18
Epoch :: 35 || Loss: 0.42670903 || it_count: 8344 || Val Loss: 0.47252683 || Val it_count: 1107 || Current Learning Rate: 0.0001 || Time: 02:05:46.29
Epoch 00020: reducing learning rate of group 0 to 1.0000e-05.
Epoch :: 36 || Loss: 0.42646816 || it_count: 8344 || Val Loss: 0.47192461 || Val it_count: 1107 || Current Learning Rate: 1e-05 || Time: 02:09:21.93
Epoch :: 37 || Loss: 0.43956372 || it_count: 8344 || Val Loss: 0.47718352 || Val it_count: 1107 || Current Learning Rate: 1e-05 || Time: 02:12:57.75
Epoch :: 38 || Loss: 0.43481381 || it_count: 8344 || Val Loss: 0.47076449 || Val it_count: 1107 || Current Learning Rate: 1e-05 || Time: 02:16:33.26
Epoch :: 39 || Loss: 0.43274708 || it_count: 8344 || Val Loss: 0.46764216 || Val it_count: 1107 || Current Learning Rate: 1e-05 || Time: 02:20:9.82
Epoch :: 40 || Loss: 0.43132527 || it_count: 8344 || Val Loss: 0.46582580 || Val it_count: 1107 || Current Learning Rate: 1e-05 || Time: 02:23:46.21
Epoch :: 41 || Loss: 0.43018540 || it_count: 8344 || Val Loss: 0.46481169 || Val it_count: 1107 || Current Learning Rate: 1e-05 || Time: 02:27:22.79
Epoch :: 42 || Loss: 0.42919096 || it_count: 8344 || Val Loss: 0.46445193 || Val it_count: 1107 || Current Learning Rate: 1e-05 || Time: 02:30:57.60
Epoch :: 43 || Loss: 0.42833177 || it_count: 8344 || Val Loss: 0.46478064 || Val it_count: 1107 || Current Learning Rate: 1e-05 || Time: 02:34:33.21
Epoch :: 44 || Loss: 0.42760306 || it_count: 8344 || Val Loss: 0.46485784 || Val it_count: 1107 || Current Learning Rate: 1e-05 || Time: 02:38:9.25
Epoch :: 45 || Loss: 0.42697197 || it_count: 8344 || Val Loss: 0.46514923 || Val it_count: 1107 || Current Learning Rate: 1e-05 || Time: 02:41:45.07
Epoch :: 46 || Loss: 0.42643431 || it_count: 8344 || Val Loss: 0.46577393 || Val it_count: 1107 || Current Learning Rate: 1e-05 || Time: 02:45:21.49
Epoch :: 47 || Loss: 0.42596086 || it_count: 8344 || Val Loss: 0.46673439 || Val it_count: 1107 || Current Learning Rate: 1e-05 || Time: 02:48:57.81
Epoch 00032: reducing learning rate of group 0 to 1.0000e-06.
Epoch :: 48 || Loss: 0.42557136 || it_count: 8344 || Val Loss: 0.46756542 || Val it_count: 1107 || Current Learning Rate: 1.0000000000000002e-06 || Time: 02:52:34.32
Epoch :: 49 || Loss: 0.43034625 || it_count: 8344 || Val Loss: 0.46988316 || Val it_count: 1107 || Current Learning Rate: 1.0000000000000002e-06 || Time: 02:56:10.89
Epoch :: 50 || Loss: 0.42920778 || it_count: 8344 || Val Loss: 0.46789389 || Val it_count: 1107 || Current Learning Rate: 1.0000000000000002e-06 || Time: 02:59:48.68
Epoch :: 51 || Loss: 0.42881934 || it_count: 8344 || Val Loss: 0.46678409 || Val it_count: 1107 || Current Learning Rate: 1.0000000000000002e-06 || Time: 03:03:24.93
Epoch :: 52 || Loss: 0.42860397 || it_count: 8344 || Val Loss: 0.46616391 || Val it_count: 1107 || Current Learning Rate: 1.0000000000000002e-06 || Time: 03:07:2.20
Epoch :: 53 || Loss: 0.42844502 || it_count: 8344 || Val Loss: 0.46574788 || Val it_count: 1107 || Current Learning Rate: 1.0000000000000002e-06 || Time: 03:10:38.39
Epoch 00038: reducing learning rate of group 0 to 1.0000e-07.
Early stopping triggered due to learning rate below threshold.
Done Total time: 03:14:16.16
best_loss: 0.4644519303709496

--------------------Testing--------------------

total_samples :: test_dataset = 139200, test_dataloader = 139200
Epoch ::  1 || Loss: 0.37756227 || it_count: 544 || Time: 00:00:12.09
MAE:  0.3309506
MSE:  0.37763494
RMSE:  0.5084688

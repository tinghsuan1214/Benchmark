--------------------Training--------------------
arch_str :: |lstm_5~0|[linear->dropout->linear]
model :: 2F
InferCell(
  info :: nodes=2, inC=1, outC=64, [1<-(I0-L0)], genotype_str: lstm_5~0
  linear_layers: [linear->dropout->linear]
  (layers): ModuleList(
    (0): LSTM(
      (lstm): LSTM(1, 64, num_layers=5, batch_first=True)
    )
  )
  (linear_layers): ModuleList(
    (0): Linear(in_features=3072, out_features=1536, bias=True)
    (1): Dropout(p=0.1, inplace=False)
    (2): Linear(in_features=1536, out_features=1, bias=True)
  )
)
tr_params :: epochs = 100, patience = 20, batch_size = 256, window_size = 48, data_size = 100
Model MACs: 12.056M, Model Params: 4.872M
learning rate scheduling :: (optimizer, mode='min', factor=0.1, patience=5, verbose=True)
total_samples :: train_dataset = 2136000, train_dataloader = 2136000
total_samples :: valid_dataset = 283200, valid_dataloader = 283200
Epoch ::  1 || Loss: 0.43647446 || it_count: 8344 || Val Loss: 0.45267335 || Val it_count: 1107 || Current Learning Rate: 0.001 || Time: 00:11:54.74
Epoch ::  2 || Loss: 0.41805608 || it_count: 8344 || Val Loss: 0.45088816 || Val it_count: 1107 || Current Learning Rate: 0.001 || Time: 00:23:49.19
Epoch ::  3 || Loss: 0.41806321 || it_count: 8344 || Val Loss: 0.45379660 || Val it_count: 1107 || Current Learning Rate: 0.001 || Time: 00:35:45.65
Epoch ::  4 || Loss: 0.41774385 || it_count: 8344 || Val Loss: 0.45301279 || Val it_count: 1107 || Current Learning Rate: 0.001 || Time: 00:47:43.74
Epoch ::  5 || Loss: 0.41741454 || it_count: 8344 || Val Loss: 0.45261211 || Val it_count: 1107 || Current Learning Rate: 0.001 || Time: 00:59:42.80
Epoch ::  6 || Loss: 0.42264074 || it_count: 8344 || Val Loss: 0.45338348 || Val it_count: 1107 || Current Learning Rate: 0.001 || Time: 01:11:42.93
Epoch ::  7 || Loss: 0.41756992 || it_count: 8344 || Val Loss: 0.45352287 || Val it_count: 1107 || Current Learning Rate: 0.001 || Time: 01:23:44.83
Epoch ::  8 || Loss: 0.41693805 || it_count: 8344 || Val Loss: 0.45452241 || Val it_count: 1107 || Current Learning Rate: 0.001 || Time: 01:35:47.59
Epoch ::  9 || Loss: 0.41671365 || it_count: 8344 || Val Loss: 0.45408112 || Val it_count: 1107 || Current Learning Rate: 0.001 || Time: 01:47:51.07
Epoch :: 10 || Loss: 0.41662764 || it_count: 8344 || Val Loss: 0.45431791 || Val it_count: 1107 || Current Learning Rate: 0.001 || Time: 01:59:56.37
Epoch :: 11 || Loss: 0.41649872 || it_count: 8344 || Val Loss: 0.45361607 || Val it_count: 1107 || Current Learning Rate: 0.001 || Time: 02:12:0.82
Epoch :: 12 || Loss: 0.41650565 || it_count: 8344 || Val Loss: 0.45353708 || Val it_count: 1107 || Current Learning Rate: 0.001 || Time: 02:24:6.23
Epoch :: 13 || Loss: 0.41608211 || it_count: 8344 || Val Loss: 0.45273045 || Val it_count: 1107 || Current Learning Rate: 0.001 || Time: 02:36:12.92
Epoch :: 14 || Loss: 0.41612730 || it_count: 8344 || Val Loss: 0.45217140 || Val it_count: 1107 || Current Learning Rate: 0.001 || Time: 02:48:18.77
Epoch :: 15 || Loss: 0.45750335 || it_count: 8344 || Val Loss: 0.45466705 || Val it_count: 1107 || Current Learning Rate: 0.001 || Time: 03:00:26.05
Epoch :: 16 || Loss: 0.41738602 || it_count: 8344 || Val Loss: 0.45007478 || Val it_count: 1107 || Current Learning Rate: 0.001 || Time: 03:12:33.38
Epoch :: 17 || Loss: 0.41514072 || it_count: 8344 || Val Loss: 0.45297352 || Val it_count: 1107 || Current Learning Rate: 0.001 || Time: 03:24:39.76
Epoch :: 18 || Loss: 0.41526987 || it_count: 8344 || Val Loss: 0.45277042 || Val it_count: 1107 || Current Learning Rate: 0.001 || Time: 03:36:46.35
Epoch :: 19 || Loss: 0.41556536 || it_count: 8344 || Val Loss: 0.45413841 || Val it_count: 1107 || Current Learning Rate: 0.001 || Time: 03:48:53.70
Epoch :: 20 || Loss: 0.41524189 || it_count: 8344 || Val Loss: 0.45452996 || Val it_count: 1107 || Current Learning Rate: 0.001 || Time: 04:01:0.41
Epoch :: 21 || Loss: 0.41465195 || it_count: 8344 || Val Loss: 0.45348591 || Val it_count: 1107 || Current Learning Rate: 0.001 || Time: 04:13:7.30
Epoch :: 22 || Loss: 0.41402745 || it_count: 8344 || Val Loss: 0.45507236 || Val it_count: 1107 || Current Learning Rate: 0.001 || Time: 04:25:15.22
Epoch :: 23 || Loss: 0.41375200 || it_count: 8344 || Val Loss: 0.45240411 || Val it_count: 1107 || Current Learning Rate: 0.001 || Time: 04:37:22.09
Epoch :: 24 || Loss: 0.41324539 || it_count: 8344 || Val Loss: 0.45137021 || Val it_count: 1107 || Current Learning Rate: 0.001 || Time: 04:49:29.20
Epoch :: 25 || Loss: 0.41278359 || it_count: 8344 || Val Loss: 0.45216069 || Val it_count: 1107 || Current Learning Rate: 0.001 || Time: 05:01:37.15
Epoch :: 26 || Loss: 0.41254942 || it_count: 8344 || Val Loss: 0.44894946 || Val it_count: 1107 || Current Learning Rate: 0.001 || Time: 05:13:44.05
Epoch :: 27 || Loss: 0.41213170 || it_count: 8344 || Val Loss: 0.45023464 || Val it_count: 1107 || Current Learning Rate: 0.001 || Time: 05:25:51.29
Epoch :: 28 || Loss: 0.41416319 || it_count: 8344 || Val Loss: 0.44945471 || Val it_count: 1107 || Current Learning Rate: 0.001 || Time: 05:37:59.10
Epoch :: 29 || Loss: 0.41329905 || it_count: 8344 || Val Loss: 0.45289273 || Val it_count: 1107 || Current Learning Rate: 0.001 || Time: 05:50:6.41
Epoch :: 30 || Loss: 0.41209140 || it_count: 8344 || Val Loss: 0.45227896 || Val it_count: 1107 || Current Learning Rate: 0.001 || Time: 06:02:13.43
Epoch :: 31 || Loss: 0.41152055 || it_count: 8344 || Val Loss: 0.45572775 || Val it_count: 1107 || Current Learning Rate: 0.001 || Time: 06:14:21.23
Epoch 00016: reducing learning rate of group 0 to 1.0000e-04.
Epoch :: 32 || Loss: 0.41185901 || it_count: 8344 || Val Loss: 0.45383017 || Val it_count: 1107 || Current Learning Rate: 0.0001 || Time: 06:26:28.16
Epoch :: 33 || Loss: 0.41652025 || it_count: 8344 || Val Loss: 0.43440957 || Val it_count: 1107 || Current Learning Rate: 0.0001 || Time: 06:38:33.64
Epoch :: 34 || Loss: 0.41394081 || it_count: 8344 || Val Loss: 0.43234398 || Val it_count: 1107 || Current Learning Rate: 0.0001 || Time: 06:50:42.09
Epoch :: 35 || Loss: 0.41294464 || it_count: 8344 || Val Loss: 0.43180786 || Val it_count: 1107 || Current Learning Rate: 0.0001 || Time: 07:02:50.46
Epoch :: 36 || Loss: 0.41225205 || it_count: 8344 || Val Loss: 0.43165948 || Val it_count: 1107 || Current Learning Rate: 0.0001 || Time: 07:14:55.66
Epoch :: 37 || Loss: 0.41182982 || it_count: 8344 || Val Loss: 0.43130054 || Val it_count: 1107 || Current Learning Rate: 0.0001 || Time: 07:27:3.58
Epoch :: 38 || Loss: 0.41142706 || it_count: 8344 || Val Loss: 0.43124952 || Val it_count: 1107 || Current Learning Rate: 0.0001 || Time: 07:39:12.19
Epoch :: 39 || Loss: 0.41115617 || it_count: 8344 || Val Loss: 0.43111165 || Val it_count: 1107 || Current Learning Rate: 0.0001 || Time: 07:51:17.26
Epoch :: 40 || Loss: 0.41082466 || it_count: 8344 || Val Loss: 0.43064815 || Val it_count: 1107 || Current Learning Rate: 0.0001 || Time: 08:03:25.23
Epoch :: 41 || Loss: 0.41043473 || it_count: 8344 || Val Loss: 0.43045812 || Val it_count: 1107 || Current Learning Rate: 0.0001 || Time: 08:15:33.56
Epoch :: 42 || Loss: 0.41012287 || it_count: 8344 || Val Loss: 0.43021369 || Val it_count: 1107 || Current Learning Rate: 0.0001 || Time: 08:27:38.59
Epoch :: 43 || Loss: 0.40974746 || it_count: 8344 || Val Loss: 0.42988377 || Val it_count: 1107 || Current Learning Rate: 0.0001 || Time: 08:39:46.47
Epoch :: 44 || Loss: 0.40955789 || it_count: 8344 || Val Loss: 0.42974526 || Val it_count: 1107 || Current Learning Rate: 0.0001 || Time: 08:51:54.66
Epoch :: 45 || Loss: 0.40929367 || it_count: 8344 || Val Loss: 0.42951905 || Val it_count: 1107 || Current Learning Rate: 0.0001 || Time: 09:03:59.83
Epoch :: 46 || Loss: 0.40906433 || it_count: 8344 || Val Loss: 0.42961769 || Val it_count: 1107 || Current Learning Rate: 0.0001 || Time: 09:16:7.71
Epoch :: 47 || Loss: 0.40902079 || it_count: 8344 || Val Loss: 0.42924271 || Val it_count: 1107 || Current Learning Rate: 0.0001 || Time: 09:28:15.36
Epoch :: 48 || Loss: 0.40870929 || it_count: 8344 || Val Loss: 0.42952950 || Val it_count: 1107 || Current Learning Rate: 0.0001 || Time: 09:40:18.95
Epoch :: 49 || Loss: 0.40850799 || it_count: 8344 || Val Loss: 0.42947068 || Val it_count: 1107 || Current Learning Rate: 0.0001 || Time: 09:52:25.49
Epoch :: 50 || Loss: 0.40826053 || it_count: 8344 || Val Loss: 0.42950582 || Val it_count: 1107 || Current Learning Rate: 0.0001 || Time: 10:04:36.03
Epoch :: 51 || Loss: 0.40808857 || it_count: 8344 || Val Loss: 0.42914537 || Val it_count: 1107 || Current Learning Rate: 0.0001 || Time: 10:16:44.40
Epoch :: 52 || Loss: 0.40794232 || it_count: 8344 || Val Loss: 0.42986487 || Val it_count: 1107 || Current Learning Rate: 0.0001 || Time: 10:28:55.58
Epoch :: 53 || Loss: 0.40775682 || it_count: 8344 || Val Loss: 0.42988703 || Val it_count: 1107 || Current Learning Rate: 0.0001 || Time: 10:41:9.59
Epoch :: 54 || Loss: 0.40768138 || it_count: 8344 || Val Loss: 0.42950824 || Val it_count: 1107 || Current Learning Rate: 0.0001 || Time: 10:53:14.36
Epoch :: 55 || Loss: 0.40751952 || it_count: 8344 || Val Loss: 0.43019107 || Val it_count: 1107 || Current Learning Rate: 0.0001 || Time: 11:05:22.60
Epoch :: 56 || Loss: 0.40748097 || it_count: 8344 || Val Loss: 0.43017518 || Val it_count: 1107 || Current Learning Rate: 0.0001 || Time: 11:17:30.94
Epoch 00041: reducing learning rate of group 0 to 1.0000e-05.
Epoch :: 57 || Loss: 0.40735779 || it_count: 8344 || Val Loss: 0.43067225 || Val it_count: 1107 || Current Learning Rate: 1e-05 || Time: 11:29:38.57
Epoch :: 58 || Loss: 0.41146345 || it_count: 8344 || Val Loss: 0.41567538 || Val it_count: 1107 || Current Learning Rate: 1e-05 || Time: 11:41:49.64
Epoch :: 59 || Loss: 0.40931913 || it_count: 8344 || Val Loss: 0.41504163 || Val it_count: 1107 || Current Learning Rate: 1e-05 || Time: 11:54:1.74
Epoch :: 60 || Loss: 0.40908422 || it_count: 8344 || Val Loss: 0.41476904 || Val it_count: 1107 || Current Learning Rate: 1e-05 || Time: 12:06:8.82
Epoch :: 61 || Loss: 0.40890241 || it_count: 8344 || Val Loss: 0.41463294 || Val it_count: 1107 || Current Learning Rate: 1e-05 || Time: 12:18:19.79
Epoch :: 62 || Loss: 0.40877284 || it_count: 8344 || Val Loss: 0.41456590 || Val it_count: 1107 || Current Learning Rate: 1e-05 || Time: 12:30:32.07
Epoch :: 63 || Loss: 0.40871415 || it_count: 8344 || Val Loss: 0.41449609 || Val it_count: 1107 || Current Learning Rate: 1e-05 || Time: 12:42:40.38
Epoch :: 64 || Loss: 0.40859647 || it_count: 8344 || Val Loss: 0.41444448 || Val it_count: 1107 || Current Learning Rate: 1e-05 || Time: 12:54:51.55
Epoch :: 65 || Loss: 0.40848693 || it_count: 8344 || Val Loss: 0.41438634 || Val it_count: 1107 || Current Learning Rate: 1e-05 || Time: 13:07:3.58
Epoch :: 66 || Loss: 0.40848749 || it_count: 8344 || Val Loss: 0.41437256 || Val it_count: 1107 || Current Learning Rate: 1e-05 || Time: 13:19:11.86
Epoch :: 67 || Loss: 0.40843357 || it_count: 8344 || Val Loss: 0.41434666 || Val it_count: 1107 || Current Learning Rate: 1e-05 || Time: 13:31:23.00
Epoch :: 68 || Loss: 0.40841803 || it_count: 8344 || Val Loss: 0.41433431 || Val it_count: 1107 || Current Learning Rate: 1e-05 || Time: 13:43:35.20
Epoch :: 69 || Loss: 0.40833159 || it_count: 8344 || Val Loss: 0.41433295 || Val it_count: 1107 || Current Learning Rate: 1e-05 || Time: 13:55:43.84
Epoch :: 70 || Loss: 0.40826988 || it_count: 8344 || Val Loss: 0.41435791 || Val it_count: 1107 || Current Learning Rate: 1e-05 || Time: 14:07:55.10
Epoch :: 71 || Loss: 0.40824074 || it_count: 8344 || Val Loss: 0.41434931 || Val it_count: 1107 || Current Learning Rate: 1e-05 || Time: 14:20:7.39
Epoch :: 72 || Loss: 0.40821152 || it_count: 8344 || Val Loss: 0.41433594 || Val it_count: 1107 || Current Learning Rate: 1e-05 || Time: 14:32:15.95
Epoch :: 73 || Loss: 0.40822531 || it_count: 8344 || Val Loss: 0.41433263 || Val it_count: 1107 || Current Learning Rate: 1e-05 || Time: 14:44:29.66
Epoch 00058: reducing learning rate of group 0 to 1.0000e-06.
Epoch :: 74 || Loss: 0.40817082 || it_count: 8344 || Val Loss: 0.41435549 || Val it_count: 1107 || Current Learning Rate: 1.0000000000000002e-06 || Time: 14:56:39.02
Epoch :: 75 || Loss: 0.40874907 || it_count: 8344 || Val Loss: 0.41334480 || Val it_count: 1107 || Current Learning Rate: 1.0000000000000002e-06 || Time: 15:08:48.38
Epoch :: 76 || Loss: 0.40844308 || it_count: 8344 || Val Loss: 0.41321508 || Val it_count: 1107 || Current Learning Rate: 1.0000000000000002e-06 || Time: 15:21:1.68
Epoch :: 77 || Loss: 0.40835558 || it_count: 8344 || Val Loss: 0.41317116 || Val it_count: 1107 || Current Learning Rate: 1.0000000000000002e-06 || Time: 15:33:11.24
Epoch :: 78 || Loss: 0.40832779 || it_count: 8344 || Val Loss: 0.41314427 || Val it_count: 1107 || Current Learning Rate: 1.0000000000000002e-06 || Time: 15:45:20.65
Epoch :: 79 || Loss: 0.40830340 || it_count: 8344 || Val Loss: 0.41313482 || Val it_count: 1107 || Current Learning Rate: 1.0000000000000002e-06 || Time: 15:57:34.31
Epoch :: 80 || Loss: 0.40833837 || it_count: 8344 || Val Loss: 0.41312502 || Val it_count: 1107 || Current Learning Rate: 1.0000000000000002e-06 || Time: 16:09:44.01
Epoch :: 81 || Loss: 0.40827349 || it_count: 8344 || Val Loss: 0.41311121 || Val it_count: 1107 || Current Learning Rate: 1.0000000000000002e-06 || Time: 16:21:53.42
Epoch :: 82 || Loss: 0.40826787 || it_count: 8344 || Val Loss: 0.41309999 || Val it_count: 1107 || Current Learning Rate: 1.0000000000000002e-06 || Time: 16:34:7.09
Epoch :: 83 || Loss: 0.40827245 || it_count: 8344 || Val Loss: 0.41309622 || Val it_count: 1107 || Current Learning Rate: 1.0000000000000002e-06 || Time: 16:46:16.33
Epoch :: 84 || Loss: 0.40824598 || it_count: 8344 || Val Loss: 0.41309141 || Val it_count: 1107 || Current Learning Rate: 1.0000000000000002e-06 || Time: 16:58:25.51
Epoch :: 85 || Loss: 0.40823985 || it_count: 8344 || Val Loss: 0.41308618 || Val it_count: 1107 || Current Learning Rate: 1.0000000000000002e-06 || Time: 17:10:38.65
Epoch :: 86 || Loss: 0.40823085 || it_count: 8344 || Val Loss: 0.41308152 || Val it_count: 1107 || Current Learning Rate: 1.0000000000000002e-06 || Time: 17:22:48.03
Epoch :: 87 || Loss: 0.40823087 || it_count: 8344 || Val Loss: 0.41307734 || Val it_count: 1107 || Current Learning Rate: 1.0000000000000002e-06 || Time: 17:34:57.33
Epoch :: 88 || Loss: 0.40824928 || it_count: 8344 || Val Loss: 0.41307258 || Val it_count: 1107 || Current Learning Rate: 1.0000000000000002e-06 || Time: 17:47:10.82
Epoch :: 89 || Loss: 0.40822983 || it_count: 8344 || Val Loss: 0.41307364 || Val it_count: 1107 || Current Learning Rate: 1.0000000000000002e-06 || Time: 17:59:20.07
Epoch :: 90 || Loss: 0.40821301 || it_count: 8344 || Val Loss: 0.41306776 || Val it_count: 1107 || Current Learning Rate: 1.0000000000000002e-06 || Time: 18:11:29.40
Epoch :: 91 || Loss: 0.40824008 || it_count: 8344 || Val Loss: 0.41306334 || Val it_count: 1107 || Current Learning Rate: 1.0000000000000002e-06 || Time: 18:23:42.99
Epoch 00076: reducing learning rate of group 0 to 1.0000e-07.
Early stopping triggered due to learning rate below threshold.
Done Total time: 18:35:52.46
best_loss: 0.41306333797237027

--------------------Testing--------------------

total_samples :: test_dataset = 139200, test_dataloader = 139200
Epoch ::  1 || Loss: 0.23644355 || it_count: 544 || Time: 00:00:27.85
MAE:  0.25345713
MSE:  0.23646122
RMSE:  0.441906

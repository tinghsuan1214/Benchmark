--------------------Training--------------------
arch_str :: |lstm_4~0|[relu->dropout->linear->dropout->linear]
model :: 2R
InferCell(
  info :: nodes=2, inC=1, outC=64, [1<-(I0-L0)], genotype_str: lstm_4~0
  linear_layers: [relu->dropout->linear->dropout->linear]
  (layers): ModuleList(
    (0): LSTM(
      (lstm): LSTM(1, 64, num_layers=4, batch_first=True)
    )
  )
  (linear_layers): ModuleList(
    (0): ReLU()
    (1): Dropout(p=0.1, inplace=False)
    (2): Linear(in_features=3072, out_features=1536, bias=True)
    (3): Dropout(p=0.1, inplace=False)
    (4): Linear(in_features=1536, out_features=1, bias=True)
  )
)
tr_params :: epochs = 100, patience = 20, batch_size = 256, window_size = 48, data_size = 100
Model MACs: 10.434M, Model Params: 4.839M
learning rate scheduling :: (optimizer, mode='min', factor=0.1, patience=5, verbose=True)
total_samples :: train_dataset = 2136000, train_dataloader = 2136000
total_samples :: valid_dataset = 283200, valid_dataloader = 283200
Epoch ::  1 || Loss: 0.42945688 || it_count: 8344 || Val Loss: 0.46045684 || Val it_count: 1107 || Current Learning Rate: 0.001 || Time: 00:04:22.07
Epoch ::  2 || Loss: 0.42104282 || it_count: 8344 || Val Loss: 0.45355141 || Val it_count: 1107 || Current Learning Rate: 0.001 || Time: 00:08:45.00
Epoch ::  3 || Loss: 0.41965683 || it_count: 8344 || Val Loss: 0.45318966 || Val it_count: 1107 || Current Learning Rate: 0.001 || Time: 00:13:5.52
Epoch ::  4 || Loss: 0.41963744 || it_count: 8344 || Val Loss: 0.45214570 || Val it_count: 1107 || Current Learning Rate: 0.001 || Time: 00:17:28.59
Epoch ::  5 || Loss: 0.41962773 || it_count: 8344 || Val Loss: 0.45305623 || Val it_count: 1107 || Current Learning Rate: 0.001 || Time: 00:21:52.47
Epoch ::  6 || Loss: 0.41908952 || it_count: 8344 || Val Loss: 0.45192433 || Val it_count: 1107 || Current Learning Rate: 0.001 || Time: 00:26:11.82
Epoch ::  7 || Loss: 0.41902433 || it_count: 8344 || Val Loss: 0.45239313 || Val it_count: 1107 || Current Learning Rate: 0.001 || Time: 00:30:34.57
Epoch ::  8 || Loss: 0.41863120 || it_count: 8344 || Val Loss: 0.45103956 || Val it_count: 1107 || Current Learning Rate: 0.001 || Time: 00:34:56.12
Epoch ::  9 || Loss: 0.41837094 || it_count: 8344 || Val Loss: 0.45175506 || Val it_count: 1107 || Current Learning Rate: 0.001 || Time: 00:39:17.92
Epoch :: 10 || Loss: 0.41826213 || it_count: 8344 || Val Loss: 0.45139801 || Val it_count: 1107 || Current Learning Rate: 0.001 || Time: 00:43:40.30
Epoch :: 11 || Loss: 0.41779633 || it_count: 8344 || Val Loss: 0.45073117 || Val it_count: 1107 || Current Learning Rate: 0.001 || Time: 00:48:3.47
Epoch :: 12 || Loss: 0.41731652 || it_count: 8344 || Val Loss: 0.45058542 || Val it_count: 1107 || Current Learning Rate: 0.001 || Time: 00:52:26.29
Epoch :: 13 || Loss: 0.41701185 || it_count: 8344 || Val Loss: 0.45182377 || Val it_count: 1107 || Current Learning Rate: 0.001 || Time: 00:56:48.24
Epoch :: 14 || Loss: 0.41675357 || it_count: 8344 || Val Loss: 0.45259838 || Val it_count: 1107 || Current Learning Rate: 0.001 || Time: 01:01:11.81
Epoch :: 15 || Loss: 0.41658788 || it_count: 8344 || Val Loss: 0.45242176 || Val it_count: 1107 || Current Learning Rate: 0.001 || Time: 01:05:34.18
Epoch :: 16 || Loss: 0.41614124 || it_count: 8344 || Val Loss: 0.45495991 || Val it_count: 1107 || Current Learning Rate: 0.001 || Time: 01:09:59.33
Epoch :: 17 || Loss: 0.41552489 || it_count: 8344 || Val Loss: 0.45214935 || Val it_count: 1107 || Current Learning Rate: 0.001 || Time: 01:14:20.87
Epoch :: 18 || Loss: 0.41457059 || it_count: 8344 || Val Loss: 0.45176291 || Val it_count: 1107 || Current Learning Rate: 0.001 || Time: 01:18:42.73
Epoch :: 19 || Loss: 0.41367404 || it_count: 8344 || Val Loss: 0.45415232 || Val it_count: 1107 || Current Learning Rate: 0.001 || Time: 01:23:4.26
Epoch :: 20 || Loss: 0.41340629 || it_count: 8344 || Val Loss: 0.45201554 || Val it_count: 1107 || Current Learning Rate: 0.001 || Time: 01:27:27.00
Epoch :: 21 || Loss: 0.41306690 || it_count: 8344 || Val Loss: 0.45284862 || Val it_count: 1107 || Current Learning Rate: 0.001 || Time: 01:31:50.48
Epoch :: 22 || Loss: 0.41260465 || it_count: 8344 || Val Loss: 0.45363316 || Val it_count: 1107 || Current Learning Rate: 0.001 || Time: 01:36:13.01
Epoch :: 23 || Loss: 0.41244432 || it_count: 8344 || Val Loss: 0.45381474 || Val it_count: 1107 || Current Learning Rate: 0.001 || Time: 01:40:35.10
Epoch 00008: reducing learning rate of group 0 to 1.0000e-04.
Epoch :: 24 || Loss: 0.41179422 || it_count: 8344 || Val Loss: 0.45344606 || Val it_count: 1107 || Current Learning Rate: 0.0001 || Time: 01:44:58.28
Epoch :: 25 || Loss: 0.41692646 || it_count: 8344 || Val Loss: 0.43346137 || Val it_count: 1107 || Current Learning Rate: 0.0001 || Time: 01:49:21.21
Epoch :: 26 || Loss: 0.41418636 || it_count: 8344 || Val Loss: 0.43203720 || Val it_count: 1107 || Current Learning Rate: 0.0001 || Time: 01:53:46.35
Epoch :: 27 || Loss: 0.41346274 || it_count: 8344 || Val Loss: 0.43205860 || Val it_count: 1107 || Current Learning Rate: 0.0001 || Time: 01:58:10.34
Epoch :: 28 || Loss: 0.41296036 || it_count: 8344 || Val Loss: 0.43220055 || Val it_count: 1107 || Current Learning Rate: 0.0001 || Time: 02:02:33.45
Epoch :: 29 || Loss: 0.41265590 || it_count: 8344 || Val Loss: 0.43206521 || Val it_count: 1107 || Current Learning Rate: 0.0001 || Time: 02:06:56.98
Epoch :: 30 || Loss: 0.41227412 || it_count: 8344 || Val Loss: 0.43118723 || Val it_count: 1107 || Current Learning Rate: 0.0001 || Time: 02:11:20.18
Epoch :: 31 || Loss: 0.41184597 || it_count: 8344 || Val Loss: 0.43103869 || Val it_count: 1107 || Current Learning Rate: 0.0001 || Time: 02:15:41.47
Epoch :: 32 || Loss: 0.41163134 || it_count: 8344 || Val Loss: 0.43119055 || Val it_count: 1107 || Current Learning Rate: 0.0001 || Time: 02:20:4.70
Epoch :: 33 || Loss: 0.41139596 || it_count: 8344 || Val Loss: 0.43078317 || Val it_count: 1107 || Current Learning Rate: 0.0001 || Time: 02:24:26.71
Epoch :: 34 || Loss: 0.41102668 || it_count: 8344 || Val Loss: 0.43090910 || Val it_count: 1107 || Current Learning Rate: 0.0001 || Time: 02:28:49.52
Epoch :: 35 || Loss: 0.41078146 || it_count: 8344 || Val Loss: 0.43069197 || Val it_count: 1107 || Current Learning Rate: 0.0001 || Time: 02:33:12.72
Epoch :: 36 || Loss: 0.41061245 || it_count: 8344 || Val Loss: 0.43086719 || Val it_count: 1107 || Current Learning Rate: 0.0001 || Time: 02:37:37.05
Epoch :: 37 || Loss: 0.41043104 || it_count: 8344 || Val Loss: 0.43100140 || Val it_count: 1107 || Current Learning Rate: 0.0001 || Time: 02:41:58.67
Epoch :: 38 || Loss: 0.40998476 || it_count: 8344 || Val Loss: 0.43075901 || Val it_count: 1107 || Current Learning Rate: 0.0001 || Time: 02:46:20.35
Epoch :: 39 || Loss: 0.40982075 || it_count: 8344 || Val Loss: 0.43123128 || Val it_count: 1107 || Current Learning Rate: 0.0001 || Time: 02:50:43.73
Epoch :: 40 || Loss: 0.40951045 || it_count: 8344 || Val Loss: 0.43112219 || Val it_count: 1107 || Current Learning Rate: 0.0001 || Time: 02:55:5.25
Epoch :: 41 || Loss: 0.40935063 || it_count: 8344 || Val Loss: 0.43061532 || Val it_count: 1107 || Current Learning Rate: 0.0001 || Time: 02:59:29.80
Epoch :: 42 || Loss: 0.40905885 || it_count: 8344 || Val Loss: 0.43093253 || Val it_count: 1107 || Current Learning Rate: 0.0001 || Time: 03:03:52.85
Epoch :: 43 || Loss: 0.40892973 || it_count: 8344 || Val Loss: 0.43170272 || Val it_count: 1107 || Current Learning Rate: 0.0001 || Time: 03:08:14.69
Epoch :: 44 || Loss: 0.40859707 || it_count: 8344 || Val Loss: 0.43243101 || Val it_count: 1107 || Current Learning Rate: 0.0001 || Time: 03:12:36.38
Epoch :: 45 || Loss: 0.40843876 || it_count: 8344 || Val Loss: 0.43203677 || Val it_count: 1107 || Current Learning Rate: 0.0001 || Time: 03:16:57.55
Epoch :: 46 || Loss: 0.40832151 || it_count: 8344 || Val Loss: 0.43152487 || Val it_count: 1107 || Current Learning Rate: 0.0001 || Time: 03:21:21.31
Epoch 00031: reducing learning rate of group 0 to 1.0000e-05.
Epoch :: 47 || Loss: 0.40805762 || it_count: 8344 || Val Loss: 0.43170926 || Val it_count: 1107 || Current Learning Rate: 1e-05 || Time: 03:25:44.91
Epoch :: 48 || Loss: 0.41221579 || it_count: 8344 || Val Loss: 0.41444029 || Val it_count: 1107 || Current Learning Rate: 1e-05 || Time: 03:30:6.41
Epoch :: 49 || Loss: 0.40994101 || it_count: 8344 || Val Loss: 0.41390544 || Val it_count: 1107 || Current Learning Rate: 1e-05 || Time: 03:34:28.84
Epoch :: 50 || Loss: 0.40971929 || it_count: 8344 || Val Loss: 0.41377881 || Val it_count: 1107 || Current Learning Rate: 1e-05 || Time: 03:38:49.42
Epoch :: 51 || Loss: 0.40949279 || it_count: 8344 || Val Loss: 0.41353877 || Val it_count: 1107 || Current Learning Rate: 1e-05 || Time: 03:43:11.50
Epoch :: 52 || Loss: 0.40942125 || it_count: 8344 || Val Loss: 0.41356785 || Val it_count: 1107 || Current Learning Rate: 1e-05 || Time: 03:47:33.20
Epoch :: 53 || Loss: 0.40934728 || it_count: 8344 || Val Loss: 0.41352226 || Val it_count: 1107 || Current Learning Rate: 1e-05 || Time: 03:51:54.72
Epoch :: 54 || Loss: 0.40930412 || it_count: 8344 || Val Loss: 0.41347046 || Val it_count: 1107 || Current Learning Rate: 1e-05 || Time: 03:56:16.98
Epoch :: 55 || Loss: 0.40921124 || it_count: 8344 || Val Loss: 0.41334902 || Val it_count: 1107 || Current Learning Rate: 1e-05 || Time: 04:00:37.37
Epoch :: 56 || Loss: 0.40920571 || it_count: 8344 || Val Loss: 0.41342234 || Val it_count: 1107 || Current Learning Rate: 1e-05 || Time: 04:04:58.50
Epoch :: 57 || Loss: 0.40907435 || it_count: 8344 || Val Loss: 0.41340112 || Val it_count: 1107 || Current Learning Rate: 1e-05 || Time: 04:09:19.67
Epoch :: 58 || Loss: 0.40897695 || it_count: 8344 || Val Loss: 0.41347510 || Val it_count: 1107 || Current Learning Rate: 1e-05 || Time: 04:13:41.75
Epoch :: 59 || Loss: 0.40903720 || it_count: 8344 || Val Loss: 0.41340529 || Val it_count: 1107 || Current Learning Rate: 1e-05 || Time: 04:18:3.69
Epoch :: 60 || Loss: 0.40891494 || it_count: 8344 || Val Loss: 0.41344644 || Val it_count: 1107 || Current Learning Rate: 1e-05 || Time: 04:22:25.67
Epoch 00045: reducing learning rate of group 0 to 1.0000e-06.
Epoch :: 61 || Loss: 0.40890036 || it_count: 8344 || Val Loss: 0.41335590 || Val it_count: 1107 || Current Learning Rate: 1.0000000000000002e-06 || Time: 04:26:47.73
Epoch :: 62 || Loss: 0.40935941 || it_count: 8344 || Val Loss: 0.41195109 || Val it_count: 1107 || Current Learning Rate: 1.0000000000000002e-06 || Time: 04:31:9.33
Epoch :: 63 || Loss: 0.40914075 || it_count: 8344 || Val Loss: 0.41178624 || Val it_count: 1107 || Current Learning Rate: 1.0000000000000002e-06 || Time: 04:35:31.98
Epoch :: 64 || Loss: 0.40908715 || it_count: 8344 || Val Loss: 0.41174472 || Val it_count: 1107 || Current Learning Rate: 1.0000000000000002e-06 || Time: 04:39:55.66
Epoch :: 65 || Loss: 0.40905624 || it_count: 8344 || Val Loss: 0.41172680 || Val it_count: 1107 || Current Learning Rate: 1.0000000000000002e-06 || Time: 04:44:18.36
Epoch :: 66 || Loss: 0.40908422 || it_count: 8344 || Val Loss: 0.41171669 || Val it_count: 1107 || Current Learning Rate: 1.0000000000000002e-06 || Time: 04:48:40.78
Epoch :: 67 || Loss: 0.40899402 || it_count: 8344 || Val Loss: 0.41170656 || Val it_count: 1107 || Current Learning Rate: 1.0000000000000002e-06 || Time: 04:53:2.97
Epoch :: 68 || Loss: 0.40899128 || it_count: 8344 || Val Loss: 0.41170278 || Val it_count: 1107 || Current Learning Rate: 1.0000000000000002e-06 || Time: 04:57:24.85
Epoch :: 69 || Loss: 0.40895181 || it_count: 8344 || Val Loss: 0.41170308 || Val it_count: 1107 || Current Learning Rate: 1.0000000000000002e-06 || Time: 05:01:46.96
Epoch :: 70 || Loss: 0.40898464 || it_count: 8344 || Val Loss: 0.41169480 || Val it_count: 1107 || Current Learning Rate: 1.0000000000000002e-06 || Time: 05:06:9.92
Epoch :: 71 || Loss: 0.40900814 || it_count: 8344 || Val Loss: 0.41169058 || Val it_count: 1107 || Current Learning Rate: 1.0000000000000002e-06 || Time: 05:10:32.93
Epoch :: 72 || Loss: 0.40898183 || it_count: 8344 || Val Loss: 0.41168328 || Val it_count: 1107 || Current Learning Rate: 1.0000000000000002e-06 || Time: 05:14:55.35
Epoch :: 73 || Loss: 0.40894867 || it_count: 8344 || Val Loss: 0.41168686 || Val it_count: 1107 || Current Learning Rate: 1.0000000000000002e-06 || Time: 05:19:16.82
Epoch 00058: reducing learning rate of group 0 to 1.0000e-07.
Early stopping triggered due to learning rate below threshold.
Done Total time: 05:23:39.75
best_loss: 0.41168328400401893

--------------------Testing--------------------

total_samples :: test_dataset = 139200, test_dataloader = 139200
Epoch ::  1 || Loss: 0.23576109 || it_count: 544 || Time: 00:00:13.74
MAE:  0.25295547
MSE:  0.23578075
RMSE:  0.44135678

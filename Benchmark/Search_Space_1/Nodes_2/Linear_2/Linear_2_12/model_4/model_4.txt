--------------------Training--------------------
arch_str :: |lstm_4~0|[relu->linear->relu->dropout->linear]
model :: 2P
InferCell(
  info :: nodes=2, inC=1, outC=64, [1<-(I0-L0)], genotype_str: lstm_4~0
  linear_layers: [relu->linear->relu->dropout->linear]
  (layers): ModuleList(
    (0): LSTM(
      (lstm): LSTM(1, 64, num_layers=4, batch_first=True)
    )
  )
  (linear_layers): ModuleList(
    (0): ReLU()
    (1): Linear(in_features=3072, out_features=1536, bias=True)
    (2): ReLU()
    (3): Dropout(p=0.1, inplace=False)
    (4): Linear(in_features=1536, out_features=1, bias=True)
  )
)
tr_params :: epochs = 100, patience = 20, batch_size = 256, window_size = 48, data_size = 100
Model FLOPs: 10.434M, Model Params: 4.839M
learning rate scheduling :: (optimizer, mode='min', factor=0.1, patience=5, verbose=True)
total_samples :: train_dataset = 2136000, train_dataloader = 2136000
total_samples :: valid_dataset = 283200, valid_dataloader = 283200
Epoch ::  1 || Loss: 0.42361923 || it_count: 8344 || Val Loss: 0.46006458 || Val it_count: 1107 || Current Learning Rate: 0.001 || Time: 00:04:27.29
Epoch ::  2 || Loss: 0.41564399 || it_count: 8344 || Val Loss: 0.45689443 || Val it_count: 1107 || Current Learning Rate: 0.001 || Time: 00:08:51.88
Epoch ::  3 || Loss: 0.41436071 || it_count: 8344 || Val Loss: 0.45537805 || Val it_count: 1107 || Current Learning Rate: 0.001 || Time: 00:13:16.89
Epoch ::  4 || Loss: 0.41305656 || it_count: 8344 || Val Loss: 0.45534484 || Val it_count: 1107 || Current Learning Rate: 0.001 || Time: 00:17:41.47
Epoch ::  5 || Loss: 0.41223657 || it_count: 8344 || Val Loss: 0.45361483 || Val it_count: 1107 || Current Learning Rate: 0.001 || Time: 00:22:6.73
Epoch ::  6 || Loss: 0.41110676 || it_count: 8344 || Val Loss: 0.45338933 || Val it_count: 1107 || Current Learning Rate: 0.001 || Time: 00:26:31.17
Epoch ::  7 || Loss: 0.41002549 || it_count: 8344 || Val Loss: 0.45397898 || Val it_count: 1107 || Current Learning Rate: 0.001 || Time: 00:30:57.05
Epoch ::  8 || Loss: 0.40891478 || it_count: 8344 || Val Loss: 0.45288688 || Val it_count: 1107 || Current Learning Rate: 0.001 || Time: 00:35:23.53
Epoch ::  9 || Loss: 0.40795480 || it_count: 8344 || Val Loss: 0.45226521 || Val it_count: 1107 || Current Learning Rate: 0.001 || Time: 00:39:51.33
Epoch :: 10 || Loss: 0.40697513 || it_count: 8344 || Val Loss: 0.45360099 || Val it_count: 1107 || Current Learning Rate: 0.001 || Time: 00:44:14.49
Epoch :: 11 || Loss: 0.40542425 || it_count: 8344 || Val Loss: 0.45220514 || Val it_count: 1107 || Current Learning Rate: 0.001 || Time: 00:48:41.02
Epoch :: 12 || Loss: 0.40361700 || it_count: 8344 || Val Loss: 0.45335726 || Val it_count: 1107 || Current Learning Rate: 0.001 || Time: 00:53:8.91
Epoch :: 13 || Loss: 0.40192521 || it_count: 8344 || Val Loss: 0.45320137 || Val it_count: 1107 || Current Learning Rate: 0.001 || Time: 00:57:36.78
Epoch :: 14 || Loss: 0.39983557 || it_count: 8344 || Val Loss: 0.45645425 || Val it_count: 1107 || Current Learning Rate: 0.001 || Time: 01:02:2.08
Epoch :: 15 || Loss: 0.39750263 || it_count: 8344 || Val Loss: 0.45849575 || Val it_count: 1107 || Current Learning Rate: 0.001 || Time: 01:06:26.90
Epoch :: 16 || Loss: 0.39475108 || it_count: 8344 || Val Loss: 0.45936680 || Val it_count: 1107 || Current Learning Rate: 0.001 || Time: 01:10:52.85
Epoch :: 17 || Loss: 0.39163209 || it_count: 8344 || Val Loss: 0.45738806 || Val it_count: 1107 || Current Learning Rate: 0.001 || Time: 01:15:20.46
Epoch :: 18 || Loss: 0.38844475 || it_count: 8344 || Val Loss: 0.45905848 || Val it_count: 1107 || Current Learning Rate: 0.001 || Time: 01:19:46.00
Epoch :: 19 || Loss: 0.38503215 || it_count: 8344 || Val Loss: 0.46481766 || Val it_count: 1107 || Current Learning Rate: 0.001 || Time: 01:24:13.91
Epoch :: 20 || Loss: 0.38184362 || it_count: 8344 || Val Loss: 0.47520751 || Val it_count: 1107 || Current Learning Rate: 0.001 || Time: 01:28:40.89
Epoch :: 21 || Loss: 0.37778799 || it_count: 8344 || Val Loss: 0.47823372 || Val it_count: 1107 || Current Learning Rate: 0.001 || Time: 01:33:5.46
Epoch :: 22 || Loss: 0.37476953 || it_count: 8344 || Val Loss: 0.48278759 || Val it_count: 1107 || Current Learning Rate: 0.001 || Time: 01:37:33.45
Epoch 00007: reducing learning rate of group 0 to 1.0000e-04.
Epoch :: 23 || Loss: 0.37098904 || it_count: 8344 || Val Loss: 0.48561689 || Val it_count: 1107 || Current Learning Rate: 0.0001 || Time: 01:41:59.90
Epoch :: 24 || Loss: 0.40071951 || it_count: 8344 || Val Loss: 0.44740558 || Val it_count: 1107 || Current Learning Rate: 0.0001 || Time: 01:46:25.55
Epoch :: 25 || Loss: 0.39224881 || it_count: 8344 || Val Loss: 0.44597464 || Val it_count: 1107 || Current Learning Rate: 0.0001 || Time: 01:50:43.82
Epoch :: 26 || Loss: 0.38732471 || it_count: 8344 || Val Loss: 0.44678790 || Val it_count: 1107 || Current Learning Rate: 0.0001 || Time: 01:55:5.10
Epoch :: 27 || Loss: 0.38382826 || it_count: 8344 || Val Loss: 0.44612289 || Val it_count: 1107 || Current Learning Rate: 0.0001 || Time: 01:59:28.42
Epoch :: 28 || Loss: 0.38064004 || it_count: 8344 || Val Loss: 0.44663620 || Val it_count: 1107 || Current Learning Rate: 0.0001 || Time: 02:03:52.00
Epoch :: 29 || Loss: 0.37776432 || it_count: 8344 || Val Loss: 0.44797915 || Val it_count: 1107 || Current Learning Rate: 0.0001 || Time: 02:08:17.72
Epoch :: 30 || Loss: 0.37495128 || it_count: 8344 || Val Loss: 0.44937863 || Val it_count: 1107 || Current Learning Rate: 0.0001 || Time: 02:12:44.06
Epoch 00015: reducing learning rate of group 0 to 1.0000e-05.
Epoch :: 31 || Loss: 0.37256919 || it_count: 8344 || Val Loss: 0.44951443 || Val it_count: 1107 || Current Learning Rate: 1e-05 || Time: 02:17:8.02
Epoch :: 32 || Loss: 0.39666923 || it_count: 8344 || Val Loss: 0.42975742 || Val it_count: 1107 || Current Learning Rate: 1e-05 || Time: 02:21:36.54
Epoch :: 33 || Loss: 0.39077496 || it_count: 8344 || Val Loss: 0.42881336 || Val it_count: 1107 || Current Learning Rate: 1e-05 || Time: 02:26:3.18
Epoch :: 34 || Loss: 0.38916708 || it_count: 8344 || Val Loss: 0.42849447 || Val it_count: 1107 || Current Learning Rate: 1e-05 || Time: 02:30:28.06
Epoch :: 35 || Loss: 0.38819449 || it_count: 8344 || Val Loss: 0.42846910 || Val it_count: 1107 || Current Learning Rate: 1e-05 || Time: 02:34:54.67
Epoch :: 36 || Loss: 0.38745013 || it_count: 8344 || Val Loss: 0.42826194 || Val it_count: 1107 || Current Learning Rate: 1e-05 || Time: 02:39:20.52
Epoch :: 37 || Loss: 0.38688441 || it_count: 8344 || Val Loss: 0.42838419 || Val it_count: 1107 || Current Learning Rate: 1e-05 || Time: 02:43:47.21
Epoch :: 38 || Loss: 0.38640538 || it_count: 8344 || Val Loss: 0.42857497 || Val it_count: 1107 || Current Learning Rate: 1e-05 || Time: 02:48:12.85
Epoch :: 39 || Loss: 0.38579464 || it_count: 8344 || Val Loss: 0.42869972 || Val it_count: 1107 || Current Learning Rate: 1e-05 || Time: 02:52:39.00
Epoch :: 40 || Loss: 0.38529651 || it_count: 8344 || Val Loss: 0.42878086 || Val it_count: 1107 || Current Learning Rate: 1e-05 || Time: 02:57:4.51
Epoch :: 41 || Loss: 0.38465605 || it_count: 8344 || Val Loss: 0.42900966 || Val it_count: 1107 || Current Learning Rate: 1e-05 || Time: 03:01:29.71
Epoch 00026: reducing learning rate of group 0 to 1.0000e-06.
Epoch :: 42 || Loss: 0.38428049 || it_count: 8344 || Val Loss: 0.42912074 || Val it_count: 1107 || Current Learning Rate: 1.0000000000000002e-06 || Time: 03:05:55.78
Epoch :: 43 || Loss: 0.39141430 || it_count: 8344 || Val Loss: 0.42696745 || Val it_count: 1107 || Current Learning Rate: 1.0000000000000002e-06 || Time: 03:10:21.46
Epoch :: 44 || Loss: 0.38935654 || it_count: 8344 || Val Loss: 0.42671181 || Val it_count: 1107 || Current Learning Rate: 1.0000000000000002e-06 || Time: 03:14:46.46
Epoch :: 45 || Loss: 0.38872576 || it_count: 8344 || Val Loss: 0.42657445 || Val it_count: 1107 || Current Learning Rate: 1.0000000000000002e-06 || Time: 03:19:13.83
Epoch :: 46 || Loss: 0.38858956 || it_count: 8344 || Val Loss: 0.42646894 || Val it_count: 1107 || Current Learning Rate: 1.0000000000000002e-06 || Time: 03:23:40.49
Epoch :: 47 || Loss: 0.38834488 || it_count: 8344 || Val Loss: 0.42632950 || Val it_count: 1107 || Current Learning Rate: 1.0000000000000002e-06 || Time: 03:28:4.14
Epoch :: 48 || Loss: 0.38824828 || it_count: 8344 || Val Loss: 0.42626225 || Val it_count: 1107 || Current Learning Rate: 1.0000000000000002e-06 || Time: 03:32:29.47
Epoch :: 49 || Loss: 0.38803114 || it_count: 8344 || Val Loss: 0.42621865 || Val it_count: 1107 || Current Learning Rate: 1.0000000000000002e-06 || Time: 03:36:56.64
Epoch :: 50 || Loss: 0.38824769 || it_count: 8344 || Val Loss: 0.42614360 || Val it_count: 1107 || Current Learning Rate: 1.0000000000000002e-06 || Time: 03:41:21.85
Epoch :: 51 || Loss: 0.38786518 || it_count: 8344 || Val Loss: 0.42611486 || Val it_count: 1107 || Current Learning Rate: 1.0000000000000002e-06 || Time: 03:45:46.58
Epoch :: 52 || Loss: 0.38775175 || it_count: 8344 || Val Loss: 0.42609599 || Val it_count: 1107 || Current Learning Rate: 1.0000000000000002e-06 || Time: 03:50:14.46
Epoch :: 53 || Loss: 0.38778294 || it_count: 8344 || Val Loss: 0.42604489 || Val it_count: 1107 || Current Learning Rate: 1.0000000000000002e-06 || Time: 03:54:42.43
Epoch :: 54 || Loss: 0.38779474 || it_count: 8344 || Val Loss: 0.42604334 || Val it_count: 1107 || Current Learning Rate: 1.0000000000000002e-06 || Time: 03:59:7.77
Epoch :: 55 || Loss: 0.38777046 || it_count: 8344 || Val Loss: 0.42598530 || Val it_count: 1107 || Current Learning Rate: 1.0000000000000002e-06 || Time: 04:03:32.73
Epoch :: 56 || Loss: 0.38760762 || it_count: 8344 || Val Loss: 0.42598307 || Val it_count: 1107 || Current Learning Rate: 1.0000000000000002e-06 || Time: 04:07:55.36
Epoch :: 57 || Loss: 0.38763574 || it_count: 8344 || Val Loss: 0.42594000 || Val it_count: 1107 || Current Learning Rate: 1.0000000000000002e-06 || Time: 04:12:20.60
Epoch :: 58 || Loss: 0.38743711 || it_count: 8344 || Val Loss: 0.42590956 || Val it_count: 1107 || Current Learning Rate: 1.0000000000000002e-06 || Time: 04:16:44.77
Epoch :: 59 || Loss: 0.38749400 || it_count: 8344 || Val Loss: 0.42591287 || Val it_count: 1107 || Current Learning Rate: 1.0000000000000002e-06 || Time: 04:21:11.43
Epoch :: 60 || Loss: 0.38745028 || it_count: 8344 || Val Loss: 0.42588973 || Val it_count: 1107 || Current Learning Rate: 1.0000000000000002e-06 || Time: 04:25:37.42
Epoch :: 61 || Loss: 0.38747235 || it_count: 8344 || Val Loss: 0.42585758 || Val it_count: 1107 || Current Learning Rate: 1.0000000000000002e-06 || Time: 04:30:4.69
Epoch :: 62 || Loss: 0.38737064 || it_count: 8344 || Val Loss: 0.42584022 || Val it_count: 1107 || Current Learning Rate: 1.0000000000000002e-06 || Time: 04:34:30.94
Epoch :: 63 || Loss: 0.38719558 || it_count: 8344 || Val Loss: 0.42582110 || Val it_count: 1107 || Current Learning Rate: 1.0000000000000002e-06 || Time: 04:38:56.87
Epoch :: 64 || Loss: 0.38730311 || it_count: 8344 || Val Loss: 0.42580119 || Val it_count: 1107 || Current Learning Rate: 1.0000000000000002e-06 || Time: 04:43:22.51
Epoch :: 65 || Loss: 0.38716998 || it_count: 8344 || Val Loss: 0.42581367 || Val it_count: 1107 || Current Learning Rate: 1.0000000000000002e-06 || Time: 04:47:48.99
Epoch :: 66 || Loss: 0.38717532 || it_count: 8344 || Val Loss: 0.42582010 || Val it_count: 1107 || Current Learning Rate: 1.0000000000000002e-06 || Time: 04:52:15.94
Epoch :: 67 || Loss: 0.38694458 || it_count: 8344 || Val Loss: 0.42581306 || Val it_count: 1107 || Current Learning Rate: 1.0000000000000002e-06 || Time: 04:56:43.48
Epoch :: 68 || Loss: 0.38710586 || it_count: 8344 || Val Loss: 0.42579618 || Val it_count: 1107 || Current Learning Rate: 1.0000000000000002e-06 || Time: 05:01:9.86
Epoch :: 69 || Loss: 0.38702531 || it_count: 8344 || Val Loss: 0.42576341 || Val it_count: 1107 || Current Learning Rate: 1.0000000000000002e-06 || Time: 05:05:35.94
Epoch :: 70 || Loss: 0.38689588 || it_count: 8344 || Val Loss: 0.42576284 || Val it_count: 1107 || Current Learning Rate: 1.0000000000000002e-06 || Time: 05:10:2.91
Epoch :: 71 || Loss: 0.38692855 || it_count: 8344 || Val Loss: 0.42577091 || Val it_count: 1107 || Current Learning Rate: 1.0000000000000002e-06 || Time: 05:14:28.01
Epoch :: 72 || Loss: 0.38691047 || it_count: 8344 || Val Loss: 0.42574237 || Val it_count: 1107 || Current Learning Rate: 1.0000000000000002e-06 || Time: 05:18:54.83
Epoch :: 73 || Loss: 0.38687324 || it_count: 8344 || Val Loss: 0.42575584 || Val it_count: 1107 || Current Learning Rate: 1.0000000000000002e-06 || Time: 05:23:20.18
Epoch :: 74 || Loss: 0.38666462 || it_count: 8344 || Val Loss: 0.42576202 || Val it_count: 1107 || Current Learning Rate: 1.0000000000000002e-06 || Time: 05:27:44.67
Epoch :: 75 || Loss: 0.38669111 || it_count: 8344 || Val Loss: 0.42570370 || Val it_count: 1107 || Current Learning Rate: 1.0000000000000002e-06 || Time: 05:32:9.00
Epoch :: 76 || Loss: 0.38665645 || it_count: 8344 || Val Loss: 0.42574929 || Val it_count: 1107 || Current Learning Rate: 1.0000000000000002e-06 || Time: 05:36:35.85
Epoch :: 77 || Loss: 0.38661054 || it_count: 8344 || Val Loss: 0.42573903 || Val it_count: 1107 || Current Learning Rate: 1.0000000000000002e-06 || Time: 05:41:1.57
Epoch 00062: reducing learning rate of group 0 to 1.0000e-07.
Early stopping triggered due to learning rate below threshold.
Done Total time: 05:45:28.51
best_loss: 0.42570370489250503

--------------------Testing--------------------

total_samples :: test_dataset = 139200, test_dataloader = 139200
Epoch ::  1 || Loss: 0.25727362 || it_count: 544 || Time: 00:00:14.12
MAE:  0.26305133
MSE:  0.25730664
RMSE:  0.45893633

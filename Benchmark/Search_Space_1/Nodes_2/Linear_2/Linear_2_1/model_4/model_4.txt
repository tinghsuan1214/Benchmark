--------------------Training--------------------
arch_str :: |lstm_4~0|[linear->linear]
model :: 2E
InferCell(
  info :: nodes=2, inC=1, outC=64, [1<-(I0-L0)], genotype_str: lstm_4~0
  linear_layers: [linear->linear]
  (layers): ModuleList(
    (0): LSTM(
      (lstm): LSTM(1, 64, num_layers=4, batch_first=True)
    )
  )
  (linear_layers): ModuleList(
    (0): Linear(in_features=3072, out_features=1536, bias=True)
    (1): Linear(in_features=1536, out_features=1, bias=True)
  )
)
tr_params :: epochs = 100, patience = 20, batch_size = 256, window_size = 48, data_size = 100
Model FLOPs: 10.434M, Model Params: 4.839M
learning rate scheduling :: (optimizer, mode='min', factor=0.1, patience=5, verbose=True)
total_samples :: train_dataset = 2136000, train_dataloader = 2136000
total_samples :: valid_dataset = 283200, valid_dataloader = 283200
Epoch ::  1 || Loss: 0.43169786 || it_count: 8344 || Val Loss: 0.45296265 || Val it_count: 1107 || Current Learning Rate: 0.001 || Time: 00:14:53.69
Epoch ::  2 || Loss: 0.41790002 || it_count: 8344 || Val Loss: 0.45175483 || Val it_count: 1107 || Current Learning Rate: 0.001 || Time: 00:29:49.14
Epoch ::  3 || Loss: 0.41721923 || it_count: 8344 || Val Loss: 0.45545272 || Val it_count: 1107 || Current Learning Rate: 0.001 || Time: 00:44:53.18
Epoch ::  4 || Loss: 0.41665475 || it_count: 8344 || Val Loss: 0.45630717 || Val it_count: 1107 || Current Learning Rate: 0.001 || Time: 01:00:2.07
Epoch ::  5 || Loss: 0.41602486 || it_count: 8344 || Val Loss: 0.45593896 || Val it_count: 1107 || Current Learning Rate: 0.001 || Time: 01:15:11.83
Epoch ::  6 || Loss: 0.41576553 || it_count: 8344 || Val Loss: 0.45594637 || Val it_count: 1107 || Current Learning Rate: 0.001 || Time: 01:30:24.71
Epoch ::  7 || Loss: 0.41548252 || it_count: 8344 || Val Loss: 0.45515271 || Val it_count: 1107 || Current Learning Rate: 0.001 || Time: 01:45:38.70
Epoch ::  8 || Loss: 0.41532813 || it_count: 8344 || Val Loss: 0.45480990 || Val it_count: 1107 || Current Learning Rate: 0.001 || Time: 02:00:55.32
Epoch ::  9 || Loss: 0.41508030 || it_count: 8344 || Val Loss: 0.45484229 || Val it_count: 1107 || Current Learning Rate: 0.001 || Time: 02:16:15.31
Epoch :: 10 || Loss: 0.41488188 || it_count: 8344 || Val Loss: 0.45501951 || Val it_count: 1107 || Current Learning Rate: 0.001 || Time: 02:31:35.40
Epoch :: 11 || Loss: 0.41465903 || it_count: 8344 || Val Loss: 0.45520631 || Val it_count: 1107 || Current Learning Rate: 0.001 || Time: 02:46:56.46
Epoch :: 12 || Loss: 0.41464283 || it_count: 8344 || Val Loss: 0.45422380 || Val it_count: 1107 || Current Learning Rate: 0.001 || Time: 03:02:17.67
Epoch :: 13 || Loss: 0.41448081 || it_count: 8344 || Val Loss: 0.45864637 || Val it_count: 1107 || Current Learning Rate: 0.001 || Time: 03:17:38.45
Epoch :: 14 || Loss: 0.41440534 || it_count: 8344 || Val Loss: 0.45425029 || Val it_count: 1107 || Current Learning Rate: 0.001 || Time: 03:33:1.94
Epoch :: 15 || Loss: 0.41414449 || it_count: 8344 || Val Loss: 0.45305601 || Val it_count: 1107 || Current Learning Rate: 0.001 || Time: 03:48:25.71
Epoch :: 16 || Loss: 0.41384096 || it_count: 8344 || Val Loss: 0.45558099 || Val it_count: 1107 || Current Learning Rate: 0.001 || Time: 04:03:50.04
Epoch :: 17 || Loss: 0.41351646 || it_count: 8344 || Val Loss: 0.45431414 || Val it_count: 1107 || Current Learning Rate: 0.001 || Time: 04:19:13.11
Epoch :: 18 || Loss: 0.41267981 || it_count: 8344 || Val Loss: 0.45302502 || Val it_count: 1107 || Current Learning Rate: 0.001 || Time: 04:34:35.88
Epoch :: 19 || Loss: 0.41223035 || it_count: 8344 || Val Loss: 0.45163589 || Val it_count: 1107 || Current Learning Rate: 0.001 || Time: 04:50:0.42
Epoch :: 20 || Loss: 0.41193941 || it_count: 8344 || Val Loss: 0.45193330 || Val it_count: 1107 || Current Learning Rate: 0.001 || Time: 05:05:24.03
Epoch :: 21 || Loss: 0.41156779 || it_count: 8344 || Val Loss: 0.45290173 || Val it_count: 1107 || Current Learning Rate: 0.001 || Time: 05:20:47.57
Epoch :: 22 || Loss: 0.41166506 || it_count: 8344 || Val Loss: 0.45237097 || Val it_count: 1107 || Current Learning Rate: 0.001 || Time: 05:36:10.37
Epoch :: 23 || Loss: 0.41128698 || it_count: 8344 || Val Loss: 0.45100392 || Val it_count: 1107 || Current Learning Rate: 0.001 || Time: 05:51:34.23
Epoch :: 24 || Loss: 0.41076179 || it_count: 8344 || Val Loss: 0.44926182 || Val it_count: 1107 || Current Learning Rate: 0.001 || Time: 06:06:57.54
Epoch :: 25 || Loss: 0.41065303 || it_count: 8344 || Val Loss: 0.44868522 || Val it_count: 1107 || Current Learning Rate: 0.001 || Time: 06:22:21.42
Epoch :: 26 || Loss: 0.41100169 || it_count: 8344 || Val Loss: 0.45026430 || Val it_count: 1107 || Current Learning Rate: 0.001 || Time: 06:37:45.54
Epoch :: 27 || Loss: 0.41013832 || it_count: 8344 || Val Loss: 0.45025380 || Val it_count: 1107 || Current Learning Rate: 0.001 || Time: 06:53:10.55
Epoch :: 28 || Loss: 0.40964526 || it_count: 8344 || Val Loss: 0.44926511 || Val it_count: 1107 || Current Learning Rate: 0.001 || Time: 07:08:34.95
Epoch :: 29 || Loss: 0.40920218 || it_count: 8344 || Val Loss: 0.44818394 || Val it_count: 1107 || Current Learning Rate: 0.001 || Time: 07:23:58.28
Epoch :: 30 || Loss: 0.40896829 || it_count: 8344 || Val Loss: 0.44904812 || Val it_count: 1107 || Current Learning Rate: 0.001 || Time: 07:39:20.12
Epoch :: 31 || Loss: 0.40866996 || it_count: 8344 || Val Loss: 0.44839091 || Val it_count: 1107 || Current Learning Rate: 0.001 || Time: 07:54:42.40
Epoch :: 32 || Loss: 0.40794539 || it_count: 8344 || Val Loss: 0.44755196 || Val it_count: 1107 || Current Learning Rate: 0.001 || Time: 08:10:5.61
Epoch :: 33 || Loss: 0.40759498 || it_count: 8344 || Val Loss: 0.44767953 || Val it_count: 1107 || Current Learning Rate: 0.001 || Time: 08:25:29.03
Epoch :: 34 || Loss: 0.40756135 || it_count: 8344 || Val Loss: 0.44670147 || Val it_count: 1107 || Current Learning Rate: 0.001 || Time: 08:40:52.10
Epoch :: 35 || Loss: 0.40689413 || it_count: 8344 || Val Loss: 0.44819864 || Val it_count: 1107 || Current Learning Rate: 0.001 || Time: 08:56:14.95
Epoch :: 36 || Loss: 0.40657335 || it_count: 8344 || Val Loss: 0.44950122 || Val it_count: 1107 || Current Learning Rate: 0.001 || Time: 09:11:36.86
Epoch :: 37 || Loss: 0.40598397 || it_count: 8344 || Val Loss: 0.44858067 || Val it_count: 1107 || Current Learning Rate: 0.001 || Time: 09:27:0.55
Epoch :: 38 || Loss: 0.40667759 || it_count: 8344 || Val Loss: 0.44817119 || Val it_count: 1107 || Current Learning Rate: 0.001 || Time: 09:42:23.41
Epoch :: 39 || Loss: 0.40571951 || it_count: 8344 || Val Loss: 0.44660240 || Val it_count: 1107 || Current Learning Rate: 0.001 || Time: 09:57:45.76
Epoch :: 40 || Loss: 0.40585668 || it_count: 8344 || Val Loss: 0.44635739 || Val it_count: 1107 || Current Learning Rate: 0.001 || Time: 10:13:9.88
Epoch :: 41 || Loss: 0.40501402 || it_count: 8344 || Val Loss: 0.44445291 || Val it_count: 1107 || Current Learning Rate: 0.001 || Time: 10:28:32.42
Epoch :: 42 || Loss: 0.40424680 || it_count: 8344 || Val Loss: 0.44654430 || Val it_count: 1107 || Current Learning Rate: 0.001 || Time: 10:43:55.00
Epoch :: 43 || Loss: 0.40374636 || it_count: 8344 || Val Loss: 0.44639237 || Val it_count: 1107 || Current Learning Rate: 0.001 || Time: 10:59:18.51
Epoch :: 44 || Loss: 0.40327201 || it_count: 8344 || Val Loss: 0.44652197 || Val it_count: 1107 || Current Learning Rate: 0.001 || Time: 11:14:40.38
Epoch :: 45 || Loss: 0.40248329 || it_count: 8344 || Val Loss: 0.44727079 || Val it_count: 1107 || Current Learning Rate: 0.001 || Time: 11:30:2.65
Epoch :: 46 || Loss: 0.40216365 || it_count: 8344 || Val Loss: 0.44686781 || Val it_count: 1107 || Current Learning Rate: 0.001 || Time: 11:45:28.97
Epoch 00031: reducing learning rate of group 0 to 1.0000e-04.
Epoch :: 47 || Loss: 0.40186695 || it_count: 8344 || Val Loss: 0.44668331 || Val it_count: 1107 || Current Learning Rate: 0.0001 || Time: 12:00:55.92
Epoch :: 48 || Loss: 0.41030100 || it_count: 8344 || Val Loss: 0.43310303 || Val it_count: 1107 || Current Learning Rate: 0.0001 || Time: 12:16:20.53
Epoch :: 49 || Loss: 0.40820580 || it_count: 8344 || Val Loss: 0.43254433 || Val it_count: 1107 || Current Learning Rate: 0.0001 || Time: 12:31:45.42
Epoch :: 50 || Loss: 0.40709791 || it_count: 8344 || Val Loss: 0.43143986 || Val it_count: 1107 || Current Learning Rate: 0.0001 || Time: 12:47:10.07
Epoch :: 51 || Loss: 0.40622983 || it_count: 8344 || Val Loss: 0.43068751 || Val it_count: 1107 || Current Learning Rate: 0.0001 || Time: 13:02:35.02
Epoch :: 52 || Loss: 0.40560503 || it_count: 8344 || Val Loss: 0.43004592 || Val it_count: 1107 || Current Learning Rate: 0.0001 || Time: 13:18:1.08
Epoch :: 53 || Loss: 0.40510325 || it_count: 8344 || Val Loss: 0.42937551 || Val it_count: 1107 || Current Learning Rate: 0.0001 || Time: 13:33:25.53
Epoch :: 54 || Loss: 0.40464819 || it_count: 8344 || Val Loss: 0.42884248 || Val it_count: 1107 || Current Learning Rate: 0.0001 || Time: 13:48:50.06
Epoch :: 55 || Loss: 0.40424621 || it_count: 8344 || Val Loss: 0.42852315 || Val it_count: 1107 || Current Learning Rate: 0.0001 || Time: 14:04:15.42
Epoch :: 56 || Loss: 0.40383710 || it_count: 8344 || Val Loss: 0.42825786 || Val it_count: 1107 || Current Learning Rate: 0.0001 || Time: 14:19:41.52
Epoch :: 57 || Loss: 0.40347665 || it_count: 8344 || Val Loss: 0.42789927 || Val it_count: 1107 || Current Learning Rate: 0.0001 || Time: 14:35:3.44
Epoch :: 58 || Loss: 0.40316079 || it_count: 8344 || Val Loss: 0.42806036 || Val it_count: 1107 || Current Learning Rate: 0.0001 || Time: 14:50:26.24
Epoch :: 59 || Loss: 0.40286513 || it_count: 8344 || Val Loss: 0.42838290 || Val it_count: 1107 || Current Learning Rate: 0.0001 || Time: 15:05:48.97
Epoch :: 60 || Loss: 0.40267979 || it_count: 8344 || Val Loss: 0.42894561 || Val it_count: 1107 || Current Learning Rate: 0.0001 || Time: 15:21:12.90
Epoch :: 61 || Loss: 0.40251920 || it_count: 8344 || Val Loss: 0.42899690 || Val it_count: 1107 || Current Learning Rate: 0.0001 || Time: 15:36:35.82
Epoch :: 62 || Loss: 0.40209797 || it_count: 8344 || Val Loss: 0.42917893 || Val it_count: 1107 || Current Learning Rate: 0.0001 || Time: 15:51:59.08
Epoch 00047: reducing learning rate of group 0 to 1.0000e-05.
Epoch :: 63 || Loss: 0.40182128 || it_count: 8344 || Val Loss: 0.42941069 || Val it_count: 1107 || Current Learning Rate: 1e-05 || Time: 16:07:23.16
Epoch :: 64 || Loss: 0.40821046 || it_count: 8344 || Val Loss: 0.41280546 || Val it_count: 1107 || Current Learning Rate: 1e-05 || Time: 16:22:46.24
Epoch :: 65 || Loss: 0.40560742 || it_count: 8344 || Val Loss: 0.41255029 || Val it_count: 1107 || Current Learning Rate: 1e-05 || Time: 16:38:9.62
Epoch :: 66 || Loss: 0.40524010 || it_count: 8344 || Val Loss: 0.41256100 || Val it_count: 1107 || Current Learning Rate: 1e-05 || Time: 16:53:34.08
Epoch :: 67 || Loss: 0.40500711 || it_count: 8344 || Val Loss: 0.41259646 || Val it_count: 1107 || Current Learning Rate: 1e-05 || Time: 17:08:55.06
Epoch :: 68 || Loss: 0.40484018 || it_count: 8344 || Val Loss: 0.41264418 || Val it_count: 1107 || Current Learning Rate: 1e-05 || Time: 17:24:17.65
Epoch :: 69 || Loss: 0.40469856 || it_count: 8344 || Val Loss: 0.41273783 || Val it_count: 1107 || Current Learning Rate: 1e-05 || Time: 17:39:40.56
Epoch :: 70 || Loss: 0.40459371 || it_count: 8344 || Val Loss: 0.41278480 || Val it_count: 1107 || Current Learning Rate: 1e-05 || Time: 17:55:3.84
Epoch 00055: reducing learning rate of group 0 to 1.0000e-06.
Epoch :: 71 || Loss: 0.40448928 || it_count: 8344 || Val Loss: 0.41288114 || Val it_count: 1107 || Current Learning Rate: 1.0000000000000002e-06 || Time: 18:10:26.85
Epoch :: 72 || Loss: 0.40504294 || it_count: 8344 || Val Loss: 0.41169955 || Val it_count: 1107 || Current Learning Rate: 1.0000000000000002e-06 || Time: 18:25:48.93
Epoch :: 73 || Loss: 0.40478447 || it_count: 8344 || Val Loss: 0.41155543 || Val it_count: 1107 || Current Learning Rate: 1.0000000000000002e-06 || Time: 18:41:12.77
Epoch :: 74 || Loss: 0.40469798 || it_count: 8344 || Val Loss: 0.41151541 || Val it_count: 1107 || Current Learning Rate: 1.0000000000000002e-06 || Time: 18:56:35.48
Epoch :: 75 || Loss: 0.40464901 || it_count: 8344 || Val Loss: 0.41150235 || Val it_count: 1107 || Current Learning Rate: 1.0000000000000002e-06 || Time: 19:11:58.74
Epoch :: 76 || Loss: 0.40461536 || it_count: 8344 || Val Loss: 0.41149753 || Val it_count: 1107 || Current Learning Rate: 1.0000000000000002e-06 || Time: 19:27:23.27
Epoch :: 77 || Loss: 0.40459034 || it_count: 8344 || Val Loss: 0.41149624 || Val it_count: 1107 || Current Learning Rate: 1.0000000000000002e-06 || Time: 19:42:45.44
Epoch :: 78 || Loss: 0.40456962 || it_count: 8344 || Val Loss: 0.41149582 || Val it_count: 1107 || Current Learning Rate: 1.0000000000000002e-06 || Time: 19:58:8.08
Epoch :: 79 || Loss: 0.40455134 || it_count: 8344 || Val Loss: 0.41149615 || Val it_count: 1107 || Current Learning Rate: 1.0000000000000002e-06 || Time: 20:13:30.62
Epoch :: 80 || Loss: 0.40453541 || it_count: 8344 || Val Loss: 0.41149620 || Val it_count: 1107 || Current Learning Rate: 1.0000000000000002e-06 || Time: 20:28:53.02
Epoch 00065: reducing learning rate of group 0 to 1.0000e-07.
Epoch :: 81 || Loss: 0.40452047 || it_count: 8344 || Val Loss: 0.41149662 || Val it_count: 1107 || Current Learning Rate: 1.0000000000000002e-07 || Time: 20:44:15.57
Epoch :: 82 || Loss: 0.40453256 || it_count: 8344 || Val Loss: 0.41142448 || Val it_count: 1107 || Current Learning Rate: 1.0000000000000002e-07 || Time: 20:59:36.20
Epoch :: 83 || Loss: 0.40451281 || it_count: 8344 || Val Loss: 0.41140603 || Val it_count: 1107 || Current Learning Rate: 1.0000000000000002e-07 || Time: 21:15:0.68
Epoch :: 84 || Loss: 0.40450866 || it_count: 8344 || Val Loss: 0.41140402 || Val it_count: 1107 || Current Learning Rate: 1.0000000000000002e-07 || Time: 21:30:24.98
Epoch :: 85 || Loss: 0.40450660 || it_count: 8344 || Val Loss: 0.41140268 || Val it_count: 1107 || Current Learning Rate: 1.0000000000000002e-07 || Time: 21:45:49.33
Epoch :: 86 || Loss: 0.40450464 || it_count: 8344 || Val Loss: 0.41140154 || Val it_count: 1107 || Current Learning Rate: 1.0000000000000002e-07 || Time: 22:01:14.06
Epoch :: 87 || Loss: 0.40450274 || it_count: 8344 || Val Loss: 0.41140051 || Val it_count: 1107 || Current Learning Rate: 1.0000000000000002e-07 || Time: 22:16:39.20
Epoch 00072: reducing learning rate of group 0 to 1.0000e-08.
Early stopping triggered due to learning rate below threshold.
Done Total time: 22:32:3.73
best_loss: 0.41140051249083587

--------------------Testing--------------------

total_samples :: test_dataset = 139200, test_dataloader = 139200
Epoch ::  1 || Loss: 0.23626548 || it_count: 544 || Time: 00:00:33.80
MAE:  0.25078958
MSE:  0.236286
RMSE:  0.4413783

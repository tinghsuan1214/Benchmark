--------------------Training--------------------
arch_str :: |lstm_1~0|[dropout->linear->dropout->linear]
model :: 2J
InferCell(
  info :: nodes=2, inC=1, outC=64, [1<-(I0-L0)], genotype_str: lstm_1~0
  linear_layers: [dropout->linear->dropout->linear]
  (layers): ModuleList(
    (0): LSTM(
      (lstm): LSTM(1, 64, batch_first=True)
    )
  )
  (linear_layers): ModuleList(
    (0): Dropout(p=0.1, inplace=False)
    (1): Linear(in_features=3072, out_features=1536, bias=True)
    (2): Dropout(p=0.1, inplace=False)
    (3): Linear(in_features=1536, out_features=1, bias=True)
  )
)
tr_params :: epochs = 100, patience = 20, batch_size = 256, window_size = 48, data_size = 100
Model FLOPs: 5.568M, Model Params: 4.739M
learning rate scheduling :: (optimizer, mode='min', factor=0.1, patience=5, verbose=True)
total_samples :: train_dataset = 2136000, train_dataloader = 2136000
total_samples :: valid_dataset = 283200, valid_dataloader = 283200
Epoch ::  1 || Loss: 0.42175372 || it_count: 8344 || Val Loss: 0.45113553 || Val it_count: 1107 || Current Learning Rate: 0.001 || Time: 00:06:12.73
Epoch ::  2 || Loss: 0.41860768 || it_count: 8344 || Val Loss: 0.45105714 || Val it_count: 1107 || Current Learning Rate: 0.001 || Time: 00:12:21.43
Epoch ::  3 || Loss: 0.41847492 || it_count: 8344 || Val Loss: 0.45151557 || Val it_count: 1107 || Current Learning Rate: 0.001 || Time: 00:18:31.89
Epoch ::  4 || Loss: 0.41835773 || it_count: 8344 || Val Loss: 0.45060372 || Val it_count: 1107 || Current Learning Rate: 0.001 || Time: 00:24:42.13
Epoch ::  5 || Loss: 0.41814710 || it_count: 8344 || Val Loss: 0.45103639 || Val it_count: 1107 || Current Learning Rate: 0.001 || Time: 00:30:51.50
Epoch ::  6 || Loss: 0.41798812 || it_count: 8344 || Val Loss: 0.45188722 || Val it_count: 1107 || Current Learning Rate: 0.001 || Time: 00:37:0.65
Epoch ::  7 || Loss: 0.41813514 || it_count: 8344 || Val Loss: 0.45101948 || Val it_count: 1107 || Current Learning Rate: 0.001 || Time: 00:43:8.21
Epoch ::  8 || Loss: 0.41788839 || it_count: 8344 || Val Loss: 0.45070122 || Val it_count: 1107 || Current Learning Rate: 0.001 || Time: 00:49:16.35
Epoch ::  9 || Loss: 0.41785631 || it_count: 8344 || Val Loss: 0.44991999 || Val it_count: 1107 || Current Learning Rate: 0.001 || Time: 00:55:24.96
Epoch :: 10 || Loss: 0.41769003 || it_count: 8344 || Val Loss: 0.44939724 || Val it_count: 1107 || Current Learning Rate: 0.001 || Time: 01:01:33.77
Epoch :: 11 || Loss: 0.41765627 || it_count: 8344 || Val Loss: 0.45001992 || Val it_count: 1107 || Current Learning Rate: 0.001 || Time: 01:07:42.44
Epoch :: 12 || Loss: 0.41758714 || it_count: 8344 || Val Loss: 0.44918141 || Val it_count: 1107 || Current Learning Rate: 0.001 || Time: 01:13:51.05
Epoch :: 13 || Loss: 0.41763219 || it_count: 8344 || Val Loss: 0.45025526 || Val it_count: 1107 || Current Learning Rate: 0.001 || Time: 01:20:0.86
Epoch :: 14 || Loss: 0.41757730 || it_count: 8344 || Val Loss: 0.44948973 || Val it_count: 1107 || Current Learning Rate: 0.001 || Time: 01:26:10.20
Epoch :: 15 || Loss: 0.41748879 || it_count: 8344 || Val Loss: 0.44969350 || Val it_count: 1107 || Current Learning Rate: 0.001 || Time: 01:32:19.17
Epoch :: 16 || Loss: 0.41747710 || it_count: 8344 || Val Loss: 0.44966051 || Val it_count: 1107 || Current Learning Rate: 0.001 || Time: 01:38:28.22
Epoch :: 17 || Loss: 0.41747329 || it_count: 8344 || Val Loss: 0.44919902 || Val it_count: 1107 || Current Learning Rate: 0.001 || Time: 01:44:36.82
Epoch :: 18 || Loss: 0.41742799 || it_count: 8344 || Val Loss: 0.45026082 || Val it_count: 1107 || Current Learning Rate: 0.001 || Time: 01:50:45.33
Epoch :: 19 || Loss: 0.41751051 || it_count: 8344 || Val Loss: 0.44980859 || Val it_count: 1107 || Current Learning Rate: 0.001 || Time: 01:56:54.33
Epoch :: 20 || Loss: 0.41733385 || it_count: 8344 || Val Loss: 0.45014982 || Val it_count: 1107 || Current Learning Rate: 0.001 || Time: 02:03:3.98
Epoch :: 21 || Loss: 0.41725013 || it_count: 8344 || Val Loss: 0.45041589 || Val it_count: 1107 || Current Learning Rate: 0.001 || Time: 02:09:13.89
Epoch :: 22 || Loss: 0.41725989 || it_count: 8344 || Val Loss: 0.44978914 || Val it_count: 1107 || Current Learning Rate: 0.001 || Time: 02:15:22.47
Epoch 00007: reducing learning rate of group 0 to 1.0000e-04.
Epoch :: 23 || Loss: 0.41735214 || it_count: 8344 || Val Loss: 0.45000501 || Val it_count: 1107 || Current Learning Rate: 0.0001 || Time: 02:21:30.61
Epoch :: 24 || Loss: 0.42457751 || it_count: 8344 || Val Loss: 0.43895777 || Val it_count: 1107 || Current Learning Rate: 0.0001 || Time: 02:27:40.43
Epoch :: 25 || Loss: 0.42153303 || it_count: 8344 || Val Loss: 0.43733810 || Val it_count: 1107 || Current Learning Rate: 0.0001 || Time: 02:33:49.89
Epoch :: 26 || Loss: 0.42101243 || it_count: 8344 || Val Loss: 0.43616009 || Val it_count: 1107 || Current Learning Rate: 0.0001 || Time: 02:39:58.21
Epoch :: 27 || Loss: 0.42077490 || it_count: 8344 || Val Loss: 0.43518068 || Val it_count: 1107 || Current Learning Rate: 0.0001 || Time: 02:46:6.58
Epoch :: 28 || Loss: 0.42055470 || it_count: 8344 || Val Loss: 0.43480252 || Val it_count: 1107 || Current Learning Rate: 0.0001 || Time: 02:52:15.18
Epoch :: 29 || Loss: 0.42036087 || it_count: 8344 || Val Loss: 0.43423907 || Val it_count: 1107 || Current Learning Rate: 0.0001 || Time: 02:58:23.02
Epoch :: 30 || Loss: 0.42019884 || it_count: 8344 || Val Loss: 0.43428323 || Val it_count: 1107 || Current Learning Rate: 0.0001 || Time: 03:04:32.47
Epoch :: 31 || Loss: 0.42006119 || it_count: 8344 || Val Loss: 0.43432794 || Val it_count: 1107 || Current Learning Rate: 0.0001 || Time: 03:10:40.02
Epoch :: 32 || Loss: 0.41995751 || it_count: 8344 || Val Loss: 0.43438419 || Val it_count: 1107 || Current Learning Rate: 0.0001 || Time: 03:16:48.87
Epoch :: 33 || Loss: 0.41981081 || it_count: 8344 || Val Loss: 0.43450623 || Val it_count: 1107 || Current Learning Rate: 0.0001 || Time: 03:22:57.27
Epoch :: 34 || Loss: 0.41965835 || it_count: 8344 || Val Loss: 0.43445756 || Val it_count: 1107 || Current Learning Rate: 0.0001 || Time: 03:29:6.06
Epoch 00019: reducing learning rate of group 0 to 1.0000e-05.
Epoch :: 35 || Loss: 0.41968240 || it_count: 8344 || Val Loss: 0.43434782 || Val it_count: 1107 || Current Learning Rate: 1e-05 || Time: 03:35:13.89
Epoch :: 36 || Loss: 0.42304293 || it_count: 8344 || Val Loss: 0.42467816 || Val it_count: 1107 || Current Learning Rate: 1e-05 || Time: 03:41:20.93
Epoch :: 37 || Loss: 0.42099122 || it_count: 8344 || Val Loss: 0.42379647 || Val it_count: 1107 || Current Learning Rate: 1e-05 || Time: 03:47:29.50
Epoch :: 38 || Loss: 0.42040348 || it_count: 8344 || Val Loss: 0.42334984 || Val it_count: 1107 || Current Learning Rate: 1e-05 || Time: 03:53:38.71
Epoch :: 39 || Loss: 0.42008284 || it_count: 8344 || Val Loss: 0.42316888 || Val it_count: 1107 || Current Learning Rate: 1e-05 || Time: 03:59:46.83
Epoch :: 40 || Loss: 0.42003324 || it_count: 8344 || Val Loss: 0.42301865 || Val it_count: 1107 || Current Learning Rate: 1e-05 || Time: 04:05:54.32
Epoch :: 41 || Loss: 0.41987757 || it_count: 8344 || Val Loss: 0.42297238 || Val it_count: 1107 || Current Learning Rate: 1e-05 || Time: 04:12:1.65
Epoch :: 42 || Loss: 0.41991279 || it_count: 8344 || Val Loss: 0.42291493 || Val it_count: 1107 || Current Learning Rate: 1e-05 || Time: 04:18:10.92
Epoch :: 43 || Loss: 0.41986852 || it_count: 8344 || Val Loss: 0.42290536 || Val it_count: 1107 || Current Learning Rate: 1e-05 || Time: 04:24:19.59
Epoch :: 44 || Loss: 0.41990256 || it_count: 8344 || Val Loss: 0.42283145 || Val it_count: 1107 || Current Learning Rate: 1e-05 || Time: 04:30:29.42
Epoch :: 45 || Loss: 0.41974438 || it_count: 8344 || Val Loss: 0.42284445 || Val it_count: 1107 || Current Learning Rate: 1e-05 || Time: 04:36:38.82
Epoch :: 46 || Loss: 0.41980022 || it_count: 8344 || Val Loss: 0.42278922 || Val it_count: 1107 || Current Learning Rate: 1e-05 || Time: 04:42:45.68
Epoch :: 47 || Loss: 0.41972134 || it_count: 8344 || Val Loss: 0.42275093 || Val it_count: 1107 || Current Learning Rate: 1e-05 || Time: 04:48:54.61
Epoch :: 48 || Loss: 0.41970656 || it_count: 8344 || Val Loss: 0.42276684 || Val it_count: 1107 || Current Learning Rate: 1e-05 || Time: 04:55:4.12
Epoch :: 49 || Loss: 0.41969043 || it_count: 8344 || Val Loss: 0.42271543 || Val it_count: 1107 || Current Learning Rate: 1e-05 || Time: 05:01:11.08
Epoch :: 50 || Loss: 0.41970156 || it_count: 8344 || Val Loss: 0.42269709 || Val it_count: 1107 || Current Learning Rate: 1e-05 || Time: 05:07:20.03
Epoch :: 51 || Loss: 0.41961325 || it_count: 8344 || Val Loss: 0.42271564 || Val it_count: 1107 || Current Learning Rate: 1e-05 || Time: 05:13:29.77
Epoch :: 52 || Loss: 0.41965108 || it_count: 8344 || Val Loss: 0.42269818 || Val it_count: 1107 || Current Learning Rate: 1e-05 || Time: 05:19:38.11
Epoch :: 53 || Loss: 0.41968382 || it_count: 8344 || Val Loss: 0.42269768 || Val it_count: 1107 || Current Learning Rate: 1e-05 || Time: 05:25:46.98
Epoch :: 54 || Loss: 0.41957105 || it_count: 8344 || Val Loss: 0.42270502 || Val it_count: 1107 || Current Learning Rate: 1e-05 || Time: 05:31:54.83
Epoch :: 55 || Loss: 0.41958268 || it_count: 8344 || Val Loss: 0.42266261 || Val it_count: 1107 || Current Learning Rate: 1e-05 || Time: 05:38:3.27
Epoch 00040: reducing learning rate of group 0 to 1.0000e-06.
Epoch :: 56 || Loss: 0.41953032 || it_count: 8344 || Val Loss: 0.42266755 || Val it_count: 1107 || Current Learning Rate: 1.0000000000000002e-06 || Time: 05:44:10.66
Epoch :: 57 || Loss: 0.41981209 || it_count: 8344 || Val Loss: 0.42194826 || Val it_count: 1107 || Current Learning Rate: 1.0000000000000002e-06 || Time: 05:50:20.54
Epoch :: 58 || Loss: 0.41973612 || it_count: 8344 || Val Loss: 0.42186326 || Val it_count: 1107 || Current Learning Rate: 1.0000000000000002e-06 || Time: 05:56:27.73
Epoch :: 59 || Loss: 0.41972071 || it_count: 8344 || Val Loss: 0.42182903 || Val it_count: 1107 || Current Learning Rate: 1.0000000000000002e-06 || Time: 06:02:35.57
Epoch :: 60 || Loss: 0.41963204 || it_count: 8344 || Val Loss: 0.42179738 || Val it_count: 1107 || Current Learning Rate: 1.0000000000000002e-06 || Time: 06:08:45.12
Epoch :: 61 || Loss: 0.41964997 || it_count: 8344 || Val Loss: 0.42178164 || Val it_count: 1107 || Current Learning Rate: 1.0000000000000002e-06 || Time: 06:14:54.36
Epoch :: 62 || Loss: 0.41964158 || it_count: 8344 || Val Loss: 0.42176342 || Val it_count: 1107 || Current Learning Rate: 1.0000000000000002e-06 || Time: 06:21:2.19
Epoch :: 63 || Loss: 0.41965055 || it_count: 8344 || Val Loss: 0.42175075 || Val it_count: 1107 || Current Learning Rate: 1.0000000000000002e-06 || Time: 06:27:10.57
Epoch :: 64 || Loss: 0.41965588 || it_count: 8344 || Val Loss: 0.42174612 || Val it_count: 1107 || Current Learning Rate: 1.0000000000000002e-06 || Time: 06:33:19.08
Epoch :: 65 || Loss: 0.41964197 || it_count: 8344 || Val Loss: 0.42173255 || Val it_count: 1107 || Current Learning Rate: 1.0000000000000002e-06 || Time: 06:39:28.73
Epoch :: 66 || Loss: 0.41962840 || it_count: 8344 || Val Loss: 0.42173252 || Val it_count: 1107 || Current Learning Rate: 1.0000000000000002e-06 || Time: 06:45:37.35
Epoch :: 67 || Loss: 0.41958372 || it_count: 8344 || Val Loss: 0.42172240 || Val it_count: 1107 || Current Learning Rate: 1.0000000000000002e-06 || Time: 06:51:45.91
Epoch :: 68 || Loss: 0.41963510 || it_count: 8344 || Val Loss: 0.42171945 || Val it_count: 1107 || Current Learning Rate: 1.0000000000000002e-06 || Time: 06:57:55.47
Epoch 00053: reducing learning rate of group 0 to 1.0000e-07.
Early stopping triggered due to learning rate below threshold.
Done Total time: 07:04:3.63
best_loss: 0.4217194481108691

--------------------Testing--------------------

total_samples :: test_dataset = 139200, test_dataloader = 139200
Epoch ::  1 || Loss: 0.25320933 || it_count: 544 || Time: 00:00:19.86
MAE:  0.26341227
MSE:  0.25323585
RMSE:  0.45356393

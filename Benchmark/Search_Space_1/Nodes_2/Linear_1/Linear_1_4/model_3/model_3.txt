--------------------Training--------------------
arch_str :: |lstm_3~0|[relu->dropout->linear]
model :: 2D
InferCell(
  info :: nodes=2, inC=1, outC=64, [1<-(I0-L0)], genotype_str: lstm_3~0
  linear_layers: [relu->dropout->linear]
  (layers): ModuleList(
    (0): LSTM(
      (lstm): LSTM(1, 64, num_layers=3, batch_first=True)
    )
  )
  (linear_layers): ModuleList(
    (0): ReLU()
    (1): Dropout(p=0.1, inplace=False)
    (2): Linear(in_features=3072, out_features=1, bias=True)
  )
)
tr_params :: epochs = 100, patience = 20, batch_size = 256, window_size = 48, data_size = 100
Model MACs: 4.095M, Model Params: 86.785K
learning rate scheduling :: (optimizer, mode='min', factor=0.1, patience=5, verbose=True)
total_samples :: train_dataset = 2136000, train_dataloader = 2136000
total_samples :: valid_dataset = 283200, valid_dataloader = 283200
Epoch ::  1 || Loss: 0.42638554 || it_count: 8344 || Val Loss: 0.44987595 || Val it_count: 1107 || Current Learning Rate: 0.001 || Time: 00:06:40.32
Epoch ::  2 || Loss: 0.41930907 || it_count: 8344 || Val Loss: 0.44746390 || Val it_count: 1107 || Current Learning Rate: 0.001 || Time: 00:13:16.86
Epoch ::  3 || Loss: 0.41881243 || it_count: 8344 || Val Loss: 0.44619647 || Val it_count: 1107 || Current Learning Rate: 0.001 || Time: 00:19:53.66
Epoch ::  4 || Loss: 0.41860571 || it_count: 8344 || Val Loss: 0.44698108 || Val it_count: 1107 || Current Learning Rate: 0.001 || Time: 00:26:30.43
Epoch ::  5 || Loss: 0.41816018 || it_count: 8344 || Val Loss: 0.44792320 || Val it_count: 1107 || Current Learning Rate: 0.001 || Time: 00:33:5.82
Epoch ::  6 || Loss: 0.41765127 || it_count: 8344 || Val Loss: 0.44928276 || Val it_count: 1107 || Current Learning Rate: 0.001 || Time: 00:39:42.29
Epoch ::  7 || Loss: 0.41719862 || it_count: 8344 || Val Loss: 0.44955441 || Val it_count: 1107 || Current Learning Rate: 0.001 || Time: 00:46:19.19
Epoch ::  8 || Loss: 0.41690093 || it_count: 8344 || Val Loss: 0.44903468 || Val it_count: 1107 || Current Learning Rate: 0.001 || Time: 00:52:57.76
Epoch ::  9 || Loss: 0.41667391 || it_count: 8344 || Val Loss: 0.44889376 || Val it_count: 1107 || Current Learning Rate: 0.001 || Time: 00:59:37.38
Epoch :: 10 || Loss: 0.41633889 || it_count: 8344 || Val Loss: 0.44805885 || Val it_count: 1107 || Current Learning Rate: 0.001 || Time: 01:06:14.73
Epoch :: 11 || Loss: 0.41642871 || it_count: 8344 || Val Loss: 0.44743865 || Val it_count: 1107 || Current Learning Rate: 0.001 || Time: 01:12:53.00
Epoch :: 12 || Loss: 0.41605754 || it_count: 8344 || Val Loss: 0.44759773 || Val it_count: 1107 || Current Learning Rate: 0.001 || Time: 01:19:31.69
Epoch :: 13 || Loss: 0.41643073 || it_count: 8344 || Val Loss: 0.44900579 || Val it_count: 1107 || Current Learning Rate: 0.001 || Time: 01:26:10.02
Epoch :: 14 || Loss: 0.41612544 || it_count: 8344 || Val Loss: 0.44895822 || Val it_count: 1107 || Current Learning Rate: 0.001 || Time: 01:32:50.33
Epoch :: 15 || Loss: 0.41597597 || it_count: 8344 || Val Loss: 0.44592133 || Val it_count: 1107 || Current Learning Rate: 0.001 || Time: 01:39:28.74
Epoch :: 16 || Loss: 0.41487980 || it_count: 8344 || Val Loss: 0.44545146 || Val it_count: 1107 || Current Learning Rate: 0.001 || Time: 01:46:7.89
Epoch :: 17 || Loss: 0.41463785 || it_count: 8344 || Val Loss: 0.44455319 || Val it_count: 1107 || Current Learning Rate: 0.001 || Time: 01:52:46.94
Epoch :: 18 || Loss: 0.41371669 || it_count: 8344 || Val Loss: 0.44403382 || Val it_count: 1107 || Current Learning Rate: 0.001 || Time: 01:59:26.76
Epoch :: 19 || Loss: 0.41305543 || it_count: 8344 || Val Loss: 0.44588185 || Val it_count: 1107 || Current Learning Rate: 0.001 || Time: 02:06:7.55
Epoch :: 20 || Loss: 0.41308346 || it_count: 8344 || Val Loss: 0.44727825 || Val it_count: 1107 || Current Learning Rate: 0.001 || Time: 02:12:48.15
Epoch :: 21 || Loss: 0.41288855 || it_count: 8344 || Val Loss: 0.44635343 || Val it_count: 1107 || Current Learning Rate: 0.001 || Time: 02:19:29.01
Epoch :: 22 || Loss: 0.41251656 || it_count: 8344 || Val Loss: 0.44727539 || Val it_count: 1107 || Current Learning Rate: 0.001 || Time: 02:26:7.64
Epoch :: 23 || Loss: 0.41249559 || it_count: 8344 || Val Loss: 0.44813536 || Val it_count: 1107 || Current Learning Rate: 0.001 || Time: 02:32:48.85
Epoch 00008: reducing learning rate of group 0 to 1.0000e-04.
Epoch :: 24 || Loss: 0.41178808 || it_count: 8344 || Val Loss: 0.44739074 || Val it_count: 1107 || Current Learning Rate: 0.0001 || Time: 02:39:30.18
Epoch :: 25 || Loss: 0.41620381 || it_count: 8344 || Val Loss: 0.42347268 || Val it_count: 1107 || Current Learning Rate: 0.0001 || Time: 02:46:8.72
Epoch :: 26 || Loss: 0.41279708 || it_count: 8344 || Val Loss: 0.42221156 || Val it_count: 1107 || Current Learning Rate: 0.0001 || Time: 02:52:47.95
Epoch :: 27 || Loss: 0.41203773 || it_count: 8344 || Val Loss: 0.42180885 || Val it_count: 1107 || Current Learning Rate: 0.0001 || Time: 02:59:27.77
Epoch :: 28 || Loss: 0.41152277 || it_count: 8344 || Val Loss: 0.42153915 || Val it_count: 1107 || Current Learning Rate: 0.0001 || Time: 03:06:6.98
Epoch :: 29 || Loss: 0.41122006 || it_count: 8344 || Val Loss: 0.42140682 || Val it_count: 1107 || Current Learning Rate: 0.0001 || Time: 03:12:46.01
Epoch :: 30 || Loss: 0.41086895 || it_count: 8344 || Val Loss: 0.42117167 || Val it_count: 1107 || Current Learning Rate: 0.0001 || Time: 03:19:26.16
Epoch :: 31 || Loss: 0.41057814 || it_count: 8344 || Val Loss: 0.42102018 || Val it_count: 1107 || Current Learning Rate: 0.0001 || Time: 03:26:5.05
Epoch :: 32 || Loss: 0.41035719 || it_count: 8344 || Val Loss: 0.42080646 || Val it_count: 1107 || Current Learning Rate: 0.0001 || Time: 03:32:44.94
Epoch :: 33 || Loss: 0.41012093 || it_count: 8344 || Val Loss: 0.42075505 || Val it_count: 1107 || Current Learning Rate: 0.0001 || Time: 03:39:24.59
Epoch :: 34 || Loss: 0.40998948 || it_count: 8344 || Val Loss: 0.42028962 || Val it_count: 1107 || Current Learning Rate: 0.0001 || Time: 03:46:3.71
Epoch :: 35 || Loss: 0.40976973 || it_count: 8344 || Val Loss: 0.42031560 || Val it_count: 1107 || Current Learning Rate: 0.0001 || Time: 03:52:42.13
Epoch :: 36 || Loss: 0.40957512 || it_count: 8344 || Val Loss: 0.41990887 || Val it_count: 1107 || Current Learning Rate: 0.0001 || Time: 03:59:21.64
Epoch :: 37 || Loss: 0.40933264 || it_count: 8344 || Val Loss: 0.41988981 || Val it_count: 1107 || Current Learning Rate: 0.0001 || Time: 04:06:0.50
Epoch :: 38 || Loss: 0.40911925 || it_count: 8344 || Val Loss: 0.41991987 || Val it_count: 1107 || Current Learning Rate: 0.0001 || Time: 04:12:40.46
Epoch :: 39 || Loss: 0.40898176 || it_count: 8344 || Val Loss: 0.42008523 || Val it_count: 1107 || Current Learning Rate: 0.0001 || Time: 04:19:20.78
Epoch :: 40 || Loss: 0.40869097 || it_count: 8344 || Val Loss: 0.41989213 || Val it_count: 1107 || Current Learning Rate: 0.0001 || Time: 04:26:2.00
Epoch :: 41 || Loss: 0.40862802 || it_count: 8344 || Val Loss: 0.41991769 || Val it_count: 1107 || Current Learning Rate: 0.0001 || Time: 04:32:40.68
Epoch :: 42 || Loss: 0.40843283 || it_count: 8344 || Val Loss: 0.41957254 || Val it_count: 1107 || Current Learning Rate: 0.0001 || Time: 04:39:23.09
Epoch :: 43 || Loss: 0.40821142 || it_count: 8344 || Val Loss: 0.41978967 || Val it_count: 1107 || Current Learning Rate: 0.0001 || Time: 04:46:2.31
Epoch :: 44 || Loss: 0.40803763 || it_count: 8344 || Val Loss: 0.41960960 || Val it_count: 1107 || Current Learning Rate: 0.0001 || Time: 04:52:41.55
Epoch :: 45 || Loss: 0.40792218 || it_count: 8344 || Val Loss: 0.41971474 || Val it_count: 1107 || Current Learning Rate: 0.0001 || Time: 04:59:21.89
Epoch :: 46 || Loss: 0.40774480 || it_count: 8344 || Val Loss: 0.41953299 || Val it_count: 1107 || Current Learning Rate: 0.0001 || Time: 05:06:1.98
Epoch :: 47 || Loss: 0.40769090 || it_count: 8344 || Val Loss: 0.41873885 || Val it_count: 1107 || Current Learning Rate: 0.0001 || Time: 05:12:42.15
Epoch :: 48 || Loss: 0.40755949 || it_count: 8344 || Val Loss: 0.41981344 || Val it_count: 1107 || Current Learning Rate: 0.0001 || Time: 05:19:22.16
Epoch :: 49 || Loss: 0.40731486 || it_count: 8344 || Val Loss: 0.41965933 || Val it_count: 1107 || Current Learning Rate: 0.0001 || Time: 05:26:2.26
Epoch :: 50 || Loss: 0.40712335 || it_count: 8344 || Val Loss: 0.41946168 || Val it_count: 1107 || Current Learning Rate: 0.0001 || Time: 05:32:41.86
Epoch :: 51 || Loss: 0.40705641 || it_count: 8344 || Val Loss: 0.41949468 || Val it_count: 1107 || Current Learning Rate: 0.0001 || Time: 05:39:19.74
Epoch :: 52 || Loss: 0.40692046 || it_count: 8344 || Val Loss: 0.41931081 || Val it_count: 1107 || Current Learning Rate: 0.0001 || Time: 05:45:59.05
Epoch 00037: reducing learning rate of group 0 to 1.0000e-05.
Epoch :: 53 || Loss: 0.40688619 || it_count: 8344 || Val Loss: 0.41975112 || Val it_count: 1107 || Current Learning Rate: 1e-05 || Time: 05:52:40.11
Epoch :: 54 || Loss: 0.40950217 || it_count: 8344 || Val Loss: 0.41210786 || Val it_count: 1107 || Current Learning Rate: 1e-05 || Time: 05:59:18.35
Epoch :: 55 || Loss: 0.40840593 || it_count: 8344 || Val Loss: 0.41182220 || Val it_count: 1107 || Current Learning Rate: 1e-05 || Time: 06:05:57.46
Epoch :: 56 || Loss: 0.40813725 || it_count: 8344 || Val Loss: 0.41173875 || Val it_count: 1107 || Current Learning Rate: 1e-05 || Time: 06:12:37.90
Epoch :: 57 || Loss: 0.40805279 || it_count: 8344 || Val Loss: 0.41160021 || Val it_count: 1107 || Current Learning Rate: 1e-05 || Time: 06:19:17.53
Epoch :: 58 || Loss: 0.40794669 || it_count: 8344 || Val Loss: 0.41157842 || Val it_count: 1107 || Current Learning Rate: 1e-05 || Time: 06:25:56.03
Epoch :: 59 || Loss: 0.40797237 || it_count: 8344 || Val Loss: 0.41154094 || Val it_count: 1107 || Current Learning Rate: 1e-05 || Time: 06:32:35.30
Epoch :: 60 || Loss: 0.40786508 || it_count: 8344 || Val Loss: 0.41142712 || Val it_count: 1107 || Current Learning Rate: 1e-05 || Time: 06:39:15.16
Epoch :: 61 || Loss: 0.40777061 || it_count: 8344 || Val Loss: 0.41144812 || Val it_count: 1107 || Current Learning Rate: 1e-05 || Time: 06:45:54.61
Epoch :: 62 || Loss: 0.40776812 || it_count: 8344 || Val Loss: 0.41134974 || Val it_count: 1107 || Current Learning Rate: 1e-05 || Time: 06:52:35.11
Epoch :: 63 || Loss: 0.40771821 || it_count: 8344 || Val Loss: 0.41138034 || Val it_count: 1107 || Current Learning Rate: 1e-05 || Time: 06:59:14.90
Epoch :: 64 || Loss: 0.40764415 || it_count: 8344 || Val Loss: 0.41130300 || Val it_count: 1107 || Current Learning Rate: 1e-05 || Time: 07:05:54.54
Epoch :: 65 || Loss: 0.40761536 || it_count: 8344 || Val Loss: 0.41128167 || Val it_count: 1107 || Current Learning Rate: 1e-05 || Time: 07:12:34.77
Epoch :: 66 || Loss: 0.40762098 || it_count: 8344 || Val Loss: 0.41131842 || Val it_count: 1107 || Current Learning Rate: 1e-05 || Time: 07:19:13.04
Epoch :: 67 || Loss: 0.40765090 || it_count: 8344 || Val Loss: 0.41129342 || Val it_count: 1107 || Current Learning Rate: 1e-05 || Time: 07:25:54.45
Epoch :: 68 || Loss: 0.40753745 || it_count: 8344 || Val Loss: 0.41121743 || Val it_count: 1107 || Current Learning Rate: 1e-05 || Time: 07:32:33.40
Epoch :: 69 || Loss: 0.40756779 || it_count: 8344 || Val Loss: 0.41122939 || Val it_count: 1107 || Current Learning Rate: 1e-05 || Time: 07:39:12.66
Epoch :: 70 || Loss: 0.40747122 || it_count: 8344 || Val Loss: 0.41119675 || Val it_count: 1107 || Current Learning Rate: 1e-05 || Time: 07:45:52.84
Epoch :: 71 || Loss: 0.40749049 || it_count: 8344 || Val Loss: 0.41119105 || Val it_count: 1107 || Current Learning Rate: 1e-05 || Time: 07:52:31.86
Epoch :: 72 || Loss: 0.40748962 || it_count: 8344 || Val Loss: 0.41116142 || Val it_count: 1107 || Current Learning Rate: 1e-05 || Time: 07:59:10.71
Epoch :: 73 || Loss: 0.40740789 || it_count: 8344 || Val Loss: 0.41112710 || Val it_count: 1107 || Current Learning Rate: 1e-05 || Time: 08:05:43.95
Epoch :: 74 || Loss: 0.40745177 || it_count: 8344 || Val Loss: 0.41114285 || Val it_count: 1107 || Current Learning Rate: 1e-05 || Time: 08:12:10.65
Epoch :: 75 || Loss: 0.40736701 || it_count: 8344 || Val Loss: 0.41105115 || Val it_count: 1107 || Current Learning Rate: 1e-05 || Time: 08:18:38.15
Epoch :: 76 || Loss: 0.40730881 || it_count: 8344 || Val Loss: 0.41110494 || Val it_count: 1107 || Current Learning Rate: 1e-05 || Time: 08:25:5.65
Epoch :: 77 || Loss: 0.40728630 || it_count: 8344 || Val Loss: 0.41102872 || Val it_count: 1107 || Current Learning Rate: 1e-05 || Time: 08:31:32.29
Epoch :: 78 || Loss: 0.40728386 || it_count: 8344 || Val Loss: 0.41108421 || Val it_count: 1107 || Current Learning Rate: 1e-05 || Time: 08:37:59.90
Epoch :: 79 || Loss: 0.40736952 || it_count: 8344 || Val Loss: 0.41102610 || Val it_count: 1107 || Current Learning Rate: 1e-05 || Time: 08:44:27.63
Epoch :: 80 || Loss: 0.40724166 || it_count: 8344 || Val Loss: 0.41099552 || Val it_count: 1107 || Current Learning Rate: 1e-05 || Time: 08:50:54.38
Epoch :: 81 || Loss: 0.40725828 || it_count: 8344 || Val Loss: 0.41096645 || Val it_count: 1107 || Current Learning Rate: 1e-05 || Time: 08:57:22.40
Epoch :: 82 || Loss: 0.40718812 || it_count: 8344 || Val Loss: 0.41103237 || Val it_count: 1107 || Current Learning Rate: 1e-05 || Time: 09:03:49.85
Epoch :: 83 || Loss: 0.40716804 || it_count: 8344 || Val Loss: 0.41101963 || Val it_count: 1107 || Current Learning Rate: 1e-05 || Time: 09:10:18.25
Epoch :: 84 || Loss: 0.40722018 || it_count: 8344 || Val Loss: 0.41097043 || Val it_count: 1107 || Current Learning Rate: 1e-05 || Time: 09:16:46.92
Epoch :: 85 || Loss: 0.40712844 || it_count: 8344 || Val Loss: 0.41102371 || Val it_count: 1107 || Current Learning Rate: 1e-05 || Time: 09:23:13.80
Epoch 00070: reducing learning rate of group 0 to 1.0000e-06.
Epoch :: 86 || Loss: 0.40713106 || it_count: 8344 || Val Loss: 0.41097996 || Val it_count: 1107 || Current Learning Rate: 1.0000000000000002e-06 || Time: 09:29:42.07
Epoch :: 87 || Loss: 0.40747318 || it_count: 8344 || Val Loss: 0.41061713 || Val it_count: 1107 || Current Learning Rate: 1.0000000000000002e-06 || Time: 09:36:9.97
Epoch :: 88 || Loss: 0.40733994 || it_count: 8344 || Val Loss: 0.41054839 || Val it_count: 1107 || Current Learning Rate: 1.0000000000000002e-06 || Time: 09:42:43.34
Epoch :: 89 || Loss: 0.40728215 || it_count: 8344 || Val Loss: 0.41052267 || Val it_count: 1107 || Current Learning Rate: 1.0000000000000002e-06 || Time: 09:49:21.83
Epoch :: 90 || Loss: 0.40729433 || it_count: 8344 || Val Loss: 0.41050343 || Val it_count: 1107 || Current Learning Rate: 1.0000000000000002e-06 || Time: 09:56:0.73
Epoch :: 91 || Loss: 0.40722277 || it_count: 8344 || Val Loss: 0.41049500 || Val it_count: 1107 || Current Learning Rate: 1.0000000000000002e-06 || Time: 10:02:41.51
Epoch :: 92 || Loss: 0.40725741 || it_count: 8344 || Val Loss: 0.41048800 || Val it_count: 1107 || Current Learning Rate: 1.0000000000000002e-06 || Time: 10:09:20.34
Epoch :: 93 || Loss: 0.40730150 || it_count: 8344 || Val Loss: 0.41048230 || Val it_count: 1107 || Current Learning Rate: 1.0000000000000002e-06 || Time: 10:16:0.09
Epoch :: 94 || Loss: 0.40730365 || it_count: 8344 || Val Loss: 0.41048061 || Val it_count: 1107 || Current Learning Rate: 1.0000000000000002e-06 || Time: 10:22:39.85
Epoch :: 95 || Loss: 0.40724844 || it_count: 8344 || Val Loss: 0.41048059 || Val it_count: 1107 || Current Learning Rate: 1.0000000000000002e-06 || Time: 10:29:19.87
Epoch 00080: reducing learning rate of group 0 to 1.0000e-07.
Early stopping triggered due to learning rate below threshold.
Done Total time: 10:35:58.64
best_loss: 0.4104805867830123

--------------------Testing--------------------

total_samples :: test_dataset = 139200, test_dataloader = 139200
Epoch ::  1 || Loss: 0.23457733 || it_count: 544 || Time: 00:00:19.62
MAE:  0.25191098
MSE:  0.23459257
RMSE:  0.44044936

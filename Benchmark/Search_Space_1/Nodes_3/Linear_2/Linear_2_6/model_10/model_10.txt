--------------------Training--------------------
arch_str :: |lstm_1~0|+|lstm_2~0|skip_connect~1|[dropout->linear->dropout->linear]
model :: 3J
InferCell(
  info :: nodes=3, inC=1, outC=64, [1<-(I0-L0) | 2<-(I0-L1,I1-L2)], genotype_str: lstm_1~0|lstm_2~0|skip_connect~1
  linear_layers: [dropout->linear->dropout->linear]
  (layers): ModuleList(
    (0): LSTM(
      (lstm): LSTM(1, 64, batch_first=True)
    )
    (1): LSTM(
      (lstm): LSTM(1, 64, num_layers=2, batch_first=True)
    )
    (2): Identity()
  )
  (linear_layers): ModuleList(
    (0): Dropout(p=0.1, inplace=False)
    (1): Linear(in_features=3072, out_features=1536, bias=True)
    (2): Dropout(p=0.1, inplace=False)
    (3): Linear(in_features=1536, out_features=1, bias=True)
  )
)
tr_params :: epochs = 100, patience = 20, batch_size = 256, window_size = 48, data_size = 100
Model MACs: 8.038M, Model Params: 4.789M
learning rate scheduling :: (optimizer, mode='min', factor=0.1, patience=5, verbose=True)
total_samples :: train_dataset = 2136000, train_dataloader = 2136000
total_samples :: valid_dataset = 283200, valid_dataloader = 283200
Epoch ::  1 || Loss: 0.42268152 || it_count: 8344 || Val Loss: 0.46271996 || Val it_count: 1107 || Current Learning Rate: 0.001 || Time: 00:03:56.81
Epoch ::  2 || Loss: 0.41863827 || it_count: 8344 || Val Loss: 0.44948382 || Val it_count: 1107 || Current Learning Rate: 0.001 || Time: 00:07:50.50
Epoch ::  3 || Loss: 0.41818032 || it_count: 8344 || Val Loss: 0.45128335 || Val it_count: 1107 || Current Learning Rate: 0.001 || Time: 00:11:46.47
Epoch ::  4 || Loss: 0.41825650 || it_count: 8344 || Val Loss: 0.44984344 || Val it_count: 1107 || Current Learning Rate: 0.001 || Time: 00:15:40.32
Epoch ::  5 || Loss: 0.41822415 || it_count: 8344 || Val Loss: 0.45101647 || Val it_count: 1107 || Current Learning Rate: 0.001 || Time: 00:19:34.07
Epoch ::  6 || Loss: 0.41794639 || it_count: 8344 || Val Loss: 0.44951070 || Val it_count: 1107 || Current Learning Rate: 0.001 || Time: 00:23:28.38
Epoch ::  7 || Loss: 0.41772836 || it_count: 8344 || Val Loss: 0.45008962 || Val it_count: 1107 || Current Learning Rate: 0.001 || Time: 00:27:23.46
Epoch ::  8 || Loss: 0.41767538 || it_count: 8344 || Val Loss: 0.45083439 || Val it_count: 1107 || Current Learning Rate: 0.001 || Time: 00:31:19.62
Epoch ::  9 || Loss: 0.41782329 || it_count: 8344 || Val Loss: 0.45022867 || Val it_count: 1107 || Current Learning Rate: 0.001 || Time: 00:35:15.00
Epoch :: 10 || Loss: 0.41724143 || it_count: 8344 || Val Loss: 0.45048877 || Val it_count: 1107 || Current Learning Rate: 0.001 || Time: 00:39:12.86
Epoch :: 11 || Loss: 0.41735261 || it_count: 8344 || Val Loss: 0.44956593 || Val it_count: 1107 || Current Learning Rate: 0.001 || Time: 00:43:10.05
Epoch :: 12 || Loss: 0.41720870 || it_count: 8344 || Val Loss: 0.44990157 || Val it_count: 1107 || Current Learning Rate: 0.001 || Time: 00:47:6.84
Epoch :: 13 || Loss: 0.41759379 || it_count: 8344 || Val Loss: 0.45005057 || Val it_count: 1107 || Current Learning Rate: 0.001 || Time: 00:51:0.87
Epoch :: 14 || Loss: 0.41760402 || it_count: 8344 || Val Loss: 0.44956691 || Val it_count: 1107 || Current Learning Rate: 0.001 || Time: 00:54:58.73
Epoch :: 15 || Loss: 0.41720855 || it_count: 8344 || Val Loss: 0.44909932 || Val it_count: 1107 || Current Learning Rate: 0.001 || Time: 00:58:58.06
Epoch :: 16 || Loss: 0.41722779 || it_count: 8344 || Val Loss: 0.44943983 || Val it_count: 1107 || Current Learning Rate: 0.001 || Time: 01:02:55.91
Epoch :: 17 || Loss: 0.41728808 || it_count: 8344 || Val Loss: 0.44870668 || Val it_count: 1107 || Current Learning Rate: 0.001 || Time: 01:06:53.29
Epoch :: 18 || Loss: 0.41717390 || it_count: 8344 || Val Loss: 0.44844609 || Val it_count: 1107 || Current Learning Rate: 0.001 || Time: 01:10:51.72
Epoch :: 19 || Loss: 0.41714762 || it_count: 8344 || Val Loss: 0.44843770 || Val it_count: 1107 || Current Learning Rate: 0.001 || Time: 01:14:51.30
Epoch :: 20 || Loss: 0.41707814 || it_count: 8344 || Val Loss: 0.44921429 || Val it_count: 1107 || Current Learning Rate: 0.001 || Time: 01:18:48.73
Epoch :: 21 || Loss: 0.41715418 || it_count: 8344 || Val Loss: 0.44936587 || Val it_count: 1107 || Current Learning Rate: 0.001 || Time: 01:22:44.69
Epoch :: 22 || Loss: 0.41708328 || it_count: 8344 || Val Loss: 0.44896750 || Val it_count: 1107 || Current Learning Rate: 0.001 || Time: 01:26:40.86
Epoch :: 23 || Loss: 0.41667795 || it_count: 8344 || Val Loss: 0.44932568 || Val it_count: 1107 || Current Learning Rate: 0.001 || Time: 01:30:36.88
Epoch :: 24 || Loss: 0.41707404 || it_count: 8344 || Val Loss: 0.44827817 || Val it_count: 1107 || Current Learning Rate: 0.001 || Time: 01:34:34.79
Epoch :: 25 || Loss: 0.41641427 || it_count: 8344 || Val Loss: 0.44658097 || Val it_count: 1107 || Current Learning Rate: 0.001 || Time: 01:38:31.93
Epoch :: 26 || Loss: 0.41650804 || it_count: 8344 || Val Loss: 0.44763666 || Val it_count: 1107 || Current Learning Rate: 0.001 || Time: 01:42:28.66
Epoch :: 27 || Loss: 0.41645843 || it_count: 8344 || Val Loss: 0.44765298 || Val it_count: 1107 || Current Learning Rate: 0.001 || Time: 01:46:27.89
Epoch :: 28 || Loss: 0.41642732 || it_count: 8344 || Val Loss: 0.44745559 || Val it_count: 1107 || Current Learning Rate: 0.001 || Time: 01:50:25.24
Epoch :: 29 || Loss: 0.41654254 || it_count: 8344 || Val Loss: 0.44655487 || Val it_count: 1107 || Current Learning Rate: 0.001 || Time: 01:54:22.68
Epoch :: 30 || Loss: 0.41632483 || it_count: 8344 || Val Loss: 0.44691316 || Val it_count: 1107 || Current Learning Rate: 0.001 || Time: 01:58:20.00
Epoch :: 31 || Loss: 0.41609390 || it_count: 8344 || Val Loss: 0.44722598 || Val it_count: 1107 || Current Learning Rate: 0.0001 || Time: 02:02:16.73
Epoch :: 32 || Loss: 0.42169111 || it_count: 8344 || Val Loss: 0.43653363 || Val it_count: 1107 || Current Learning Rate: 0.0001 || Time: 02:06:15.36
Epoch :: 33 || Loss: 0.41948674 || it_count: 8344 || Val Loss: 0.43562261 || Val it_count: 1107 || Current Learning Rate: 0.0001 || Time: 02:10:12.90
Epoch :: 34 || Loss: 0.41899115 || it_count: 8344 || Val Loss: 0.43369566 || Val it_count: 1107 || Current Learning Rate: 0.0001 || Time: 02:14:11.12
Epoch :: 35 || Loss: 0.41856296 || it_count: 8344 || Val Loss: 0.43372104 || Val it_count: 1107 || Current Learning Rate: 0.0001 || Time: 02:18:9.45
Epoch :: 36 || Loss: 0.41851586 || it_count: 8344 || Val Loss: 0.43223722 || Val it_count: 1107 || Current Learning Rate: 0.0001 || Time: 02:22:9.23
Epoch :: 37 || Loss: 0.41837762 || it_count: 8344 || Val Loss: 0.43213741 || Val it_count: 1107 || Current Learning Rate: 0.0001 || Time: 02:26:8.49
Epoch :: 38 || Loss: 0.41829829 || it_count: 8344 || Val Loss: 0.43201611 || Val it_count: 1107 || Current Learning Rate: 0.0001 || Time: 02:30:0.73
Epoch :: 39 || Loss: 0.41815993 || it_count: 8344 || Val Loss: 0.43312176 || Val it_count: 1107 || Current Learning Rate: 0.0001 || Time: 02:33:59.37
Epoch :: 40 || Loss: 0.41807743 || it_count: 8344 || Val Loss: 0.43250392 || Val it_count: 1107 || Current Learning Rate: 0.0001 || Time: 02:37:58.70
Epoch :: 41 || Loss: 0.41805056 || it_count: 8344 || Val Loss: 0.43422554 || Val it_count: 1107 || Current Learning Rate: 0.0001 || Time: 02:41:56.29
Epoch :: 42 || Loss: 0.41796079 || it_count: 8344 || Val Loss: 0.43293200 || Val it_count: 1107 || Current Learning Rate: 0.0001 || Time: 02:45:52.93
Epoch :: 43 || Loss: 0.41796924 || it_count: 8344 || Val Loss: 0.43124595 || Val it_count: 1107 || Current Learning Rate: 0.0001 || Time: 02:49:49.25
Epoch :: 44 || Loss: 0.41773050 || it_count: 8344 || Val Loss: 0.43106063 || Val it_count: 1107 || Current Learning Rate: 0.0001 || Time: 02:53:47.46
Epoch :: 45 || Loss: 0.41769728 || it_count: 8344 || Val Loss: 0.43997010 || Val it_count: 1107 || Current Learning Rate: 0.0001 || Time: 02:57:45.69
Epoch :: 46 || Loss: 0.41936351 || it_count: 8344 || Val Loss: 0.43438461 || Val it_count: 1107 || Current Learning Rate: 0.0001 || Time: 03:01:42.92
Epoch :: 47 || Loss: 0.41772684 || it_count: 8344 || Val Loss: 0.43300313 || Val it_count: 1107 || Current Learning Rate: 0.0001 || Time: 03:05:39.00
Epoch :: 48 || Loss: 0.41756216 || it_count: 8344 || Val Loss: 0.43221364 || Val it_count: 1107 || Current Learning Rate: 0.0001 || Time: 03:09:35.40
Epoch :: 49 || Loss: 0.41758438 || it_count: 8344 || Val Loss: 0.43150897 || Val it_count: 1107 || Current Learning Rate: 0.0001 || Time: 03:13:36.08
Epoch :: 50 || Loss: 0.41733559 || it_count: 8344 || Val Loss: 0.43243094 || Val it_count: 1107 || Current Learning Rate: 1e-05 || Time: 03:17:32.00
Epoch :: 51 || Loss: 0.42032005 || it_count: 8344 || Val Loss: 0.42128275 || Val it_count: 1107 || Current Learning Rate: 1e-05 || Time: 03:21:28.93
Epoch :: 52 || Loss: 0.41885778 || it_count: 8344 || Val Loss: 0.42069535 || Val it_count: 1107 || Current Learning Rate: 1e-05 || Time: 03:25:27.35
Epoch :: 53 || Loss: 0.41876169 || it_count: 8344 || Val Loss: 0.42057194 || Val it_count: 1107 || Current Learning Rate: 1e-05 || Time: 03:29:26.60
Epoch :: 54 || Loss: 0.41854694 || it_count: 8344 || Val Loss: 0.42055141 || Val it_count: 1107 || Current Learning Rate: 1e-05 || Time: 03:33:23.62
Epoch :: 55 || Loss: 0.41841089 || it_count: 8344 || Val Loss: 0.42041751 || Val it_count: 1107 || Current Learning Rate: 1e-05 || Time: 03:37:21.09
Epoch :: 56 || Loss: 0.41839175 || it_count: 8344 || Val Loss: 0.42034818 || Val it_count: 1107 || Current Learning Rate: 1e-05 || Time: 03:41:20.17
Epoch :: 57 || Loss: 0.41842680 || it_count: 8344 || Val Loss: 0.42036709 || Val it_count: 1107 || Current Learning Rate: 1e-05 || Time: 03:45:18.35
Epoch :: 58 || Loss: 0.41829469 || it_count: 8344 || Val Loss: 0.42039536 || Val it_count: 1107 || Current Learning Rate: 1e-05 || Time: 03:49:16.91
Epoch :: 59 || Loss: 0.41828626 || it_count: 8344 || Val Loss: 0.42033423 || Val it_count: 1107 || Current Learning Rate: 1e-05 || Time: 03:53:14.19
Epoch :: 60 || Loss: 0.41825519 || it_count: 8344 || Val Loss: 0.42031475 || Val it_count: 1107 || Current Learning Rate: 1e-05 || Time: 03:57:10.90
Epoch :: 61 || Loss: 0.41828053 || it_count: 8344 || Val Loss: 0.42039553 || Val it_count: 1107 || Current Learning Rate: 1e-05 || Time: 04:01:10.80
Epoch :: 62 || Loss: 0.41819885 || it_count: 8344 || Val Loss: 0.42033880 || Val it_count: 1107 || Current Learning Rate: 1.0000000000000002e-06 || Time: 04:05:9.49
Epoch :: 63 || Loss: 0.41837518 || it_count: 8344 || Val Loss: 0.41977070 || Val it_count: 1107 || Current Learning Rate: 1.0000000000000002e-06 || Time: 04:09:6.73
Epoch :: 64 || Loss: 0.41834014 || it_count: 8344 || Val Loss: 0.41975624 || Val it_count: 1107 || Current Learning Rate: 1.0000000000000002e-06 || Time: 04:13:4.74
Epoch :: 65 || Loss: 0.41836399 || it_count: 8344 || Val Loss: 0.41975167 || Val it_count: 1107 || Current Learning Rate: 1.0000000000000002e-06 || Time: 04:17:3.13
Epoch :: 66 || Loss: 0.41833847 || it_count: 8344 || Val Loss: 0.41974376 || Val it_count: 1107 || Current Learning Rate: 1.0000000000000002e-06 || Time: 04:21:2.13
Epoch :: 67 || Loss: 0.41834370 || it_count: 8344 || Val Loss: 0.41973938 || Val it_count: 1107 || Current Learning Rate: 1.0000000000000002e-06 || Time: 04:24:58.41
Epoch :: 68 || Loss: 0.41836063 || it_count: 8344 || Val Loss: 0.41973390 || Val it_count: 1107 || Current Learning Rate: 1.0000000000000002e-06 || Time: 04:28:54.48
Early stopping triggered due to learning rate below threshold.
Done Total time: 04:32:53.42
best_loss: 0.4197339032452428

--------------------Testing--------------------

total_samples :: test_dataset = 139200, test_dataloader = 139200
Epoch ::  1 || Loss: 0.24772945 || it_count: 544 || Time: 00:00:12.82
MAE:  0.26141292
MSE:  0.24775292
RMSE:  0.45056522

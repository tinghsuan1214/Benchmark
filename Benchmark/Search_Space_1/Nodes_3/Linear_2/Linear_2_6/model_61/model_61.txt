--------------------Training--------------------
arch_str :: |lstm_3~0|+|lstm_3~0|lstm_1~1|[dropout->linear->dropout->linear]
model :: 3J
InferCell(
  info :: nodes=3, inC=1, outC=64, [1<-(I0-L0) | 2<-(I0-L1,I1-L2)], genotype_str: lstm_3~0|lstm_3~0|lstm_1~1
  linear_layers: [dropout->linear->dropout->linear]
  (layers): ModuleList(
    (0-1): 2 x LSTM(
      (lstm): LSTM(1, 64, num_layers=3, batch_first=True)
    )
    (2): LSTM(
      (lstm): LSTM(64, 64, batch_first=True)
    )
  )
  (linear_layers): ModuleList(
    (0): Dropout(p=0.1, inplace=False)
    (1): Linear(in_features=3072, out_features=1536, bias=True)
    (2): Dropout(p=0.1, inplace=False)
    (3): Linear(in_features=1536, out_features=1, bias=True)
  )
)
tr_params :: epochs = 100, patience = 20, batch_size = 256, window_size = 48, data_size = 100
Model MACs: 14.526M, Model Params: 4.922M
learning rate scheduling :: (optimizer, mode='min', factor=0.1, patience=5, verbose=True)
total_samples :: train_dataset = 2136000, train_dataloader = 2136000
total_samples :: valid_dataset = 283200, valid_dataloader = 283200
Epoch ::  1 || Loss: 0.42713749 || it_count: 8344 || Val Loss: 0.47498152 || Val it_count: 1107 || Current Learning Rate: 0.001 || Time: 00:05:11.98
Epoch ::  2 || Loss: 0.41868885 || it_count: 8344 || Val Loss: 0.45082111 || Val it_count: 1107 || Current Learning Rate: 0.001 || Time: 00:10:14.50
Epoch ::  3 || Loss: 0.41798312 || it_count: 8344 || Val Loss: 0.44915586 || Val it_count: 1107 || Current Learning Rate: 0.001 || Time: 00:15:22.07
Epoch ::  4 || Loss: 0.41741188 || it_count: 8344 || Val Loss: 0.45127906 || Val it_count: 1107 || Current Learning Rate: 0.001 || Time: 00:22:29.49
Epoch ::  5 || Loss: 0.41736814 || it_count: 8344 || Val Loss: 0.45196455 || Val it_count: 1107 || Current Learning Rate: 0.001 || Time: 00:30:5.98
Epoch ::  6 || Loss: 0.41655394 || it_count: 8344 || Val Loss: 0.45126705 || Val it_count: 1107 || Current Learning Rate: 0.001 || Time: 00:36:28.88
Epoch ::  7 || Loss: 0.41671566 || it_count: 8344 || Val Loss: 0.45206125 || Val it_count: 1107 || Current Learning Rate: 0.001 || Time: 00:41:45.21
Epoch ::  8 || Loss: 0.41635198 || it_count: 8344 || Val Loss: 0.45099176 || Val it_count: 1107 || Current Learning Rate: 0.001 || Time: 00:47:17.18
Epoch ::  9 || Loss: 0.41622906 || it_count: 8344 || Val Loss: 0.45075960 || Val it_count: 1107 || Current Learning Rate: 0.001 || Time: 00:52:27.00
Epoch :: 10 || Loss: 0.41602451 || it_count: 8344 || Val Loss: 0.45096009 || Val it_count: 1107 || Current Learning Rate: 0.001 || Time: 00:58:34.13
Epoch :: 11 || Loss: 0.41600162 || it_count: 8344 || Val Loss: 0.44974812 || Val it_count: 1107 || Current Learning Rate: 0.001 || Time: 01:04:47.46
Epoch :: 12 || Loss: 0.41561518 || it_count: 8344 || Val Loss: 0.44991513 || Val it_count: 1107 || Current Learning Rate: 0.001 || Time: 01:11:2.16
Epoch :: 13 || Loss: 0.41474074 || it_count: 8344 || Val Loss: 0.45033762 || Val it_count: 1107 || Current Learning Rate: 0.001 || Time: 01:17:13.34
Epoch :: 14 || Loss: 0.41363408 || it_count: 8344 || Val Loss: 0.44910764 || Val it_count: 1107 || Current Learning Rate: 0.001 || Time: 01:23:27.61
Epoch :: 15 || Loss: 0.41333309 || it_count: 8344 || Val Loss: 0.45006999 || Val it_count: 1107 || Current Learning Rate: 0.001 || Time: 01:29:58.33
Epoch :: 16 || Loss: 0.41296552 || it_count: 8344 || Val Loss: 0.44895153 || Val it_count: 1107 || Current Learning Rate: 0.001 || Time: 01:36:32.26
Epoch :: 17 || Loss: 0.41255810 || it_count: 8344 || Val Loss: 0.44912630 || Val it_count: 1107 || Current Learning Rate: 0.001 || Time: 01:43:5.11
Epoch :: 18 || Loss: 0.41240147 || it_count: 8344 || Val Loss: 0.44907237 || Val it_count: 1107 || Current Learning Rate: 0.001 || Time: 01:49:38.02
Epoch :: 19 || Loss: 0.41246180 || it_count: 8344 || Val Loss: 0.44918039 || Val it_count: 1107 || Current Learning Rate: 0.001 || Time: 01:56:12.33
Epoch :: 20 || Loss: 0.41187704 || it_count: 8344 || Val Loss: 0.44816695 || Val it_count: 1107 || Current Learning Rate: 0.001 || Time: 02:02:46.43
Epoch :: 21 || Loss: 0.41136335 || it_count: 8344 || Val Loss: 0.44770065 || Val it_count: 1107 || Current Learning Rate: 0.001 || Time: 02:09:21.26
Epoch :: 22 || Loss: 0.41089087 || it_count: 8344 || Val Loss: 0.44759232 || Val it_count: 1107 || Current Learning Rate: 0.001 || Time: 02:15:53.98
Epoch :: 23 || Loss: 0.41041747 || it_count: 8344 || Val Loss: 0.44593073 || Val it_count: 1107 || Current Learning Rate: 0.001 || Time: 02:22:27.04
Epoch :: 24 || Loss: 0.41029814 || it_count: 8344 || Val Loss: 0.44751993 || Val it_count: 1107 || Current Learning Rate: 0.001 || Time: 02:28:52.05
Epoch :: 25 || Loss: 0.41015535 || it_count: 8344 || Val Loss: 0.44871121 || Val it_count: 1107 || Current Learning Rate: 0.001 || Time: 02:35:13.71
Epoch :: 26 || Loss: 0.40961343 || it_count: 8344 || Val Loss: 0.44887766 || Val it_count: 1107 || Current Learning Rate: 0.001 || Time: 02:41:34.08
Epoch :: 27 || Loss: 0.40925159 || it_count: 8344 || Val Loss: 0.44964999 || Val it_count: 1107 || Current Learning Rate: 0.001 || Time: 02:47:56.63
Epoch :: 28 || Loss: 0.40866910 || it_count: 8344 || Val Loss: 0.44935912 || Val it_count: 1107 || Current Learning Rate: 0.001 || Time: 02:54:16.75
Epoch :: 29 || Loss: 0.40814485 || it_count: 8344 || Val Loss: 0.44907649 || Val it_count: 1107 || Current Learning Rate: 0.0001 || Time: 03:00:38.60
Epoch :: 30 || Loss: 0.41469973 || it_count: 8344 || Val Loss: 0.43021316 || Val it_count: 1107 || Current Learning Rate: 0.0001 || Time: 03:06:59.06
Epoch :: 31 || Loss: 0.41123961 || it_count: 8344 || Val Loss: 0.42866112 || Val it_count: 1107 || Current Learning Rate: 0.0001 || Time: 03:13:22.71
Epoch :: 32 || Loss: 0.41015487 || it_count: 8344 || Val Loss: 0.42775977 || Val it_count: 1107 || Current Learning Rate: 0.0001 || Time: 03:19:54.96
Epoch :: 33 || Loss: 0.40961737 || it_count: 8344 || Val Loss: 0.42709276 || Val it_count: 1107 || Current Learning Rate: 0.0001 || Time: 03:26:26.48
Epoch :: 34 || Loss: 0.40914669 || it_count: 8344 || Val Loss: 0.42677095 || Val it_count: 1107 || Current Learning Rate: 0.0001 || Time: 03:32:55.70
Epoch :: 35 || Loss: 0.40881559 || it_count: 8344 || Val Loss: 0.42590761 || Val it_count: 1107 || Current Learning Rate: 0.0001 || Time: 03:39:32.45
Epoch :: 36 || Loss: 0.40844867 || it_count: 8344 || Val Loss: 0.42573688 || Val it_count: 1107 || Current Learning Rate: 0.0001 || Time: 03:46:8.46
Epoch :: 37 || Loss: 0.40815160 || it_count: 8344 || Val Loss: 0.42565573 || Val it_count: 1107 || Current Learning Rate: 0.0001 || Time: 03:52:45.63
Epoch :: 38 || Loss: 0.40789972 || it_count: 8344 || Val Loss: 0.42529966 || Val it_count: 1107 || Current Learning Rate: 0.0001 || Time: 03:59:24.04
Epoch :: 39 || Loss: 0.40756146 || it_count: 8344 || Val Loss: 0.42486230 || Val it_count: 1107 || Current Learning Rate: 0.0001 || Time: 04:05:42.38
Epoch :: 40 || Loss: 0.40727638 || it_count: 8344 || Val Loss: 0.42488666 || Val it_count: 1107 || Current Learning Rate: 0.0001 || Time: 04:12:2.95
Epoch :: 41 || Loss: 0.40698775 || it_count: 8344 || Val Loss: 0.42488337 || Val it_count: 1107 || Current Learning Rate: 0.0001 || Time: 04:18:25.57
Epoch :: 42 || Loss: 0.40677315 || it_count: 8344 || Val Loss: 0.42478492 || Val it_count: 1107 || Current Learning Rate: 0.0001 || Time: 04:24:41.86
Epoch :: 43 || Loss: 0.40653609 || it_count: 8344 || Val Loss: 0.42445639 || Val it_count: 1107 || Current Learning Rate: 0.0001 || Time: 04:31:0.59
Epoch :: 44 || Loss: 0.40631602 || it_count: 8344 || Val Loss: 0.42479445 || Val it_count: 1107 || Current Learning Rate: 0.0001 || Time: 04:37:19.72
Epoch :: 45 || Loss: 0.40609878 || it_count: 8344 || Val Loss: 0.42427187 || Val it_count: 1107 || Current Learning Rate: 0.0001 || Time: 04:43:40.33
Epoch :: 46 || Loss: 0.40599997 || it_count: 8344 || Val Loss: 0.42467573 || Val it_count: 1107 || Current Learning Rate: 0.0001 || Time: 04:50:1.58
Epoch :: 47 || Loss: 0.40577067 || it_count: 8344 || Val Loss: 0.42492261 || Val it_count: 1107 || Current Learning Rate: 0.0001 || Time: 04:56:20.63
Epoch :: 48 || Loss: 0.40563788 || it_count: 8344 || Val Loss: 0.42555647 || Val it_count: 1107 || Current Learning Rate: 0.0001 || Time: 05:02:41.90
Epoch :: 49 || Loss: 0.40536650 || it_count: 8344 || Val Loss: 0.42460415 || Val it_count: 1107 || Current Learning Rate: 0.0001 || Time: 05:09:2.64
Epoch :: 50 || Loss: 0.40519531 || it_count: 8344 || Val Loss: 0.42503854 || Val it_count: 1107 || Current Learning Rate: 0.0001 || Time: 05:15:23.55
Epoch :: 51 || Loss: 0.40499119 || it_count: 8344 || Val Loss: 0.42636360 || Val it_count: 1107 || Current Learning Rate: 1e-05 || Time: 05:21:49.73
Epoch :: 52 || Loss: 0.40955440 || it_count: 8344 || Val Loss: 0.41336760 || Val it_count: 1107 || Current Learning Rate: 1e-05 || Time: 05:28:10.52
Epoch :: 53 || Loss: 0.40733155 || it_count: 8344 || Val Loss: 0.41333962 || Val it_count: 1107 || Current Learning Rate: 1e-05 || Time: 05:34:30.79
Epoch :: 54 || Loss: 0.40713693 || it_count: 8344 || Val Loss: 0.41340666 || Val it_count: 1107 || Current Learning Rate: 1e-05 || Time: 05:40:50.53
Epoch :: 55 || Loss: 0.40701143 || it_count: 8344 || Val Loss: 0.41348907 || Val it_count: 1107 || Current Learning Rate: 1e-05 || Time: 05:47:12.33
Epoch :: 56 || Loss: 0.40685373 || it_count: 8344 || Val Loss: 0.41347259 || Val it_count: 1107 || Current Learning Rate: 1e-05 || Time: 05:53:31.37
Epoch :: 57 || Loss: 0.40678386 || it_count: 8344 || Val Loss: 0.41344866 || Val it_count: 1107 || Current Learning Rate: 1e-05 || Time: 05:59:53.92
Epoch :: 58 || Loss: 0.40671079 || it_count: 8344 || Val Loss: 0.41347157 || Val it_count: 1107 || Current Learning Rate: 1.0000000000000002e-06 || Time: 06:06:2.48
Epoch :: 59 || Loss: 0.40711253 || it_count: 8344 || Val Loss: 0.41237498 || Val it_count: 1107 || Current Learning Rate: 1.0000000000000002e-06 || Time: 06:11:59.94
Epoch :: 60 || Loss: 0.40687437 || it_count: 8344 || Val Loss: 0.41228406 || Val it_count: 1107 || Current Learning Rate: 1.0000000000000002e-06 || Time: 06:17:58.90
Epoch :: 61 || Loss: 0.40683316 || it_count: 8344 || Val Loss: 0.41227686 || Val it_count: 1107 || Current Learning Rate: 1.0000000000000002e-06 || Time: 06:23:55.59
Epoch :: 62 || Loss: 0.40689138 || it_count: 8344 || Val Loss: 0.41230001 || Val it_count: 1107 || Current Learning Rate: 1.0000000000000002e-06 || Time: 06:29:56.10
Epoch :: 63 || Loss: 0.40682384 || it_count: 8344 || Val Loss: 0.41228958 || Val it_count: 1107 || Current Learning Rate: 1.0000000000000002e-06 || Time: 06:35:50.67
Epoch :: 64 || Loss: 0.40683421 || it_count: 8344 || Val Loss: 0.41227180 || Val it_count: 1107 || Current Learning Rate: 1.0000000000000002e-06 || Time: 06:41:44.70
Epoch :: 65 || Loss: 0.40682995 || it_count: 8344 || Val Loss: 0.41227397 || Val it_count: 1107 || Current Learning Rate: 1.0000000000000002e-06 || Time: 06:47:40.87
Early stopping triggered due to learning rate below threshold.
Done Total time: 06:53:39.03
best_loss: 0.41227179833427086

--------------------Testing--------------------

total_samples :: test_dataset = 139200, test_dataloader = 139200
Epoch ::  1 || Loss: 0.23478603 || it_count: 544 || Time: 00:00:19.07
MAE:  0.25237063
MSE:  0.23480247
RMSE:  0.44079155

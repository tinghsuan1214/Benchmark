--------------------Training--------------------
arch_str :: |lstm_3~0|+|skip_connect~0|lstm_1~1|[dropout->linear->linear]
model :: 3I
InferCell(
  info :: nodes=3, inC=1, outC=64, [1<-(I0-L0) | 2<-(I0-L1,I1-L2)], genotype_str: lstm_3~0|skip_connect~0|lstm_1~1
  linear_layers: [dropout->linear->linear]
  (layers): ModuleList(
    (0): LSTM(
      (lstm): LSTM(1, 64, num_layers=3, batch_first=True)
    )
    (1): FactorizedReduce(
      C_in=1, C_out=64, stride=1
      (relu): ReLU()
      (conv): Conv1d(1, 64, kernel_size=(1,), stride=(1,), bias=False)
      (bn): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (2): LSTM(
      (lstm): LSTM(64, 64, batch_first=True)
    )
  )
  (linear_layers): ModuleList(
    (0): Dropout(p=0.1, inplace=False)
    (1): Linear(in_features=3072, out_features=1536, bias=True)
    (2): Linear(in_features=1536, out_features=1, bias=True)
  )
)
tr_params :: epochs = 100, patience = 20, batch_size = 256, window_size = 48, data_size = 100
Model MACs: 10.449M, Model Params: 4.839M
learning rate scheduling :: (optimizer, mode='min', factor=0.1, patience=5, verbose=True)
total_samples :: train_dataset = 2136000, train_dataloader = 2136000
total_samples :: valid_dataset = 283200, valid_dataloader = 283200
Epoch ::  1 || Loss: 0.44891994 || it_count: 8344 || Val Loss: 0.48419103 || Val it_count: 1107 || Current Learning Rate: 0.001 || Time: 00:04:26.00
Epoch ::  2 || Loss: 0.41513858 || it_count: 8344 || Val Loss: 0.46822095 || Val it_count: 1107 || Current Learning Rate: 0.001 || Time: 00:08:42.41
Epoch ::  3 || Loss: 0.41246867 || it_count: 8344 || Val Loss: 0.46923430 || Val it_count: 1107 || Current Learning Rate: 0.001 || Time: 00:12:59.03
Epoch ::  4 || Loss: 0.41145513 || it_count: 8344 || Val Loss: 0.47369550 || Val it_count: 1107 || Current Learning Rate: 0.001 || Time: 00:17:14.35
Epoch ::  5 || Loss: 0.41139756 || it_count: 8344 || Val Loss: 0.46952178 || Val it_count: 1107 || Current Learning Rate: 0.001 || Time: 00:21:28.16
Epoch ::  6 || Loss: 0.41124441 || it_count: 8344 || Val Loss: 0.47033465 || Val it_count: 1107 || Current Learning Rate: 0.001 || Time: 00:25:42.71
Epoch ::  7 || Loss: 0.41102156 || it_count: 8344 || Val Loss: 0.46938971 || Val it_count: 1107 || Current Learning Rate: 0.001 || Time: 00:29:56.93
Epoch ::  8 || Loss: 0.41014191 || it_count: 8344 || Val Loss: 0.47336687 || Val it_count: 1107 || Current Learning Rate: 0.001 || Time: 00:34:10.94
Epoch ::  9 || Loss: 0.41007988 || it_count: 8344 || Val Loss: 0.46999151 || Val it_count: 1107 || Current Learning Rate: 0.001 || Time: 00:38:24.35
Epoch :: 10 || Loss: 0.40978053 || it_count: 8344 || Val Loss: 0.47429272 || Val it_count: 1107 || Current Learning Rate: 0.001 || Time: 00:42:42.09
Epoch :: 11 || Loss: 0.40932680 || it_count: 8344 || Val Loss: 0.46857229 || Val it_count: 1107 || Current Learning Rate: 0.001 || Time: 00:46:58.30
Epoch :: 12 || Loss: 0.40882670 || it_count: 8344 || Val Loss: 0.46988962 || Val it_count: 1107 || Current Learning Rate: 0.001 || Time: 00:51:13.36
Epoch :: 13 || Loss: 0.40862813 || it_count: 8344 || Val Loss: 0.46942958 || Val it_count: 1107 || Current Learning Rate: 0.001 || Time: 00:55:31.83
Epoch :: 14 || Loss: 0.40820750 || it_count: 8344 || Val Loss: 0.47512663 || Val it_count: 1107 || Current Learning Rate: 0.001 || Time: 00:59:50.93
Epoch :: 15 || Loss: 0.40822686 || it_count: 8344 || Val Loss: 0.47089655 || Val it_count: 1107 || Current Learning Rate: 0.001 || Time: 01:04:7.51
Epoch :: 16 || Loss: 0.40714694 || it_count: 8344 || Val Loss: 0.47414914 || Val it_count: 1107 || Current Learning Rate: 0.001 || Time: 01:08:22.48
Epoch :: 17 || Loss: 0.40698342 || it_count: 8344 || Val Loss: 0.47036165 || Val it_count: 1107 || Current Learning Rate: 0.001 || Time: 01:12:40.15
Epoch :: 18 || Loss: 0.40640207 || it_count: 8344 || Val Loss: 0.47704076 || Val it_count: 1107 || Current Learning Rate: 0.001 || Time: 01:16:56.66
Epoch :: 19 || Loss: 0.40644996 || it_count: 8344 || Val Loss: 0.47300203 || Val it_count: 1107 || Current Learning Rate: 0.001 || Time: 01:21:14.38
Epoch :: 20 || Loss: 0.40598180 || it_count: 8344 || Val Loss: 0.46616294 || Val it_count: 1107 || Current Learning Rate: 0.001 || Time: 01:25:34.33
Epoch :: 21 || Loss: 0.40505785 || it_count: 8344 || Val Loss: 0.46872996 || Val it_count: 1107 || Current Learning Rate: 0.001 || Time: 01:29:53.29
Epoch :: 22 || Loss: 0.40463507 || it_count: 8344 || Val Loss: 0.47138770 || Val it_count: 1107 || Current Learning Rate: 0.001 || Time: 01:34:10.83
Epoch :: 23 || Loss: 0.40426406 || it_count: 8344 || Val Loss: 0.46439831 || Val it_count: 1107 || Current Learning Rate: 0.001 || Time: 01:38:29.70
Epoch :: 24 || Loss: 0.40294650 || it_count: 8344 || Val Loss: 0.47233547 || Val it_count: 1107 || Current Learning Rate: 0.001 || Time: 01:42:49.06
Epoch :: 25 || Loss: 0.40232732 || it_count: 8344 || Val Loss: 0.46968797 || Val it_count: 1107 || Current Learning Rate: 0.001 || Time: 01:47:6.15
Epoch :: 26 || Loss: 0.40188132 || it_count: 8344 || Val Loss: 0.46672004 || Val it_count: 1107 || Current Learning Rate: 0.001 || Time: 01:51:21.43
Epoch :: 27 || Loss: 0.40090699 || it_count: 8344 || Val Loss: 0.46847320 || Val it_count: 1107 || Current Learning Rate: 0.001 || Time: 01:55:37.93
Epoch :: 28 || Loss: 0.40052156 || it_count: 8344 || Val Loss: 0.46735902 || Val it_count: 1107 || Current Learning Rate: 0.001 || Time: 01:59:56.31
Epoch :: 29 || Loss: 0.39953134 || it_count: 8344 || Val Loss: 0.46817144 || Val it_count: 1107 || Current Learning Rate: 0.0001 || Time: 02:04:14.77
Epoch :: 30 || Loss: 0.40943957 || it_count: 8344 || Val Loss: 0.45790334 || Val it_count: 1107 || Current Learning Rate: 0.0001 || Time: 02:08:33.36
Epoch :: 31 || Loss: 0.40627220 || it_count: 8344 || Val Loss: 0.45706001 || Val it_count: 1107 || Current Learning Rate: 0.0001 || Time: 02:12:52.54
Epoch :: 32 || Loss: 0.40498930 || it_count: 8344 || Val Loss: 0.45805675 || Val it_count: 1107 || Current Learning Rate: 0.0001 || Time: 02:17:11.77
Epoch :: 33 || Loss: 0.40402275 || it_count: 8344 || Val Loss: 0.45832571 || Val it_count: 1107 || Current Learning Rate: 0.0001 || Time: 02:21:29.91
Epoch :: 34 || Loss: 0.40330393 || it_count: 8344 || Val Loss: 0.45715625 || Val it_count: 1107 || Current Learning Rate: 0.0001 || Time: 02:25:48.74
Epoch :: 35 || Loss: 0.40260191 || it_count: 8344 || Val Loss: 0.45916914 || Val it_count: 1107 || Current Learning Rate: 0.0001 || Time: 02:30:7.15
Epoch :: 36 || Loss: 0.40203657 || it_count: 8344 || Val Loss: 0.46061539 || Val it_count: 1107 || Current Learning Rate: 0.0001 || Time: 02:34:26.62
Epoch :: 37 || Loss: 0.40153979 || it_count: 8344 || Val Loss: 0.45802682 || Val it_count: 1107 || Current Learning Rate: 1e-05 || Time: 02:38:44.39
Epoch :: 38 || Loss: 0.40823761 || it_count: 8344 || Val Loss: 0.43928153 || Val it_count: 1107 || Current Learning Rate: 1e-05 || Time: 02:43:4.40
Epoch :: 39 || Loss: 0.40520944 || it_count: 8344 || Val Loss: 0.44046712 || Val it_count: 1107 || Current Learning Rate: 1e-05 || Time: 02:47:23.33
Epoch :: 40 || Loss: 0.40475257 || it_count: 8344 || Val Loss: 0.44156354 || Val it_count: 1107 || Current Learning Rate: 1e-05 || Time: 02:51:41.04
Epoch :: 41 || Loss: 0.40449635 || it_count: 8344 || Val Loss: 0.44253551 || Val it_count: 1107 || Current Learning Rate: 1e-05 || Time: 02:56:0.88
Epoch :: 42 || Loss: 0.40426134 || it_count: 8344 || Val Loss: 0.44307358 || Val it_count: 1107 || Current Learning Rate: 1e-05 || Time: 03:00:26.60
Epoch :: 43 || Loss: 0.40416938 || it_count: 8344 || Val Loss: 0.44380255 || Val it_count: 1107 || Current Learning Rate: 1e-05 || Time: 03:05:7.40
Epoch :: 44 || Loss: 0.40403997 || it_count: 8344 || Val Loss: 0.44418183 || Val it_count: 1107 || Current Learning Rate: 1.0000000000000002e-06 || Time: 03:09:46.58
Epoch :: 45 || Loss: 0.40512306 || it_count: 8344 || Val Loss: 0.43880307 || Val it_count: 1107 || Current Learning Rate: 1.0000000000000002e-06 || Time: 03:14:27.28
Epoch :: 46 || Loss: 0.40450808 || it_count: 8344 || Val Loss: 0.43728053 || Val it_count: 1107 || Current Learning Rate: 1.0000000000000002e-06 || Time: 03:19:3.55
Epoch :: 47 || Loss: 0.40428170 || it_count: 8344 || Val Loss: 0.43677027 || Val it_count: 1107 || Current Learning Rate: 1.0000000000000002e-06 || Time: 03:23:42.41
Epoch :: 48 || Loss: 0.40420902 || it_count: 8344 || Val Loss: 0.43661799 || Val it_count: 1107 || Current Learning Rate: 1.0000000000000002e-06 || Time: 03:28:28.35
Epoch :: 49 || Loss: 0.40416980 || it_count: 8344 || Val Loss: 0.43668307 || Val it_count: 1107 || Current Learning Rate: 1.0000000000000002e-06 || Time: 03:33:14.17
Epoch :: 50 || Loss: 0.40413006 || it_count: 8344 || Val Loss: 0.43672595 || Val it_count: 1107 || Current Learning Rate: 1.0000000000000002e-06 || Time: 03:37:50.24
Epoch :: 51 || Loss: 0.40411716 || it_count: 8344 || Val Loss: 0.43679355 || Val it_count: 1107 || Current Learning Rate: 1.0000000000000002e-06 || Time: 03:42:19.58
Epoch :: 52 || Loss: 0.40406509 || it_count: 8344 || Val Loss: 0.43693867 || Val it_count: 1107 || Current Learning Rate: 1.0000000000000002e-06 || Time: 03:46:49.48
Epoch :: 53 || Loss: 0.40411387 || it_count: 8344 || Val Loss: 0.43695544 || Val it_count: 1107 || Current Learning Rate: 1.0000000000000002e-06 || Time: 03:51:18.52
Early stopping triggered due to learning rate below threshold.
Done Total time: 03:55:55.72
best_loss: 0.4366179863425511

--------------------Testing--------------------

total_samples :: test_dataset = 139200, test_dataloader = 139200
Epoch ::  1 || Loss: 0.27873268 || it_count: 544 || Time: 00:00:14.39
MAE:  0.2837575
MSE:  0.27877328
RMSE:  0.4734428

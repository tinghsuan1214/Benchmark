--------------------Training--------------------
arch_str :: |lstm_3~0|+|skip_connect~0|skip_connect~1|[dropout->linear->linear]
model :: 3I
InferCell(
  info :: nodes=3, inC=1, outC=64, [1<-(I0-L0) | 2<-(I0-L1,I1-L2)], genotype_str: lstm_3~0|skip_connect~0|skip_connect~1
  linear_layers: [dropout->linear->linear]
  (layers): ModuleList(
    (0): LSTM(
      (lstm): LSTM(1, 64, num_layers=3, batch_first=True)
    )
    (1): FactorizedReduce(
      C_in=1, C_out=64, stride=1
      (relu): ReLU()
      (conv): Conv1d(1, 64, kernel_size=(1,), stride=(1,), bias=False)
      (bn): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (2): Identity()
  )
  (linear_layers): ModuleList(
    (0): Dropout(p=0.1, inplace=False)
    (1): Linear(in_features=3072, out_features=1536, bias=True)
    (2): Linear(in_features=1536, out_features=1, bias=True)
  )
)
tr_params :: epochs = 100, patience = 20, batch_size = 256, window_size = 48, data_size = 100
Model MACs: 8.827M, Model Params: 4.806M
learning rate scheduling :: (optimizer, mode='min', factor=0.1, patience=5, verbose=True)
total_samples :: train_dataset = 2136000, train_dataloader = 2136000
total_samples :: valid_dataset = 283200, valid_dataloader = 283200
Epoch ::  1 || Loss: 0.44798218 || it_count: 8344 || Val Loss: 0.47185584 || Val it_count: 1107 || Current Learning Rate: 0.001 || Time: 00:04:28.51
Epoch ::  2 || Loss: 0.41458886 || it_count: 8344 || Val Loss: 0.46977352 || Val it_count: 1107 || Current Learning Rate: 0.001 || Time: 00:08:52.17
Epoch ::  3 || Loss: 0.41269446 || it_count: 8344 || Val Loss: 0.46897634 || Val it_count: 1107 || Current Learning Rate: 0.001 || Time: 00:13:16.53
Epoch ::  4 || Loss: 0.41144883 || it_count: 8344 || Val Loss: 0.47318615 || Val it_count: 1107 || Current Learning Rate: 0.001 || Time: 00:17:40.50
Epoch ::  5 || Loss: 0.41055505 || it_count: 8344 || Val Loss: 0.47009710 || Val it_count: 1107 || Current Learning Rate: 0.001 || Time: 00:22:5.11
Epoch ::  6 || Loss: 0.41063386 || it_count: 8344 || Val Loss: 0.47369595 || Val it_count: 1107 || Current Learning Rate: 0.001 || Time: 00:26:30.81
Epoch ::  7 || Loss: 0.41018532 || it_count: 8344 || Val Loss: 0.46726662 || Val it_count: 1107 || Current Learning Rate: 0.001 || Time: 00:30:51.75
Epoch ::  8 || Loss: 0.40969441 || it_count: 8344 || Val Loss: 0.46925008 || Val it_count: 1107 || Current Learning Rate: 0.001 || Time: 00:35:14.55
Epoch ::  9 || Loss: 0.40940250 || it_count: 8344 || Val Loss: 0.46947013 || Val it_count: 1107 || Current Learning Rate: 0.001 || Time: 00:39:39.56
Epoch :: 10 || Loss: 0.40889532 || it_count: 8344 || Val Loss: 0.47002002 || Val it_count: 1107 || Current Learning Rate: 0.001 || Time: 00:44:3.80
Epoch :: 11 || Loss: 0.40851137 || it_count: 8344 || Val Loss: 0.46935635 || Val it_count: 1107 || Current Learning Rate: 0.001 || Time: 00:48:28.83
Epoch :: 12 || Loss: 0.40786024 || it_count: 8344 || Val Loss: 0.47350359 || Val it_count: 1107 || Current Learning Rate: 0.001 || Time: 00:52:54.57
Epoch :: 13 || Loss: 0.40765397 || it_count: 8344 || Val Loss: 0.47058227 || Val it_count: 1107 || Current Learning Rate: 0.001 || Time: 00:57:20.38
Epoch :: 14 || Loss: 0.40749546 || it_count: 8344 || Val Loss: 0.46853629 || Val it_count: 1107 || Current Learning Rate: 0.001 || Time: 01:01:47.19
Epoch :: 15 || Loss: 0.40683770 || it_count: 8344 || Val Loss: 0.47019925 || Val it_count: 1107 || Current Learning Rate: 0.001 || Time: 01:06:1.79
Epoch :: 16 || Loss: 0.40646745 || it_count: 8344 || Val Loss: 0.47225173 || Val it_count: 1107 || Current Learning Rate: 0.001 || Time: 01:10:5.48
Epoch :: 17 || Loss: 0.40581389 || it_count: 8344 || Val Loss: 0.47004991 || Val it_count: 1107 || Current Learning Rate: 0.001 || Time: 01:14:14.91
Epoch :: 18 || Loss: 0.40549312 || it_count: 8344 || Val Loss: 0.46932912 || Val it_count: 1107 || Current Learning Rate: 0.001 || Time: 01:18:24.37
Epoch :: 19 || Loss: 0.40485822 || it_count: 8344 || Val Loss: 0.47325427 || Val it_count: 1107 || Current Learning Rate: 0.001 || Time: 01:22:34.63
Epoch :: 20 || Loss: 0.40422529 || it_count: 8344 || Val Loss: 0.47321900 || Val it_count: 1107 || Current Learning Rate: 0.001 || Time: 01:26:53.74
Epoch :: 21 || Loss: 0.40318068 || it_count: 8344 || Val Loss: 0.47007272 || Val it_count: 1107 || Current Learning Rate: 0.001 || Time: 01:31:21.32
Epoch :: 22 || Loss: 0.40266905 || it_count: 8344 || Val Loss: 0.47588028 || Val it_count: 1107 || Current Learning Rate: 0.001 || Time: 01:35:41.87
Epoch :: 23 || Loss: 0.40194720 || it_count: 8344 || Val Loss: 0.47214890 || Val it_count: 1107 || Current Learning Rate: 0.001 || Time: 01:39:50.39
Epoch :: 24 || Loss: 0.40113492 || it_count: 8344 || Val Loss: 0.47597031 || Val it_count: 1107 || Current Learning Rate: 0.0001 || Time: 01:43:56.10
Epoch :: 25 || Loss: 0.40982157 || it_count: 8344 || Val Loss: 0.45697527 || Val it_count: 1107 || Current Learning Rate: 0.0001 || Time: 01:48:6.85
Epoch :: 26 || Loss: 0.40687505 || it_count: 8344 || Val Loss: 0.45728379 || Val it_count: 1107 || Current Learning Rate: 0.0001 || Time: 01:52:16.76
Epoch :: 27 || Loss: 0.40580979 || it_count: 8344 || Val Loss: 0.45558961 || Val it_count: 1107 || Current Learning Rate: 0.0001 || Time: 01:56:26.74
Epoch :: 28 || Loss: 0.40502463 || it_count: 8344 || Val Loss: 0.45611256 || Val it_count: 1107 || Current Learning Rate: 0.0001 || Time: 02:00:37.59
Epoch :: 29 || Loss: 0.40443826 || it_count: 8344 || Val Loss: 0.45420287 || Val it_count: 1107 || Current Learning Rate: 0.0001 || Time: 02:04:48.37
Epoch :: 30 || Loss: 0.40374768 || it_count: 8344 || Val Loss: 0.45701460 || Val it_count: 1107 || Current Learning Rate: 0.0001 || Time: 02:09:0.34
Epoch :: 31 || Loss: 0.40336900 || it_count: 8344 || Val Loss: 0.45546371 || Val it_count: 1107 || Current Learning Rate: 0.0001 || Time: 02:13:7.73
Epoch :: 32 || Loss: 0.40284879 || it_count: 8344 || Val Loss: 0.45578529 || Val it_count: 1107 || Current Learning Rate: 0.0001 || Time: 02:17:19.41
Epoch :: 33 || Loss: 0.40235368 || it_count: 8344 || Val Loss: 0.45688057 || Val it_count: 1107 || Current Learning Rate: 0.0001 || Time: 02:21:40.66
Epoch :: 34 || Loss: 0.40204393 || it_count: 8344 || Val Loss: 0.45571231 || Val it_count: 1107 || Current Learning Rate: 0.0001 || Time: 02:26:2.63
Epoch :: 35 || Loss: 0.40183742 || it_count: 8344 || Val Loss: 0.45787427 || Val it_count: 1107 || Current Learning Rate: 1e-05 || Time: 02:30:23.41
Epoch :: 36 || Loss: 0.40904026 || it_count: 8344 || Val Loss: 0.44258539 || Val it_count: 1107 || Current Learning Rate: 1e-05 || Time: 02:34:45.27
Epoch :: 37 || Loss: 0.40611437 || it_count: 8344 || Val Loss: 0.44367640 || Val it_count: 1107 || Current Learning Rate: 1e-05 || Time: 02:39:4.42
Epoch :: 38 || Loss: 0.40551489 || it_count: 8344 || Val Loss: 0.44463284 || Val it_count: 1107 || Current Learning Rate: 1e-05 || Time: 02:43:13.69
Epoch :: 39 || Loss: 0.40521010 || it_count: 8344 || Val Loss: 0.44519991 || Val it_count: 1107 || Current Learning Rate: 1e-05 || Time: 02:47:25.93
Epoch :: 40 || Loss: 0.40499979 || it_count: 8344 || Val Loss: 0.44575551 || Val it_count: 1107 || Current Learning Rate: 1e-05 || Time: 02:51:39.60
Epoch :: 41 || Loss: 0.40478246 || it_count: 8344 || Val Loss: 0.44636256 || Val it_count: 1107 || Current Learning Rate: 1e-05 || Time: 02:55:54.94
Epoch :: 42 || Loss: 0.40468831 || it_count: 8344 || Val Loss: 0.44689571 || Val it_count: 1107 || Current Learning Rate: 1.0000000000000002e-06 || Time: 03:00:8.07
Epoch :: 43 || Loss: 0.40603376 || it_count: 8344 || Val Loss: 0.44111514 || Val it_count: 1107 || Current Learning Rate: 1.0000000000000002e-06 || Time: 03:04:21.06
Epoch :: 44 || Loss: 0.40531597 || it_count: 8344 || Val Loss: 0.43963230 || Val it_count: 1107 || Current Learning Rate: 1.0000000000000002e-06 || Time: 03:08:35.47
Epoch :: 45 || Loss: 0.40510395 || it_count: 8344 || Val Loss: 0.43915328 || Val it_count: 1107 || Current Learning Rate: 1.0000000000000002e-06 || Time: 03:12:46.66
Epoch :: 46 || Loss: 0.40497432 || it_count: 8344 || Val Loss: 0.43889652 || Val it_count: 1107 || Current Learning Rate: 1.0000000000000002e-06 || Time: 03:16:54.68
Epoch :: 47 || Loss: 0.40490337 || it_count: 8344 || Val Loss: 0.43878109 || Val it_count: 1107 || Current Learning Rate: 1.0000000000000002e-06 || Time: 03:21:4.20
Epoch :: 48 || Loss: 0.40480620 || it_count: 8344 || Val Loss: 0.43874189 || Val it_count: 1107 || Current Learning Rate: 1.0000000000000002e-06 || Time: 03:25:13.59
Epoch :: 49 || Loss: 0.40477166 || it_count: 8344 || Val Loss: 0.43877262 || Val it_count: 1107 || Current Learning Rate: 1.0000000000000002e-06 || Time: 03:29:23.67
Epoch :: 50 || Loss: 0.40478172 || it_count: 8344 || Val Loss: 0.43873744 || Val it_count: 1107 || Current Learning Rate: 1.0000000000000002e-06 || Time: 03:33:34.69
Epoch :: 51 || Loss: 0.40464766 || it_count: 8344 || Val Loss: 0.43871771 || Val it_count: 1107 || Current Learning Rate: 1.0000000000000002e-06 || Time: 03:37:44.46
Epoch :: 52 || Loss: 0.40466831 || it_count: 8344 || Val Loss: 0.43880115 || Val it_count: 1107 || Current Learning Rate: 1.0000000000000002e-06 || Time: 03:41:53.29
Epoch :: 53 || Loss: 0.40473448 || it_count: 8344 || Val Loss: 0.43882698 || Val it_count: 1107 || Current Learning Rate: 1.0000000000000002e-06 || Time: 03:45:58.37
Epoch :: 54 || Loss: 0.40467610 || it_count: 8344 || Val Loss: 0.43884959 || Val it_count: 1107 || Current Learning Rate: 1.0000000000000002e-06 || Time: 03:50:3.97
Epoch :: 55 || Loss: 0.40465445 || it_count: 8344 || Val Loss: 0.43887497 || Val it_count: 1107 || Current Learning Rate: 1.0000000000000002e-06 || Time: 03:54:4.50
Epoch :: 56 || Loss: 0.40462073 || it_count: 8344 || Val Loss: 0.43895502 || Val it_count: 1107 || Current Learning Rate: 1.0000000000000002e-06 || Time: 03:58:5.93
Early stopping triggered due to learning rate below threshold.
Done Total time: 04:02:7.60
best_loss: 0.438717710608308

--------------------Testing--------------------

total_samples :: test_dataset = 139200, test_dataloader = 139200
Epoch ::  1 || Loss: 0.28224198 || it_count: 544 || Time: 00:00:12.93
MAE:  0.2854645
MSE:  0.2822835
RMSE:  0.4749471

--------------------Training--------------------
arch_str :: |lstm_1~0|+|lstm_3~0|lstm_3~1|[dropout->linear->linear]
model :: 3I
InferCell(
  info :: nodes=3, inC=1, outC=64, [1<-(I0-L0) | 2<-(I0-L1,I1-L2)], genotype_str: lstm_1~0|lstm_3~0|lstm_3~1
  linear_layers: [dropout->linear->linear]
  (layers): ModuleList(
    (0): LSTM(
      (lstm): LSTM(1, 64, batch_first=True)
    )
    (1): LSTM(
      (lstm): LSTM(1, 64, num_layers=3, batch_first=True)
    )
    (2): LSTM(
      (lstm): LSTM(64, 64, num_layers=3, batch_first=True)
    )
  )
  (linear_layers): ModuleList(
    (0): Dropout(p=0.1, inplace=False)
    (1): Linear(in_features=3072, out_features=1536, bias=True)
    (2): Linear(in_features=1536, out_features=1, bias=True)
  )
)
tr_params :: epochs = 100, patience = 20, batch_size = 256, window_size = 48, data_size = 100
Model MACs: 14.526M, Model Params: 4.922M
learning rate scheduling :: (optimizer, mode='min', factor=0.1, patience=5, verbose=True)
total_samples :: train_dataset = 2136000, train_dataloader = 2136000
total_samples :: valid_dataset = 283200, valid_dataloader = 283200
Epoch ::  1 || Loss: 0.42850934 || it_count: 8344 || Val Loss: 0.46766355 || Val it_count: 1107 || Current Learning Rate: 0.001 || Time: 00:05:15.80
Epoch ::  2 || Loss: 0.41865191 || it_count: 8344 || Val Loss: 0.45130134 || Val it_count: 1107 || Current Learning Rate: 0.001 || Time: 00:10:31.56
Epoch ::  3 || Loss: 0.41757735 || it_count: 8344 || Val Loss: 0.45013339 || Val it_count: 1107 || Current Learning Rate: 0.001 || Time: 00:15:49.01
Epoch ::  4 || Loss: 0.41698133 || it_count: 8344 || Val Loss: 0.44995528 || Val it_count: 1107 || Current Learning Rate: 0.001 || Time: 00:21:7.65
Epoch ::  5 || Loss: 0.41661413 || it_count: 8344 || Val Loss: 0.45304893 || Val it_count: 1107 || Current Learning Rate: 0.001 || Time: 00:26:24.35
Epoch ::  6 || Loss: 0.41668353 || it_count: 8344 || Val Loss: 0.45308022 || Val it_count: 1107 || Current Learning Rate: 0.001 || Time: 00:31:29.97
Epoch ::  7 || Loss: 0.41634519 || it_count: 8344 || Val Loss: 0.45215474 || Val it_count: 1107 || Current Learning Rate: 0.001 || Time: 00:36:36.02
Epoch ::  8 || Loss: 0.41588397 || it_count: 8344 || Val Loss: 0.45252355 || Val it_count: 1107 || Current Learning Rate: 0.001 || Time: 00:41:41.51
Epoch ::  9 || Loss: 0.41557024 || it_count: 8344 || Val Loss: 0.45253625 || Val it_count: 1107 || Current Learning Rate: 0.001 || Time: 00:46:45.50
Epoch :: 10 || Loss: 0.41505086 || it_count: 8344 || Val Loss: 0.45264966 || Val it_count: 1107 || Current Learning Rate: 0.001 || Time: 00:51:47.21
Epoch :: 11 || Loss: 0.41548715 || it_count: 8344 || Val Loss: 0.45111375 || Val it_count: 1107 || Current Learning Rate: 0.001 || Time: 00:56:47.55
Epoch :: 12 || Loss: 0.41491878 || it_count: 8344 || Val Loss: 0.45139160 || Val it_count: 1107 || Current Learning Rate: 0.001 || Time: 01:01:53.89
Epoch :: 13 || Loss: 0.41483218 || it_count: 8344 || Val Loss: 0.44943445 || Val it_count: 1107 || Current Learning Rate: 0.001 || Time: 01:06:59.76
Epoch :: 14 || Loss: 0.41458640 || it_count: 8344 || Val Loss: 0.45040570 || Val it_count: 1107 || Current Learning Rate: 0.001 || Time: 01:12:11.01
Epoch :: 15 || Loss: 0.41476225 || it_count: 8344 || Val Loss: 0.44924597 || Val it_count: 1107 || Current Learning Rate: 0.001 || Time: 01:17:23.92
Epoch :: 16 || Loss: 0.41449424 || it_count: 8344 || Val Loss: 0.44896287 || Val it_count: 1107 || Current Learning Rate: 0.001 || Time: 01:22:39.17
Epoch :: 17 || Loss: 0.41330577 || it_count: 8344 || Val Loss: 0.44902870 || Val it_count: 1107 || Current Learning Rate: 0.001 || Time: 01:27:56.17
Epoch :: 18 || Loss: 0.41295354 || it_count: 8344 || Val Loss: 0.44873182 || Val it_count: 1107 || Current Learning Rate: 0.001 || Time: 01:33:11.59
Epoch :: 19 || Loss: 0.41251296 || it_count: 8344 || Val Loss: 0.44904963 || Val it_count: 1107 || Current Learning Rate: 0.001 || Time: 01:38:27.87
Epoch :: 20 || Loss: 0.41252140 || it_count: 8344 || Val Loss: 0.44807514 || Val it_count: 1107 || Current Learning Rate: 0.001 || Time: 01:43:44.66
Epoch :: 21 || Loss: 0.41267864 || it_count: 8344 || Val Loss: 0.44850751 || Val it_count: 1107 || Current Learning Rate: 0.001 || Time: 01:48:59.66
Epoch :: 22 || Loss: 0.41207160 || it_count: 8344 || Val Loss: 0.44632800 || Val it_count: 1107 || Current Learning Rate: 0.001 || Time: 01:54:15.96
Epoch :: 23 || Loss: 0.41163023 || it_count: 8344 || Val Loss: 0.44641365 || Val it_count: 1107 || Current Learning Rate: 0.001 || Time: 01:59:34.42
Epoch :: 24 || Loss: 0.41348161 || it_count: 8344 || Val Loss: 0.44859943 || Val it_count: 1107 || Current Learning Rate: 0.001 || Time: 02:04:54.10
Epoch :: 25 || Loss: 0.41143054 || it_count: 8344 || Val Loss: 0.44670405 || Val it_count: 1107 || Current Learning Rate: 0.001 || Time: 02:17:17.62
Epoch :: 26 || Loss: 0.41123072 || it_count: 8344 || Val Loss: 0.44715838 || Val it_count: 1107 || Current Learning Rate: 0.001 || Time: 02:29:20.14
Epoch :: 27 || Loss: 0.41069626 || it_count: 8344 || Val Loss: 0.44635361 || Val it_count: 1107 || Current Learning Rate: 0.001 || Time: 02:37:1.68
Epoch :: 28 || Loss: 0.41090590 || it_count: 8344 || Val Loss: 0.44608563 || Val it_count: 1107 || Current Learning Rate: 0.001 || Time: 02:42:12.91
Epoch :: 29 || Loss: 0.41084077 || it_count: 8344 || Val Loss: 0.44595765 || Val it_count: 1107 || Current Learning Rate: 0.001 || Time: 02:47:25.73
Epoch :: 30 || Loss: 0.41041852 || it_count: 8344 || Val Loss: 0.44531374 || Val it_count: 1107 || Current Learning Rate: 0.001 || Time: 02:52:37.42
Epoch :: 31 || Loss: 0.41022640 || it_count: 8344 || Val Loss: 0.44608441 || Val it_count: 1107 || Current Learning Rate: 0.001 || Time: 02:57:43.09
Epoch :: 32 || Loss: 0.40964689 || it_count: 8344 || Val Loss: 0.44631456 || Val it_count: 1107 || Current Learning Rate: 0.001 || Time: 03:02:47.29
Epoch :: 33 || Loss: 0.40935771 || it_count: 8344 || Val Loss: 0.44696147 || Val it_count: 1107 || Current Learning Rate: 0.001 || Time: 03:07:54.36
Epoch :: 34 || Loss: 0.40895177 || it_count: 8344 || Val Loss: 0.44519897 || Val it_count: 1107 || Current Learning Rate: 0.001 || Time: 03:13:1.03
Epoch :: 35 || Loss: 0.40871791 || it_count: 8344 || Val Loss: 0.44481894 || Val it_count: 1107 || Current Learning Rate: 0.001 || Time: 03:18:7.87
Epoch :: 36 || Loss: 0.40864316 || it_count: 8344 || Val Loss: 0.44529185 || Val it_count: 1107 || Current Learning Rate: 0.001 || Time: 03:23:14.57
Epoch :: 37 || Loss: 0.40838517 || it_count: 8344 || Val Loss: 0.44455830 || Val it_count: 1107 || Current Learning Rate: 0.001 || Time: 03:28:20.60
Epoch :: 38 || Loss: 0.40825138 || it_count: 8344 || Val Loss: 0.44615783 || Val it_count: 1107 || Current Learning Rate: 0.001 || Time: 03:33:27.66
Epoch :: 39 || Loss: 0.40799980 || it_count: 8344 || Val Loss: 0.44620020 || Val it_count: 1107 || Current Learning Rate: 0.001 || Time: 03:38:31.23
Epoch :: 40 || Loss: 0.40782193 || it_count: 8344 || Val Loss: 0.44469464 || Val it_count: 1107 || Current Learning Rate: 0.001 || Time: 03:43:36.24
Epoch :: 41 || Loss: 0.40750253 || it_count: 8344 || Val Loss: 0.44584356 || Val it_count: 1107 || Current Learning Rate: 0.001 || Time: 03:48:43.52
Epoch :: 42 || Loss: 0.40728908 || it_count: 8344 || Val Loss: 0.44576805 || Val it_count: 1107 || Current Learning Rate: 0.001 || Time: 03:53:49.18
Epoch :: 43 || Loss: 0.40707017 || it_count: 8344 || Val Loss: 0.44470215 || Val it_count: 1107 || Current Learning Rate: 0.0001 || Time: 04:01:8.59
Epoch :: 44 || Loss: 0.41335860 || it_count: 8344 || Val Loss: 0.42767579 || Val it_count: 1107 || Current Learning Rate: 0.0001 || Time: 04:06:15.47
Epoch :: 45 || Loss: 0.41038006 || it_count: 8344 || Val Loss: 0.42570952 || Val it_count: 1107 || Current Learning Rate: 0.0001 || Time: 04:14:16.58
Epoch :: 46 || Loss: 0.40948673 || it_count: 8344 || Val Loss: 0.42499400 || Val it_count: 1107 || Current Learning Rate: 0.0001 || Time: 04:19:47.95
Epoch :: 47 || Loss: 0.40884179 || it_count: 8344 || Val Loss: 0.42449482 || Val it_count: 1107 || Current Learning Rate: 0.0001 || Time: 04:25:40.34
Epoch :: 48 || Loss: 0.40843385 || it_count: 8344 || Val Loss: 0.42406956 || Val it_count: 1107 || Current Learning Rate: 0.0001 || Time: 04:34:53.93
Epoch :: 49 || Loss: 0.40801148 || it_count: 8344 || Val Loss: 0.42360553 || Val it_count: 1107 || Current Learning Rate: 0.0001 || Time: 04:40:20.77
Epoch :: 50 || Loss: 0.40775591 || it_count: 8344 || Val Loss: 0.42345834 || Val it_count: 1107 || Current Learning Rate: 0.0001 || Time: 04:45:45.94
Epoch :: 51 || Loss: 0.40741259 || it_count: 8344 || Val Loss: 0.42319149 || Val it_count: 1107 || Current Learning Rate: 0.0001 || Time: 04:50:59.11
Epoch :: 52 || Loss: 0.40725413 || it_count: 8344 || Val Loss: 0.42287583 || Val it_count: 1107 || Current Learning Rate: 0.0001 || Time: 04:56:22.68
Epoch :: 53 || Loss: 0.40696935 || it_count: 8344 || Val Loss: 0.42289445 || Val it_count: 1107 || Current Learning Rate: 0.0001 || Time: 05:01:45.35
Epoch :: 54 || Loss: 0.40687087 || it_count: 8344 || Val Loss: 0.42276961 || Val it_count: 1107 || Current Learning Rate: 0.0001 || Time: 05:06:54.63
Epoch :: 55 || Loss: 0.40664634 || it_count: 8344 || Val Loss: 0.42251127 || Val it_count: 1107 || Current Learning Rate: 0.0001 || Time: 05:12:8.51
Epoch :: 56 || Loss: 0.40634212 || it_count: 8344 || Val Loss: 0.42282213 || Val it_count: 1107 || Current Learning Rate: 0.0001 || Time: 05:17:25.43
Epoch :: 57 || Loss: 0.40625295 || it_count: 8344 || Val Loss: 0.42300406 || Val it_count: 1107 || Current Learning Rate: 0.0001 || Time: 05:22:47.51
Epoch :: 58 || Loss: 0.40612843 || it_count: 8344 || Val Loss: 0.42311437 || Val it_count: 1107 || Current Learning Rate: 0.0001 || Time: 05:27:51.90
Epoch :: 59 || Loss: 0.40591189 || it_count: 8344 || Val Loss: 0.42333968 || Val it_count: 1107 || Current Learning Rate: 0.0001 || Time: 05:33:8.73
Epoch :: 60 || Loss: 0.40570914 || it_count: 8344 || Val Loss: 0.42391086 || Val it_count: 1107 || Current Learning Rate: 0.0001 || Time: 05:38:16.08
Epoch :: 61 || Loss: 0.40558206 || it_count: 8344 || Val Loss: 0.42412070 || Val it_count: 1107 || Current Learning Rate: 1e-05 || Time: 05:43:37.40
Epoch :: 62 || Loss: 0.40974949 || it_count: 8344 || Val Loss: 0.41268500 || Val it_count: 1107 || Current Learning Rate: 1e-05 || Time: 05:49:4.60
Epoch :: 63 || Loss: 0.40786523 || it_count: 8344 || Val Loss: 0.41222717 || Val it_count: 1107 || Current Learning Rate: 1e-05 || Time: 05:54:25.93
Epoch :: 64 || Loss: 0.40769810 || it_count: 8344 || Val Loss: 0.41213742 || Val it_count: 1107 || Current Learning Rate: 1e-05 || Time: 05:59:37.76
Epoch :: 65 || Loss: 0.40761262 || it_count: 8344 || Val Loss: 0.41208022 || Val it_count: 1107 || Current Learning Rate: 1e-05 || Time: 06:04:44.71
Epoch :: 66 || Loss: 0.40746121 || it_count: 8344 || Val Loss: 0.41206044 || Val it_count: 1107 || Current Learning Rate: 1e-05 || Time: 06:09:51.57
Epoch :: 67 || Loss: 0.40742066 || it_count: 8344 || Val Loss: 0.41204068 || Val it_count: 1107 || Current Learning Rate: 1e-05 || Time: 06:14:59.72
Epoch :: 68 || Loss: 0.40734466 || it_count: 8344 || Val Loss: 0.41204359 || Val it_count: 1107 || Current Learning Rate: 1e-05 || Time: 06:20:6.69
Epoch :: 69 || Loss: 0.40724644 || it_count: 8344 || Val Loss: 0.41203675 || Val it_count: 1107 || Current Learning Rate: 1e-05 || Time: 06:25:15.16
Epoch :: 70 || Loss: 0.40716767 || it_count: 8344 || Val Loss: 0.41203377 || Val it_count: 1107 || Current Learning Rate: 1e-05 || Time: 06:30:23.52
Epoch :: 71 || Loss: 0.40714449 || it_count: 8344 || Val Loss: 0.41204751 || Val it_count: 1107 || Current Learning Rate: 1e-05 || Time: 06:35:31.75
Epoch :: 72 || Loss: 0.40710181 || it_count: 8344 || Val Loss: 0.41206421 || Val it_count: 1107 || Current Learning Rate: 1e-05 || Time: 06:40:36.28
Epoch :: 73 || Loss: 0.40707056 || it_count: 8344 || Val Loss: 0.41208560 || Val it_count: 1107 || Current Learning Rate: 1e-05 || Time: 06:45:43.09
Epoch :: 74 || Loss: 0.40700997 || it_count: 8344 || Val Loss: 0.41214022 || Val it_count: 1107 || Current Learning Rate: 1e-05 || Time: 06:50:50.55
Epoch :: 75 || Loss: 0.40693709 || it_count: 8344 || Val Loss: 0.41212500 || Val it_count: 1107 || Current Learning Rate: 1.0000000000000002e-06 || Time: 06:55:55.14
Epoch :: 76 || Loss: 0.40745186 || it_count: 8344 || Val Loss: 0.41095065 || Val it_count: 1107 || Current Learning Rate: 1.0000000000000002e-06 || Time: 07:00:59.79
Epoch :: 77 || Loss: 0.40719898 || it_count: 8344 || Val Loss: 0.41082927 || Val it_count: 1107 || Current Learning Rate: 1.0000000000000002e-06 || Time: 07:06:10.87
Epoch :: 78 || Loss: 0.40708398 || it_count: 8344 || Val Loss: 0.41078804 || Val it_count: 1107 || Current Learning Rate: 1.0000000000000002e-06 || Time: 07:11:17.65
Epoch :: 79 || Loss: 0.40709133 || it_count: 8344 || Val Loss: 0.41076906 || Val it_count: 1107 || Current Learning Rate: 1.0000000000000002e-06 || Time: 07:16:25.08
Epoch :: 80 || Loss: 0.40706681 || it_count: 8344 || Val Loss: 0.41075292 || Val it_count: 1107 || Current Learning Rate: 1.0000000000000002e-06 || Time: 07:21:31.44
Epoch :: 81 || Loss: 0.40702349 || it_count: 8344 || Val Loss: 0.41073992 || Val it_count: 1107 || Current Learning Rate: 1.0000000000000002e-06 || Time: 07:27:3.53
Epoch :: 82 || Loss: 0.40703161 || it_count: 8344 || Val Loss: 0.41073213 || Val it_count: 1107 || Current Learning Rate: 1.0000000000000002e-06 || Time: 07:32:33.68
Epoch :: 83 || Loss: 0.40702357 || it_count: 8344 || Val Loss: 0.41073158 || Val it_count: 1107 || Current Learning Rate: 1.0000000000000002e-06 || Time: 07:37:55.42
Epoch :: 84 || Loss: 0.40696318 || it_count: 8344 || Val Loss: 0.41072151 || Val it_count: 1107 || Current Learning Rate: 1.0000000000000002e-06 || Time: 07:43:4.43
Epoch :: 85 || Loss: 0.40702080 || it_count: 8344 || Val Loss: 0.41071645 || Val it_count: 1107 || Current Learning Rate: 1.0000000000000002e-06 || Time: 07:48:30.77
Epoch :: 86 || Loss: 0.40699651 || it_count: 8344 || Val Loss: 0.41071361 || Val it_count: 1107 || Current Learning Rate: 1.0000000000000002e-06 || Time: 07:53:55.81
Early stopping triggered due to learning rate below threshold.
Done Total time: 07:59:25.63
best_loss: 0.4107136107883304

--------------------Testing--------------------

total_samples :: test_dataset = 139200, test_dataloader = 139200
Epoch ::  1 || Loss: 0.23507184 || it_count: 544 || Time: 00:00:16.61
MAE:  0.2516355
MSE:  0.2350876
RMSE:  0.44082248

--------------------Training--------------------
arch_str :: |lstm_1~0|+|lstm_3~0|lstm_3~1|[relu->linear->dropout->linear]
model :: 3N
InferCell(
  info :: nodes=3, inC=1, outC=64, [1<-(I0-L0) | 2<-(I0-L1,I1-L2)], genotype_str: lstm_1~0|lstm_3~0|lstm_3~1
  linear_layers: [relu->linear->dropout->linear]
  (layers): ModuleList(
    (0): LSTM(
      (lstm): LSTM(1, 64, batch_first=True)
    )
    (1): LSTM(
      (lstm): LSTM(1, 64, num_layers=3, batch_first=True)
    )
    (2): LSTM(
      (lstm): LSTM(64, 64, num_layers=3, batch_first=True)
    )
  )
  (linear_layers): ModuleList(
    (0): ReLU()
    (1): Linear(in_features=3072, out_features=1536, bias=True)
    (2): Dropout(p=0.1, inplace=False)
    (3): Linear(in_features=1536, out_features=1, bias=True)
  )
)
tr_params :: epochs = 100, patience = 20, batch_size = 256, window_size = 48, data_size = 100
Model MACs: 14.526M, Model Params: 4.922M
learning rate scheduling :: (optimizer, mode='min', factor=0.1, patience=5, verbose=True)
total_samples :: train_dataset = 2136000, train_dataloader = 2136000
total_samples :: valid_dataset = 283200, valid_dataloader = 283200
Epoch ::  1 || Loss: 0.42675842 || it_count: 8344 || Val Loss: 0.45449243 || Val it_count: 1107 || Current Learning Rate: 0.001 || Time: 00:11:52.55
Epoch ::  2 || Loss: 0.41851029 || it_count: 8344 || Val Loss: 0.45386286 || Val it_count: 1107 || Current Learning Rate: 0.001 || Time: 00:23:51.80
Epoch ::  3 || Loss: 0.41792707 || it_count: 8344 || Val Loss: 0.45220006 || Val it_count: 1107 || Current Learning Rate: 0.001 || Time: 00:35:56.64
Epoch ::  4 || Loss: 0.41770601 || it_count: 8344 || Val Loss: 0.45157419 || Val it_count: 1107 || Current Learning Rate: 0.001 || Time: 00:48:5.17
Epoch ::  5 || Loss: 0.41739438 || it_count: 8344 || Val Loss: 0.45094677 || Val it_count: 1107 || Current Learning Rate: 0.001 || Time: 01:00:16.01
Epoch ::  6 || Loss: 0.41728249 || it_count: 8344 || Val Loss: 0.45220212 || Val it_count: 1107 || Current Learning Rate: 0.001 || Time: 01:12:28.20
Epoch ::  7 || Loss: 0.41727144 || it_count: 8344 || Val Loss: 0.45101131 || Val it_count: 1107 || Current Learning Rate: 0.001 || Time: 01:24:40.63
Epoch ::  8 || Loss: 0.41725051 || it_count: 8344 || Val Loss: 0.45157299 || Val it_count: 1107 || Current Learning Rate: 0.001 || Time: 01:36:53.36
Epoch ::  9 || Loss: 0.41700540 || it_count: 8344 || Val Loss: 0.45227233 || Val it_count: 1107 || Current Learning Rate: 0.001 || Time: 01:49:6.43
Epoch :: 10 || Loss: 0.41681416 || it_count: 8344 || Val Loss: 0.45210722 || Val it_count: 1107 || Current Learning Rate: 0.001 || Time: 02:01:20.47
Epoch :: 11 || Loss: 0.41649311 || it_count: 8344 || Val Loss: 0.44914006 || Val it_count: 1107 || Current Learning Rate: 0.001 || Time: 02:13:34.37
Epoch :: 12 || Loss: 0.41629158 || it_count: 8344 || Val Loss: 0.45055864 || Val it_count: 1107 || Current Learning Rate: 0.001 || Time: 02:25:48.66
Epoch :: 13 || Loss: 0.41637937 || it_count: 8344 || Val Loss: 0.45183228 || Val it_count: 1107 || Current Learning Rate: 0.001 || Time: 02:38:2.73
Epoch :: 14 || Loss: 0.41642409 || it_count: 8344 || Val Loss: 0.45246338 || Val it_count: 1107 || Current Learning Rate: 0.001 || Time: 02:50:17.41
Epoch :: 15 || Loss: 0.41654434 || it_count: 8344 || Val Loss: 0.45314524 || Val it_count: 1107 || Current Learning Rate: 0.001 || Time: 03:02:32.53
Epoch :: 16 || Loss: 0.41661249 || it_count: 8344 || Val Loss: 0.45369519 || Val it_count: 1107 || Current Learning Rate: 0.001 || Time: 03:14:48.17
Epoch :: 17 || Loss: 0.41598815 || it_count: 8344 || Val Loss: 0.45322144 || Val it_count: 1107 || Current Learning Rate: 0.001 || Time: 03:27:3.83
Epoch :: 18 || Loss: 0.41575962 || it_count: 8344 || Val Loss: 0.45311218 || Val it_count: 1107 || Current Learning Rate: 0.001 || Time: 03:39:19.50
Epoch :: 19 || Loss: 0.41585460 || it_count: 8344 || Val Loss: 0.45243705 || Val it_count: 1107 || Current Learning Rate: 0.001 || Time: 03:51:34.71
Epoch :: 20 || Loss: 0.41482061 || it_count: 8344 || Val Loss: 0.45338082 || Val it_count: 1107 || Current Learning Rate: 0.001 || Time: 04:03:50.41
Epoch :: 21 || Loss: 0.41445882 || it_count: 8344 || Val Loss: 0.45648128 || Val it_count: 1107 || Current Learning Rate: 0.001 || Time: 04:16:5.72
Epoch :: 22 || Loss: 0.41420150 || it_count: 8344 || Val Loss: 0.45494574 || Val it_count: 1107 || Current Learning Rate: 0.001 || Time: 04:28:21.68
Epoch :: 23 || Loss: 0.41440490 || it_count: 8344 || Val Loss: 0.45387534 || Val it_count: 1107 || Current Learning Rate: 0.001 || Time: 04:40:37.24
Epoch :: 24 || Loss: 0.41379525 || it_count: 8344 || Val Loss: 0.45497517 || Val it_count: 1107 || Current Learning Rate: 0.001 || Time: 04:52:53.29
Epoch :: 25 || Loss: 0.41353108 || it_count: 8344 || Val Loss: 0.45234531 || Val it_count: 1107 || Current Learning Rate: 0.001 || Time: 05:05:7.78
Epoch :: 26 || Loss: 0.41336871 || it_count: 8344 || Val Loss: 0.45214229 || Val it_count: 1107 || Current Learning Rate: 0.001 || Time: 05:17:22.91
Epoch :: 27 || Loss: 0.41361268 || it_count: 8344 || Val Loss: 0.45027165 || Val it_count: 1107 || Current Learning Rate: 0.001 || Time: 05:29:37.75
Epoch :: 28 || Loss: 0.41319152 || it_count: 8344 || Val Loss: 0.44925396 || Val it_count: 1107 || Current Learning Rate: 0.001 || Time: 05:41:53.01
Epoch :: 29 || Loss: 0.41219776 || it_count: 8344 || Val Loss: 0.45005888 || Val it_count: 1107 || Current Learning Rate: 0.001 || Time: 05:54:7.84
Epoch :: 30 || Loss: 0.41206538 || it_count: 8344 || Val Loss: 0.44877252 || Val it_count: 1107 || Current Learning Rate: 0.001 || Time: 06:06:22.78
Epoch :: 31 || Loss: 0.41210308 || it_count: 8344 || Val Loss: 0.44718885 || Val it_count: 1107 || Current Learning Rate: 0.001 || Time: 06:18:38.12
Epoch :: 32 || Loss: 0.41262440 || it_count: 8344 || Val Loss: 0.44679034 || Val it_count: 1107 || Current Learning Rate: 0.001 || Time: 06:30:53.52
Epoch :: 33 || Loss: 0.41197777 || it_count: 8344 || Val Loss: 0.44579862 || Val it_count: 1107 || Current Learning Rate: 0.001 || Time: 06:43:8.61
Epoch :: 34 || Loss: 0.41187751 || it_count: 8344 || Val Loss: 0.44560665 || Val it_count: 1107 || Current Learning Rate: 0.001 || Time: 06:55:23.59
Epoch :: 35 || Loss: 0.41186813 || it_count: 8344 || Val Loss: 0.44317470 || Val it_count: 1107 || Current Learning Rate: 0.001 || Time: 07:07:38.82
Epoch :: 36 || Loss: 0.41193618 || it_count: 8344 || Val Loss: 0.44662633 || Val it_count: 1107 || Current Learning Rate: 0.001 || Time: 07:19:54.29
Epoch :: 37 || Loss: 0.41122367 || it_count: 8344 || Val Loss: 0.44651246 || Val it_count: 1107 || Current Learning Rate: 0.001 || Time: 07:32:9.49
Epoch :: 38 || Loss: 0.41078780 || it_count: 8344 || Val Loss: 0.44566250 || Val it_count: 1107 || Current Learning Rate: 0.001 || Time: 07:44:19.39
Epoch :: 39 || Loss: 0.41049526 || it_count: 8344 || Val Loss: 0.44969123 || Val it_count: 1107 || Current Learning Rate: 0.001 || Time: 07:56:31.99
Epoch :: 40 || Loss: 0.41052446 || it_count: 8344 || Val Loss: 0.44639891 || Val it_count: 1107 || Current Learning Rate: 0.001 || Time: 08:08:46.00
Epoch 00025: reducing learning rate of group 0 to 1.0000e-04.
Epoch :: 41 || Loss: 0.41118159 || it_count: 8344 || Val Loss: 0.44731758 || Val it_count: 1107 || Current Learning Rate: 0.0001 || Time: 08:20:59.73
Epoch :: 42 || Loss: 0.41519494 || it_count: 8344 || Val Loss: 0.42833311 || Val it_count: 1107 || Current Learning Rate: 0.0001 || Time: 08:33:13.60
Epoch :: 43 || Loss: 0.41190709 || it_count: 8344 || Val Loss: 0.42688197 || Val it_count: 1107 || Current Learning Rate: 0.0001 || Time: 08:45:27.29
Epoch :: 44 || Loss: 0.41119769 || it_count: 8344 || Val Loss: 0.42652584 || Val it_count: 1107 || Current Learning Rate: 0.0001 || Time: 08:57:41.19
Epoch :: 45 || Loss: 0.41076672 || it_count: 8344 || Val Loss: 0.42655689 || Val it_count: 1107 || Current Learning Rate: 0.0001 || Time: 09:09:54.76
Epoch :: 46 || Loss: 0.41041523 || it_count: 8344 || Val Loss: 0.42670782 || Val it_count: 1107 || Current Learning Rate: 0.0001 || Time: 09:22:8.24
Epoch :: 47 || Loss: 0.41000656 || it_count: 8344 || Val Loss: 0.42665872 || Val it_count: 1107 || Current Learning Rate: 0.0001 || Time: 09:34:21.52
Epoch :: 48 || Loss: 0.40985885 || it_count: 8344 || Val Loss: 0.42702287 || Val it_count: 1107 || Current Learning Rate: 0.0001 || Time: 09:46:35.47
Epoch :: 49 || Loss: 0.40969394 || it_count: 8344 || Val Loss: 0.42682156 || Val it_count: 1107 || Current Learning Rate: 0.0001 || Time: 09:58:48.95
Epoch 00034: reducing learning rate of group 0 to 1.0000e-05.
Epoch :: 50 || Loss: 0.40944081 || it_count: 8344 || Val Loss: 0.42713142 || Val it_count: 1107 || Current Learning Rate: 1e-05 || Time: 10:11:2.65
Epoch :: 51 || Loss: 0.41218760 || it_count: 8344 || Val Loss: 0.41701741 || Val it_count: 1107 || Current Learning Rate: 1e-05 || Time: 10:23:16.13
Epoch :: 52 || Loss: 0.41076130 || it_count: 8344 || Val Loss: 0.41688056 || Val it_count: 1107 || Current Learning Rate: 1e-05 || Time: 10:35:29.93
Epoch :: 53 || Loss: 0.41046836 || it_count: 8344 || Val Loss: 0.41672446 || Val it_count: 1107 || Current Learning Rate: 1e-05 || Time: 10:47:43.55
Epoch :: 54 || Loss: 0.41034211 || it_count: 8344 || Val Loss: 0.41664530 || Val it_count: 1107 || Current Learning Rate: 1e-05 || Time: 10:59:57.66
Epoch :: 55 || Loss: 0.41022447 || it_count: 8344 || Val Loss: 0.41661252 || Val it_count: 1107 || Current Learning Rate: 1e-05 || Time: 11:12:11.19
Epoch :: 56 || Loss: 0.41016747 || it_count: 8344 || Val Loss: 0.41658353 || Val it_count: 1107 || Current Learning Rate: 1e-05 || Time: 11:24:25.26
Epoch :: 57 || Loss: 0.41011501 || it_count: 8344 || Val Loss: 0.41653985 || Val it_count: 1107 || Current Learning Rate: 1e-05 || Time: 11:36:38.94
Epoch :: 58 || Loss: 0.41006022 || it_count: 8344 || Val Loss: 0.41653126 || Val it_count: 1107 || Current Learning Rate: 1e-05 || Time: 11:48:52.82
Epoch :: 59 || Loss: 0.41000533 || it_count: 8344 || Val Loss: 0.41651199 || Val it_count: 1107 || Current Learning Rate: 1e-05 || Time: 12:01:6.39
Epoch :: 60 || Loss: 0.41000476 || it_count: 8344 || Val Loss: 0.41651491 || Val it_count: 1107 || Current Learning Rate: 1e-05 || Time: 12:13:20.48
Epoch :: 61 || Loss: 0.40991849 || it_count: 8344 || Val Loss: 0.41649882 || Val it_count: 1107 || Current Learning Rate: 1e-05 || Time: 12:25:34.00
Epoch :: 62 || Loss: 0.40989575 || it_count: 8344 || Val Loss: 0.41646827 || Val it_count: 1107 || Current Learning Rate: 1e-05 || Time: 12:37:47.96
Epoch :: 63 || Loss: 0.40988372 || it_count: 8344 || Val Loss: 0.41647616 || Val it_count: 1107 || Current Learning Rate: 1e-05 || Time: 12:50:1.82
Epoch :: 64 || Loss: 0.40982429 || it_count: 8344 || Val Loss: 0.41645464 || Val it_count: 1107 || Current Learning Rate: 1e-05 || Time: 13:02:15.28
Epoch :: 65 || Loss: 0.40978469 || it_count: 8344 || Val Loss: 0.41646984 || Val it_count: 1107 || Current Learning Rate: 1e-05 || Time: 13:14:28.99
Epoch :: 66 || Loss: 0.40974541 || it_count: 8344 || Val Loss: 0.41646568 || Val it_count: 1107 || Current Learning Rate: 1e-05 || Time: 13:26:42.64
Epoch :: 67 || Loss: 0.40972199 || it_count: 8344 || Val Loss: 0.41648053 || Val it_count: 1107 || Current Learning Rate: 1e-05 || Time: 13:38:56.15
Epoch 00052: reducing learning rate of group 0 to 1.0000e-06.
Epoch :: 68 || Loss: 0.40967319 || it_count: 8344 || Val Loss: 0.41643007 || Val it_count: 1107 || Current Learning Rate: 1.0000000000000002e-06 || Time: 13:51:9.80
Epoch :: 69 || Loss: 0.40989722 || it_count: 8344 || Val Loss: 0.41589026 || Val it_count: 1107 || Current Learning Rate: 1.0000000000000002e-06 || Time: 14:03:22.91
Epoch :: 70 || Loss: 0.40977222 || it_count: 8344 || Val Loss: 0.41580637 || Val it_count: 1107 || Current Learning Rate: 1.0000000000000002e-06 || Time: 14:15:36.74
Epoch :: 71 || Loss: 0.40971645 || it_count: 8344 || Val Loss: 0.41577471 || Val it_count: 1107 || Current Learning Rate: 1.0000000000000002e-06 || Time: 14:27:49.95
Epoch :: 72 || Loss: 0.40971694 || it_count: 8344 || Val Loss: 0.41575197 || Val it_count: 1107 || Current Learning Rate: 1.0000000000000002e-06 || Time: 14:40:4.16
Epoch :: 73 || Loss: 0.40969941 || it_count: 8344 || Val Loss: 0.41574397 || Val it_count: 1107 || Current Learning Rate: 1.0000000000000002e-06 || Time: 14:52:17.99
Epoch :: 74 || Loss: 0.40970303 || it_count: 8344 || Val Loss: 0.41573434 || Val it_count: 1107 || Current Learning Rate: 1.0000000000000002e-06 || Time: 15:04:31.68
Epoch :: 75 || Loss: 0.40968202 || it_count: 8344 || Val Loss: 0.41573418 || Val it_count: 1107 || Current Learning Rate: 1.0000000000000002e-06 || Time: 15:16:45.10
Epoch :: 76 || Loss: 0.40971014 || it_count: 8344 || Val Loss: 0.41572933 || Val it_count: 1107 || Current Learning Rate: 1.0000000000000002e-06 || Time: 15:28:59.12
Epoch :: 77 || Loss: 0.40967059 || it_count: 8344 || Val Loss: 0.41571824 || Val it_count: 1107 || Current Learning Rate: 1.0000000000000002e-06 || Time: 15:41:12.91
Epoch 00062: reducing learning rate of group 0 to 1.0000e-07.
Early stopping triggered due to learning rate below threshold.
Done Total time: 15:53:27.16
best_loss: 0.41571824222245046

--------------------Testing--------------------

total_samples :: test_dataset = 139200, test_dataloader = 139200
Epoch ::  1 || Loss: 0.23795277 || it_count: 544 || Time: 00:00:28.19
MAE:  0.253207
MSE:  0.23797125
RMSE:  0.4430613

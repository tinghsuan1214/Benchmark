--------------------Training--------------------
arch_str :: |none~0|+|lstm_2~0|lstm_2~1|[relu->linear->dropout->linear]
model :: 3N
InferCell(
  info :: nodes=3, inC=1, outC=64, [1<-(I0-L0) | 2<-(I0-L1,I1-L2)], genotype_str: none~0|lstm_2~0|lstm_2~1
  linear_layers: [relu->linear->dropout->linear]
  (layers): ModuleList(
    (0): Zero(C_in=1, C_out=64, stride=1)
    (1): LSTM(
      (lstm): LSTM(1, 64, num_layers=2, batch_first=True)
    )
    (2): LSTM(
      (lstm): LSTM(64, 64, num_layers=2, batch_first=True)
    )
  )
  (linear_layers): ModuleList(
    (0): ReLU()
    (1): Linear(in_features=3072, out_features=1536, bias=True)
    (2): Dropout(p=0.1, inplace=False)
    (3): Linear(in_features=1536, out_features=1, bias=True)
  )
)
tr_params :: epochs = 100, patience = 20, batch_size = 256, window_size = 48, data_size = 100
Model MACs: 10.434M, Model Params: 4.839M
learning rate scheduling :: (optimizer, mode='min', factor=0.1, patience=5, verbose=True)
total_samples :: train_dataset = 2136000, train_dataloader = 2136000
total_samples :: valid_dataset = 283200, valid_dataloader = 283200
Epoch ::  1 || Loss: 0.42356313 || it_count: 8344 || Val Loss: 0.46031452 || Val it_count: 1107 || Current Learning Rate: 0.001 || Time: 00:08:45.67
Epoch ::  2 || Loss: 0.41841584 || it_count: 8344 || Val Loss: 0.45567093 || Val it_count: 1107 || Current Learning Rate: 0.001 || Time: 00:17:30.08
Epoch ::  3 || Loss: 0.41723627 || it_count: 8344 || Val Loss: 0.45485441 || Val it_count: 1107 || Current Learning Rate: 0.001 || Time: 00:26:15.35
Epoch ::  4 || Loss: 0.41695666 || it_count: 8344 || Val Loss: 0.45418303 || Val it_count: 1107 || Current Learning Rate: 0.001 || Time: 00:35:3.50
Epoch ::  5 || Loss: 0.41630439 || it_count: 8344 || Val Loss: 0.45342623 || Val it_count: 1107 || Current Learning Rate: 0.001 || Time: 00:43:54.48
Epoch ::  6 || Loss: 0.41559824 || it_count: 8344 || Val Loss: 0.45034591 || Val it_count: 1107 || Current Learning Rate: 0.001 || Time: 00:52:50.41
Epoch ::  7 || Loss: 0.41542641 || it_count: 8344 || Val Loss: 0.44894277 || Val it_count: 1107 || Current Learning Rate: 0.001 || Time: 01:01:47.96
Epoch ::  8 || Loss: 0.41511987 || it_count: 8344 || Val Loss: 0.44795490 || Val it_count: 1107 || Current Learning Rate: 0.001 || Time: 01:10:47.92
Epoch ::  9 || Loss: 0.41488461 || it_count: 8344 || Val Loss: 0.44868799 || Val it_count: 1107 || Current Learning Rate: 0.001 || Time: 01:19:48.34
Epoch :: 10 || Loss: 0.41484470 || it_count: 8344 || Val Loss: 0.44915851 || Val it_count: 1107 || Current Learning Rate: 0.001 || Time: 01:28:49.70
Epoch :: 11 || Loss: 0.41477127 || it_count: 8344 || Val Loss: 0.44944323 || Val it_count: 1107 || Current Learning Rate: 0.001 || Time: 01:37:50.23
Epoch :: 12 || Loss: 0.41485927 || it_count: 8344 || Val Loss: 0.44916950 || Val it_count: 1107 || Current Learning Rate: 0.001 || Time: 01:46:50.18
Epoch :: 13 || Loss: 0.41463943 || it_count: 8344 || Val Loss: 0.44975618 || Val it_count: 1107 || Current Learning Rate: 0.001 || Time: 01:55:50.65
Epoch :: 14 || Loss: 0.41457521 || it_count: 8344 || Val Loss: 0.44905990 || Val it_count: 1107 || Current Learning Rate: 0.001 || Time: 02:04:53.26
Epoch :: 15 || Loss: 0.41427570 || it_count: 8344 || Val Loss: 0.44887142 || Val it_count: 1107 || Current Learning Rate: 0.001 || Time: 02:13:56.92
Epoch :: 16 || Loss: 0.41406916 || it_count: 8344 || Val Loss: 0.44744682 || Val it_count: 1107 || Current Learning Rate: 0.001 || Time: 02:23:2.21
Epoch :: 17 || Loss: 0.41368327 || it_count: 8344 || Val Loss: 0.44673683 || Val it_count: 1107 || Current Learning Rate: 0.001 || Time: 02:32:7.97
Epoch :: 18 || Loss: 0.41284665 || it_count: 8344 || Val Loss: 0.44737354 || Val it_count: 1107 || Current Learning Rate: 0.001 || Time: 02:41:14.50
Epoch :: 19 || Loss: 0.41233704 || it_count: 8344 || Val Loss: 0.44731637 || Val it_count: 1107 || Current Learning Rate: 0.001 || Time: 02:50:21.03
Epoch :: 20 || Loss: 0.41203129 || it_count: 8344 || Val Loss: 0.44718169 || Val it_count: 1107 || Current Learning Rate: 0.001 || Time: 02:59:26.57
Epoch :: 21 || Loss: 0.41154168 || it_count: 8344 || Val Loss: 0.44613371 || Val it_count: 1107 || Current Learning Rate: 0.001 || Time: 03:08:30.18
Epoch :: 22 || Loss: 0.41142822 || it_count: 8344 || Val Loss: 0.44735300 || Val it_count: 1107 || Current Learning Rate: 0.001 || Time: 03:17:34.38
Epoch :: 23 || Loss: 0.41125639 || it_count: 8344 || Val Loss: 0.44742243 || Val it_count: 1107 || Current Learning Rate: 0.001 || Time: 03:26:38.13
Epoch :: 24 || Loss: 0.41091338 || it_count: 8344 || Val Loss: 0.44748790 || Val it_count: 1107 || Current Learning Rate: 0.001 || Time: 03:35:41.60
Epoch :: 25 || Loss: 0.41088565 || it_count: 8344 || Val Loss: 0.44691212 || Val it_count: 1107 || Current Learning Rate: 0.001 || Time: 03:44:44.55
Epoch :: 26 || Loss: 0.41072385 || it_count: 8344 || Val Loss: 0.44803745 || Val it_count: 1107 || Current Learning Rate: 0.001 || Time: 03:53:47.84
Epoch 00011: reducing learning rate of group 0 to 1.0000e-04.
Epoch :: 27 || Loss: 0.41030865 || it_count: 8344 || Val Loss: 0.44828366 || Val it_count: 1107 || Current Learning Rate: 0.0001 || Time: 04:02:51.28
Epoch :: 28 || Loss: 0.41612935 || it_count: 8344 || Val Loss: 0.43122051 || Val it_count: 1107 || Current Learning Rate: 0.0001 || Time: 04:11:53.49
Epoch :: 29 || Loss: 0.41341566 || it_count: 8344 || Val Loss: 0.43053236 || Val it_count: 1107 || Current Learning Rate: 0.0001 || Time: 04:20:56.54
Epoch :: 30 || Loss: 0.41281267 || it_count: 8344 || Val Loss: 0.43011967 || Val it_count: 1107 || Current Learning Rate: 0.0001 || Time: 04:29:59.55
Epoch :: 31 || Loss: 0.41234873 || it_count: 8344 || Val Loss: 0.42933777 || Val it_count: 1107 || Current Learning Rate: 0.0001 || Time: 04:39:2.09
Epoch :: 32 || Loss: 0.41195288 || it_count: 8344 || Val Loss: 0.42890928 || Val it_count: 1107 || Current Learning Rate: 0.0001 || Time: 04:48:6.08
Epoch :: 33 || Loss: 0.41168280 || it_count: 8344 || Val Loss: 0.42832586 || Val it_count: 1107 || Current Learning Rate: 0.0001 || Time: 04:57:10.14
Epoch :: 34 || Loss: 0.41135247 || it_count: 8344 || Val Loss: 0.42792462 || Val it_count: 1107 || Current Learning Rate: 0.0001 || Time: 05:06:13.83
Epoch :: 35 || Loss: 0.41115884 || it_count: 8344 || Val Loss: 0.42765564 || Val it_count: 1107 || Current Learning Rate: 0.0001 || Time: 05:15:17.76
Epoch :: 36 || Loss: 0.41095025 || it_count: 8344 || Val Loss: 0.42761474 || Val it_count: 1107 || Current Learning Rate: 0.0001 || Time: 05:24:21.37
Epoch :: 37 || Loss: 0.41071295 || it_count: 8344 || Val Loss: 0.42765044 || Val it_count: 1107 || Current Learning Rate: 0.0001 || Time: 05:33:24.12
Epoch :: 38 || Loss: 0.41055810 || it_count: 8344 || Val Loss: 0.42777292 || Val it_count: 1107 || Current Learning Rate: 0.0001 || Time: 05:42:27.83
Epoch :: 39 || Loss: 0.41043712 || it_count: 8344 || Val Loss: 0.42745356 || Val it_count: 1107 || Current Learning Rate: 0.0001 || Time: 05:51:31.38
Epoch :: 40 || Loss: 0.41026335 || it_count: 8344 || Val Loss: 0.42739427 || Val it_count: 1107 || Current Learning Rate: 0.0001 || Time: 06:00:34.71
Epoch :: 41 || Loss: 0.41016544 || it_count: 8344 || Val Loss: 0.42705625 || Val it_count: 1107 || Current Learning Rate: 0.0001 || Time: 06:09:37.69
Epoch :: 42 || Loss: 0.40994373 || it_count: 8344 || Val Loss: 0.42715234 || Val it_count: 1107 || Current Learning Rate: 0.0001 || Time: 06:18:39.82
Epoch :: 43 || Loss: 0.40978290 || it_count: 8344 || Val Loss: 0.42686562 || Val it_count: 1107 || Current Learning Rate: 0.0001 || Time: 06:27:42.28
Epoch :: 44 || Loss: 0.40966849 || it_count: 8344 || Val Loss: 0.42693948 || Val it_count: 1107 || Current Learning Rate: 0.0001 || Time: 06:36:44.32
Epoch :: 45 || Loss: 0.40945857 || it_count: 8344 || Val Loss: 0.42677472 || Val it_count: 1107 || Current Learning Rate: 0.0001 || Time: 06:45:47.67
Epoch :: 46 || Loss: 0.40932058 || it_count: 8344 || Val Loss: 0.42676250 || Val it_count: 1107 || Current Learning Rate: 0.0001 || Time: 06:54:50.06
Epoch :: 47 || Loss: 0.40919562 || it_count: 8344 || Val Loss: 0.42672853 || Val it_count: 1107 || Current Learning Rate: 0.0001 || Time: 07:03:53.12
Epoch :: 48 || Loss: 0.40904173 || it_count: 8344 || Val Loss: 0.42685883 || Val it_count: 1107 || Current Learning Rate: 0.0001 || Time: 07:12:55.32
Epoch :: 49 || Loss: 0.40891983 || it_count: 8344 || Val Loss: 0.42639496 || Val it_count: 1107 || Current Learning Rate: 0.0001 || Time: 07:21:58.08
Epoch :: 50 || Loss: 0.40877102 || it_count: 8344 || Val Loss: 0.42641787 || Val it_count: 1107 || Current Learning Rate: 0.0001 || Time: 07:30:58.99
Epoch :: 51 || Loss: 0.40866850 || it_count: 8344 || Val Loss: 0.42616234 || Val it_count: 1107 || Current Learning Rate: 0.0001 || Time: 07:40:1.87
Epoch :: 52 || Loss: 0.40855639 || it_count: 8344 || Val Loss: 0.42600182 || Val it_count: 1107 || Current Learning Rate: 0.0001 || Time: 07:49:4.54
Epoch :: 53 || Loss: 0.40849777 || it_count: 8344 || Val Loss: 0.42591651 || Val it_count: 1107 || Current Learning Rate: 0.0001 || Time: 07:58:7.92
Epoch :: 54 || Loss: 0.40839367 || it_count: 8344 || Val Loss: 0.42609918 || Val it_count: 1107 || Current Learning Rate: 0.0001 || Time: 08:07:11.68
Epoch :: 55 || Loss: 0.40829435 || it_count: 8344 || Val Loss: 0.42600280 || Val it_count: 1107 || Current Learning Rate: 0.0001 || Time: 08:16:14.95
Epoch :: 56 || Loss: 0.40817518 || it_count: 8344 || Val Loss: 0.42611191 || Val it_count: 1107 || Current Learning Rate: 0.0001 || Time: 08:25:16.58
Epoch :: 57 || Loss: 0.40808225 || it_count: 8344 || Val Loss: 0.42601152 || Val it_count: 1107 || Current Learning Rate: 0.0001 || Time: 08:34:18.37
Epoch :: 58 || Loss: 0.40800053 || it_count: 8344 || Val Loss: 0.42593646 || Val it_count: 1107 || Current Learning Rate: 0.0001 || Time: 08:43:21.92
Epoch 00043: reducing learning rate of group 0 to 1.0000e-05.
Epoch :: 59 || Loss: 0.40787308 || it_count: 8344 || Val Loss: 0.42604312 || Val it_count: 1107 || Current Learning Rate: 1e-05 || Time: 08:52:23.67
Epoch :: 60 || Loss: 0.41195405 || it_count: 8344 || Val Loss: 0.41420719 || Val it_count: 1107 || Current Learning Rate: 1e-05 || Time: 09:01:26.74
Epoch :: 61 || Loss: 0.40960070 || it_count: 8344 || Val Loss: 0.41399210 || Val it_count: 1107 || Current Learning Rate: 1e-05 || Time: 09:10:29.93
Epoch :: 62 || Loss: 0.40940169 || it_count: 8344 || Val Loss: 0.41397250 || Val it_count: 1107 || Current Learning Rate: 1e-05 || Time: 09:19:33.07
Epoch :: 63 || Loss: 0.40928723 || it_count: 8344 || Val Loss: 0.41395122 || Val it_count: 1107 || Current Learning Rate: 1e-05 || Time: 09:28:36.22
Epoch :: 64 || Loss: 0.40917222 || it_count: 8344 || Val Loss: 0.41396413 || Val it_count: 1107 || Current Learning Rate: 1e-05 || Time: 09:37:38.46
Epoch :: 65 || Loss: 0.40908592 || it_count: 8344 || Val Loss: 0.41395342 || Val it_count: 1107 || Current Learning Rate: 1e-05 || Time: 09:46:40.71
Epoch :: 66 || Loss: 0.40905306 || it_count: 8344 || Val Loss: 0.41393184 || Val it_count: 1107 || Current Learning Rate: 1e-05 || Time: 09:55:43.69
Epoch :: 67 || Loss: 0.40898814 || it_count: 8344 || Val Loss: 0.41389781 || Val it_count: 1107 || Current Learning Rate: 1e-05 || Time: 10:04:46.29
Epoch :: 68 || Loss: 0.40895867 || it_count: 8344 || Val Loss: 0.41388428 || Val it_count: 1107 || Current Learning Rate: 1e-05 || Time: 10:13:49.11
Epoch :: 69 || Loss: 0.40889738 || it_count: 8344 || Val Loss: 0.41391489 || Val it_count: 1107 || Current Learning Rate: 1e-05 || Time: 10:22:52.15
Epoch :: 70 || Loss: 0.40890076 || it_count: 8344 || Val Loss: 0.41389843 || Val it_count: 1107 || Current Learning Rate: 1e-05 || Time: 10:31:54.84
Epoch :: 71 || Loss: 0.40884160 || it_count: 8344 || Val Loss: 0.41388752 || Val it_count: 1107 || Current Learning Rate: 1e-05 || Time: 10:40:57.61
Epoch :: 72 || Loss: 0.40881420 || it_count: 8344 || Val Loss: 0.41389331 || Val it_count: 1107 || Current Learning Rate: 1e-05 || Time: 10:50:0.11
Epoch :: 73 || Loss: 0.40877142 || it_count: 8344 || Val Loss: 0.41390678 || Val it_count: 1107 || Current Learning Rate: 1e-05 || Time: 10:59:2.80
Epoch 00058: reducing learning rate of group 0 to 1.0000e-06.
Epoch :: 74 || Loss: 0.40871711 || it_count: 8344 || Val Loss: 0.41388022 || Val it_count: 1107 || Current Learning Rate: 1.0000000000000002e-06 || Time: 11:08:5.38
Epoch :: 75 || Loss: 0.40913112 || it_count: 8344 || Val Loss: 0.41280079 || Val it_count: 1107 || Current Learning Rate: 1.0000000000000002e-06 || Time: 11:17:9.05
Epoch :: 76 || Loss: 0.40893977 || it_count: 8344 || Val Loss: 0.41269695 || Val it_count: 1107 || Current Learning Rate: 1.0000000000000002e-06 || Time: 11:26:12.41
Epoch :: 77 || Loss: 0.40890070 || it_count: 8344 || Val Loss: 0.41266223 || Val it_count: 1107 || Current Learning Rate: 1.0000000000000002e-06 || Time: 11:35:15.82
Epoch :: 78 || Loss: 0.40888948 || it_count: 8344 || Val Loss: 0.41264955 || Val it_count: 1107 || Current Learning Rate: 1.0000000000000002e-06 || Time: 11:44:19.74
Epoch :: 79 || Loss: 0.40885839 || it_count: 8344 || Val Loss: 0.41264537 || Val it_count: 1107 || Current Learning Rate: 1.0000000000000002e-06 || Time: 11:53:22.88
Epoch :: 80 || Loss: 0.40889765 || it_count: 8344 || Val Loss: 0.41264530 || Val it_count: 1107 || Current Learning Rate: 1.0000000000000002e-06 || Time: 12:02:26.08
Epoch :: 81 || Loss: 0.40883150 || it_count: 8344 || Val Loss: 0.41263234 || Val it_count: 1107 || Current Learning Rate: 1.0000000000000002e-06 || Time: 12:11:28.41
Epoch :: 82 || Loss: 0.40887936 || it_count: 8344 || Val Loss: 0.41263247 || Val it_count: 1107 || Current Learning Rate: 1.0000000000000002e-06 || Time: 12:20:32.36
Epoch :: 83 || Loss: 0.40883759 || it_count: 8344 || Val Loss: 0.41262775 || Val it_count: 1107 || Current Learning Rate: 1.0000000000000002e-06 || Time: 12:29:36.07
Epoch 00068: reducing learning rate of group 0 to 1.0000e-07.
Early stopping triggered due to learning rate below threshold.
Done Total time: 12:38:40.57
best_loss: 0.41262775454606815

--------------------Testing--------------------

total_samples :: test_dataset = 139200, test_dataloader = 139200
Epoch ::  1 || Loss: 0.23694644 || it_count: 544 || Time: 00:00:23.69
MAE:  0.25464842
MSE:  0.23696446
RMSE:  0.442575

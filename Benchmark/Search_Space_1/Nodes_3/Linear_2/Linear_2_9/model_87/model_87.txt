--------------------Training--------------------
arch_str :: |none~0|+|lstm_3~0|lstm_2~1|[relu->linear->linear]
model :: 3M
InferCell(
  info :: nodes=3, inC=1, outC=64, [1<-(I0-L0) | 2<-(I0-L1,I1-L2)], genotype_str: none~0|lstm_3~0|lstm_2~1
  linear_layers: [relu->linear->linear]
  (layers): ModuleList(
    (0): Zero(C_in=1, C_out=64, stride=1)
    (1): LSTM(
      (lstm): LSTM(1, 64, num_layers=3, batch_first=True)
    )
    (2): LSTM(
      (lstm): LSTM(64, 64, num_layers=2, batch_first=True)
    )
  )
  (linear_layers): ModuleList(
    (0): ReLU()
    (1): Linear(in_features=3072, out_features=1536, bias=True)
    (2): Linear(in_features=1536, out_features=1, bias=True)
  )
)
tr_params :: epochs = 100, patience = 20, batch_size = 256, window_size = 48, data_size = 100
Model MACs: 12.056M, Model Params: 4.872M
learning rate scheduling :: (optimizer, mode='min', factor=0.1, patience=5, verbose=True)
total_samples :: train_dataset = 2136000, train_dataloader = 2136000
total_samples :: valid_dataset = 283200, valid_dataloader = 283200
Epoch ::  1 || Loss: 0.42553921 || it_count: 8344 || Val Loss: 0.46280822 || Val it_count: 1107 || Current Learning Rate: 0.001 || Time: 00:11:7.32
Epoch ::  2 || Loss: 0.41775409 || it_count: 8344 || Val Loss: 0.45765597 || Val it_count: 1107 || Current Learning Rate: 0.001 || Time: 00:21:45.54
Epoch ::  3 || Loss: 0.41702475 || it_count: 8344 || Val Loss: 0.45528572 || Val it_count: 1107 || Current Learning Rate: 0.001 || Time: 00:32:19.98
Epoch ::  4 || Loss: 0.41653495 || it_count: 8344 || Val Loss: 0.45558787 || Val it_count: 1107 || Current Learning Rate: 0.001 || Time: 00:42:56.27
Epoch ::  5 || Loss: 0.41633475 || it_count: 8344 || Val Loss: 0.45587100 || Val it_count: 1107 || Current Learning Rate: 0.001 || Time: 00:53:30.78
Epoch ::  6 || Loss: 0.41602890 || it_count: 8344 || Val Loss: 0.45490282 || Val it_count: 1107 || Current Learning Rate: 0.001 || Time: 01:04:19.47
Epoch ::  7 || Loss: 0.41536747 || it_count: 8344 || Val Loss: 0.45360670 || Val it_count: 1107 || Current Learning Rate: 0.001 || Time: 01:14:59.24
Epoch ::  8 || Loss: 0.41497723 || it_count: 8344 || Val Loss: 0.45383665 || Val it_count: 1107 || Current Learning Rate: 0.001 || Time: 01:25:47.20
Epoch ::  9 || Loss: 0.41501220 || it_count: 8344 || Val Loss: 0.45379900 || Val it_count: 1107 || Current Learning Rate: 0.001 || Time: 01:36:38.46
Epoch :: 10 || Loss: 0.41475034 || it_count: 8344 || Val Loss: 0.45327900 || Val it_count: 1107 || Current Learning Rate: 0.001 || Time: 01:47:25.85
Epoch :: 11 || Loss: 0.41444946 || it_count: 8344 || Val Loss: 0.45361796 || Val it_count: 1107 || Current Learning Rate: 0.001 || Time: 01:58:18.58
Epoch :: 12 || Loss: 0.41485681 || it_count: 8344 || Val Loss: 0.45337375 || Val it_count: 1107 || Current Learning Rate: 0.001 || Time: 02:09:10.49
Epoch :: 13 || Loss: 0.41413448 || it_count: 8344 || Val Loss: 0.45286393 || Val it_count: 1107 || Current Learning Rate: 0.001 || Time: 02:20:6.72
Epoch :: 14 || Loss: 0.41416077 || it_count: 8344 || Val Loss: 0.45248712 || Val it_count: 1107 || Current Learning Rate: 0.001 || Time: 02:31:7.36
Epoch :: 15 || Loss: 0.41375912 || it_count: 8344 || Val Loss: 0.45236690 || Val it_count: 1107 || Current Learning Rate: 0.001 || Time: 02:42:10.52
Epoch :: 16 || Loss: 0.41389570 || it_count: 8344 || Val Loss: 0.45304004 || Val it_count: 1107 || Current Learning Rate: 0.001 || Time: 02:53:13.13
Epoch :: 17 || Loss: 0.41453196 || it_count: 8344 || Val Loss: 0.45764349 || Val it_count: 1107 || Current Learning Rate: 0.001 || Time: 03:04:22.80
Epoch :: 18 || Loss: 0.41379722 || it_count: 8344 || Val Loss: 0.45114463 || Val it_count: 1107 || Current Learning Rate: 0.001 || Time: 03:15:31.58
Epoch :: 19 || Loss: 0.41301638 || it_count: 8344 || Val Loss: 0.45232190 || Val it_count: 1107 || Current Learning Rate: 0.001 || Time: 03:26:35.40
Epoch :: 20 || Loss: 0.41258507 || it_count: 8344 || Val Loss: 0.44927484 || Val it_count: 1107 || Current Learning Rate: 0.001 || Time: 03:37:34.59
Epoch :: 21 || Loss: 0.41241695 || it_count: 8344 || Val Loss: 0.45161332 || Val it_count: 1107 || Current Learning Rate: 0.001 || Time: 03:48:35.81
Epoch :: 22 || Loss: 0.41166790 || it_count: 8344 || Val Loss: 0.44909760 || Val it_count: 1107 || Current Learning Rate: 0.001 || Time: 03:59:40.90
Epoch :: 23 || Loss: 0.41135348 || it_count: 8344 || Val Loss: 0.45010386 || Val it_count: 1107 || Current Learning Rate: 0.001 || Time: 04:10:41.63
Epoch :: 24 || Loss: 0.41106800 || it_count: 8344 || Val Loss: 0.44957132 || Val it_count: 1107 || Current Learning Rate: 0.001 || Time: 04:21:43.69
Epoch :: 25 || Loss: 0.41097078 || it_count: 8344 || Val Loss: 0.44885548 || Val it_count: 1107 || Current Learning Rate: 0.001 || Time: 04:32:52.58
Epoch :: 26 || Loss: 0.41083284 || it_count: 8344 || Val Loss: 0.44880303 || Val it_count: 1107 || Current Learning Rate: 0.001 || Time: 04:43:58.97
Epoch :: 27 || Loss: 0.41061987 || it_count: 8344 || Val Loss: 0.44846657 || Val it_count: 1107 || Current Learning Rate: 0.001 || Time: 04:55:3.01
Epoch :: 28 || Loss: 0.41033377 || it_count: 8344 || Val Loss: 0.44701653 || Val it_count: 1107 || Current Learning Rate: 0.001 || Time: 05:06:15.13
Epoch :: 29 || Loss: 0.40964965 || it_count: 8344 || Val Loss: 0.44743440 || Val it_count: 1107 || Current Learning Rate: 0.001 || Time: 05:17:24.88
Epoch :: 30 || Loss: 0.40906634 || it_count: 8344 || Val Loss: 0.44921171 || Val it_count: 1107 || Current Learning Rate: 0.001 || Time: 05:28:35.32
Epoch :: 31 || Loss: 0.40871860 || it_count: 8344 || Val Loss: 0.44850970 || Val it_count: 1107 || Current Learning Rate: 0.001 || Time: 05:39:43.99
Epoch :: 32 || Loss: 0.40847613 || it_count: 8344 || Val Loss: 0.45239647 || Val it_count: 1107 || Current Learning Rate: 0.001 || Time: 05:50:56.10
Epoch :: 33 || Loss: 0.40809325 || it_count: 8344 || Val Loss: 0.44582921 || Val it_count: 1107 || Current Learning Rate: 0.001 || Time: 06:02:8.86
Epoch :: 34 || Loss: 0.40752534 || it_count: 8344 || Val Loss: 0.44589634 || Val it_count: 1107 || Current Learning Rate: 0.001 || Time: 06:13:22.35
Epoch :: 35 || Loss: 0.40744142 || it_count: 8344 || Val Loss: 0.44562325 || Val it_count: 1107 || Current Learning Rate: 0.001 || Time: 06:24:31.10
Epoch :: 36 || Loss: 0.40756649 || it_count: 8344 || Val Loss: 0.44504672 || Val it_count: 1107 || Current Learning Rate: 0.001 || Time: 06:35:42.68
Epoch :: 37 || Loss: 0.40708804 || it_count: 8344 || Val Loss: 0.44720592 || Val it_count: 1107 || Current Learning Rate: 0.001 || Time: 06:46:54.12
Epoch :: 38 || Loss: 0.40702163 || it_count: 8344 || Val Loss: 0.44648847 || Val it_count: 1107 || Current Learning Rate: 0.001 || Time: 06:58:5.04
Epoch :: 39 || Loss: 0.40648952 || it_count: 8344 || Val Loss: 0.44707001 || Val it_count: 1107 || Current Learning Rate: 0.001 || Time: 07:09:21.94
Epoch :: 40 || Loss: 0.40620584 || it_count: 8344 || Val Loss: 0.44607218 || Val it_count: 1107 || Current Learning Rate: 0.001 || Time: 07:20:38.72
Epoch :: 41 || Loss: 0.40593968 || it_count: 8344 || Val Loss: 0.44925772 || Val it_count: 1107 || Current Learning Rate: 0.001 || Time: 07:31:52.31
Epoch 00026: reducing learning rate of group 0 to 1.0000e-04.
Epoch :: 42 || Loss: 0.40590306 || it_count: 8344 || Val Loss: 0.44653989 || Val it_count: 1107 || Current Learning Rate: 0.0001 || Time: 07:43:8.11
Epoch :: 43 || Loss: 0.41154149 || it_count: 8344 || Val Loss: 0.43097039 || Val it_count: 1107 || Current Learning Rate: 0.0001 || Time: 07:54:23.00
Epoch :: 44 || Loss: 0.40907417 || it_count: 8344 || Val Loss: 0.42956809 || Val it_count: 1107 || Current Learning Rate: 0.0001 || Time: 08:05:20.85
Epoch :: 45 || Loss: 0.40818919 || it_count: 8344 || Val Loss: 0.42936952 || Val it_count: 1107 || Current Learning Rate: 0.0001 || Time: 08:16:12.13
Epoch :: 46 || Loss: 0.40759737 || it_count: 8344 || Val Loss: 0.42903087 || Val it_count: 1107 || Current Learning Rate: 0.0001 || Time: 08:27:9.52
Epoch :: 47 || Loss: 0.40710913 || it_count: 8344 || Val Loss: 0.42857573 || Val it_count: 1107 || Current Learning Rate: 0.0001 || Time: 08:38:15.15
Epoch :: 48 || Loss: 0.40665980 || it_count: 8344 || Val Loss: 0.42795764 || Val it_count: 1107 || Current Learning Rate: 0.0001 || Time: 08:49:58.47
Epoch :: 49 || Loss: 0.40628311 || it_count: 8344 || Val Loss: 0.42723711 || Val it_count: 1107 || Current Learning Rate: 0.0001 || Time: 09:02:17.47
Epoch :: 50 || Loss: 0.40592886 || it_count: 8344 || Val Loss: 0.42687010 || Val it_count: 1107 || Current Learning Rate: 0.0001 || Time: 09:14:13.97
Epoch :: 51 || Loss: 0.40564046 || it_count: 8344 || Val Loss: 0.42665427 || Val it_count: 1107 || Current Learning Rate: 0.0001 || Time: 09:25:19.31
Epoch :: 52 || Loss: 0.40535530 || it_count: 8344 || Val Loss: 0.42623271 || Val it_count: 1107 || Current Learning Rate: 0.0001 || Time: 09:36:38.66
Epoch :: 53 || Loss: 0.40503156 || it_count: 8344 || Val Loss: 0.42629004 || Val it_count: 1107 || Current Learning Rate: 0.0001 || Time: 09:48:12.34
Epoch :: 54 || Loss: 0.40478119 || it_count: 8344 || Val Loss: 0.42635769 || Val it_count: 1107 || Current Learning Rate: 0.0001 || Time: 09:59:34.99
Epoch :: 55 || Loss: 0.40450984 || it_count: 8344 || Val Loss: 0.42630516 || Val it_count: 1107 || Current Learning Rate: 0.0001 || Time: 10:11:19.29
Epoch :: 56 || Loss: 0.40423336 || it_count: 8344 || Val Loss: 0.42627059 || Val it_count: 1107 || Current Learning Rate: 0.0001 || Time: 10:23:2.67
Epoch :: 57 || Loss: 0.40396148 || it_count: 8344 || Val Loss: 0.42623327 || Val it_count: 1107 || Current Learning Rate: 0.0001 || Time: 10:34:40.24
Epoch 00042: reducing learning rate of group 0 to 1.0000e-05.
Epoch :: 58 || Loss: 0.40369638 || it_count: 8344 || Val Loss: 0.42667162 || Val it_count: 1107 || Current Learning Rate: 1e-05 || Time: 10:46:38.88
Epoch :: 59 || Loss: 0.40894569 || it_count: 8344 || Val Loss: 0.41249645 || Val it_count: 1107 || Current Learning Rate: 1e-05 || Time: 10:58:27.95
Epoch :: 60 || Loss: 0.40641242 || it_count: 8344 || Val Loss: 0.41223065 || Val it_count: 1107 || Current Learning Rate: 1e-05 || Time: 11:09:58.75
Epoch :: 61 || Loss: 0.40620101 || it_count: 8344 || Val Loss: 0.41208296 || Val it_count: 1107 || Current Learning Rate: 1e-05 || Time: 11:21:31.56
Epoch :: 62 || Loss: 0.40604541 || it_count: 8344 || Val Loss: 0.41202659 || Val it_count: 1107 || Current Learning Rate: 1e-05 || Time: 11:32:58.84
Epoch :: 63 || Loss: 0.40594001 || it_count: 8344 || Val Loss: 0.41201310 || Val it_count: 1107 || Current Learning Rate: 1e-05 || Time: 11:44:9.79
Epoch :: 64 || Loss: 0.40585028 || it_count: 8344 || Val Loss: 0.41200434 || Val it_count: 1107 || Current Learning Rate: 1e-05 || Time: 11:55:25.72
Epoch :: 65 || Loss: 0.40577523 || it_count: 8344 || Val Loss: 0.41201379 || Val it_count: 1107 || Current Learning Rate: 1e-05 || Time: 12:06:25.49
Epoch :: 66 || Loss: 0.40570430 || it_count: 8344 || Val Loss: 0.41203334 || Val it_count: 1107 || Current Learning Rate: 1e-05 || Time: 12:17:21.45
Epoch :: 67 || Loss: 0.40563584 || it_count: 8344 || Val Loss: 0.41204786 || Val it_count: 1107 || Current Learning Rate: 1e-05 || Time: 12:28:28.07
Epoch 00052: reducing learning rate of group 0 to 1.0000e-06.
Epoch :: 68 || Loss: 0.40557274 || it_count: 8344 || Val Loss: 0.41207118 || Val it_count: 1107 || Current Learning Rate: 1.0000000000000002e-06 || Time: 12:39:34.40
Epoch :: 69 || Loss: 0.40597864 || it_count: 8344 || Val Loss: 0.41127768 || Val it_count: 1107 || Current Learning Rate: 1.0000000000000002e-06 || Time: 12:50:39.84
Epoch :: 70 || Loss: 0.40574999 || it_count: 8344 || Val Loss: 0.41114305 || Val it_count: 1107 || Current Learning Rate: 1.0000000000000002e-06 || Time: 13:01:38.31
Epoch :: 71 || Loss: 0.40567826 || it_count: 8344 || Val Loss: 0.41109563 || Val it_count: 1107 || Current Learning Rate: 1.0000000000000002e-06 || Time: 13:12:42.37
Epoch :: 72 || Loss: 0.40564265 || it_count: 8344 || Val Loss: 0.41106871 || Val it_count: 1107 || Current Learning Rate: 1.0000000000000002e-06 || Time: 13:23:38.57
Epoch :: 73 || Loss: 0.40561807 || it_count: 8344 || Val Loss: 0.41105224 || Val it_count: 1107 || Current Learning Rate: 1.0000000000000002e-06 || Time: 13:34:33.93
Epoch :: 74 || Loss: 0.40559871 || it_count: 8344 || Val Loss: 0.41103851 || Val it_count: 1107 || Current Learning Rate: 1.0000000000000002e-06 || Time: 13:45:26.80
Epoch :: 75 || Loss: 0.40558242 || it_count: 8344 || Val Loss: 0.41102726 || Val it_count: 1107 || Current Learning Rate: 1.0000000000000002e-06 || Time: 13:56:18.38
Epoch :: 76 || Loss: 0.40556828 || it_count: 8344 || Val Loss: 0.41101771 || Val it_count: 1107 || Current Learning Rate: 1.0000000000000002e-06 || Time: 14:07:8.90
Epoch :: 77 || Loss: 0.40555555 || it_count: 8344 || Val Loss: 0.41100927 || Val it_count: 1107 || Current Learning Rate: 1.0000000000000002e-06 || Time: 14:18:4.73
Epoch :: 78 || Loss: 0.40554409 || it_count: 8344 || Val Loss: 0.41100171 || Val it_count: 1107 || Current Learning Rate: 1.0000000000000002e-06 || Time: 14:29:3.40
Epoch :: 79 || Loss: 0.40553353 || it_count: 8344 || Val Loss: 0.41099519 || Val it_count: 1107 || Current Learning Rate: 1.0000000000000002e-06 || Time: 14:40:4.11
Epoch :: 80 || Loss: 0.40552350 || it_count: 8344 || Val Loss: 0.41098911 || Val it_count: 1107 || Current Learning Rate: 1.0000000000000002e-06 || Time: 14:51:5.39
Epoch :: 81 || Loss: 0.40551397 || it_count: 8344 || Val Loss: 0.41098369 || Val it_count: 1107 || Current Learning Rate: 1.0000000000000002e-06 || Time: 15:02:8.13
Epoch :: 82 || Loss: 0.40550495 || it_count: 8344 || Val Loss: 0.41097864 || Val it_count: 1107 || Current Learning Rate: 1.0000000000000002e-06 || Time: 15:13:13.01
Epoch 00067: reducing learning rate of group 0 to 1.0000e-07.
Early stopping triggered due to learning rate below threshold.
Done Total time: 15:24:22.26
best_loss: 0.41097864073965173

--------------------Testing--------------------

total_samples :: test_dataset = 139200, test_dataloader = 139200
Epoch ::  1 || Loss: 0.23625438 || it_count: 544 || Time: 00:00:24.90
MAE:  0.2524527
MSE:  0.23627408
RMSE:  0.44176432

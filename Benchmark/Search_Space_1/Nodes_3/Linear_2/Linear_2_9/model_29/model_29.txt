--------------------Training--------------------
arch_str :: |lstm_2~0|+|lstm_1~0|none~1|[relu->linear->linear]
model :: 3M
InferCell(
  info :: nodes=3, inC=1, outC=64, [1<-(I0-L0) | 2<-(I0-L1,I1-L2)], genotype_str: lstm_2~0|lstm_1~0|none~1
  linear_layers: [relu->linear->linear]
  (layers): ModuleList(
    (0): LSTM(
      (lstm): LSTM(1, 64, num_layers=2, batch_first=True)
    )
    (1): LSTM(
      (lstm): LSTM(1, 64, batch_first=True)
    )
    (2): Zero(C_in=64, C_out=64, stride=1)
  )
  (linear_layers): ModuleList(
    (0): ReLU()
    (1): Linear(in_features=3072, out_features=1536, bias=True)
    (2): Linear(in_features=1536, out_features=1, bias=True)
  )
)
tr_params :: epochs = 100, patience = 20, batch_size = 256, window_size = 48, data_size = 100
Model MACs: 8.038M, Model Params: 4.789M
learning rate scheduling :: (optimizer, mode='min', factor=0.1, patience=5, verbose=True)
total_samples :: train_dataset = 2136000, train_dataloader = 2136000
total_samples :: valid_dataset = 283200, valid_dataloader = 283200
Epoch ::  1 || Loss: 0.42095201 || it_count: 8344 || Val Loss: 0.45190320 || Val it_count: 1107 || Current Learning Rate: 0.001 || Time: 00:07:56.95
Epoch ::  2 || Loss: 0.41747205 || it_count: 8344 || Val Loss: 0.44968673 || Val it_count: 1107 || Current Learning Rate: 0.001 || Time: 00:15:50.79
Epoch ::  3 || Loss: 0.41739555 || it_count: 8344 || Val Loss: 0.44866223 || Val it_count: 1107 || Current Learning Rate: 0.001 || Time: 00:23:43.75
Epoch ::  4 || Loss: 0.41712772 || it_count: 8344 || Val Loss: 0.44665995 || Val it_count: 1107 || Current Learning Rate: 0.001 || Time: 00:31:38.14
Epoch ::  5 || Loss: 0.41659425 || it_count: 8344 || Val Loss: 0.44608527 || Val it_count: 1107 || Current Learning Rate: 0.001 || Time: 00:39:32.36
Epoch ::  6 || Loss: 0.41626953 || it_count: 8344 || Val Loss: 0.44516629 || Val it_count: 1107 || Current Learning Rate: 0.001 || Time: 00:47:27.89
Epoch ::  7 || Loss: 0.41600241 || it_count: 8344 || Val Loss: 0.44511999 || Val it_count: 1107 || Current Learning Rate: 0.001 || Time: 00:55:22.59
Epoch ::  8 || Loss: 0.41569754 || it_count: 8344 || Val Loss: 0.44458521 || Val it_count: 1107 || Current Learning Rate: 0.001 || Time: 01:03:18.64
Epoch ::  9 || Loss: 0.41565250 || it_count: 8344 || Val Loss: 0.44506217 || Val it_count: 1107 || Current Learning Rate: 0.001 || Time: 01:11:14.03
Epoch :: 10 || Loss: 0.41533084 || it_count: 8344 || Val Loss: 0.44438360 || Val it_count: 1107 || Current Learning Rate: 0.001 || Time: 01:19:9.52
Epoch :: 11 || Loss: 0.41504801 || it_count: 8344 || Val Loss: 0.44514556 || Val it_count: 1107 || Current Learning Rate: 0.001 || Time: 01:27:5.54
Epoch :: 12 || Loss: 0.41473272 || it_count: 8344 || Val Loss: 0.44453743 || Val it_count: 1107 || Current Learning Rate: 0.001 || Time: 01:35:1.25
Epoch :: 13 || Loss: 0.41433922 || it_count: 8344 || Val Loss: 0.44429375 || Val it_count: 1107 || Current Learning Rate: 0.001 || Time: 01:42:56.78
Epoch :: 14 || Loss: 0.41413360 || it_count: 8344 || Val Loss: 0.44423545 || Val it_count: 1107 || Current Learning Rate: 0.001 || Time: 01:50:52.16
Epoch :: 15 || Loss: 0.41397135 || it_count: 8344 || Val Loss: 0.44418348 || Val it_count: 1107 || Current Learning Rate: 0.001 || Time: 01:58:47.17
Epoch :: 16 || Loss: 0.41400067 || it_count: 8344 || Val Loss: 0.44355693 || Val it_count: 1107 || Current Learning Rate: 0.001 || Time: 02:06:43.44
Epoch :: 17 || Loss: 0.41361290 || it_count: 8344 || Val Loss: 0.44262904 || Val it_count: 1107 || Current Learning Rate: 0.001 || Time: 02:14:39.55
Epoch :: 18 || Loss: 0.41338724 || it_count: 8344 || Val Loss: 0.44260039 || Val it_count: 1107 || Current Learning Rate: 0.001 || Time: 02:22:37.07
Epoch :: 19 || Loss: 0.41330035 || it_count: 8344 || Val Loss: 0.44225370 || Val it_count: 1107 || Current Learning Rate: 0.001 || Time: 02:30:33.48
Epoch :: 20 || Loss: 0.41327809 || it_count: 8344 || Val Loss: 0.44303780 || Val it_count: 1107 || Current Learning Rate: 0.001 || Time: 02:38:30.71
Epoch :: 21 || Loss: 0.41314170 || it_count: 8344 || Val Loss: 0.44273570 || Val it_count: 1107 || Current Learning Rate: 0.001 || Time: 02:46:30.38
Epoch :: 22 || Loss: 0.41309168 || it_count: 8344 || Val Loss: 0.44317413 || Val it_count: 1107 || Current Learning Rate: 0.001 || Time: 02:54:28.87
Epoch :: 23 || Loss: 0.41291762 || it_count: 8344 || Val Loss: 0.44263025 || Val it_count: 1107 || Current Learning Rate: 0.001 || Time: 03:02:26.82
Epoch :: 24 || Loss: 0.41271926 || it_count: 8344 || Val Loss: 0.44375507 || Val it_count: 1107 || Current Learning Rate: 0.001 || Time: 03:10:23.13
Epoch 00009: reducing learning rate of group 0 to 1.0000e-04.
Epoch :: 25 || Loss: 0.41242986 || it_count: 8344 || Val Loss: 0.44393501 || Val it_count: 1107 || Current Learning Rate: 0.0001 || Time: 03:18:19.55
Epoch :: 26 || Loss: 0.41915581 || it_count: 8344 || Val Loss: 0.43543884 || Val it_count: 1107 || Current Learning Rate: 0.0001 || Time: 03:26:17.42
Epoch :: 27 || Loss: 0.41723111 || it_count: 8344 || Val Loss: 0.43379430 || Val it_count: 1107 || Current Learning Rate: 0.0001 || Time: 03:34:14.84
Epoch :: 28 || Loss: 0.41656729 || it_count: 8344 || Val Loss: 0.43293094 || Val it_count: 1107 || Current Learning Rate: 0.0001 || Time: 03:42:13.05
Epoch :: 29 || Loss: 0.41618388 || it_count: 8344 || Val Loss: 0.43261918 || Val it_count: 1107 || Current Learning Rate: 0.0001 || Time: 03:50:7.96
Epoch :: 30 || Loss: 0.41588844 || it_count: 8344 || Val Loss: 0.43254446 || Val it_count: 1107 || Current Learning Rate: 0.0001 || Time: 03:58:3.32
Epoch :: 31 || Loss: 0.41566729 || it_count: 8344 || Val Loss: 0.43235200 || Val it_count: 1107 || Current Learning Rate: 0.0001 || Time: 04:05:58.01
Epoch :: 32 || Loss: 0.41545473 || it_count: 8344 || Val Loss: 0.43236095 || Val it_count: 1107 || Current Learning Rate: 0.0001 || Time: 04:13:53.64
Epoch :: 33 || Loss: 0.41524180 || it_count: 8344 || Val Loss: 0.43240315 || Val it_count: 1107 || Current Learning Rate: 0.0001 || Time: 04:21:49.60
Epoch :: 34 || Loss: 0.41506044 || it_count: 8344 || Val Loss: 0.43238553 || Val it_count: 1107 || Current Learning Rate: 0.0001 || Time: 04:29:44.94
Epoch :: 35 || Loss: 0.41489775 || it_count: 8344 || Val Loss: 0.43250837 || Val it_count: 1107 || Current Learning Rate: 0.0001 || Time: 04:37:40.23
Epoch :: 36 || Loss: 0.41475298 || it_count: 8344 || Val Loss: 0.43259393 || Val it_count: 1107 || Current Learning Rate: 0.0001 || Time: 04:45:34.05
Epoch 00021: reducing learning rate of group 0 to 1.0000e-05.
Epoch :: 37 || Loss: 0.41464160 || it_count: 8344 || Val Loss: 0.43266421 || Val it_count: 1107 || Current Learning Rate: 1e-05 || Time: 04:53:30.33
Epoch :: 38 || Loss: 0.41832407 || it_count: 8344 || Val Loss: 0.42206161 || Val it_count: 1107 || Current Learning Rate: 1e-05 || Time: 05:01:24.61
Epoch :: 39 || Loss: 0.41653747 || it_count: 8344 || Val Loss: 0.42119060 || Val it_count: 1107 || Current Learning Rate: 1e-05 || Time: 05:09:20.05
Epoch :: 40 || Loss: 0.41611046 || it_count: 8344 || Val Loss: 0.42081832 || Val it_count: 1107 || Current Learning Rate: 1e-05 || Time: 05:17:15.84
Epoch :: 41 || Loss: 0.41586827 || it_count: 8344 || Val Loss: 0.42059603 || Val it_count: 1107 || Current Learning Rate: 1e-05 || Time: 05:25:11.09
Epoch :: 42 || Loss: 0.41570650 || it_count: 8344 || Val Loss: 0.42045946 || Val it_count: 1107 || Current Learning Rate: 1e-05 || Time: 05:33:6.72
Epoch :: 43 || Loss: 0.41558876 || it_count: 8344 || Val Loss: 0.42036630 || Val it_count: 1107 || Current Learning Rate: 1e-05 || Time: 05:41:4.24
Epoch :: 44 || Loss: 0.41550031 || it_count: 8344 || Val Loss: 0.42032326 || Val it_count: 1107 || Current Learning Rate: 1e-05 || Time: 05:49:2.44
Epoch :: 45 || Loss: 0.41543059 || it_count: 8344 || Val Loss: 0.42030053 || Val it_count: 1107 || Current Learning Rate: 1e-05 || Time: 05:56:58.15
Epoch :: 46 || Loss: 0.41537397 || it_count: 8344 || Val Loss: 0.42026688 || Val it_count: 1107 || Current Learning Rate: 1e-05 || Time: 06:04:54.75
Epoch :: 47 || Loss: 0.41532595 || it_count: 8344 || Val Loss: 0.42024006 || Val it_count: 1107 || Current Learning Rate: 1e-05 || Time: 06:12:51.42
Epoch :: 48 || Loss: 0.41529804 || it_count: 8344 || Val Loss: 0.42021007 || Val it_count: 1107 || Current Learning Rate: 1e-05 || Time: 06:20:47.70
Epoch :: 49 || Loss: 0.41526287 || it_count: 8344 || Val Loss: 0.42020103 || Val it_count: 1107 || Current Learning Rate: 1e-05 || Time: 06:28:44.88
Epoch :: 50 || Loss: 0.41522767 || it_count: 8344 || Val Loss: 0.42022589 || Val it_count: 1107 || Current Learning Rate: 1e-05 || Time: 06:36:42.58
Epoch :: 51 || Loss: 0.41520348 || it_count: 8344 || Val Loss: 0.42024006 || Val it_count: 1107 || Current Learning Rate: 1e-05 || Time: 06:44:38.85
Epoch :: 52 || Loss: 0.41518113 || it_count: 8344 || Val Loss: 0.42025957 || Val it_count: 1107 || Current Learning Rate: 1e-05 || Time: 06:52:36.32
Epoch :: 53 || Loss: 0.41515040 || it_count: 8344 || Val Loss: 0.42029537 || Val it_count: 1107 || Current Learning Rate: 1e-05 || Time: 07:00:34.12
Epoch 00038: reducing learning rate of group 0 to 1.0000e-06.
Epoch :: 54 || Loss: 0.41514272 || it_count: 8344 || Val Loss: 0.42029820 || Val it_count: 1107 || Current Learning Rate: 1.0000000000000002e-06 || Time: 07:08:31.22
Epoch :: 55 || Loss: 0.41553030 || it_count: 8344 || Val Loss: 0.41930363 || Val it_count: 1107 || Current Learning Rate: 1.0000000000000002e-06 || Time: 07:16:28.67
Epoch :: 56 || Loss: 0.41534893 || it_count: 8344 || Val Loss: 0.41911952 || Val it_count: 1107 || Current Learning Rate: 1.0000000000000002e-06 || Time: 07:24:26.71
Epoch :: 57 || Loss: 0.41528475 || it_count: 8344 || Val Loss: 0.41902350 || Val it_count: 1107 || Current Learning Rate: 1.0000000000000002e-06 || Time: 07:32:26.06
Epoch :: 58 || Loss: 0.41525023 || it_count: 8344 || Val Loss: 0.41896807 || Val it_count: 1107 || Current Learning Rate: 1.0000000000000002e-06 || Time: 07:40:21.32
Epoch :: 59 || Loss: 0.41522888 || it_count: 8344 || Val Loss: 0.41893513 || Val it_count: 1107 || Current Learning Rate: 1.0000000000000002e-06 || Time: 07:48:16.75
Epoch :: 60 || Loss: 0.41521425 || it_count: 8344 || Val Loss: 0.41891496 || Val it_count: 1107 || Current Learning Rate: 1.0000000000000002e-06 || Time: 07:56:13.77
Epoch :: 61 || Loss: 0.41520295 || it_count: 8344 || Val Loss: 0.41890189 || Val it_count: 1107 || Current Learning Rate: 1.0000000000000002e-06 || Time: 08:04:9.43
Epoch :: 62 || Loss: 0.41519418 || it_count: 8344 || Val Loss: 0.41889307 || Val it_count: 1107 || Current Learning Rate: 1.0000000000000002e-06 || Time: 08:12:6.22
Epoch :: 63 || Loss: 0.41518692 || it_count: 8344 || Val Loss: 0.41888694 || Val it_count: 1107 || Current Learning Rate: 1.0000000000000002e-06 || Time: 08:20:2.52
Epoch :: 64 || Loss: 0.41518069 || it_count: 8344 || Val Loss: 0.41888263 || Val it_count: 1107 || Current Learning Rate: 1.0000000000000002e-06 || Time: 08:27:59.83
Epoch :: 65 || Loss: 0.41517568 || it_count: 8344 || Val Loss: 0.41887872 || Val it_count: 1107 || Current Learning Rate: 1.0000000000000002e-06 || Time: 08:35:57.72
Epoch 00050: reducing learning rate of group 0 to 1.0000e-07.
Early stopping triggered due to learning rate below threshold.
Done Total time: 08:43:54.81
best_loss: 0.41887871532091303

--------------------Testing--------------------

total_samples :: test_dataset = 139200, test_dataloader = 139200
Epoch ::  1 || Loss: 0.24410726 || it_count: 544 || Time: 00:00:22.13
MAE:  0.25964317
MSE:  0.2441287
RMSE:  0.4483365

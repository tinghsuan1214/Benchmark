--------------------Training--------------------
arch_str :: |none~0|+|lstm_1~0|lstm_3~1|[relu->linear->linear]
model :: 3M
InferCell(
  info :: nodes=3, inC=1, outC=64, [1<-(I0-L0) | 2<-(I0-L1,I1-L2)], genotype_str: none~0|lstm_1~0|lstm_3~1
  linear_layers: [relu->linear->linear]
  (layers): ModuleList(
    (0): Zero(C_in=1, C_out=64, stride=1)
    (1): LSTM(
      (lstm): LSTM(1, 64, batch_first=True)
    )
    (2): LSTM(
      (lstm): LSTM(64, 64, num_layers=3, batch_first=True)
    )
  )
  (linear_layers): ModuleList(
    (0): ReLU()
    (1): Linear(in_features=3072, out_features=1536, bias=True)
    (2): Linear(in_features=1536, out_features=1, bias=True)
  )
)
tr_params :: epochs = 100, patience = 20, batch_size = 256, window_size = 48, data_size = 100
Model MACs: 10.434M, Model Params: 4.839M
learning rate scheduling :: (optimizer, mode='min', factor=0.1, patience=5, verbose=True)
total_samples :: train_dataset = 2136000, train_dataloader = 2136000
total_samples :: valid_dataset = 283200, valid_dataloader = 283200
Epoch ::  1 || Loss: 0.42082860 || it_count: 8344 || Val Loss: 0.45256795 || Val it_count: 1107 || Current Learning Rate: 0.001 || Time: 00:09:41.02
Epoch ::  2 || Loss: 0.41728613 || it_count: 8344 || Val Loss: 0.45306294 || Val it_count: 1107 || Current Learning Rate: 0.001 || Time: 00:19:21.39
Epoch ::  3 || Loss: 0.41657302 || it_count: 8344 || Val Loss: 0.45446785 || Val it_count: 1107 || Current Learning Rate: 0.001 || Time: 00:29:6.24
Epoch ::  4 || Loss: 0.41630948 || it_count: 8344 || Val Loss: 0.45239771 || Val it_count: 1107 || Current Learning Rate: 0.001 || Time: 00:38:43.46
Epoch ::  5 || Loss: 0.41559093 || it_count: 8344 || Val Loss: 0.45045901 || Val it_count: 1107 || Current Learning Rate: 0.001 || Time: 00:48:25.43
Epoch ::  6 || Loss: 0.41535929 || it_count: 8344 || Val Loss: 0.44920911 || Val it_count: 1107 || Current Learning Rate: 0.001 || Time: 00:58:6.63
Epoch ::  7 || Loss: 0.41481029 || it_count: 8344 || Val Loss: 0.44753480 || Val it_count: 1107 || Current Learning Rate: 0.001 || Time: 01:07:49.07
Epoch ::  8 || Loss: 0.41468789 || it_count: 8344 || Val Loss: 0.44854687 || Val it_count: 1107 || Current Learning Rate: 0.001 || Time: 01:17:34.70
Epoch ::  9 || Loss: 0.41415743 || it_count: 8344 || Val Loss: 0.44905942 || Val it_count: 1107 || Current Learning Rate: 0.001 || Time: 01:27:21.58
Epoch :: 10 || Loss: 0.41384460 || it_count: 8344 || Val Loss: 0.44790993 || Val it_count: 1107 || Current Learning Rate: 0.001 || Time: 01:37:12.88
Epoch :: 11 || Loss: 0.41351323 || it_count: 8344 || Val Loss: 0.44683214 || Val it_count: 1107 || Current Learning Rate: 0.001 || Time: 01:47:8.24
Epoch :: 12 || Loss: 0.41347172 || it_count: 8344 || Val Loss: 0.44607540 || Val it_count: 1107 || Current Learning Rate: 0.001 || Time: 01:57:5.68
Epoch :: 13 || Loss: 0.41315751 || it_count: 8344 || Val Loss: 0.44594567 || Val it_count: 1107 || Current Learning Rate: 0.001 || Time: 02:07:11.99
Epoch :: 14 || Loss: 0.41304070 || it_count: 8344 || Val Loss: 0.44414621 || Val it_count: 1107 || Current Learning Rate: 0.001 || Time: 02:17:15.03
Epoch :: 15 || Loss: 0.41264823 || it_count: 8344 || Val Loss: 0.44315419 || Val it_count: 1107 || Current Learning Rate: 0.001 || Time: 02:27:17.25
Epoch :: 16 || Loss: 0.41262824 || it_count: 8344 || Val Loss: 0.44279783 || Val it_count: 1107 || Current Learning Rate: 0.001 || Time: 02:37:16.91
Epoch :: 17 || Loss: 0.41220978 || it_count: 8344 || Val Loss: 0.44279877 || Val it_count: 1107 || Current Learning Rate: 0.001 || Time: 02:47:11.73
Epoch :: 18 || Loss: 0.41215806 || it_count: 8344 || Val Loss: 0.44226605 || Val it_count: 1107 || Current Learning Rate: 0.001 || Time: 02:57:4.74
Epoch :: 19 || Loss: 0.41204549 || it_count: 8344 || Val Loss: 0.44150197 || Val it_count: 1107 || Current Learning Rate: 0.001 || Time: 03:06:56.45
Epoch :: 20 || Loss: 0.41195162 || it_count: 8344 || Val Loss: 0.44245476 || Val it_count: 1107 || Current Learning Rate: 0.001 || Time: 03:16:50.41
Epoch :: 21 || Loss: 0.41220037 || it_count: 8344 || Val Loss: 0.44321681 || Val it_count: 1107 || Current Learning Rate: 0.001 || Time: 03:26:43.76
Epoch :: 22 || Loss: 0.41164209 || it_count: 8344 || Val Loss: 0.44238287 || Val it_count: 1107 || Current Learning Rate: 0.001 || Time: 03:36:40.43
Epoch :: 23 || Loss: 0.41127528 || it_count: 8344 || Val Loss: 0.44466243 || Val it_count: 1107 || Current Learning Rate: 0.001 || Time: 03:46:30.78
Epoch :: 24 || Loss: 0.41118640 || it_count: 8344 || Val Loss: 0.44153797 || Val it_count: 1107 || Current Learning Rate: 0.001 || Time: 03:56:22.07
Epoch :: 25 || Loss: 0.41065977 || it_count: 8344 || Val Loss: 0.44098192 || Val it_count: 1107 || Current Learning Rate: 0.001 || Time: 04:06:17.65
Epoch :: 26 || Loss: 0.41055552 || it_count: 8344 || Val Loss: 0.44171441 || Val it_count: 1107 || Current Learning Rate: 0.001 || Time: 04:16:11.31
Epoch :: 27 || Loss: 0.41037701 || it_count: 8344 || Val Loss: 0.44058164 || Val it_count: 1107 || Current Learning Rate: 0.001 || Time: 04:26:7.63
Epoch :: 28 || Loss: 0.40988245 || it_count: 8344 || Val Loss: 0.44046948 || Val it_count: 1107 || Current Learning Rate: 0.001 || Time: 04:36:1.19
Epoch :: 29 || Loss: 0.40966515 || it_count: 8344 || Val Loss: 0.43971973 || Val it_count: 1107 || Current Learning Rate: 0.001 || Time: 04:46:0.62
Epoch :: 30 || Loss: 0.40958969 || it_count: 8344 || Val Loss: 0.44072745 || Val it_count: 1107 || Current Learning Rate: 0.001 || Time: 04:56:5.64
Epoch :: 31 || Loss: 0.40908403 || it_count: 8344 || Val Loss: 0.44101338 || Val it_count: 1107 || Current Learning Rate: 0.001 || Time: 05:06:12.25
Epoch :: 32 || Loss: 0.40881161 || it_count: 8344 || Val Loss: 0.44103896 || Val it_count: 1107 || Current Learning Rate: 0.001 || Time: 05:16:11.98
Epoch :: 33 || Loss: 0.40839857 || it_count: 8344 || Val Loss: 0.44196297 || Val it_count: 1107 || Current Learning Rate: 0.001 || Time: 05:26:15.60
Epoch :: 34 || Loss: 0.40820927 || it_count: 8344 || Val Loss: 0.44308791 || Val it_count: 1107 || Current Learning Rate: 0.001 || Time: 05:36:22.20
Epoch 00019: reducing learning rate of group 0 to 1.0000e-04.
Epoch :: 35 || Loss: 0.40793111 || it_count: 8344 || Val Loss: 0.44556369 || Val it_count: 1107 || Current Learning Rate: 0.0001 || Time: 05:46:29.00
Epoch :: 36 || Loss: 0.41705776 || it_count: 8344 || Val Loss: 0.43377754 || Val it_count: 1107 || Current Learning Rate: 0.0001 || Time: 05:56:38.61
Epoch :: 37 || Loss: 0.41467181 || it_count: 8344 || Val Loss: 0.43245396 || Val it_count: 1107 || Current Learning Rate: 0.0001 || Time: 06:06:44.52
Epoch :: 38 || Loss: 0.41391922 || it_count: 8344 || Val Loss: 0.43177778 || Val it_count: 1107 || Current Learning Rate: 0.0001 || Time: 06:16:51.84
Epoch :: 39 || Loss: 0.41332393 || it_count: 8344 || Val Loss: 0.43132065 || Val it_count: 1107 || Current Learning Rate: 0.0001 || Time: 06:26:59.54
Epoch :: 40 || Loss: 0.41288554 || it_count: 8344 || Val Loss: 0.43104251 || Val it_count: 1107 || Current Learning Rate: 0.0001 || Time: 06:37:12.56
Epoch :: 41 || Loss: 0.41243865 || it_count: 8344 || Val Loss: 0.43074783 || Val it_count: 1107 || Current Learning Rate: 0.0001 || Time: 06:47:21.70
Epoch :: 42 || Loss: 0.41206488 || it_count: 8344 || Val Loss: 0.43037108 || Val it_count: 1107 || Current Learning Rate: 0.0001 || Time: 06:57:30.01
Epoch :: 43 || Loss: 0.41175023 || it_count: 8344 || Val Loss: 0.43011133 || Val it_count: 1107 || Current Learning Rate: 0.0001 || Time: 07:07:36.66
Epoch :: 44 || Loss: 0.41146600 || it_count: 8344 || Val Loss: 0.42998314 || Val it_count: 1107 || Current Learning Rate: 0.0001 || Time: 07:17:41.10
Epoch :: 45 || Loss: 0.41120379 || it_count: 8344 || Val Loss: 0.42986704 || Val it_count: 1107 || Current Learning Rate: 0.0001 || Time: 07:27:49.74
Epoch :: 46 || Loss: 0.41095797 || it_count: 8344 || Val Loss: 0.42969873 || Val it_count: 1107 || Current Learning Rate: 0.0001 || Time: 07:37:56.83
Epoch :: 47 || Loss: 0.41072648 || it_count: 8344 || Val Loss: 0.42969514 || Val it_count: 1107 || Current Learning Rate: 0.0001 || Time: 07:48:0.70
Epoch :: 48 || Loss: 0.41053636 || it_count: 8344 || Val Loss: 0.42962831 || Val it_count: 1107 || Current Learning Rate: 0.0001 || Time: 07:58:5.65
Epoch :: 49 || Loss: 0.41035081 || it_count: 8344 || Val Loss: 0.42965407 || Val it_count: 1107 || Current Learning Rate: 0.0001 || Time: 08:08:11.07
Epoch :: 50 || Loss: 0.41019226 || it_count: 8344 || Val Loss: 0.42964807 || Val it_count: 1107 || Current Learning Rate: 0.0001 || Time: 08:18:21.11
Epoch :: 51 || Loss: 0.41004093 || it_count: 8344 || Val Loss: 0.42982917 || Val it_count: 1107 || Current Learning Rate: 0.0001 || Time: 08:28:27.31
Epoch :: 52 || Loss: 0.40993184 || it_count: 8344 || Val Loss: 0.42963766 || Val it_count: 1107 || Current Learning Rate: 0.0001 || Time: 08:38:40.86
Epoch :: 53 || Loss: 0.40978063 || it_count: 8344 || Val Loss: 0.42974167 || Val it_count: 1107 || Current Learning Rate: 0.0001 || Time: 08:48:47.35
Epoch 00038: reducing learning rate of group 0 to 1.0000e-05.
Epoch :: 54 || Loss: 0.40965447 || it_count: 8344 || Val Loss: 0.42976894 || Val it_count: 1107 || Current Learning Rate: 1e-05 || Time: 08:59:1.50
Epoch :: 55 || Loss: 0.41512041 || it_count: 8344 || Val Loss: 0.41859625 || Val it_count: 1107 || Current Learning Rate: 1e-05 || Time: 09:09:10.12
Epoch :: 56 || Loss: 0.41295495 || it_count: 8344 || Val Loss: 0.41758774 || Val it_count: 1107 || Current Learning Rate: 1e-05 || Time: 09:19:5.00
Epoch :: 57 || Loss: 0.41242382 || it_count: 8344 || Val Loss: 0.41708217 || Val it_count: 1107 || Current Learning Rate: 1e-05 || Time: 09:29:1.30
Epoch :: 58 || Loss: 0.41214760 || it_count: 8344 || Val Loss: 0.41682614 || Val it_count: 1107 || Current Learning Rate: 1e-05 || Time: 09:38:53.04
Epoch :: 59 || Loss: 0.41197295 || it_count: 8344 || Val Loss: 0.41666291 || Val it_count: 1107 || Current Learning Rate: 1e-05 || Time: 09:48:48.30
Epoch :: 60 || Loss: 0.41184572 || it_count: 8344 || Val Loss: 0.41656788 || Val it_count: 1107 || Current Learning Rate: 1e-05 || Time: 09:58:42.49
Epoch :: 61 || Loss: 0.41175247 || it_count: 8344 || Val Loss: 0.41650096 || Val it_count: 1107 || Current Learning Rate: 1e-05 || Time: 10:08:34.94
Epoch :: 62 || Loss: 0.41167667 || it_count: 8344 || Val Loss: 0.41645763 || Val it_count: 1107 || Current Learning Rate: 1e-05 || Time: 10:18:30.15
Epoch :: 63 || Loss: 0.41161382 || it_count: 8344 || Val Loss: 0.41642343 || Val it_count: 1107 || Current Learning Rate: 1e-05 || Time: 10:28:21.18
Epoch :: 64 || Loss: 0.41155998 || it_count: 8344 || Val Loss: 0.41640208 || Val it_count: 1107 || Current Learning Rate: 1e-05 || Time: 10:38:11.04
Epoch :: 65 || Loss: 0.41151318 || it_count: 8344 || Val Loss: 0.41638733 || Val it_count: 1107 || Current Learning Rate: 1e-05 || Time: 10:48:4.09
Epoch :: 66 || Loss: 0.41147052 || it_count: 8344 || Val Loss: 0.41637920 || Val it_count: 1107 || Current Learning Rate: 1e-05 || Time: 10:57:49.71
Epoch :: 67 || Loss: 0.41143303 || it_count: 8344 || Val Loss: 0.41637452 || Val it_count: 1107 || Current Learning Rate: 1e-05 || Time: 11:07:42.93
Epoch :: 68 || Loss: 0.41139790 || it_count: 8344 || Val Loss: 0.41637559 || Val it_count: 1107 || Current Learning Rate: 1e-05 || Time: 11:17:32.85
Epoch :: 69 || Loss: 0.41136773 || it_count: 8344 || Val Loss: 0.41636614 || Val it_count: 1107 || Current Learning Rate: 1e-05 || Time: 11:27:19.87
Epoch 00054: reducing learning rate of group 0 to 1.0000e-06.
Epoch :: 70 || Loss: 0.41133646 || it_count: 8344 || Val Loss: 0.41636115 || Val it_count: 1107 || Current Learning Rate: 1.0000000000000002e-06 || Time: 11:37:14.34
Epoch :: 71 || Loss: 0.41195153 || it_count: 8344 || Val Loss: 0.41522478 || Val it_count: 1107 || Current Learning Rate: 1.0000000000000002e-06 || Time: 11:47:4.51
Epoch :: 72 || Loss: 0.41167589 || it_count: 8344 || Val Loss: 0.41503745 || Val it_count: 1107 || Current Learning Rate: 1.0000000000000002e-06 || Time: 11:56:55.54
Epoch :: 73 || Loss: 0.41159282 || it_count: 8344 || Val Loss: 0.41493422 || Val it_count: 1107 || Current Learning Rate: 1.0000000000000002e-06 || Time: 12:06:51.73
Epoch :: 74 || Loss: 0.41154827 || it_count: 8344 || Val Loss: 0.41486710 || Val it_count: 1107 || Current Learning Rate: 1.0000000000000002e-06 || Time: 12:16:42.40
Epoch :: 75 || Loss: 0.41151904 || it_count: 8344 || Val Loss: 0.41481871 || Val it_count: 1107 || Current Learning Rate: 1.0000000000000002e-06 || Time: 12:26:42.75
Epoch :: 76 || Loss: 0.41149760 || it_count: 8344 || Val Loss: 0.41478301 || Val it_count: 1107 || Current Learning Rate: 1.0000000000000002e-06 || Time: 12:36:44.19
Epoch :: 77 || Loss: 0.41148059 || it_count: 8344 || Val Loss: 0.41475527 || Val it_count: 1107 || Current Learning Rate: 1.0000000000000002e-06 || Time: 12:46:41.51
Epoch :: 78 || Loss: 0.41146663 || it_count: 8344 || Val Loss: 0.41473476 || Val it_count: 1107 || Current Learning Rate: 1.0000000000000002e-06 || Time: 12:56:37.03
Epoch :: 79 || Loss: 0.41145479 || it_count: 8344 || Val Loss: 0.41471843 || Val it_count: 1107 || Current Learning Rate: 1.0000000000000002e-06 || Time: 13:06:33.26
Epoch :: 80 || Loss: 0.41144455 || it_count: 8344 || Val Loss: 0.41470556 || Val it_count: 1107 || Current Learning Rate: 1.0000000000000002e-06 || Time: 13:16:30.08
Epoch :: 81 || Loss: 0.41143556 || it_count: 8344 || Val Loss: 0.41469488 || Val it_count: 1107 || Current Learning Rate: 1.0000000000000002e-06 || Time: 13:26:27.06
Epoch :: 82 || Loss: 0.41142758 || it_count: 8344 || Val Loss: 0.41468565 || Val it_count: 1107 || Current Learning Rate: 1.0000000000000002e-06 || Time: 13:36:24.48
Epoch :: 83 || Loss: 0.41142017 || it_count: 8344 || Val Loss: 0.41467789 || Val it_count: 1107 || Current Learning Rate: 1.0000000000000002e-06 || Time: 13:46:21.37
Epoch :: 84 || Loss: 0.41141346 || it_count: 8344 || Val Loss: 0.41467110 || Val it_count: 1107 || Current Learning Rate: 1.0000000000000002e-06 || Time: 13:56:19.98
Epoch :: 85 || Loss: 0.41140722 || it_count: 8344 || Val Loss: 0.41466519 || Val it_count: 1107 || Current Learning Rate: 1.0000000000000002e-06 || Time: 14:06:17.49
Epoch :: 86 || Loss: 0.41140127 || it_count: 8344 || Val Loss: 0.41466064 || Val it_count: 1107 || Current Learning Rate: 1.0000000000000002e-06 || Time: 14:16:11.73
Epoch :: 87 || Loss: 0.41139571 || it_count: 8344 || Val Loss: 0.41465639 || Val it_count: 1107 || Current Learning Rate: 1.0000000000000002e-06 || Time: 14:26:15.80
Epoch :: 88 || Loss: 0.41139041 || it_count: 8344 || Val Loss: 0.41465347 || Val it_count: 1107 || Current Learning Rate: 1.0000000000000002e-06 || Time: 14:36:30.40
Epoch :: 89 || Loss: 0.41138520 || it_count: 8344 || Val Loss: 0.41464961 || Val it_count: 1107 || Current Learning Rate: 1.0000000000000002e-06 || Time: 14:46:50.20
Epoch :: 90 || Loss: 0.41138053 || it_count: 8344 || Val Loss: 0.41464582 || Val it_count: 1107 || Current Learning Rate: 1.0000000000000002e-06 || Time: 14:56:53.03
Epoch :: 91 || Loss: 0.41137585 || it_count: 8344 || Val Loss: 0.41464215 || Val it_count: 1107 || Current Learning Rate: 1.0000000000000002e-06 || Time: 15:07:3.92
Epoch 00076: reducing learning rate of group 0 to 1.0000e-07.
Early stopping triggered due to learning rate below threshold.
Done Total time: 15:17:4.46
best_loss: 0.4146421530174863

--------------------Testing--------------------

total_samples :: test_dataset = 139200, test_dataloader = 139200
Epoch ::  1 || Loss: 0.24021825 || it_count: 544 || Time: 00:00:24.07
MAE:  0.25723907
MSE:  0.24023713
RMSE:  0.4449474

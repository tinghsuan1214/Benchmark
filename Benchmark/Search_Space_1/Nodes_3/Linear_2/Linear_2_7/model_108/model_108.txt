--------------------Training--------------------
arch_str :: |skip_connect~0|+|lstm_2~0|lstm_3~1|[dropout->linear->relu->linear]
model :: 3K
InferCell(
  info :: nodes=3, inC=1, outC=64, [1<-(I0-L0) | 2<-(I0-L1,I1-L2)], genotype_str: skip_connect~0|lstm_2~0|lstm_3~1
  linear_layers: [dropout->linear->relu->linear]
  (layers): ModuleList(
    (0): FactorizedReduce(
      C_in=1, C_out=64, stride=1
      (relu): ReLU()
      (conv): Conv1d(1, 64, kernel_size=(1,), stride=(1,), bias=False)
      (bn): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (1): LSTM(
      (lstm): LSTM(1, 64, num_layers=2, batch_first=True)
    )
    (2): LSTM(
      (lstm): LSTM(64, 64, num_layers=3, batch_first=True)
    )
  )
  (linear_layers): ModuleList(
    (0): Dropout(p=0.1, inplace=False)
    (1): Linear(in_features=3072, out_features=1536, bias=True)
    (2): ReLU()
    (3): Linear(in_features=1536, out_features=1, bias=True)
  )
)
tr_params :: epochs = 100, patience = 20, batch_size = 256, window_size = 48, data_size = 100
Model MACs: 12.071M, Model Params: 4.872M
learning rate scheduling :: (optimizer, mode='min', factor=0.1, patience=5, verbose=True)
total_samples :: train_dataset = 2136000, train_dataloader = 2136000
total_samples :: valid_dataset = 283200, valid_dataloader = 283200
Epoch ::  1 || Loss: 0.41938189 || it_count: 8344 || Val Loss: 0.46037936 || Val it_count: 1107 || Current Learning Rate: 0.001 || Time: 00:05:22.71
Epoch ::  2 || Loss: 0.41194439 || it_count: 8344 || Val Loss: 0.45764759 || Val it_count: 1107 || Current Learning Rate: 0.001 || Time: 00:10:41.59
Epoch ::  3 || Loss: 0.40938828 || it_count: 8344 || Val Loss: 0.45669607 || Val it_count: 1107 || Current Learning Rate: 0.001 || Time: 00:16:1.04
Epoch ::  4 || Loss: 0.40724478 || it_count: 8344 || Val Loss: 0.45815957 || Val it_count: 1107 || Current Learning Rate: 0.001 || Time: 00:21:19.72
Epoch ::  5 || Loss: 0.40548845 || it_count: 8344 || Val Loss: 0.45963731 || Val it_count: 1107 || Current Learning Rate: 0.001 || Time: 00:26:36.48
Epoch ::  6 || Loss: 0.40413016 || it_count: 8344 || Val Loss: 0.45697435 || Val it_count: 1107 || Current Learning Rate: 0.001 || Time: 00:31:55.90
Epoch ::  7 || Loss: 0.40288633 || it_count: 8344 || Val Loss: 0.45770381 || Val it_count: 1107 || Current Learning Rate: 0.001 || Time: 00:36:42.90
Epoch ::  8 || Loss: 0.40194171 || it_count: 8344 || Val Loss: 0.45776437 || Val it_count: 1107 || Current Learning Rate: 0.001 || Time: 00:41:25.62
Epoch ::  9 || Loss: 0.40080704 || it_count: 8344 || Val Loss: 0.45680029 || Val it_count: 1107 || Current Learning Rate: 0.001 || Time: 00:46:7.76
Epoch :: 10 || Loss: 0.39946964 || it_count: 8344 || Val Loss: 0.46678731 || Val it_count: 1107 || Current Learning Rate: 0.001 || Time: 00:50:49.31
Epoch :: 11 || Loss: 0.39830384 || it_count: 8344 || Val Loss: 0.46554066 || Val it_count: 1107 || Current Learning Rate: 0.001 || Time: 00:55:32.04
Epoch :: 12 || Loss: 0.39694886 || it_count: 8344 || Val Loss: 0.46565601 || Val it_count: 1107 || Current Learning Rate: 0.001 || Time: 01:00:12.20
Epoch :: 13 || Loss: 0.39540073 || it_count: 8344 || Val Loss: 0.47004532 || Val it_count: 1107 || Current Learning Rate: 0.001 || Time: 01:04:52.78
Epoch :: 14 || Loss: 0.39358030 || it_count: 8344 || Val Loss: 0.47164542 || Val it_count: 1107 || Current Learning Rate: 0.001 || Time: 01:09:33.98
Epoch :: 15 || Loss: 0.39143794 || it_count: 8344 || Val Loss: 0.47306822 || Val it_count: 1107 || Current Learning Rate: 0.001 || Time: 01:14:16.14
Epoch :: 16 || Loss: 0.38966002 || it_count: 8344 || Val Loss: 0.47490515 || Val it_count: 1107 || Current Learning Rate: 0.001 || Time: 01:18:58.79
Epoch :: 17 || Loss: 0.38727338 || it_count: 8344 || Val Loss: 0.47708869 || Val it_count: 1107 || Current Learning Rate: 0.001 || Time: 01:23:41.96
Epoch :: 18 || Loss: 0.38486139 || it_count: 8344 || Val Loss: 0.48606330 || Val it_count: 1107 || Current Learning Rate: 0.001 || Time: 01:28:26.90
Epoch :: 19 || Loss: 0.38260614 || it_count: 8344 || Val Loss: 0.50448177 || Val it_count: 1107 || Current Learning Rate: 0.001 || Time: 01:33:16.54
Epoch :: 20 || Loss: 0.37996584 || it_count: 8344 || Val Loss: 0.48642238 || Val it_count: 1107 || Current Learning Rate: 0.001 || Time: 01:38:8.11
Epoch :: 21 || Loss: 0.37761423 || it_count: 8344 || Val Loss: 0.49092118 || Val it_count: 1107 || Current Learning Rate: 0.001 || Time: 01:42:59.89
Epoch :: 22 || Loss: 0.37502922 || it_count: 8344 || Val Loss: 0.48106598 || Val it_count: 1107 || Current Learning Rate: 0.001 || Time: 01:47:51.28
Epoch :: 23 || Loss: 0.37273180 || it_count: 8344 || Val Loss: 0.49615422 || Val it_count: 1107 || Current Learning Rate: 0.0001 || Time: 01:52:44.19
Early stopping triggered due to patience exceeded.
Done Total time: 01:52:44.19
best_loss: 0.456696070169598

--------------------Testing--------------------

total_samples :: test_dataset = 139200, test_dataloader = 139200
Epoch ::  1 || Loss: 0.35206000 || it_count: 544 || Time: 00:00:14.94
MAE:  0.2899632
MSE:  0.35213742
RMSE:  0.5011313

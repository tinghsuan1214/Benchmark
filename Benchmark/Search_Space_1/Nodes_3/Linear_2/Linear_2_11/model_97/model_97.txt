--------------------Training--------------------
arch_str :: |none~0|+|skip_connect~0|lstm_2~1|[relu->linear->relu->linear]
model :: 3O
InferCell(
  info :: nodes=3, inC=1, outC=64, [1<-(I0-L0) | 2<-(I0-L1,I1-L2)], genotype_str: none~0|skip_connect~0|lstm_2~1
  linear_layers: [relu->linear->relu->linear]
  (layers): ModuleList(
    (0): Zero(C_in=1, C_out=64, stride=1)
    (1): FactorizedReduce(
      C_in=1, C_out=64, stride=1
      (relu): ReLU()
      (conv): Conv1d(1, 64, kernel_size=(1,), stride=(1,), bias=False)
      (bn): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (2): LSTM(
      (lstm): LSTM(64, 64, num_layers=2, batch_first=True)
    )
  )
  (linear_layers): ModuleList(
    (0): ReLU()
    (1): Linear(in_features=3072, out_features=1536, bias=True)
    (2): ReLU()
    (3): Linear(in_features=1536, out_features=1, bias=True)
  )
)
tr_params :: epochs = 100, patience = 20, batch_size = 256, window_size = 48, data_size = 100
Model MACs: 7.980M, Model Params: 4.788M
learning rate scheduling :: (optimizer, mode='min', factor=0.1, patience=5, verbose=True)
total_samples :: train_dataset = 2136000, train_dataloader = 2136000
total_samples :: valid_dataset = 283200, valid_dataloader = 283200
Epoch ::  1 || Loss: 0.47462648 || it_count: 8344 || Val Loss: 0.49341871 || Val it_count: 1107 || Current Learning Rate: 0.001 || Time: 00:07:54.86
Epoch ::  2 || Loss: 0.45722995 || it_count: 8344 || Val Loss: 0.51011395 || Val it_count: 1107 || Current Learning Rate: 0.001 || Time: 00:15:50.83
Epoch ::  3 || Loss: 0.46009335 || it_count: 8344 || Val Loss: 0.56362621 || Val it_count: 1107 || Current Learning Rate: 0.001 || Time: 00:23:47.52
Epoch ::  4 || Loss: 0.45949603 || it_count: 8344 || Val Loss: 0.51090257 || Val it_count: 1107 || Current Learning Rate: 0.001 || Time: 00:31:44.52
Epoch ::  5 || Loss: 0.45910694 || it_count: 8344 || Val Loss: 0.50114523 || Val it_count: 1107 || Current Learning Rate: 0.001 || Time: 00:39:41.94
Epoch ::  6 || Loss: 0.45953913 || it_count: 8344 || Val Loss: 0.51366145 || Val it_count: 1107 || Current Learning Rate: 0.001 || Time: 00:47:39.99
Epoch ::  7 || Loss: 0.45708474 || it_count: 8344 || Val Loss: 0.54368301 || Val it_count: 1107 || Current Learning Rate: 0.001 || Time: 00:55:37.27
Epoch ::  8 || Loss: 0.46013841 || it_count: 8344 || Val Loss: 0.49363064 || Val it_count: 1107 || Current Learning Rate: 0.001 || Time: 01:03:34.63
Epoch ::  9 || Loss: 0.45659503 || it_count: 8344 || Val Loss: 0.52528597 || Val it_count: 1107 || Current Learning Rate: 0.001 || Time: 01:11:31.76
Epoch :: 10 || Loss: 0.45782557 || it_count: 8344 || Val Loss: 0.55265105 || Val it_count: 1107 || Current Learning Rate: 0.001 || Time: 01:19:29.22
Epoch :: 11 || Loss: 0.45626107 || it_count: 8344 || Val Loss: 0.52088551 || Val it_count: 1107 || Current Learning Rate: 0.001 || Time: 01:27:26.95
Epoch :: 12 || Loss: 0.45449161 || it_count: 8344 || Val Loss: 0.51721583 || Val it_count: 1107 || Current Learning Rate: 0.001 || Time: 01:35:23.51
Epoch :: 13 || Loss: 0.45553934 || it_count: 8344 || Val Loss: 0.51436931 || Val it_count: 1107 || Current Learning Rate: 0.001 || Time: 01:43:20.30
Epoch :: 14 || Loss: 0.45428036 || it_count: 8344 || Val Loss: 0.51509334 || Val it_count: 1107 || Current Learning Rate: 0.001 || Time: 01:51:16.53
Epoch :: 15 || Loss: 0.45407204 || it_count: 8344 || Val Loss: 0.51582786 || Val it_count: 1107 || Current Learning Rate: 0.001 || Time: 01:59:12.71
Epoch :: 16 || Loss: 0.45288864 || it_count: 8344 || Val Loss: 0.51789751 || Val it_count: 1107 || Current Learning Rate: 0.001 || Time: 02:07:10.17
Epoch :: 17 || Loss: 0.46788738 || it_count: 8344 || Val Loss: 0.47321307 || Val it_count: 1107 || Current Learning Rate: 0.001 || Time: 02:15:7.46
Epoch :: 18 || Loss: 0.45463467 || it_count: 8344 || Val Loss: 0.46867725 || Val it_count: 1107 || Current Learning Rate: 0.001 || Time: 02:23:3.18
Epoch :: 19 || Loss: 0.45621762 || it_count: 8344 || Val Loss: 0.52204800 || Val it_count: 1107 || Current Learning Rate: 0.001 || Time: 02:30:59.27
Epoch :: 20 || Loss: 0.45614648 || it_count: 8344 || Val Loss: 0.55859545 || Val it_count: 1107 || Current Learning Rate: 0.001 || Time: 02:38:55.45
Epoch :: 21 || Loss: 0.45474516 || it_count: 8344 || Val Loss: 0.55137273 || Val it_count: 1107 || Current Learning Rate: 0.001 || Time: 02:46:50.52
Epoch :: 22 || Loss: 0.45397769 || it_count: 8344 || Val Loss: 0.52843654 || Val it_count: 1107 || Current Learning Rate: 0.001 || Time: 02:54:44.55
Epoch :: 23 || Loss: 0.45444097 || it_count: 8344 || Val Loss: 0.50081096 || Val it_count: 1107 || Current Learning Rate: 0.001 || Time: 03:02:37.97
Epoch 00008: reducing learning rate of group 0 to 1.0000e-04.
Epoch :: 24 || Loss: 0.45401788 || it_count: 8344 || Val Loss: 0.48762406 || Val it_count: 1107 || Current Learning Rate: 0.0001 || Time: 03:10:32.39
Epoch :: 25 || Loss: 0.45248612 || it_count: 8344 || Val Loss: 0.47865292 || Val it_count: 1107 || Current Learning Rate: 0.0001 || Time: 03:18:25.52
Epoch :: 26 || Loss: 0.44035540 || it_count: 8344 || Val Loss: 0.47478902 || Val it_count: 1107 || Current Learning Rate: 0.0001 || Time: 03:26:17.97
Epoch :: 27 || Loss: 0.43763523 || it_count: 8344 || Val Loss: 0.47439119 || Val it_count: 1107 || Current Learning Rate: 0.0001 || Time: 03:34:10.30
Epoch :: 28 || Loss: 0.43620029 || it_count: 8344 || Val Loss: 0.47596160 || Val it_count: 1107 || Current Learning Rate: 0.0001 || Time: 03:42:3.36
Epoch :: 29 || Loss: 0.43506523 || it_count: 8344 || Val Loss: 0.47574497 || Val it_count: 1107 || Current Learning Rate: 0.0001 || Time: 03:49:56.01
Epoch 00014: reducing learning rate of group 0 to 1.0000e-05.
Epoch :: 30 || Loss: 0.43392802 || it_count: 8344 || Val Loss: 0.47728182 || Val it_count: 1107 || Current Learning Rate: 1e-05 || Time: 03:57:49.10
Epoch :: 31 || Loss: 0.43863385 || it_count: 8344 || Val Loss: 0.47237212 || Val it_count: 1107 || Current Learning Rate: 1e-05 || Time: 04:05:42.85
Epoch :: 32 || Loss: 0.43599282 || it_count: 8344 || Val Loss: 0.47071187 || Val it_count: 1107 || Current Learning Rate: 1e-05 || Time: 04:13:36.30
Epoch :: 33 || Loss: 0.43456419 || it_count: 8344 || Val Loss: 0.46979750 || Val it_count: 1107 || Current Learning Rate: 1e-05 || Time: 04:21:29.27
Epoch :: 34 || Loss: 0.43358296 || it_count: 8344 || Val Loss: 0.46941942 || Val it_count: 1107 || Current Learning Rate: 1e-05 || Time: 04:29:23.05
Epoch :: 35 || Loss: 0.43283762 || it_count: 8344 || Val Loss: 0.46926402 || Val it_count: 1107 || Current Learning Rate: 1e-05 || Time: 04:37:15.92
Epoch 00020: reducing learning rate of group 0 to 1.0000e-06.
Epoch :: 36 || Loss: 0.43221917 || it_count: 8344 || Val Loss: 0.46924024 || Val it_count: 1107 || Current Learning Rate: 1.0000000000000002e-06 || Time: 04:45:8.71
Epoch :: 37 || Loss: 0.43413387 || it_count: 8344 || Val Loss: 0.47711412 || Val it_count: 1107 || Current Learning Rate: 1.0000000000000002e-06 || Time: 04:53:2.38
Epoch :: 38 || Loss: 0.43390470 || it_count: 8344 || Val Loss: 0.47719720 || Val it_count: 1107 || Current Learning Rate: 1.0000000000000002e-06 || Time: 05:00:55.39
Early stopping triggered due to patience exceeded.
Done Total time: 05:00:55.39
best_loss: 0.468677245781015

--------------------Testing--------------------

total_samples :: test_dataset = 139200, test_dataloader = 139200
Epoch ::  1 || Loss: 0.42516828 || it_count: 544 || Time: 00:00:24.44
MAE:  0.32970205
MSE:  0.42526948
RMSE:  0.5240392

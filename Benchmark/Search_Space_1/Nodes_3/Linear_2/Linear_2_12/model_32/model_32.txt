--------------------Training--------------------
arch_str :: |lstm_2~0|+|lstm_2~0|lstm_2~1|[relu->linear->relu->dropout->linear]
model :: 3P
InferCell(
  info :: nodes=3, inC=1, outC=64, [1<-(I0-L0) | 2<-(I0-L1,I1-L2)], genotype_str: lstm_2~0|lstm_2~0|lstm_2~1
  linear_layers: [relu->linear->relu->dropout->linear]
  (layers): ModuleList(
    (0): LSTM(
      (lstm): LSTM(1, 64, num_layers=2, batch_first=True)
    )
    (1): LSTM(
      (lstm): LSTM(1, 64, num_layers=2, batch_first=True)
    )
    (2): LSTM(
      (lstm): LSTM(64, 64, num_layers=2, batch_first=True)
    )
  )
  (linear_layers): ModuleList(
    (0): ReLU()
    (1): Linear(in_features=3072, out_features=1536, bias=True)
    (2): ReLU()
    (3): Dropout(p=0.1, inplace=False)
    (4): Linear(in_features=1536, out_features=1, bias=True)
  )
)
tr_params :: epochs = 100, patience = 20, batch_size = 256, window_size = 48, data_size = 100
Model MACs: 12.904M, Model Params: 4.889M
learning rate scheduling :: (optimizer, mode='min', factor=0.1, patience=5, verbose=True)
total_samples :: train_dataset = 2136000, train_dataloader = 2136000
total_samples :: valid_dataset = 283200, valid_dataloader = 283200
Epoch ::  1 || Loss: 0.41944975 || it_count: 8344 || Val Loss: 0.45736486 || Val it_count: 1107 || Current Learning Rate: 0.001 || Time: 00:15:53.62
Epoch ::  2 || Loss: 0.41603695 || it_count: 8344 || Val Loss: 0.45004990 || Val it_count: 1107 || Current Learning Rate: 0.001 || Time: 00:31:57.16
Epoch ::  3 || Loss: 0.41388940 || it_count: 8344 || Val Loss: 0.44973642 || Val it_count: 1107 || Current Learning Rate: 0.001 || Time: 00:48:4.21
Epoch ::  4 || Loss: 0.41293691 || it_count: 8344 || Val Loss: 0.45105230 || Val it_count: 1107 || Current Learning Rate: 0.001 || Time: 01:04:12.00
Epoch ::  5 || Loss: 0.41217507 || it_count: 8344 || Val Loss: 0.44935731 || Val it_count: 1107 || Current Learning Rate: 0.001 || Time: 01:20:22.13
Epoch ::  6 || Loss: 0.41134816 || it_count: 8344 || Val Loss: 0.45229677 || Val it_count: 1107 || Current Learning Rate: 0.001 || Time: 01:36:36.45
Epoch ::  7 || Loss: 0.41095095 || it_count: 8344 || Val Loss: 0.44977823 || Val it_count: 1107 || Current Learning Rate: 0.001 || Time: 01:52:52.88
Epoch ::  8 || Loss: 0.41026282 || it_count: 8344 || Val Loss: 0.45048035 || Val it_count: 1107 || Current Learning Rate: 0.001 || Time: 02:09:12.15
Epoch ::  9 || Loss: 0.40913462 || it_count: 8344 || Val Loss: 0.45092484 || Val it_count: 1107 || Current Learning Rate: 0.001 || Time: 02:25:31.49
Epoch :: 10 || Loss: 0.40856524 || it_count: 8344 || Val Loss: 0.44956222 || Val it_count: 1107 || Current Learning Rate: 0.001 || Time: 02:41:51.34
Epoch :: 11 || Loss: 0.40736964 || it_count: 8344 || Val Loss: 0.45012353 || Val it_count: 1107 || Current Learning Rate: 0.001 || Time: 02:58:9.52
Epoch :: 12 || Loss: 0.40632122 || it_count: 8344 || Val Loss: 0.45122891 || Val it_count: 1107 || Current Learning Rate: 0.001 || Time: 03:14:32.29
Epoch :: 13 || Loss: 0.40511917 || it_count: 8344 || Val Loss: 0.45076658 || Val it_count: 1107 || Current Learning Rate: 0.001 || Time: 03:30:51.57
Epoch :: 14 || Loss: 0.40439293 || it_count: 8344 || Val Loss: 0.44943374 || Val it_count: 1107 || Current Learning Rate: 0.001 || Time: 03:47:11.47
Epoch :: 15 || Loss: 0.40310363 || it_count: 8344 || Val Loss: 0.44968186 || Val it_count: 1107 || Current Learning Rate: 0.001 || Time: 04:03:32.44
Epoch :: 16 || Loss: 0.40217664 || it_count: 8344 || Val Loss: 0.44990312 || Val it_count: 1107 || Current Learning Rate: 0.001 || Time: 04:19:54.72
Epoch :: 17 || Loss: 0.40052494 || it_count: 8344 || Val Loss: 0.44648098 || Val it_count: 1107 || Current Learning Rate: 0.001 || Time: 04:36:12.28
Epoch :: 18 || Loss: 0.39909579 || it_count: 8344 || Val Loss: 0.44959917 || Val it_count: 1107 || Current Learning Rate: 0.001 || Time: 04:52:33.09
Epoch :: 19 || Loss: 0.39823487 || it_count: 8344 || Val Loss: 0.45244536 || Val it_count: 1107 || Current Learning Rate: 0.001 || Time: 05:08:52.09
Epoch :: 20 || Loss: 0.39697311 || it_count: 8344 || Val Loss: 0.45188659 || Val it_count: 1107 || Current Learning Rate: 0.001 || Time: 05:25:15.79
Epoch :: 21 || Loss: 0.39549631 || it_count: 8344 || Val Loss: 0.45235707 || Val it_count: 1107 || Current Learning Rate: 0.001 || Time: 05:41:37.20
Epoch :: 22 || Loss: 0.39394486 || it_count: 8344 || Val Loss: 0.45805087 || Val it_count: 1107 || Current Learning Rate: 0.001 || Time: 05:58:1.33
Epoch 00007: reducing learning rate of group 0 to 1.0000e-04.
Epoch :: 23 || Loss: 0.39199002 || it_count: 8344 || Val Loss: 0.45280486 || Val it_count: 1107 || Current Learning Rate: 0.0001 || Time: 06:14:25.75
Epoch :: 24 || Loss: 0.40584219 || it_count: 8344 || Val Loss: 0.42783580 || Val it_count: 1107 || Current Learning Rate: 0.0001 || Time: 06:30:52.60
Epoch :: 25 || Loss: 0.40120225 || it_count: 8344 || Val Loss: 0.42625336 || Val it_count: 1107 || Current Learning Rate: 0.0001 || Time: 06:47:14.79
Epoch :: 26 || Loss: 0.39893270 || it_count: 8344 || Val Loss: 0.42714603 || Val it_count: 1107 || Current Learning Rate: 0.0001 || Time: 07:03:37.85
Epoch :: 27 || Loss: 0.39730448 || it_count: 8344 || Val Loss: 0.42733279 || Val it_count: 1107 || Current Learning Rate: 0.0001 || Time: 07:20:0.69
Epoch :: 28 || Loss: 0.39571353 || it_count: 8344 || Val Loss: 0.42780678 || Val it_count: 1107 || Current Learning Rate: 0.0001 || Time: 07:36:26.61
Epoch :: 29 || Loss: 0.39438693 || it_count: 8344 || Val Loss: 0.42870242 || Val it_count: 1107 || Current Learning Rate: 0.0001 || Time: 07:52:49.69
Epoch :: 30 || Loss: 0.39308082 || it_count: 8344 || Val Loss: 0.42919391 || Val it_count: 1107 || Current Learning Rate: 0.0001 || Time: 08:09:15.10
Epoch 00015: reducing learning rate of group 0 to 1.0000e-05.
Epoch :: 31 || Loss: 0.39180489 || it_count: 8344 || Val Loss: 0.42998057 || Val it_count: 1107 || Current Learning Rate: 1e-05 || Time: 08:25:40.42
Epoch :: 32 || Loss: 0.40080989 || it_count: 8344 || Val Loss: 0.41881044 || Val it_count: 1107 || Current Learning Rate: 1e-05 || Time: 08:42:6.19
Epoch :: 33 || Loss: 0.39857432 || it_count: 8344 || Val Loss: 0.41858923 || Val it_count: 1107 || Current Learning Rate: 1e-05 || Time: 08:58:31.06
Epoch :: 34 || Loss: 0.39795923 || it_count: 8344 || Val Loss: 0.41906016 || Val it_count: 1107 || Current Learning Rate: 1e-05 || Time: 09:14:56.00
Epoch :: 35 || Loss: 0.39741609 || it_count: 8344 || Val Loss: 0.41920147 || Val it_count: 1107 || Current Learning Rate: 1e-05 || Time: 09:31:19.02
Epoch :: 36 || Loss: 0.39723931 || it_count: 8344 || Val Loss: 0.41889901 || Val it_count: 1107 || Current Learning Rate: 1e-05 || Time: 09:47:45.09
Epoch :: 37 || Loss: 0.39694260 || it_count: 8344 || Val Loss: 0.41848258 || Val it_count: 1107 || Current Learning Rate: 1e-05 || Time: 10:04:8.96
Epoch :: 38 || Loss: 0.39681362 || it_count: 8344 || Val Loss: 0.41843986 || Val it_count: 1107 || Current Learning Rate: 1e-05 || Time: 10:20:32.85
Epoch :: 39 || Loss: 0.39648266 || it_count: 8344 || Val Loss: 0.41831989 || Val it_count: 1107 || Current Learning Rate: 1e-05 || Time: 10:36:58.17
Epoch :: 40 || Loss: 0.39627609 || it_count: 8344 || Val Loss: 0.41806440 || Val it_count: 1107 || Current Learning Rate: 1e-05 || Time: 10:53:25.58
Epoch :: 41 || Loss: 0.39616471 || it_count: 8344 || Val Loss: 0.41795237 || Val it_count: 1107 || Current Learning Rate: 1e-05 || Time: 11:09:47.81
Epoch :: 42 || Loss: 0.39600844 || it_count: 8344 || Val Loss: 0.41791531 || Val it_count: 1107 || Current Learning Rate: 1e-05 || Time: 11:26:13.05
Epoch :: 43 || Loss: 0.39599369 || it_count: 8344 || Val Loss: 0.41801158 || Val it_count: 1107 || Current Learning Rate: 1e-05 || Time: 11:42:36.73
Epoch :: 44 || Loss: 0.39575781 || it_count: 8344 || Val Loss: 0.41794049 || Val it_count: 1107 || Current Learning Rate: 1e-05 || Time: 11:59:2.78
Epoch :: 45 || Loss: 0.39556440 || it_count: 8344 || Val Loss: 0.41799593 || Val it_count: 1107 || Current Learning Rate: 1e-05 || Time: 12:15:27.65
Epoch :: 46 || Loss: 0.39524266 || it_count: 8344 || Val Loss: 0.41805437 || Val it_count: 1107 || Current Learning Rate: 1e-05 || Time: 12:31:53.74
Epoch 00031: reducing learning rate of group 0 to 1.0000e-06.
Epoch :: 47 || Loss: 0.39518388 || it_count: 8344 || Val Loss: 0.41810388 || Val it_count: 1107 || Current Learning Rate: 1.0000000000000002e-06 || Time: 12:48:18.77
Epoch :: 48 || Loss: 0.39636933 || it_count: 8344 || Val Loss: 0.41786086 || Val it_count: 1107 || Current Learning Rate: 1.0000000000000002e-06 || Time: 13:04:45.94
Epoch :: 49 || Loss: 0.39598529 || it_count: 8344 || Val Loss: 0.41792637 || Val it_count: 1107 || Current Learning Rate: 1.0000000000000002e-06 || Time: 13:21:10.49
Epoch :: 50 || Loss: 0.39607384 || it_count: 8344 || Val Loss: 0.41795219 || Val it_count: 1107 || Current Learning Rate: 1.0000000000000002e-06 || Time: 13:37:33.26
Epoch :: 51 || Loss: 0.39594469 || it_count: 8344 || Val Loss: 0.41798187 || Val it_count: 1107 || Current Learning Rate: 1.0000000000000002e-06 || Time: 13:53:58.07
Epoch :: 52 || Loss: 0.39600871 || it_count: 8344 || Val Loss: 0.41798108 || Val it_count: 1107 || Current Learning Rate: 1.0000000000000002e-06 || Time: 14:10:25.16
Epoch :: 53 || Loss: 0.39592910 || it_count: 8344 || Val Loss: 0.41799287 || Val it_count: 1107 || Current Learning Rate: 1.0000000000000002e-06 || Time: 14:26:47.95
Epoch 00038: reducing learning rate of group 0 to 1.0000e-07.
Early stopping triggered due to learning rate below threshold.
Done Total time: 14:43:13.99
best_loss: 0.41786086111215653

--------------------Testing--------------------

total_samples :: test_dataset = 139200, test_dataloader = 139200
Epoch ::  1 || Loss: 0.24710098 || it_count: 544 || Time: 00:00:31.13
MAE:  0.25728783
MSE:  0.2471242
RMSE:  0.45070994

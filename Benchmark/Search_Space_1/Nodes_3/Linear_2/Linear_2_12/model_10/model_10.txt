--------------------Training--------------------
arch_str :: |lstm_1~0|+|lstm_2~0|skip_connect~1|[relu->linear->relu->dropout->linear]
model :: 3P
InferCell(
  info :: nodes=3, inC=1, outC=64, [1<-(I0-L0) | 2<-(I0-L1,I1-L2)], genotype_str: lstm_1~0|lstm_2~0|skip_connect~1
  linear_layers: [relu->linear->relu->dropout->linear]
  (layers): ModuleList(
    (0): LSTM(
      (lstm): LSTM(1, 64, batch_first=True)
    )
    (1): LSTM(
      (lstm): LSTM(1, 64, num_layers=2, batch_first=True)
    )
    (2): Identity()
  )
  (linear_layers): ModuleList(
    (0): ReLU()
    (1): Linear(in_features=3072, out_features=1536, bias=True)
    (2): ReLU()
    (3): Dropout(p=0.1, inplace=False)
    (4): Linear(in_features=1536, out_features=1, bias=True)
  )
)
tr_params :: epochs = 100, patience = 20, batch_size = 256, window_size = 48, data_size = 100
Model MACs: 8.038M, Model Params: 4.789M
learning rate scheduling :: (optimizer, mode='min', factor=0.1, patience=5, verbose=True)
total_samples :: train_dataset = 2136000, train_dataloader = 2136000
total_samples :: valid_dataset = 283200, valid_dataloader = 283200
Epoch ::  1 || Loss: 0.41751229 || it_count: 8344 || Val Loss: 0.45455644 || Val it_count: 1107 || Current Learning Rate: 0.001 || Time: 00:10:53.34
Epoch ::  2 || Loss: 0.41514368 || it_count: 8344 || Val Loss: 0.44801520 || Val it_count: 1107 || Current Learning Rate: 0.001 || Time: 00:21:48.71
Epoch ::  3 || Loss: 0.41359063 || it_count: 8344 || Val Loss: 0.44775466 || Val it_count: 1107 || Current Learning Rate: 0.001 || Time: 00:32:46.05
Epoch ::  4 || Loss: 0.41282008 || it_count: 8344 || Val Loss: 0.44471615 || Val it_count: 1107 || Current Learning Rate: 0.001 || Time: 00:43:42.22
Epoch ::  5 || Loss: 0.41222635 || it_count: 8344 || Val Loss: 0.44832388 || Val it_count: 1107 || Current Learning Rate: 0.001 || Time: 00:54:39.28
Epoch ::  6 || Loss: 0.41118441 || it_count: 8344 || Val Loss: 0.44893509 || Val it_count: 1107 || Current Learning Rate: 0.001 || Time: 01:05:38.28
Epoch ::  7 || Loss: 0.41029276 || it_count: 8344 || Val Loss: 0.44899578 || Val it_count: 1107 || Current Learning Rate: 0.001 || Time: 01:16:36.36
Epoch ::  8 || Loss: 0.40930802 || it_count: 8344 || Val Loss: 0.44579430 || Val it_count: 1107 || Current Learning Rate: 0.001 || Time: 01:27:37.30
Epoch ::  9 || Loss: 0.40862112 || it_count: 8344 || Val Loss: 0.44908786 || Val it_count: 1107 || Current Learning Rate: 0.001 || Time: 01:38:39.92
Epoch :: 10 || Loss: 0.40772466 || it_count: 8344 || Val Loss: 0.44625458 || Val it_count: 1107 || Current Learning Rate: 0.001 || Time: 01:49:42.26
Epoch :: 11 || Loss: 0.40688513 || it_count: 8344 || Val Loss: 0.44471190 || Val it_count: 1107 || Current Learning Rate: 0.001 || Time: 02:00:45.61
Epoch :: 12 || Loss: 0.40622146 || it_count: 8344 || Val Loss: 0.44525761 || Val it_count: 1107 || Current Learning Rate: 0.001 || Time: 02:11:49.21
Epoch :: 13 || Loss: 0.40499771 || it_count: 8344 || Val Loss: 0.44200654 || Val it_count: 1107 || Current Learning Rate: 0.001 || Time: 02:22:53.12
Epoch :: 14 || Loss: 0.40386778 || it_count: 8344 || Val Loss: 0.44214841 || Val it_count: 1107 || Current Learning Rate: 0.001 || Time: 02:33:56.79
Epoch :: 15 || Loss: 0.40246891 || it_count: 8344 || Val Loss: 0.44179741 || Val it_count: 1107 || Current Learning Rate: 0.001 || Time: 02:45:0.83
Epoch :: 16 || Loss: 0.40152677 || it_count: 8344 || Val Loss: 0.44288225 || Val it_count: 1107 || Current Learning Rate: 0.001 || Time: 02:56:4.19
Epoch :: 17 || Loss: 0.40037139 || it_count: 8344 || Val Loss: 0.44228401 || Val it_count: 1107 || Current Learning Rate: 0.001 || Time: 03:07:8.00
Epoch :: 18 || Loss: 0.39920203 || it_count: 8344 || Val Loss: 0.44154084 || Val it_count: 1107 || Current Learning Rate: 0.001 || Time: 03:18:12.05
Epoch :: 19 || Loss: 0.39751711 || it_count: 8344 || Val Loss: 0.44268245 || Val it_count: 1107 || Current Learning Rate: 0.001 || Time: 03:29:15.75
Epoch :: 20 || Loss: 0.39596940 || it_count: 8344 || Val Loss: 0.44294215 || Val it_count: 1107 || Current Learning Rate: 0.001 || Time: 03:40:19.08
Epoch :: 21 || Loss: 0.39441820 || it_count: 8344 || Val Loss: 0.44368931 || Val it_count: 1107 || Current Learning Rate: 0.001 || Time: 03:51:23.63
Epoch :: 22 || Loss: 0.39277407 || it_count: 8344 || Val Loss: 0.44440470 || Val it_count: 1107 || Current Learning Rate: 0.001 || Time: 04:02:26.59
Epoch :: 23 || Loss: 0.39135232 || it_count: 8344 || Val Loss: 0.44776641 || Val it_count: 1107 || Current Learning Rate: 0.001 || Time: 04:13:30.19
Epoch 00008: reducing learning rate of group 0 to 1.0000e-04.
Epoch :: 24 || Loss: 0.39000185 || it_count: 8344 || Val Loss: 0.44677004 || Val it_count: 1107 || Current Learning Rate: 0.0001 || Time: 04:24:33.40
Epoch :: 25 || Loss: 0.40396618 || it_count: 8344 || Val Loss: 0.42463692 || Val it_count: 1107 || Current Learning Rate: 0.0001 || Time: 04:35:37.80
Epoch :: 26 || Loss: 0.39900578 || it_count: 8344 || Val Loss: 0.42367596 || Val it_count: 1107 || Current Learning Rate: 0.0001 || Time: 04:46:42.40
Epoch :: 27 || Loss: 0.39699068 || it_count: 8344 || Val Loss: 0.42365620 || Val it_count: 1107 || Current Learning Rate: 0.0001 || Time: 04:57:47.53
Epoch :: 28 || Loss: 0.39529935 || it_count: 8344 || Val Loss: 0.42395315 || Val it_count: 1107 || Current Learning Rate: 0.0001 || Time: 05:08:51.34
Epoch :: 29 || Loss: 0.39396830 || it_count: 8344 || Val Loss: 0.42410547 || Val it_count: 1107 || Current Learning Rate: 0.0001 || Time: 05:19:55.32
Epoch :: 30 || Loss: 0.39286803 || it_count: 8344 || Val Loss: 0.42427508 || Val it_count: 1107 || Current Learning Rate: 0.0001 || Time: 05:30:59.52
Epoch :: 31 || Loss: 0.39183548 || it_count: 8344 || Val Loss: 0.42494542 || Val it_count: 1107 || Current Learning Rate: 0.0001 || Time: 05:42:3.81
Epoch 00016: reducing learning rate of group 0 to 1.0000e-05.
Epoch :: 32 || Loss: 0.39063766 || it_count: 8344 || Val Loss: 0.42506455 || Val it_count: 1107 || Current Learning Rate: 1e-05 || Time: 05:53:7.25
Epoch :: 33 || Loss: 0.40023221 || it_count: 8344 || Val Loss: 0.41925211 || Val it_count: 1107 || Current Learning Rate: 1e-05 || Time: 06:04:11.50
Epoch :: 34 || Loss: 0.39721603 || it_count: 8344 || Val Loss: 0.41899470 || Val it_count: 1107 || Current Learning Rate: 1e-05 || Time: 06:15:15.93
Epoch :: 35 || Loss: 0.39671102 || it_count: 8344 || Val Loss: 0.41885612 || Val it_count: 1107 || Current Learning Rate: 1e-05 || Time: 06:26:19.98
Epoch :: 36 || Loss: 0.39628963 || it_count: 8344 || Val Loss: 0.41876416 || Val it_count: 1107 || Current Learning Rate: 1e-05 || Time: 06:37:24.09
Epoch :: 37 || Loss: 0.39603748 || it_count: 8344 || Val Loss: 0.41872708 || Val it_count: 1107 || Current Learning Rate: 1e-05 || Time: 06:48:28.63
Epoch :: 38 || Loss: 0.39588748 || it_count: 8344 || Val Loss: 0.41869788 || Val it_count: 1107 || Current Learning Rate: 1e-05 || Time: 06:59:32.42
Epoch :: 39 || Loss: 0.39559203 || it_count: 8344 || Val Loss: 0.41866123 || Val it_count: 1107 || Current Learning Rate: 1e-05 || Time: 07:10:37.31
Epoch :: 40 || Loss: 0.39547037 || it_count: 8344 || Val Loss: 0.41866392 || Val it_count: 1107 || Current Learning Rate: 1e-05 || Time: 07:21:40.83
Epoch :: 41 || Loss: 0.39528139 || it_count: 8344 || Val Loss: 0.41867689 || Val it_count: 1107 || Current Learning Rate: 1e-05 || Time: 07:32:45.25
Epoch :: 42 || Loss: 0.39504749 || it_count: 8344 || Val Loss: 0.41865771 || Val it_count: 1107 || Current Learning Rate: 1e-05 || Time: 07:43:49.29
Epoch :: 43 || Loss: 0.39494487 || it_count: 8344 || Val Loss: 0.41865852 || Val it_count: 1107 || Current Learning Rate: 1e-05 || Time: 07:54:53.72
Epoch 00028: reducing learning rate of group 0 to 1.0000e-06.
Epoch :: 44 || Loss: 0.39469327 || it_count: 8344 || Val Loss: 0.41873568 || Val it_count: 1107 || Current Learning Rate: 1.0000000000000002e-06 || Time: 08:05:57.21
Epoch :: 45 || Loss: 0.39565879 || it_count: 8344 || Val Loss: 0.41815934 || Val it_count: 1107 || Current Learning Rate: 1.0000000000000002e-06 || Time: 08:17:1.44
Epoch :: 46 || Loss: 0.39531728 || it_count: 8344 || Val Loss: 0.41807043 || Val it_count: 1107 || Current Learning Rate: 1.0000000000000002e-06 || Time: 08:28:6.12
Epoch :: 47 || Loss: 0.39528446 || it_count: 8344 || Val Loss: 0.41801288 || Val it_count: 1107 || Current Learning Rate: 1.0000000000000002e-06 || Time: 08:39:10.29
Epoch :: 48 || Loss: 0.39530076 || it_count: 8344 || Val Loss: 0.41797461 || Val it_count: 1107 || Current Learning Rate: 1.0000000000000002e-06 || Time: 08:50:13.19
Epoch :: 49 || Loss: 0.39529879 || it_count: 8344 || Val Loss: 0.41793254 || Val it_count: 1107 || Current Learning Rate: 1.0000000000000002e-06 || Time: 09:01:17.27
Epoch :: 50 || Loss: 0.39520742 || it_count: 8344 || Val Loss: 0.41792015 || Val it_count: 1107 || Current Learning Rate: 1.0000000000000002e-06 || Time: 09:12:21.14
Epoch :: 51 || Loss: 0.39505653 || it_count: 8344 || Val Loss: 0.41790081 || Val it_count: 1107 || Current Learning Rate: 1.0000000000000002e-06 || Time: 09:23:25.68
Epoch :: 52 || Loss: 0.39519308 || it_count: 8344 || Val Loss: 0.41789568 || Val it_count: 1107 || Current Learning Rate: 1.0000000000000002e-06 || Time: 09:34:29.46
Epoch :: 53 || Loss: 0.39517629 || it_count: 8344 || Val Loss: 0.41786227 || Val it_count: 1107 || Current Learning Rate: 1.0000000000000002e-06 || Time: 09:45:33.83
Epoch :: 54 || Loss: 0.39520915 || it_count: 8344 || Val Loss: 0.41784884 || Val it_count: 1107 || Current Learning Rate: 1.0000000000000002e-06 || Time: 09:56:37.62
Epoch :: 55 || Loss: 0.39505482 || it_count: 8344 || Val Loss: 0.41785367 || Val it_count: 1107 || Current Learning Rate: 1.0000000000000002e-06 || Time: 10:07:41.61
Epoch :: 56 || Loss: 0.39507599 || it_count: 8344 || Val Loss: 0.41783336 || Val it_count: 1107 || Current Learning Rate: 1.0000000000000002e-06 || Time: 10:18:45.07
Epoch :: 57 || Loss: 0.39502880 || it_count: 8344 || Val Loss: 0.41783273 || Val it_count: 1107 || Current Learning Rate: 1.0000000000000002e-06 || Time: 10:29:49.57
Epoch :: 58 || Loss: 0.39512910 || it_count: 8344 || Val Loss: 0.41782348 || Val it_count: 1107 || Current Learning Rate: 1.0000000000000002e-06 || Time: 10:40:54.16
Epoch 00043: reducing learning rate of group 0 to 1.0000e-07.
Early stopping triggered due to learning rate below threshold.
Done Total time: 10:51:58.41
best_loss: 0.4178234848482515

--------------------Testing--------------------

total_samples :: test_dataset = 139200, test_dataloader = 139200
Epoch ::  1 || Loss: 0.24549153 || it_count: 544 || Time: 00:00:25.33
MAE:  0.25610495
MSE:  0.24551556
RMSE:  0.44953686

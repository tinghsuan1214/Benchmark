--------------------Training--------------------
arch_str :: |lstm_2~0|+|lstm_1~0|skip_connect~1|[relu->dropout->linear->dropout->linear]
model :: 3R
InferCell(
  info :: nodes=3, inC=1, outC=64, [1<-(I0-L0) | 2<-(I0-L1,I1-L2)], genotype_str: lstm_2~0|lstm_1~0|skip_connect~1
  linear_layers: [relu->dropout->linear->dropout->linear]
  (layers): ModuleList(
    (0): LSTM(
      (lstm): LSTM(1, 64, num_layers=2, batch_first=True)
    )
    (1): LSTM(
      (lstm): LSTM(1, 64, batch_first=True)
    )
    (2): Identity()
  )
  (linear_layers): ModuleList(
    (0): ReLU()
    (1): Dropout(p=0.1, inplace=False)
    (2): Linear(in_features=3072, out_features=1536, bias=True)
    (3): Dropout(p=0.1, inplace=False)
    (4): Linear(in_features=1536, out_features=1, bias=True)
  )
)
tr_params :: epochs = 100, patience = 20, batch_size = 256, window_size = 48, data_size = 100
Model MACs: 8.038M, Model Params: 4.789M
learning rate scheduling :: (optimizer, mode='min', factor=0.1, patience=5, verbose=True)
total_samples :: train_dataset = 2136000, train_dataloader = 2136000
total_samples :: valid_dataset = 283200, valid_dataloader = 283200
Epoch ::  1 || Loss: 0.42445271 || it_count: 8344 || Val Loss: 0.44755443 || Val it_count: 1107 || Current Learning Rate: 0.001 || Time: 00:04:6.21
Epoch ::  2 || Loss: 0.42112425 || it_count: 8344 || Val Loss: 0.44480012 || Val it_count: 1107 || Current Learning Rate: 0.001 || Time: 00:08:8.28
Epoch ::  3 || Loss: 0.42116343 || it_count: 8344 || Val Loss: 0.44239672 || Val it_count: 1107 || Current Learning Rate: 0.001 || Time: 00:12:11.04
Epoch ::  4 || Loss: 0.42091761 || it_count: 8344 || Val Loss: 0.44349075 || Val it_count: 1107 || Current Learning Rate: 0.001 || Time: 00:16:14.04
Epoch ::  5 || Loss: 0.42036886 || it_count: 8344 || Val Loss: 0.43995137 || Val it_count: 1107 || Current Learning Rate: 0.001 || Time: 00:20:19.95
Epoch ::  6 || Loss: 0.42015599 || it_count: 8344 || Val Loss: 0.44380210 || Val it_count: 1107 || Current Learning Rate: 0.001 || Time: 00:24:25.47
Epoch ::  7 || Loss: 0.41918552 || it_count: 8344 || Val Loss: 0.44561129 || Val it_count: 1107 || Current Learning Rate: 0.001 || Time: 00:28:28.82
Epoch ::  8 || Loss: 0.41879566 || it_count: 8344 || Val Loss: 0.44302189 || Val it_count: 1107 || Current Learning Rate: 0.001 || Time: 00:32:30.16
Epoch ::  9 || Loss: 0.41994625 || it_count: 8344 || Val Loss: 0.44477298 || Val it_count: 1107 || Current Learning Rate: 0.001 || Time: 00:36:30.67
Epoch :: 10 || Loss: 0.41956113 || it_count: 8344 || Val Loss: 0.44408759 || Val it_count: 1107 || Current Learning Rate: 0.001 || Time: 00:40:33.31
Epoch :: 11 || Loss: 0.41872186 || it_count: 8344 || Val Loss: 0.44235124 || Val it_count: 1107 || Current Learning Rate: 0.001 || Time: 00:44:41.83
Epoch :: 12 || Loss: 0.41820934 || it_count: 8344 || Val Loss: 0.44309447 || Val it_count: 1107 || Current Learning Rate: 0.001 || Time: 00:48:50.31
Epoch :: 13 || Loss: 0.41796089 || it_count: 8344 || Val Loss: 0.44121197 || Val it_count: 1107 || Current Learning Rate: 0.001 || Time: 00:52:58.27
Epoch :: 14 || Loss: 0.41755353 || it_count: 8344 || Val Loss: 0.44466513 || Val it_count: 1107 || Current Learning Rate: 0.001 || Time: 00:57:7.18
Epoch :: 15 || Loss: 0.41703740 || it_count: 8344 || Val Loss: 0.44481508 || Val it_count: 1107 || Current Learning Rate: 0.001 || Time: 01:01:15.01
Epoch :: 16 || Loss: 0.41662662 || it_count: 8344 || Val Loss: 0.44192504 || Val it_count: 1107 || Current Learning Rate: 0.001 || Time: 01:05:23.20
Epoch :: 17 || Loss: 0.41646219 || it_count: 8344 || Val Loss: 0.44346422 || Val it_count: 1107 || Current Learning Rate: 0.001 || Time: 01:09:31.11
Epoch :: 18 || Loss: 0.41538269 || it_count: 8344 || Val Loss: 0.44310137 || Val it_count: 1107 || Current Learning Rate: 0.001 || Time: 01:13:38.42
Epoch :: 19 || Loss: 0.41530397 || it_count: 8344 || Val Loss: 0.44552560 || Val it_count: 1107 || Current Learning Rate: 0.001 || Time: 01:17:46.38
Epoch :: 20 || Loss: 0.41485195 || it_count: 8344 || Val Loss: 0.44152192 || Val it_count: 1107 || Current Learning Rate: 0.001 || Time: 01:21:55.05
Epoch :: 21 || Loss: 0.41528218 || it_count: 8344 || Val Loss: 0.44146991 || Val it_count: 1107 || Current Learning Rate: 0.001 || Time: 01:26:4.41
Epoch :: 22 || Loss: 0.41630289 || it_count: 8344 || Val Loss: 0.44209903 || Val it_count: 1107 || Current Learning Rate: 0.001 || Time: 01:30:14.41
Epoch :: 23 || Loss: 0.41489437 || it_count: 8344 || Val Loss: 0.44227258 || Val it_count: 1107 || Current Learning Rate: 0.001 || Time: 01:34:24.05
Epoch :: 24 || Loss: 0.41476456 || it_count: 8344 || Val Loss: 0.44220084 || Val it_count: 1107 || Current Learning Rate: 0.001 || Time: 01:38:32.35
Epoch :: 25 || Loss: 0.41355065 || it_count: 8344 || Val Loss: 0.44505707 || Val it_count: 1107 || Current Learning Rate: 0.001 || Time: 01:42:39.71
Early stopping triggered due to patience exceeded.
Done Total time: 01:42:39.71
best_loss: 0.43995137123905875

--------------------Testing--------------------

total_samples :: test_dataset = 139200, test_dataloader = 139200
Epoch ::  1 || Loss: 0.32805349 || it_count: 544 || Time: 00:00:13.26
MAE:  0.27872214
MSE:  0.32812804
RMSE:  0.48126966

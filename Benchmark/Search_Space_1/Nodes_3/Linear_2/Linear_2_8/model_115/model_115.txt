--------------------Training--------------------
arch_str :: |skip_connect~0|+|lstm_3~0|skip_connect~1|[dropout->linear->relu->dropout->linear]
model :: 3L
InferCell(
  info :: nodes=3, inC=1, outC=64, [1<-(I0-L0) | 2<-(I0-L1,I1-L2)], genotype_str: skip_connect~0|lstm_3~0|skip_connect~1
  linear_layers: [dropout->linear->relu->dropout->linear]
  (layers): ModuleList(
    (0): FactorizedReduce(
      C_in=1, C_out=64, stride=1
      (relu): ReLU()
      (conv): Conv1d(1, 64, kernel_size=(1,), stride=(1,), bias=False)
      (bn): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (1): LSTM(
      (lstm): LSTM(1, 64, num_layers=3, batch_first=True)
    )
    (2): Identity()
  )
  (linear_layers): ModuleList(
    (0): Dropout(p=0.1, inplace=False)
    (1): Linear(in_features=3072, out_features=1536, bias=True)
    (2): ReLU()
    (3): Dropout(p=0.1, inplace=False)
    (4): Linear(in_features=1536, out_features=1, bias=True)
  )
)
tr_params :: epochs = 100, patience = 20, batch_size = 256, window_size = 48, data_size = 100
Model MACs: 8.827M, Model Params: 4.806M
learning rate scheduling :: (optimizer, mode='min', factor=0.1, patience=5, verbose=True)
total_samples :: train_dataset = 2136000, train_dataloader = 2136000
total_samples :: valid_dataset = 283200, valid_dataloader = 283200
Epoch ::  1 || Loss: 0.46890759 || it_count: 8344 || Val Loss: 0.48390403 || Val it_count: 1107 || Current Learning Rate: 0.001 || Time: 00:03:59.62
Epoch ::  2 || Loss: 0.44209429 || it_count: 8344 || Val Loss: 0.47624728 || Val it_count: 1107 || Current Learning Rate: 0.001 || Time: 00:07:54.69
Epoch ::  3 || Loss: 0.42248856 || it_count: 8344 || Val Loss: 0.47268169 || Val it_count: 1107 || Current Learning Rate: 0.001 || Time: 00:11:49.70
Epoch ::  4 || Loss: 0.41577113 || it_count: 8344 || Val Loss: 0.46877289 || Val it_count: 1107 || Current Learning Rate: 0.001 || Time: 00:15:47.76
Epoch ::  5 || Loss: 0.41324913 || it_count: 8344 || Val Loss: 0.46731108 || Val it_count: 1107 || Current Learning Rate: 0.001 || Time: 00:19:42.78
Epoch ::  6 || Loss: 0.41170538 || it_count: 8344 || Val Loss: 0.47674774 || Val it_count: 1107 || Current Learning Rate: 0.001 || Time: 00:23:39.67
Epoch ::  7 || Loss: 0.41014859 || it_count: 8344 || Val Loss: 0.47001324 || Val it_count: 1107 || Current Learning Rate: 0.001 || Time: 00:27:37.24
Epoch ::  8 || Loss: 0.40917256 || it_count: 8344 || Val Loss: 0.47881425 || Val it_count: 1107 || Current Learning Rate: 0.001 || Time: 00:31:33.68
Epoch ::  9 || Loss: 0.40897227 || it_count: 8344 || Val Loss: 0.46896429 || Val it_count: 1107 || Current Learning Rate: 0.001 || Time: 00:35:29.04
Epoch :: 10 || Loss: 0.40791571 || it_count: 8344 || Val Loss: 0.46483012 || Val it_count: 1107 || Current Learning Rate: 0.001 || Time: 00:39:25.98
Epoch :: 11 || Loss: 0.40752791 || it_count: 8344 || Val Loss: 0.46425825 || Val it_count: 1107 || Current Learning Rate: 0.001 || Time: 00:43:23.65
Epoch :: 12 || Loss: 0.40659338 || it_count: 8344 || Val Loss: 0.46978501 || Val it_count: 1107 || Current Learning Rate: 0.001 || Time: 00:47:21.10
Epoch :: 13 || Loss: 0.40608184 || it_count: 8344 || Val Loss: 0.46688316 || Val it_count: 1107 || Current Learning Rate: 0.001 || Time: 00:51:16.88
Epoch :: 14 || Loss: 0.40545484 || it_count: 8344 || Val Loss: 0.46431586 || Val it_count: 1107 || Current Learning Rate: 0.001 || Time: 00:55:11.95
Epoch :: 15 || Loss: 0.40443132 || it_count: 8344 || Val Loss: 0.46567395 || Val it_count: 1107 || Current Learning Rate: 0.001 || Time: 00:59:7.09
Epoch :: 16 || Loss: 0.40361362 || it_count: 8344 || Val Loss: 0.47024872 || Val it_count: 1107 || Current Learning Rate: 0.001 || Time: 01:03:3.74
Epoch :: 17 || Loss: 0.40258905 || it_count: 8344 || Val Loss: 0.47113095 || Val it_count: 1107 || Current Learning Rate: 0.001 || Time: 01:07:1.11
Epoch :: 18 || Loss: 0.40215273 || it_count: 8344 || Val Loss: 0.47252395 || Val it_count: 1107 || Current Learning Rate: 0.001 || Time: 01:10:57.61
Epoch :: 19 || Loss: 0.40133243 || it_count: 8344 || Val Loss: 0.47863578 || Val it_count: 1107 || Current Learning Rate: 0.001 || Time: 01:14:54.96
Epoch :: 20 || Loss: 0.40073271 || it_count: 8344 || Val Loss: 0.46887913 || Val it_count: 1107 || Current Learning Rate: 0.001 || Time: 01:18:51.05
Epoch :: 21 || Loss: 0.39968504 || it_count: 8344 || Val Loss: 0.47153708 || Val it_count: 1107 || Current Learning Rate: 0.001 || Time: 01:22:47.13
Epoch :: 22 || Loss: 0.39833583 || it_count: 8344 || Val Loss: 0.47911891 || Val it_count: 1107 || Current Learning Rate: 0.001 || Time: 01:26:44.20
Epoch :: 23 || Loss: 0.39772600 || it_count: 8344 || Val Loss: 0.48015184 || Val it_count: 1107 || Current Learning Rate: 0.001 || Time: 01:30:40.62
Epoch :: 24 || Loss: 0.39663786 || it_count: 8344 || Val Loss: 0.47578209 || Val it_count: 1107 || Current Learning Rate: 0.001 || Time: 01:34:35.53
Epoch :: 25 || Loss: 0.39725588 || it_count: 8344 || Val Loss: 0.47723008 || Val it_count: 1107 || Current Learning Rate: 0.001 || Time: 01:38:31.19
Epoch :: 26 || Loss: 0.39457061 || it_count: 8344 || Val Loss: 0.48923630 || Val it_count: 1107 || Current Learning Rate: 0.0001 || Time: 01:42:28.73
Epoch :: 27 || Loss: 0.40051223 || it_count: 8344 || Val Loss: 0.46323149 || Val it_count: 1107 || Current Learning Rate: 0.0001 || Time: 01:46:26.38
Epoch :: 28 || Loss: 0.39581058 || it_count: 8344 || Val Loss: 0.46195418 || Val it_count: 1107 || Current Learning Rate: 0.0001 || Time: 01:50:23.33
Epoch :: 29 || Loss: 0.39357495 || it_count: 8344 || Val Loss: 0.46363842 || Val it_count: 1107 || Current Learning Rate: 0.0001 || Time: 01:54:19.90
Epoch :: 30 || Loss: 0.39161522 || it_count: 8344 || Val Loss: 0.46253587 || Val it_count: 1107 || Current Learning Rate: 0.0001 || Time: 01:58:17.28
Epoch :: 31 || Loss: 0.39007738 || it_count: 8344 || Val Loss: 0.46377105 || Val it_count: 1107 || Current Learning Rate: 0.0001 || Time: 02:02:14.10
Epoch :: 32 || Loss: 0.38860459 || it_count: 8344 || Val Loss: 0.46593992 || Val it_count: 1107 || Current Learning Rate: 0.0001 || Time: 02:06:9.76
Epoch :: 33 || Loss: 0.38707176 || it_count: 8344 || Val Loss: 0.46488240 || Val it_count: 1107 || Current Learning Rate: 0.0001 || Time: 02:10:5.58
Epoch :: 34 || Loss: 0.38565149 || it_count: 8344 || Val Loss: 0.46524923 || Val it_count: 1107 || Current Learning Rate: 1e-05 || Time: 02:14:1.10
Epoch :: 35 || Loss: 0.39424688 || it_count: 8344 || Val Loss: 0.45230870 || Val it_count: 1107 || Current Learning Rate: 1e-05 || Time: 02:17:58.76
Epoch :: 36 || Loss: 0.39207644 || it_count: 8344 || Val Loss: 0.45240518 || Val it_count: 1107 || Current Learning Rate: 1e-05 || Time: 02:21:59.41
Epoch :: 37 || Loss: 0.39148617 || it_count: 8344 || Val Loss: 0.45301147 || Val it_count: 1107 || Current Learning Rate: 1e-05 || Time: 02:26:1.15
Epoch :: 38 || Loss: 0.39111438 || it_count: 8344 || Val Loss: 0.45415039 || Val it_count: 1107 || Current Learning Rate: 1e-05 || Time: 02:30:3.25
Epoch :: 39 || Loss: 0.39077012 || it_count: 8344 || Val Loss: 0.45444557 || Val it_count: 1107 || Current Learning Rate: 1e-05 || Time: 02:34:3.86
Epoch :: 40 || Loss: 0.39062584 || it_count: 8344 || Val Loss: 0.45478174 || Val it_count: 1107 || Current Learning Rate: 1e-05 || Time: 02:38:5.40
Epoch :: 41 || Loss: 0.39014832 || it_count: 8344 || Val Loss: 0.45542150 || Val it_count: 1107 || Current Learning Rate: 1.0000000000000002e-06 || Time: 02:42:7.61
Epoch :: 42 || Loss: 0.39360278 || it_count: 8344 || Val Loss: 0.45088199 || Val it_count: 1107 || Current Learning Rate: 1.0000000000000002e-06 || Time: 02:46:9.47
Epoch :: 43 || Loss: 0.39232759 || it_count: 8344 || Val Loss: 0.44974316 || Val it_count: 1107 || Current Learning Rate: 1.0000000000000002e-06 || Time: 02:50:12.44
Epoch :: 44 || Loss: 0.39194094 || it_count: 8344 || Val Loss: 0.44937474 || Val it_count: 1107 || Current Learning Rate: 1.0000000000000002e-06 || Time: 02:54:13.97
Epoch :: 45 || Loss: 0.39195066 || it_count: 8344 || Val Loss: 0.44918957 || Val it_count: 1107 || Current Learning Rate: 1.0000000000000002e-06 || Time: 02:58:16.75
Epoch :: 46 || Loss: 0.39177128 || it_count: 8344 || Val Loss: 0.44905151 || Val it_count: 1107 || Current Learning Rate: 1.0000000000000002e-06 || Time: 03:02:19.54
Epoch :: 47 || Loss: 0.39155398 || it_count: 8344 || Val Loss: 0.44909217 || Val it_count: 1107 || Current Learning Rate: 1.0000000000000002e-06 || Time: 03:06:21.36
Epoch :: 48 || Loss: 0.39159224 || it_count: 8344 || Val Loss: 0.44918614 || Val it_count: 1107 || Current Learning Rate: 1.0000000000000002e-06 || Time: 03:10:22.27
Epoch :: 49 || Loss: 0.39166743 || it_count: 8344 || Val Loss: 0.44923205 || Val it_count: 1107 || Current Learning Rate: 1.0000000000000002e-06 || Time: 03:14:24.61
Epoch :: 50 || Loss: 0.39157400 || it_count: 8344 || Val Loss: 0.44922960 || Val it_count: 1107 || Current Learning Rate: 1.0000000000000002e-06 || Time: 03:18:30.50
Epoch :: 51 || Loss: 0.39157018 || it_count: 8344 || Val Loss: 0.44907525 || Val it_count: 1107 || Current Learning Rate: 1.0000000000000002e-06 || Time: 03:22:36.81
Early stopping triggered due to learning rate below threshold.
Done Total time: 03:26:42.79
best_loss: 0.44905150916365033

--------------------Testing--------------------

total_samples :: test_dataset = 139200, test_dataloader = 139200
Epoch ::  1 || Loss: 0.35734975 || it_count: 544 || Time: 00:00:12.87
MAE:  0.28736183
MSE:  0.35742334
RMSE:  0.4886796

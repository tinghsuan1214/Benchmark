--------------------Training--------------------
arch_str :: |lstm_2~0|+|lstm_2~0|lstm_2~1|[linear->relu->linear]
model :: 3G
InferCell(
  info :: nodes=3, inC=1, outC=64, [1<-(I0-L0) | 2<-(I0-L1,I1-L2)], genotype_str: lstm_2~0|lstm_2~0|lstm_2~1
  linear_layers: [linear->relu->linear]
  (layers): ModuleList(
    (0): LSTM(
      (lstm): LSTM(1, 64, num_layers=2, batch_first=True)
    )
    (1): LSTM(
      (lstm): LSTM(1, 64, num_layers=2, batch_first=True)
    )
    (2): LSTM(
      (lstm): LSTM(64, 64, num_layers=2, batch_first=True)
    )
  )
  (linear_layers): ModuleList(
    (0): Linear(in_features=3072, out_features=1536, bias=True)
    (1): ReLU()
    (2): Linear(in_features=1536, out_features=1, bias=True)
  )
)
tr_params :: epochs = 100, patience = 20, batch_size = 256, window_size = 48, data_size = 100
Model MACs: 12.904M, Model Params: 4.889M
learning rate scheduling :: (optimizer, mode='min', factor=0.1, patience=5, verbose=True)
total_samples :: train_dataset = 2136000, train_dataloader = 2136000
total_samples :: valid_dataset = 283200, valid_dataloader = 283200
Epoch ::  1 || Loss: 0.41872714 || it_count: 8344 || Val Loss: 0.45236070 || Val it_count: 1107 || Current Learning Rate: 0.001 || Time: 00:15:27.01
Epoch ::  2 || Loss: 0.41352065 || it_count: 8344 || Val Loss: 0.45248673 || Val it_count: 1107 || Current Learning Rate: 0.001 || Time: 00:30:52.41
Epoch ::  3 || Loss: 0.41276285 || it_count: 8344 || Val Loss: 0.45260831 || Val it_count: 1107 || Current Learning Rate: 0.001 || Time: 00:46:18.33
Epoch ::  4 || Loss: 0.41206140 || it_count: 8344 || Val Loss: 0.44884332 || Val it_count: 1107 || Current Learning Rate: 0.001 || Time: 01:01:52.43
Epoch ::  5 || Loss: 0.41049105 || it_count: 8344 || Val Loss: 0.45151058 || Val it_count: 1107 || Current Learning Rate: 0.001 || Time: 01:17:37.34
Epoch ::  6 || Loss: 0.40925869 || it_count: 8344 || Val Loss: 0.45166285 || Val it_count: 1107 || Current Learning Rate: 0.001 || Time: 01:33:24.78
Epoch ::  7 || Loss: 0.40803332 || it_count: 8344 || Val Loss: 0.44911098 || Val it_count: 1107 || Current Learning Rate: 0.001 || Time: 01:49:11.39
Epoch ::  8 || Loss: 0.40684965 || it_count: 8344 || Val Loss: 0.44768152 || Val it_count: 1107 || Current Learning Rate: 0.001 || Time: 02:05:0.07
Epoch ::  9 || Loss: 0.40535513 || it_count: 8344 || Val Loss: 0.44740524 || Val it_count: 1107 || Current Learning Rate: 0.001 || Time: 02:20:48.29
Epoch :: 10 || Loss: 0.40383909 || it_count: 8344 || Val Loss: 0.44699323 || Val it_count: 1107 || Current Learning Rate: 0.001 || Time: 02:36:36.63
Epoch :: 11 || Loss: 0.40198107 || it_count: 8344 || Val Loss: 0.44579687 || Val it_count: 1107 || Current Learning Rate: 0.001 || Time: 02:52:25.50
Epoch :: 12 || Loss: 0.39950598 || it_count: 8344 || Val Loss: 0.44848970 || Val it_count: 1107 || Current Learning Rate: 0.001 || Time: 03:08:15.68
Epoch :: 13 || Loss: 0.39685052 || it_count: 8344 || Val Loss: 0.44588946 || Val it_count: 1107 || Current Learning Rate: 0.001 || Time: 03:24:5.74
Epoch :: 14 || Loss: 0.39346293 || it_count: 8344 || Val Loss: 0.44735638 || Val it_count: 1107 || Current Learning Rate: 0.001 || Time: 03:39:56.04
Epoch :: 15 || Loss: 0.38925875 || it_count: 8344 || Val Loss: 0.44758611 || Val it_count: 1107 || Current Learning Rate: 0.001 || Time: 03:55:48.25
Epoch :: 16 || Loss: 0.38455068 || it_count: 8344 || Val Loss: 0.45154211 || Val it_count: 1107 || Current Learning Rate: 0.001 || Time: 04:11:40.95
Epoch :: 17 || Loss: 0.37929839 || it_count: 8344 || Val Loss: 0.45582216 || Val it_count: 1107 || Current Learning Rate: 0.001 || Time: 04:27:32.48
Epoch :: 18 || Loss: 0.37385804 || it_count: 8344 || Val Loss: 0.46485430 || Val it_count: 1107 || Current Learning Rate: 0.001 || Time: 04:43:26.84
Epoch :: 19 || Loss: 0.36820120 || it_count: 8344 || Val Loss: 0.46974395 || Val it_count: 1107 || Current Learning Rate: 0.001 || Time: 04:59:19.45
Epoch :: 20 || Loss: 0.36304847 || it_count: 8344 || Val Loss: 0.47965098 || Val it_count: 1107 || Current Learning Rate: 0.001 || Time: 05:15:13.26
Epoch :: 21 || Loss: 0.35832863 || it_count: 8344 || Val Loss: 0.48857179 || Val it_count: 1107 || Current Learning Rate: 0.001 || Time: 05:31:8.41
Epoch :: 22 || Loss: 0.35501805 || it_count: 8344 || Val Loss: 0.48749335 || Val it_count: 1107 || Current Learning Rate: 0.001 || Time: 05:47:2.28
Epoch 00007: reducing learning rate of group 0 to 1.0000e-04.
Epoch :: 23 || Loss: 0.35011115 || it_count: 8344 || Val Loss: 0.49465995 || Val it_count: 1107 || Current Learning Rate: 0.0001 || Time: 06:02:58.07
Epoch :: 24 || Loss: 0.37346709 || it_count: 8344 || Val Loss: 0.44701384 || Val it_count: 1107 || Current Learning Rate: 0.0001 || Time: 06:18:53.25
Epoch :: 25 || Loss: 0.36259724 || it_count: 8344 || Val Loss: 0.44688027 || Val it_count: 1107 || Current Learning Rate: 0.0001 || Time: 06:34:48.55
Epoch :: 26 || Loss: 0.35578099 || it_count: 8344 || Val Loss: 0.44811247 || Val it_count: 1107 || Current Learning Rate: 0.0001 || Time: 06:50:45.73
Epoch :: 27 || Loss: 0.35036907 || it_count: 8344 || Val Loss: 0.44938554 || Val it_count: 1107 || Current Learning Rate: 0.0001 || Time: 07:06:41.87
Epoch :: 28 || Loss: 0.34564694 || it_count: 8344 || Val Loss: 0.45104865 || Val it_count: 1107 || Current Learning Rate: 0.0001 || Time: 07:22:39.74
Epoch :: 29 || Loss: 0.34140155 || it_count: 8344 || Val Loss: 0.45263097 || Val it_count: 1107 || Current Learning Rate: 0.0001 || Time: 07:38:34.94
Epoch :: 30 || Loss: 0.33754746 || it_count: 8344 || Val Loss: 0.45441896 || Val it_count: 1107 || Current Learning Rate: 0.0001 || Time: 07:54:33.72
Epoch 00015: reducing learning rate of group 0 to 1.0000e-05.
Epoch :: 31 || Loss: 0.33403175 || it_count: 8344 || Val Loss: 0.45607016 || Val it_count: 1107 || Current Learning Rate: 1e-05 || Time: 08:10:29.47
Early stopping triggered due to patience exceeded.
Done Total time: 08:10:29.47
best_loss: 0.4457968680885039

--------------------Testing--------------------

total_samples :: test_dataset = 139200, test_dataloader = 139200
Epoch ::  1 || Loss: 0.30162872 || it_count: 544 || Time: 00:00:29.86
MAE:  0.2900459
MSE:  0.3016826
RMSE:  0.48076397

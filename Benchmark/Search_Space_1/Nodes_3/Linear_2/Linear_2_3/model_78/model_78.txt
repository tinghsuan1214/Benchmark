--------------------Training--------------------
arch_str :: |none~0|+|lstm_1~0|lstm_3~1|[linear->relu->linear]
model :: 3G
InferCell(
  info :: nodes=3, inC=1, outC=64, [1<-(I0-L0) | 2<-(I0-L1,I1-L2)], genotype_str: none~0|lstm_1~0|lstm_3~1
  linear_layers: [linear->relu->linear]
  (layers): ModuleList(
    (0): Zero(C_in=1, C_out=64, stride=1)
    (1): LSTM(
      (lstm): LSTM(1, 64, batch_first=True)
    )
    (2): LSTM(
      (lstm): LSTM(64, 64, num_layers=3, batch_first=True)
    )
  )
  (linear_layers): ModuleList(
    (0): Linear(in_features=3072, out_features=1536, bias=True)
    (1): ReLU()
    (2): Linear(in_features=1536, out_features=1, bias=True)
  )
)
tr_params :: epochs = 100, patience = 20, batch_size = 256, window_size = 48, data_size = 100
Model MACs: 10.434M, Model Params: 4.839M
learning rate scheduling :: (optimizer, mode='min', factor=0.1, patience=5, verbose=True)
total_samples :: train_dataset = 2136000, train_dataloader = 2136000
total_samples :: valid_dataset = 283200, valid_dataloader = 283200
Epoch ::  1 || Loss: 0.41637057 || it_count: 8344 || Val Loss: 0.44783329 || Val it_count: 1107 || Current Learning Rate: 0.001 || Time: 00:11:7.69
Epoch ::  2 || Loss: 0.41302057 || it_count: 8344 || Val Loss: 0.44521396 || Val it_count: 1107 || Current Learning Rate: 0.001 || Time: 00:22:13.36
Epoch ::  3 || Loss: 0.41236780 || it_count: 8344 || Val Loss: 0.44470062 || Val it_count: 1107 || Current Learning Rate: 0.001 || Time: 00:33:21.04
Epoch ::  4 || Loss: 0.41133151 || it_count: 8344 || Val Loss: 0.44358294 || Val it_count: 1107 || Current Learning Rate: 0.001 || Time: 00:44:31.81
Epoch ::  5 || Loss: 0.41034189 || it_count: 8344 || Val Loss: 0.44928524 || Val it_count: 1107 || Current Learning Rate: 0.001 || Time: 00:55:44.16
Epoch ::  6 || Loss: 0.40904868 || it_count: 8344 || Val Loss: 0.45150489 || Val it_count: 1107 || Current Learning Rate: 0.001 || Time: 01:06:59.74
Epoch ::  7 || Loss: 0.40822798 || it_count: 8344 || Val Loss: 0.44351303 || Val it_count: 1107 || Current Learning Rate: 0.001 || Time: 01:18:14.77
Epoch ::  8 || Loss: 0.40728432 || it_count: 8344 || Val Loss: 0.43986309 || Val it_count: 1107 || Current Learning Rate: 0.001 || Time: 01:29:30.13
Epoch ::  9 || Loss: 0.40635981 || it_count: 8344 || Val Loss: 0.43979418 || Val it_count: 1107 || Current Learning Rate: 0.001 || Time: 01:40:45.99
Epoch :: 10 || Loss: 0.40570339 || it_count: 8344 || Val Loss: 0.44475076 || Val it_count: 1107 || Current Learning Rate: 0.001 || Time: 01:52:2.95
Epoch :: 11 || Loss: 0.40496366 || it_count: 8344 || Val Loss: 0.44045310 || Val it_count: 1107 || Current Learning Rate: 0.001 || Time: 02:03:19.73
Epoch :: 12 || Loss: 0.40437533 || it_count: 8344 || Val Loss: 0.44244380 || Val it_count: 1107 || Current Learning Rate: 0.001 || Time: 02:14:36.93
Epoch :: 13 || Loss: 0.40355727 || it_count: 8344 || Val Loss: 0.44092445 || Val it_count: 1107 || Current Learning Rate: 0.001 || Time: 02:25:54.85
Epoch :: 14 || Loss: 0.40235682 || it_count: 8344 || Val Loss: 0.44210014 || Val it_count: 1107 || Current Learning Rate: 0.001 || Time: 02:37:12.20
Epoch :: 15 || Loss: 0.40154063 || it_count: 8344 || Val Loss: 0.43933963 || Val it_count: 1107 || Current Learning Rate: 0.001 || Time: 02:48:28.79
Epoch :: 16 || Loss: 0.40050095 || it_count: 8344 || Val Loss: 0.44263071 || Val it_count: 1107 || Current Learning Rate: 0.001 || Time: 02:59:45.47
Epoch :: 17 || Loss: 0.39932099 || it_count: 8344 || Val Loss: 0.44221928 || Val it_count: 1107 || Current Learning Rate: 0.001 || Time: 03:11:2.17
Epoch :: 18 || Loss: 0.39821763 || it_count: 8344 || Val Loss: 0.44383098 || Val it_count: 1107 || Current Learning Rate: 0.001 || Time: 03:22:18.62
Epoch :: 19 || Loss: 0.39696171 || it_count: 8344 || Val Loss: 0.44640153 || Val it_count: 1107 || Current Learning Rate: 0.001 || Time: 03:33:35.20
Epoch :: 20 || Loss: 0.39563870 || it_count: 8344 || Val Loss: 0.44794896 || Val it_count: 1107 || Current Learning Rate: 0.001 || Time: 03:44:52.29
Epoch :: 21 || Loss: 0.39429509 || it_count: 8344 || Val Loss: 0.44632270 || Val it_count: 1107 || Current Learning Rate: 0.001 || Time: 03:56:9.66
Epoch :: 22 || Loss: 0.39261356 || it_count: 8344 || Val Loss: 0.44616936 || Val it_count: 1107 || Current Learning Rate: 0.001 || Time: 04:07:26.86
Epoch 00007: reducing learning rate of group 0 to 1.0000e-04.
Epoch :: 23 || Loss: 0.39095084 || it_count: 8344 || Val Loss: 0.44843787 || Val it_count: 1107 || Current Learning Rate: 0.0001 || Time: 04:18:43.41
Epoch :: 24 || Loss: 0.40169457 || it_count: 8344 || Val Loss: 0.42283940 || Val it_count: 1107 || Current Learning Rate: 0.0001 || Time: 04:29:59.89
Epoch :: 25 || Loss: 0.39599167 || it_count: 8344 || Val Loss: 0.42216173 || Val it_count: 1107 || Current Learning Rate: 0.0001 || Time: 04:41:16.89
Epoch :: 26 || Loss: 0.39366640 || it_count: 8344 || Val Loss: 0.42233972 || Val it_count: 1107 || Current Learning Rate: 0.0001 || Time: 04:52:33.45
Epoch :: 27 || Loss: 0.39181569 || it_count: 8344 || Val Loss: 0.42262932 || Val it_count: 1107 || Current Learning Rate: 0.0001 || Time: 05:03:50.05
Epoch :: 28 || Loss: 0.39017414 || it_count: 8344 || Val Loss: 0.42316915 || Val it_count: 1107 || Current Learning Rate: 0.0001 || Time: 05:15:7.06
Epoch :: 29 || Loss: 0.38867675 || it_count: 8344 || Val Loss: 0.42390788 || Val it_count: 1107 || Current Learning Rate: 0.0001 || Time: 05:26:24.64
Epoch :: 30 || Loss: 0.38724924 || it_count: 8344 || Val Loss: 0.42457039 || Val it_count: 1107 || Current Learning Rate: 0.0001 || Time: 05:37:42.27
Epoch 00015: reducing learning rate of group 0 to 1.0000e-05.
Epoch :: 31 || Loss: 0.38588748 || it_count: 8344 || Val Loss: 0.42526018 || Val it_count: 1107 || Current Learning Rate: 1e-05 || Time: 05:48:59.20
Epoch :: 32 || Loss: 0.39338192 || it_count: 8344 || Val Loss: 0.42121742 || Val it_count: 1107 || Current Learning Rate: 1e-05 || Time: 06:00:15.87
Epoch :: 33 || Loss: 0.39073773 || it_count: 8344 || Val Loss: 0.42071928 || Val it_count: 1107 || Current Learning Rate: 1e-05 || Time: 06:11:32.78
Epoch :: 34 || Loss: 0.39017236 || it_count: 8344 || Val Loss: 0.42055618 || Val it_count: 1107 || Current Learning Rate: 1e-05 || Time: 06:22:49.63
Epoch :: 35 || Loss: 0.38980297 || it_count: 8344 || Val Loss: 0.42050087 || Val it_count: 1107 || Current Learning Rate: 1e-05 || Time: 06:34:6.78
Epoch :: 36 || Loss: 0.38949279 || it_count: 8344 || Val Loss: 0.42049526 || Val it_count: 1107 || Current Learning Rate: 1e-05 || Time: 06:45:24.06
Epoch :: 37 || Loss: 0.38920755 || it_count: 8344 || Val Loss: 0.42050659 || Val it_count: 1107 || Current Learning Rate: 1e-05 || Time: 06:56:41.64
Epoch :: 38 || Loss: 0.38894258 || it_count: 8344 || Val Loss: 0.42051621 || Val it_count: 1107 || Current Learning Rate: 1e-05 || Time: 07:07:59.09
Epoch :: 39 || Loss: 0.38869281 || it_count: 8344 || Val Loss: 0.42055371 || Val it_count: 1107 || Current Learning Rate: 1e-05 || Time: 07:19:16.07
Epoch :: 40 || Loss: 0.38845271 || it_count: 8344 || Val Loss: 0.42057899 || Val it_count: 1107 || Current Learning Rate: 1e-05 || Time: 07:30:32.93
Epoch 00025: reducing learning rate of group 0 to 1.0000e-06.
Epoch :: 41 || Loss: 0.38822060 || it_count: 8344 || Val Loss: 0.42063128 || Val it_count: 1107 || Current Learning Rate: 1.0000000000000002e-06 || Time: 07:41:49.88
Epoch :: 42 || Loss: 0.38869340 || it_count: 8344 || Val Loss: 0.42099384 || Val it_count: 1107 || Current Learning Rate: 1.0000000000000002e-06 || Time: 07:53:6.79
Epoch :: 43 || Loss: 0.38848664 || it_count: 8344 || Val Loss: 0.42116163 || Val it_count: 1107 || Current Learning Rate: 1.0000000000000002e-06 || Time: 08:04:23.79
Epoch :: 44 || Loss: 0.38838440 || it_count: 8344 || Val Loss: 0.42120986 || Val it_count: 1107 || Current Learning Rate: 1.0000000000000002e-06 || Time: 08:15:41.23
Epoch :: 45 || Loss: 0.38831582 || it_count: 8344 || Val Loss: 0.42121470 || Val it_count: 1107 || Current Learning Rate: 1.0000000000000002e-06 || Time: 08:26:58.89
Epoch :: 46 || Loss: 0.38826280 || it_count: 8344 || Val Loss: 0.42121239 || Val it_count: 1107 || Current Learning Rate: 1.0000000000000002e-06 || Time: 08:38:16.69
Epoch 00031: reducing learning rate of group 0 to 1.0000e-07.
Early stopping triggered due to learning rate below threshold.
Done Total time: 08:49:33.52
best_loss: 0.4204952569375003

--------------------Testing--------------------

total_samples :: test_dataset = 139200, test_dataloader = 139200
Epoch ::  1 || Loss: 0.24575131 || it_count: 544 || Time: 00:00:26.46
MAE:  0.2580192
MSE:  0.24577406
RMSE:  0.44999683

--------------------Training--------------------
arch_str :: |lstm_1~0|+|lstm_1~0|skip_connect~1|[linear->relu->linear]
model :: 3G
InferCell(
  info :: nodes=3, inC=1, outC=64, [1<-(I0-L0) | 2<-(I0-L1,I1-L2)], genotype_str: lstm_1~0|lstm_1~0|skip_connect~1
  linear_layers: [linear->relu->linear]
  (layers): ModuleList(
    (0): LSTM(
      (lstm): LSTM(1, 64, batch_first=True)
    )
    (1): LSTM(
      (lstm): LSTM(1, 64, batch_first=True)
    )
    (2): Identity()
  )
  (linear_layers): ModuleList(
    (0): Linear(in_features=3072, out_features=1536, bias=True)
    (1): ReLU()
    (2): Linear(in_features=1536, out_features=1, bias=True)
  )
)
tr_params :: epochs = 100, patience = 20, batch_size = 256, window_size = 48, data_size = 100
Model MACs: 6.416M, Model Params: 4.756M
learning rate scheduling :: (optimizer, mode='min', factor=0.1, patience=5, verbose=True)
total_samples :: train_dataset = 2136000, train_dataloader = 2136000
total_samples :: valid_dataset = 283200, valid_dataloader = 283200
Epoch ::  1 || Loss: 0.41537618 || it_count: 8344 || Val Loss: 0.44581051 || Val it_count: 1107 || Current Learning Rate: 0.001 || Time: 00:09:43.32
Epoch ::  2 || Loss: 0.41288472 || it_count: 8344 || Val Loss: 0.44839418 || Val it_count: 1107 || Current Learning Rate: 0.001 || Time: 00:19:23.97
Epoch ::  3 || Loss: 0.41232630 || it_count: 8344 || Val Loss: 0.44483288 || Val it_count: 1107 || Current Learning Rate: 0.001 || Time: 00:29:5.40
Epoch ::  4 || Loss: 0.41144961 || it_count: 8344 || Val Loss: 0.44559761 || Val it_count: 1107 || Current Learning Rate: 0.001 || Time: 00:38:47.39
Epoch ::  5 || Loss: 0.41091623 || it_count: 8344 || Val Loss: 0.44650591 || Val it_count: 1107 || Current Learning Rate: 0.001 || Time: 00:48:29.99
Epoch ::  6 || Loss: 0.40992982 || it_count: 8344 || Val Loss: 0.44014155 || Val it_count: 1107 || Current Learning Rate: 0.001 || Time: 00:58:12.86
Epoch ::  7 || Loss: 0.40861849 || it_count: 8344 || Val Loss: 0.45193678 || Val it_count: 1107 || Current Learning Rate: 0.001 || Time: 01:07:55.80
Epoch ::  8 || Loss: 0.40805332 || it_count: 8344 || Val Loss: 0.44850970 || Val it_count: 1107 || Current Learning Rate: 0.001 || Time: 01:17:38.64
Epoch ::  9 || Loss: 0.40657943 || it_count: 8344 || Val Loss: 0.44067161 || Val it_count: 1107 || Current Learning Rate: 0.001 || Time: 01:27:21.51
Epoch :: 10 || Loss: 0.40556398 || it_count: 8344 || Val Loss: 0.45378169 || Val it_count: 1107 || Current Learning Rate: 0.001 || Time: 01:37:4.55
Epoch :: 11 || Loss: 0.40478562 || it_count: 8344 || Val Loss: 0.44688150 || Val it_count: 1107 || Current Learning Rate: 0.001 || Time: 01:46:47.63
Epoch :: 12 || Loss: 0.40370443 || it_count: 8344 || Val Loss: 0.44610493 || Val it_count: 1107 || Current Learning Rate: 0.001 || Time: 01:56:30.74
Epoch :: 13 || Loss: 0.40260134 || it_count: 8344 || Val Loss: 0.44803006 || Val it_count: 1107 || Current Learning Rate: 0.001 || Time: 02:06:13.92
Epoch :: 14 || Loss: 0.40151115 || it_count: 8344 || Val Loss: 0.44808777 || Val it_count: 1107 || Current Learning Rate: 0.001 || Time: 02:15:57.16
Epoch :: 15 || Loss: 0.40032243 || it_count: 8344 || Val Loss: 0.45249249 || Val it_count: 1107 || Current Learning Rate: 0.001 || Time: 02:25:40.64
Epoch :: 16 || Loss: 0.39909819 || it_count: 8344 || Val Loss: 0.45427479 || Val it_count: 1107 || Current Learning Rate: 0.001 || Time: 02:35:24.03
Epoch :: 17 || Loss: 0.39772734 || it_count: 8344 || Val Loss: 0.45196342 || Val it_count: 1107 || Current Learning Rate: 0.001 || Time: 02:45:8.04
Epoch :: 18 || Loss: 0.39621488 || it_count: 8344 || Val Loss: 0.44935029 || Val it_count: 1107 || Current Learning Rate: 0.001 || Time: 02:54:52.36
Epoch :: 19 || Loss: 0.39471627 || it_count: 8344 || Val Loss: 0.44920175 || Val it_count: 1107 || Current Learning Rate: 0.001 || Time: 03:04:36.26
Epoch :: 20 || Loss: 0.39275959 || it_count: 8344 || Val Loss: 0.45278832 || Val it_count: 1107 || Current Learning Rate: 0.001 || Time: 03:14:20.54
Epoch :: 21 || Loss: 0.39098477 || it_count: 8344 || Val Loss: 0.44723897 || Val it_count: 1107 || Current Learning Rate: 0.001 || Time: 03:24:4.84
Epoch :: 22 || Loss: 0.38851628 || it_count: 8344 || Val Loss: 0.45061269 || Val it_count: 1107 || Current Learning Rate: 0.001 || Time: 03:33:49.26
Epoch :: 23 || Loss: 0.38626111 || it_count: 8344 || Val Loss: 0.45008945 || Val it_count: 1107 || Current Learning Rate: 0.001 || Time: 03:43:33.63
Epoch :: 24 || Loss: 0.38335300 || it_count: 8344 || Val Loss: 0.45696514 || Val it_count: 1107 || Current Learning Rate: 0.001 || Time: 03:53:18.10
Epoch :: 25 || Loss: 0.38073686 || it_count: 8344 || Val Loss: 0.45535630 || Val it_count: 1107 || Current Learning Rate: 0.001 || Time: 04:03:3.05
Epoch :: 26 || Loss: 0.37833938 || it_count: 8344 || Val Loss: 0.46384988 || Val it_count: 1107 || Current Learning Rate: 0.001 || Time: 04:12:47.45
Early stopping triggered due to patience exceeded.
Done Total time: 04:12:47.45
best_loss: 0.44014154655082677

--------------------Testing--------------------

total_samples :: test_dataset = 139200, test_dataloader = 139200
Epoch ::  1 || Loss: 0.29893853 || it_count: 544 || Time: 00:00:24.40
MAE:  0.2912075
MSE:  0.29899433
RMSE:  0.4783698

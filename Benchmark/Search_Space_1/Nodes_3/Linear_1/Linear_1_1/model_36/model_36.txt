--------------------Training--------------------
arch_str :: |lstm_2~0|+|lstm_3~0|lstm_1~1|[linear]
model :: 3A
InferCell(
  info :: nodes=3, inC=1, outC=64, [1<-(I0-L0) | 2<-(I0-L1,I1-L2)], genotype_str: lstm_2~0|lstm_3~0|lstm_1~1
  linear_layers: [linear]
  (layers): ModuleList(
    (0): LSTM(
      (lstm): LSTM(1, 64, num_layers=2, batch_first=True)
    )
    (1): LSTM(
      (lstm): LSTM(1, 64, num_layers=3, batch_first=True)
    )
    (2): LSTM(
      (lstm): LSTM(64, 64, batch_first=True)
    )
  )
  (linear_layers): ModuleList(
    (0): Linear(in_features=3072, out_features=1, bias=True)
  )
)
tr_params :: epochs = 100, patience = 20, batch_size = 256, window_size = 48, data_size = 100
Model MACs: 8.187M, Model Params: 170.497K
learning rate scheduling :: (optimizer, mode='min', factor=0.1, patience=5, verbose=True)
total_samples :: train_dataset = 2136000, train_dataloader = 2136000
total_samples :: valid_dataset = 283200, valid_dataloader = 283200
Epoch ::  1 || Loss: 0.42294166 || it_count: 8344 || Val Loss: 0.45117994 || Val it_count: 1107 || Current Learning Rate: 0.001 || Time: 00:04:50.84
Epoch ::  2 || Loss: 0.41856082 || it_count: 8344 || Val Loss: 0.45061192 || Val it_count: 1107 || Current Learning Rate: 0.001 || Time: 00:09:42.37
Epoch ::  3 || Loss: 0.41840816 || it_count: 8344 || Val Loss: 0.45160758 || Val it_count: 1107 || Current Learning Rate: 0.001 || Time: 00:14:36.37
Epoch ::  4 || Loss: 0.41832562 || it_count: 8344 || Val Loss: 0.45172140 || Val it_count: 1107 || Current Learning Rate: 0.001 || Time: 00:19:40.98
Epoch ::  5 || Loss: 0.41810358 || it_count: 8344 || Val Loss: 0.45097620 || Val it_count: 1107 || Current Learning Rate: 0.001 || Time: 00:24:37.01
Epoch ::  6 || Loss: 0.41751674 || it_count: 8344 || Val Loss: 0.45085153 || Val it_count: 1107 || Current Learning Rate: 0.001 || Time: 00:29:33.37
Epoch ::  7 || Loss: 0.41742918 || it_count: 8344 || Val Loss: 0.45140347 || Val it_count: 1107 || Current Learning Rate: 0.001 || Time: 00:34:16.05
Epoch ::  8 || Loss: 0.41703896 || it_count: 8344 || Val Loss: 0.45117930 || Val it_count: 1107 || Current Learning Rate: 0.001 || Time: 00:39:0.69
Epoch ::  9 || Loss: 0.41719848 || it_count: 8344 || Val Loss: 0.45062704 || Val it_count: 1107 || Current Learning Rate: 0.001 || Time: 00:43:44.41
Epoch :: 10 || Loss: 0.41684851 || it_count: 8344 || Val Loss: 0.44976197 || Val it_count: 1107 || Current Learning Rate: 0.001 || Time: 00:48:29.22
Epoch :: 11 || Loss: 0.41655231 || it_count: 8344 || Val Loss: 0.44944182 || Val it_count: 1107 || Current Learning Rate: 0.001 || Time: 00:53:12.40
Epoch :: 12 || Loss: 0.41618081 || it_count: 8344 || Val Loss: 0.44871108 || Val it_count: 1107 || Current Learning Rate: 0.001 || Time: 00:57:57.76
Epoch :: 13 || Loss: 0.41595602 || it_count: 8344 || Val Loss: 0.44784950 || Val it_count: 1107 || Current Learning Rate: 0.001 || Time: 01:02:41.68
Epoch :: 14 || Loss: 0.41563306 || it_count: 8344 || Val Loss: 0.44698244 || Val it_count: 1107 || Current Learning Rate: 0.001 || Time: 01:07:20.48
Epoch :: 15 || Loss: 0.41418649 || it_count: 8344 || Val Loss: 0.44495295 || Val it_count: 1107 || Current Learning Rate: 0.001 || Time: 01:12:2.94
Epoch :: 16 || Loss: 0.41271964 || it_count: 8344 || Val Loss: 0.44381943 || Val it_count: 1107 || Current Learning Rate: 0.001 || Time: 01:16:49.53
Epoch :: 17 || Loss: 0.41221885 || it_count: 8344 || Val Loss: 0.44289705 || Val it_count: 1107 || Current Learning Rate: 0.001 || Time: 01:21:34.47
Epoch :: 18 || Loss: 0.41204154 || it_count: 8344 || Val Loss: 0.44300684 || Val it_count: 1107 || Current Learning Rate: 0.001 || Time: 01:26:14.21
Epoch :: 19 || Loss: 0.41193593 || it_count: 8344 || Val Loss: 0.44436780 || Val it_count: 1107 || Current Learning Rate: 0.001 || Time: 01:30:59.57
Epoch :: 20 || Loss: 0.41158818 || it_count: 8344 || Val Loss: 0.44581842 || Val it_count: 1107 || Current Learning Rate: 0.001 || Time: 01:35:51.68
Epoch :: 21 || Loss: 0.41118310 || it_count: 8344 || Val Loss: 0.44736205 || Val it_count: 1107 || Current Learning Rate: 0.001 || Time: 01:40:39.21
Epoch :: 22 || Loss: 0.41132982 || it_count: 8344 || Val Loss: 0.44814067 || Val it_count: 1107 || Current Learning Rate: 0.001 || Time: 01:45:23.59
Epoch 00007: reducing learning rate of group 0 to 1.0000e-04.
Epoch :: 23 || Loss: 0.41072589 || it_count: 8344 || Val Loss: 0.44939482 || Val it_count: 1107 || Current Learning Rate: 0.0001 || Time: 01:50:7.72
Epoch :: 24 || Loss: 0.41550452 || it_count: 8344 || Val Loss: 0.42188979 || Val it_count: 1107 || Current Learning Rate: 0.0001 || Time: 01:55:5.21
Epoch :: 25 || Loss: 0.41159850 || it_count: 8344 || Val Loss: 0.42108214 || Val it_count: 1107 || Current Learning Rate: 0.0001 || Time: 01:59:59.49
Epoch :: 26 || Loss: 0.41095402 || it_count: 8344 || Val Loss: 0.42078742 || Val it_count: 1107 || Current Learning Rate: 0.0001 || Time: 02:04:44.14
Epoch :: 27 || Loss: 0.41051673 || it_count: 8344 || Val Loss: 0.42062327 || Val it_count: 1107 || Current Learning Rate: 0.0001 || Time: 02:09:28.83
Epoch :: 28 || Loss: 0.41018430 || it_count: 8344 || Val Loss: 0.42041286 || Val it_count: 1107 || Current Learning Rate: 0.0001 || Time: 02:14:12.84
Epoch :: 29 || Loss: 0.40990805 || it_count: 8344 || Val Loss: 0.42022205 || Val it_count: 1107 || Current Learning Rate: 0.0001 || Time: 02:18:56.94
Epoch :: 30 || Loss: 0.40963897 || it_count: 8344 || Val Loss: 0.41993402 || Val it_count: 1107 || Current Learning Rate: 0.0001 || Time: 02:23:46.38
Epoch :: 31 || Loss: 0.40938716 || it_count: 8344 || Val Loss: 0.41961064 || Val it_count: 1107 || Current Learning Rate: 0.0001 || Time: 02:28:32.41
Epoch :: 32 || Loss: 0.40911662 || it_count: 8344 || Val Loss: 0.41924323 || Val it_count: 1107 || Current Learning Rate: 0.0001 || Time: 02:33:17.44
Epoch :: 33 || Loss: 0.40884072 || it_count: 8344 || Val Loss: 0.41893550 || Val it_count: 1107 || Current Learning Rate: 0.0001 || Time: 02:38:4.17
Epoch :: 34 || Loss: 0.40857248 || it_count: 8344 || Val Loss: 0.41878852 || Val it_count: 1107 || Current Learning Rate: 0.0001 || Time: 02:43:3.75
Epoch :: 35 || Loss: 0.40832670 || it_count: 8344 || Val Loss: 0.41874832 || Val it_count: 1107 || Current Learning Rate: 0.0001 || Time: 02:48:2.11
Epoch :: 36 || Loss: 0.40808400 || it_count: 8344 || Val Loss: 0.41870933 || Val it_count: 1107 || Current Learning Rate: 0.0001 || Time: 02:53:0.97
Epoch :: 37 || Loss: 0.40785161 || it_count: 8344 || Val Loss: 0.41877678 || Val it_count: 1107 || Current Learning Rate: 0.0001 || Time: 02:58:1.40
Epoch :: 38 || Loss: 0.40761066 || it_count: 8344 || Val Loss: 0.41891810 || Val it_count: 1107 || Current Learning Rate: 0.0001 || Time: 03:02:58.24
Epoch :: 39 || Loss: 0.40736173 || it_count: 8344 || Val Loss: 0.41903523 || Val it_count: 1107 || Current Learning Rate: 0.0001 || Time: 03:07:59.43
Epoch :: 40 || Loss: 0.40713391 || it_count: 8344 || Val Loss: 0.41916284 || Val it_count: 1107 || Current Learning Rate: 0.0001 || Time: 03:12:47.39
Epoch :: 41 || Loss: 0.40692494 || it_count: 8344 || Val Loss: 0.41924316 || Val it_count: 1107 || Current Learning Rate: 0.0001 || Time: 03:17:34.02
Epoch 00026: reducing learning rate of group 0 to 1.0000e-05.
Epoch :: 42 || Loss: 0.40672403 || it_count: 8344 || Val Loss: 0.41931027 || Val it_count: 1107 || Current Learning Rate: 1e-05 || Time: 03:22:22.56
Epoch :: 43 || Loss: 0.40878891 || it_count: 8344 || Val Loss: 0.41337430 || Val it_count: 1107 || Current Learning Rate: 1e-05 || Time: 03:27:7.25
Epoch :: 44 || Loss: 0.40775194 || it_count: 8344 || Val Loss: 0.41320705 || Val it_count: 1107 || Current Learning Rate: 1e-05 || Time: 03:31:51.34
Epoch :: 45 || Loss: 0.40752197 || it_count: 8344 || Val Loss: 0.41313615 || Val it_count: 1107 || Current Learning Rate: 1e-05 || Time: 03:36:32.62
Epoch :: 46 || Loss: 0.40742179 || it_count: 8344 || Val Loss: 0.41312250 || Val it_count: 1107 || Current Learning Rate: 1e-05 || Time: 03:41:16.67
Epoch :: 47 || Loss: 0.40735284 || it_count: 8344 || Val Loss: 0.41312716 || Val it_count: 1107 || Current Learning Rate: 1e-05 || Time: 03:46:3.52
Epoch :: 48 || Loss: 0.40729848 || it_count: 8344 || Val Loss: 0.41314162 || Val it_count: 1107 || Current Learning Rate: 1e-05 || Time: 03:50:48.59
Epoch :: 49 || Loss: 0.40725213 || it_count: 8344 || Val Loss: 0.41315669 || Val it_count: 1107 || Current Learning Rate: 1e-05 || Time: 03:55:38.54
Epoch :: 50 || Loss: 0.40721090 || it_count: 8344 || Val Loss: 0.41316645 || Val it_count: 1107 || Current Learning Rate: 1e-05 || Time: 04:00:22.04
Epoch 00035: reducing learning rate of group 0 to 1.0000e-06.
Epoch :: 51 || Loss: 0.40717297 || it_count: 8344 || Val Loss: 0.41317290 || Val it_count: 1107 || Current Learning Rate: 1.0000000000000002e-06 || Time: 04:05:7.84
Epoch :: 52 || Loss: 0.40734495 || it_count: 8344 || Val Loss: 0.41297709 || Val it_count: 1107 || Current Learning Rate: 1.0000000000000002e-06 || Time: 04:09:53.93
Epoch :: 53 || Loss: 0.40727060 || it_count: 8344 || Val Loss: 0.41293627 || Val it_count: 1107 || Current Learning Rate: 1.0000000000000002e-06 || Time: 04:14:37.19
Epoch :: 54 || Loss: 0.40724067 || it_count: 8344 || Val Loss: 0.41291883 || Val it_count: 1107 || Current Learning Rate: 1.0000000000000002e-06 || Time: 04:19:23.74
Epoch :: 55 || Loss: 0.40722299 || it_count: 8344 || Val Loss: 0.41291015 || Val it_count: 1107 || Current Learning Rate: 1.0000000000000002e-06 || Time: 04:24:3.78
Epoch :: 56 || Loss: 0.40721067 || it_count: 8344 || Val Loss: 0.41290586 || Val it_count: 1107 || Current Learning Rate: 1.0000000000000002e-06 || Time: 04:28:47.85
Epoch :: 57 || Loss: 0.40720115 || it_count: 8344 || Val Loss: 0.41290391 || Val it_count: 1107 || Current Learning Rate: 1.0000000000000002e-06 || Time: 04:33:27.99
Epoch :: 58 || Loss: 0.40719328 || it_count: 8344 || Val Loss: 0.41290322 || Val it_count: 1107 || Current Learning Rate: 1.0000000000000002e-06 || Time: 04:38:8.12
Epoch :: 59 || Loss: 0.40718645 || it_count: 8344 || Val Loss: 0.41290318 || Val it_count: 1107 || Current Learning Rate: 1.0000000000000002e-06 || Time: 04:42:52.04
Epoch 00044: reducing learning rate of group 0 to 1.0000e-07.
Early stopping triggered due to learning rate below threshold.
Done Total time: 04:47:36.67
best_loss: 0.4129031779120085

--------------------Testing--------------------

total_samples :: test_dataset = 139200, test_dataloader = 139200
Epoch ::  1 || Loss: 0.23626639 || it_count: 544 || Time: 00:00:14.44
MAE:  0.2523451
MSE:  0.23628539
RMSE:  0.44189388

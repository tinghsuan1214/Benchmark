--------------------Training--------------------
arch_str :: |skip_connect~0|+|skip_connect~0|skip_connect~1|[linear]
model :: 3A
InferCell(
  info :: nodes=3, inC=1, outC=64, [1<-(I0-L0) | 2<-(I0-L1,I1-L2)], genotype_str: skip_connect~0|skip_connect~0|skip_connect~1
  linear_layers: [linear]
  (layers): ModuleList(
    (0-1): 2 x FactorizedReduce(
      C_in=1, C_out=64, stride=1
      (relu): ReLU()
      (conv): Conv1d(1, 64, kernel_size=(1,), stride=(1,), bias=False)
      (bn): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (2): Identity()
  )
  (linear_layers): ModuleList(
    (0): Linear(in_features=3072, out_features=1, bias=True)
  )
)
tr_params :: epochs = 100, patience = 20, batch_size = 256, window_size = 48, data_size = 100
Model FLOPs: 33.792K, Model Params: 3.457K
learning rate scheduling :: (optimizer, mode='min', factor=0.1, patience=5, verbose=True)
total_samples :: train_dataset = 2136000, train_dataloader = 2136000
total_samples :: valid_dataset = 283200, valid_dataloader = 283200
Epoch ::  1 || Loss: 0.48545762 || it_count: 8344 || Val Loss: 0.45622835 || Val it_count: 1107 || Current Learning Rate: 0.001 || Time: 00:02:59.46
Epoch ::  2 || Loss: 0.46972618 || it_count: 8344 || Val Loss: 0.45966610 || Val it_count: 1107 || Current Learning Rate: 0.001 || Time: 00:05:51.30
Epoch ::  3 || Loss: 0.46879649 || it_count: 8344 || Val Loss: 0.45843092 || Val it_count: 1107 || Current Learning Rate: 0.001 || Time: 00:08:40.95
Epoch ::  4 || Loss: 0.46940174 || it_count: 8344 || Val Loss: 0.44843143 || Val it_count: 1107 || Current Learning Rate: 0.001 || Time: 00:11:30.80
Epoch ::  5 || Loss: 0.46825670 || it_count: 8344 || Val Loss: 0.45863592 || Val it_count: 1107 || Current Learning Rate: 0.001 || Time: 00:14:21.86
Epoch ::  6 || Loss: 0.46919897 || it_count: 8344 || Val Loss: 0.45629115 || Val it_count: 1107 || Current Learning Rate: 0.001 || Time: 00:17:12.95
Epoch ::  7 || Loss: 0.47035887 || it_count: 8344 || Val Loss: 0.46066477 || Val it_count: 1107 || Current Learning Rate: 0.001 || Time: 00:20:3.23
Epoch ::  8 || Loss: 0.46889053 || it_count: 8344 || Val Loss: 0.45935732 || Val it_count: 1107 || Current Learning Rate: 0.001 || Time: 00:22:55.53
Epoch ::  9 || Loss: 0.47026315 || it_count: 8344 || Val Loss: 0.45396580 || Val it_count: 1107 || Current Learning Rate: 0.001 || Time: 00:25:46.40
Epoch :: 10 || Loss: 0.46937095 || it_count: 8344 || Val Loss: 0.45690375 || Val it_count: 1107 || Current Learning Rate: 0.001 || Time: 00:28:39.80
Epoch :: 11 || Loss: 0.47041201 || it_count: 8344 || Val Loss: 0.46094268 || Val it_count: 1107 || Current Learning Rate: 0.001 || Time: 00:31:33.45
Epoch :: 12 || Loss: 0.47135856 || it_count: 8344 || Val Loss: 0.46205026 || Val it_count: 1107 || Current Learning Rate: 0.001 || Time: 00:34:23.53
Epoch :: 13 || Loss: 0.46860808 || it_count: 8344 || Val Loss: 0.46425191 || Val it_count: 1107 || Current Learning Rate: 0.001 || Time: 00:37:14.84
Epoch :: 14 || Loss: 0.46954819 || it_count: 8344 || Val Loss: 0.46256762 || Val it_count: 1107 || Current Learning Rate: 0.001 || Time: 00:40:6.48
Epoch :: 15 || Loss: 0.46979997 || it_count: 8344 || Val Loss: 0.45819894 || Val it_count: 1107 || Current Learning Rate: 0.001 || Time: 00:43:2.30
Epoch :: 16 || Loss: 0.46906563 || it_count: 8344 || Val Loss: 0.46498254 || Val it_count: 1107 || Current Learning Rate: 0.001 || Time: 00:45:54.09
Epoch :: 17 || Loss: 0.46933926 || it_count: 8344 || Val Loss: 0.45942146 || Val it_count: 1107 || Current Learning Rate: 0.001 || Time: 00:48:45.40
Epoch :: 18 || Loss: 0.47045250 || it_count: 8344 || Val Loss: 0.46141660 || Val it_count: 1107 || Current Learning Rate: 0.001 || Time: 00:51:40.35
Epoch :: 19 || Loss: 0.47076798 || it_count: 8344 || Val Loss: 0.46423046 || Val it_count: 1107 || Current Learning Rate: 0.001 || Time: 00:54:37.65
Epoch :: 20 || Loss: 0.46940363 || it_count: 8344 || Val Loss: 0.46476258 || Val it_count: 1107 || Current Learning Rate: 0.001 || Time: 00:57:29.15
Epoch :: 21 || Loss: 0.47007001 || it_count: 8344 || Val Loss: 0.46656765 || Val it_count: 1107 || Current Learning Rate: 0.001 || Time: 01:00:21.48
Epoch :: 22 || Loss: 0.46943744 || it_count: 8344 || Val Loss: 0.45875682 || Val it_count: 1107 || Current Learning Rate: 0.001 || Time: 01:03:12.30
Epoch :: 23 || Loss: 0.46982967 || it_count: 8344 || Val Loss: 0.46358408 || Val it_count: 1107 || Current Learning Rate: 0.001 || Time: 01:06:3.34
Epoch :: 24 || Loss: 0.47029712 || it_count: 8344 || Val Loss: 0.46526001 || Val it_count: 1107 || Current Learning Rate: 0.001 || Time: 01:08:54.66
Early stopping triggered due to patience exceeded.
Done Total time: 01:08:54.66
best_loss: 0.4484314308287154

--------------------Testing--------------------

total_samples :: test_dataset = 139200, test_dataloader = 139200
Epoch ::  1 || Loss: 0.30755889 || it_count: 544 || Time: 00:00:9.57
MAE:  0.2881949
MSE:  0.30762285
RMSE:  0.49095213

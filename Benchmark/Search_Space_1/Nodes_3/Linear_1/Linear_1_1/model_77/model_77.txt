--------------------Training--------------------
arch_str :: |none~0|+|lstm_1~0|lstm_2~1|[linear]
model :: 3A
InferCell(
  info :: nodes=3, inC=1, outC=64, [1<-(I0-L0) | 2<-(I0-L1,I1-L2)], genotype_str: none~0|lstm_1~0|lstm_2~1
  linear_layers: [linear]
  (layers): ModuleList(
    (0): Zero(C_in=1, C_out=64, stride=1)
    (1): LSTM(
      (lstm): LSTM(1, 64, batch_first=True)
    )
    (2): LSTM(
      (lstm): LSTM(64, 64, num_layers=2, batch_first=True)
    )
  )
  (linear_layers): ModuleList(
    (0): Linear(in_features=3072, out_features=1, bias=True)
  )
)
tr_params :: epochs = 100, patience = 20, batch_size = 256, window_size = 48, data_size = 100
Model FLOPs: 4.095M, Model Params: 86.785K
learning rate scheduling :: (optimizer, mode='min', factor=0.1, patience=5, verbose=True)
total_samples :: train_dataset = 2136000, train_dataloader = 2136000
total_samples :: valid_dataset = 283200, valid_dataloader = 283200
Epoch ::  1 || Loss: 0.42116785 || it_count: 8344 || Val Loss: 0.44986585 || Val it_count: 1107 || Current Learning Rate: 0.001 || Time: 00:08:5.68
Epoch ::  2 || Loss: 0.41953469 || it_count: 8344 || Val Loss: 0.44894422 || Val it_count: 1107 || Current Learning Rate: 0.001 || Time: 00:16:9.69
Epoch ::  3 || Loss: 0.41888367 || it_count: 8344 || Val Loss: 0.44704996 || Val it_count: 1107 || Current Learning Rate: 0.001 || Time: 00:24:13.91
Epoch ::  4 || Loss: 0.41831559 || it_count: 8344 || Val Loss: 0.44576115 || Val it_count: 1107 || Current Learning Rate: 0.001 || Time: 00:32:26.19
Epoch ::  5 || Loss: 0.41816863 || it_count: 8344 || Val Loss: 0.44382845 || Val it_count: 1107 || Current Learning Rate: 0.001 || Time: 00:40:39.78
Epoch ::  6 || Loss: 0.41797272 || it_count: 8344 || Val Loss: 0.44266765 || Val it_count: 1107 || Current Learning Rate: 0.001 || Time: 00:48:52.65
Epoch ::  7 || Loss: 0.41780793 || it_count: 8344 || Val Loss: 0.44189371 || Val it_count: 1107 || Current Learning Rate: 0.001 || Time: 00:57:5.08
Epoch ::  8 || Loss: 0.41753933 || it_count: 8344 || Val Loss: 0.44101454 || Val it_count: 1107 || Current Learning Rate: 0.001 || Time: 01:05:18.09
Epoch ::  9 || Loss: 0.41729040 || it_count: 8344 || Val Loss: 0.44029786 || Val it_count: 1107 || Current Learning Rate: 0.001 || Time: 01:13:30.92
Epoch :: 10 || Loss: 0.41709407 || it_count: 8344 || Val Loss: 0.43994752 || Val it_count: 1107 || Current Learning Rate: 0.001 || Time: 01:21:43.80
Epoch :: 11 || Loss: 0.41684166 || it_count: 8344 || Val Loss: 0.43978687 || Val it_count: 1107 || Current Learning Rate: 0.001 || Time: 01:29:56.63
Epoch :: 12 || Loss: 0.41658688 || it_count: 8344 || Val Loss: 0.43944383 || Val it_count: 1107 || Current Learning Rate: 0.001 || Time: 01:38:9.45
Epoch :: 13 || Loss: 0.41644787 || it_count: 8344 || Val Loss: 0.43973298 || Val it_count: 1107 || Current Learning Rate: 0.001 || Time: 01:46:22.08
Epoch :: 14 || Loss: 0.41629230 || it_count: 8344 || Val Loss: 0.44036697 || Val it_count: 1107 || Current Learning Rate: 0.001 || Time: 01:54:35.13
Epoch :: 15 || Loss: 0.41625749 || it_count: 8344 || Val Loss: 0.43969508 || Val it_count: 1107 || Current Learning Rate: 0.001 || Time: 02:02:48.46
Epoch :: 16 || Loss: 0.41611070 || it_count: 8344 || Val Loss: 0.43954000 || Val it_count: 1107 || Current Learning Rate: 0.001 || Time: 02:11:1.56
Epoch :: 17 || Loss: 0.41601808 || it_count: 8344 || Val Loss: 0.43958081 || Val it_count: 1107 || Current Learning Rate: 0.001 || Time: 02:19:15.30
Epoch :: 18 || Loss: 0.41601364 || it_count: 8344 || Val Loss: 0.43971763 || Val it_count: 1107 || Current Learning Rate: 0.001 || Time: 02:27:27.96
Epoch :: 19 || Loss: 0.41595629 || it_count: 8344 || Val Loss: 0.43996906 || Val it_count: 1107 || Current Learning Rate: 0.001 || Time: 02:35:41.60
Epoch :: 20 || Loss: 0.41594496 || it_count: 8344 || Val Loss: 0.44028248 || Val it_count: 1107 || Current Learning Rate: 0.001 || Time: 02:43:54.57
Epoch :: 21 || Loss: 0.41588873 || it_count: 8344 || Val Loss: 0.43993175 || Val it_count: 1107 || Current Learning Rate: 0.001 || Time: 02:52:7.41
Epoch :: 22 || Loss: 0.41582722 || it_count: 8344 || Val Loss: 0.43970253 || Val it_count: 1107 || Current Learning Rate: 0.001 || Time: 03:00:20.73
Epoch 00007: reducing learning rate of group 0 to 1.0000e-04.
Epoch :: 23 || Loss: 0.41576972 || it_count: 8344 || Val Loss: 0.43972262 || Val it_count: 1107 || Current Learning Rate: 0.0001 || Time: 03:08:34.14
Epoch :: 24 || Loss: 0.42056022 || it_count: 8344 || Val Loss: 0.42619605 || Val it_count: 1107 || Current Learning Rate: 0.0001 || Time: 03:16:47.22
Epoch :: 25 || Loss: 0.41698962 || it_count: 8344 || Val Loss: 0.42460807 || Val it_count: 1107 || Current Learning Rate: 0.0001 || Time: 03:24:59.90
Epoch :: 26 || Loss: 0.41613562 || it_count: 8344 || Val Loss: 0.42403603 || Val it_count: 1107 || Current Learning Rate: 0.0001 || Time: 03:33:13.52
Epoch :: 27 || Loss: 0.41589430 || it_count: 8344 || Val Loss: 0.42384375 || Val it_count: 1107 || Current Learning Rate: 0.0001 || Time: 03:41:26.63
Epoch :: 28 || Loss: 0.41575482 || it_count: 8344 || Val Loss: 0.42372556 || Val it_count: 1107 || Current Learning Rate: 0.0001 || Time: 03:49:39.93
Epoch :: 29 || Loss: 0.41564649 || it_count: 8344 || Val Loss: 0.42363214 || Val it_count: 1107 || Current Learning Rate: 0.0001 || Time: 03:57:53.04
Epoch :: 30 || Loss: 0.41556565 || it_count: 8344 || Val Loss: 0.42354258 || Val it_count: 1107 || Current Learning Rate: 0.0001 || Time: 04:06:6.28
Epoch :: 31 || Loss: 0.41548148 || it_count: 8344 || Val Loss: 0.42346754 || Val it_count: 1107 || Current Learning Rate: 0.0001 || Time: 04:14:19.93
Epoch :: 32 || Loss: 0.41540248 || it_count: 8344 || Val Loss: 0.42336361 || Val it_count: 1107 || Current Learning Rate: 0.0001 || Time: 04:22:33.08
Epoch :: 33 || Loss: 0.41532412 || it_count: 8344 || Val Loss: 0.42324200 || Val it_count: 1107 || Current Learning Rate: 0.0001 || Time: 04:30:46.18
Epoch :: 34 || Loss: 0.41524521 || it_count: 8344 || Val Loss: 0.42310207 || Val it_count: 1107 || Current Learning Rate: 0.0001 || Time: 04:39:0.12
Epoch :: 35 || Loss: 0.41515869 || it_count: 8344 || Val Loss: 0.42293095 || Val it_count: 1107 || Current Learning Rate: 0.0001 || Time: 04:47:15.61
Epoch :: 36 || Loss: 0.41507696 || it_count: 8344 || Val Loss: 0.42274932 || Val it_count: 1107 || Current Learning Rate: 0.0001 || Time: 04:55:32.23
Epoch :: 37 || Loss: 0.41498979 || it_count: 8344 || Val Loss: 0.42252900 || Val it_count: 1107 || Current Learning Rate: 0.0001 || Time: 05:03:52.73
Epoch :: 38 || Loss: 0.41489008 || it_count: 8344 || Val Loss: 0.42228799 || Val it_count: 1107 || Current Learning Rate: 0.0001 || Time: 05:12:8.86
Epoch :: 39 || Loss: 0.41477307 || it_count: 8344 || Val Loss: 0.42201645 || Val it_count: 1107 || Current Learning Rate: 0.0001 || Time: 05:20:27.60
Epoch :: 40 || Loss: 0.41462918 || it_count: 8344 || Val Loss: 0.42170239 || Val it_count: 1107 || Current Learning Rate: 0.0001 || Time: 05:28:48.18
Epoch :: 41 || Loss: 0.41444573 || it_count: 8344 || Val Loss: 0.42135986 || Val it_count: 1107 || Current Learning Rate: 0.0001 || Time: 05:37:8.80
Epoch :: 42 || Loss: 0.41421911 || it_count: 8344 || Val Loss: 0.42101185 || Val it_count: 1107 || Current Learning Rate: 0.0001 || Time: 05:45:30.13
Epoch :: 43 || Loss: 0.41399284 || it_count: 8344 || Val Loss: 0.42068817 || Val it_count: 1107 || Current Learning Rate: 0.0001 || Time: 05:53:51.20
Epoch :: 44 || Loss: 0.41383936 || it_count: 8344 || Val Loss: 0.42046254 || Val it_count: 1107 || Current Learning Rate: 0.0001 || Time: 06:02:11.84
Epoch :: 45 || Loss: 0.41371579 || it_count: 8344 || Val Loss: 0.42035983 || Val it_count: 1107 || Current Learning Rate: 0.0001 || Time: 06:10:33.34
Epoch :: 46 || Loss: 0.41361211 || it_count: 8344 || Val Loss: 0.42030067 || Val it_count: 1107 || Current Learning Rate: 0.0001 || Time: 06:18:54.66
Epoch :: 47 || Loss: 0.41352608 || it_count: 8344 || Val Loss: 0.42026897 || Val it_count: 1107 || Current Learning Rate: 0.0001 || Time: 06:27:16.42
Epoch :: 48 || Loss: 0.41344725 || it_count: 8344 || Val Loss: 0.42027889 || Val it_count: 1107 || Current Learning Rate: 0.0001 || Time: 06:35:37.58
Epoch :: 49 || Loss: 0.41336631 || it_count: 8344 || Val Loss: 0.42032400 || Val it_count: 1107 || Current Learning Rate: 0.0001 || Time: 06:43:58.23
Epoch :: 50 || Loss: 0.41330485 || it_count: 8344 || Val Loss: 0.42035948 || Val it_count: 1107 || Current Learning Rate: 0.0001 || Time: 06:52:19.42
Epoch :: 51 || Loss: 0.41324003 || it_count: 8344 || Val Loss: 0.42041475 || Val it_count: 1107 || Current Learning Rate: 0.0001 || Time: 07:00:41.40
Epoch 00036: reducing learning rate of group 0 to 1.0000e-05.
Epoch :: 52 || Loss: 0.41317566 || it_count: 8344 || Val Loss: 0.42045668 || Val it_count: 1107 || Current Learning Rate: 1e-05 || Time: 07:09:3.01
Epoch :: 53 || Loss: 0.41416006 || it_count: 8344 || Val Loss: 0.41750158 || Val it_count: 1107 || Current Learning Rate: 1e-05 || Time: 07:17:23.43
Epoch :: 54 || Loss: 0.41385206 || it_count: 8344 || Val Loss: 0.41735541 || Val it_count: 1107 || Current Learning Rate: 1e-05 || Time: 07:25:44.40
Epoch :: 55 || Loss: 0.41367019 || it_count: 8344 || Val Loss: 0.41729709 || Val it_count: 1107 || Current Learning Rate: 1e-05 || Time: 07:34:5.63
Epoch :: 56 || Loss: 0.41356107 || it_count: 8344 || Val Loss: 0.41724226 || Val it_count: 1107 || Current Learning Rate: 1e-05 || Time: 07:42:27.68
Epoch :: 57 || Loss: 0.41349099 || it_count: 8344 || Val Loss: 0.41720222 || Val it_count: 1107 || Current Learning Rate: 1e-05 || Time: 07:50:49.51
Epoch :: 58 || Loss: 0.41344030 || it_count: 8344 || Val Loss: 0.41717052 || Val it_count: 1107 || Current Learning Rate: 1e-05 || Time: 07:59:10.96
Epoch :: 59 || Loss: 0.41339994 || it_count: 8344 || Val Loss: 0.41714395 || Val it_count: 1107 || Current Learning Rate: 1e-05 || Time: 08:07:31.85
Epoch :: 60 || Loss: 0.41336835 || it_count: 8344 || Val Loss: 0.41712028 || Val it_count: 1107 || Current Learning Rate: 1e-05 || Time: 08:15:53.48
Epoch :: 61 || Loss: 0.41333820 || it_count: 8344 || Val Loss: 0.41709981 || Val it_count: 1107 || Current Learning Rate: 1e-05 || Time: 08:24:14.44
Epoch :: 62 || Loss: 0.41331115 || it_count: 8344 || Val Loss: 0.41708139 || Val it_count: 1107 || Current Learning Rate: 1e-05 || Time: 08:32:35.66
Epoch :: 63 || Loss: 0.41328785 || it_count: 8344 || Val Loss: 0.41706417 || Val it_count: 1107 || Current Learning Rate: 1e-05 || Time: 08:40:57.34
Epoch :: 64 || Loss: 0.41326443 || it_count: 8344 || Val Loss: 0.41705027 || Val it_count: 1107 || Current Learning Rate: 1e-05 || Time: 08:49:19.47
Epoch :: 65 || Loss: 0.41324211 || it_count: 8344 || Val Loss: 0.41703821 || Val it_count: 1107 || Current Learning Rate: 1e-05 || Time: 08:57:41.28
Epoch :: 66 || Loss: 0.41322082 || it_count: 8344 || Val Loss: 0.41702774 || Val it_count: 1107 || Current Learning Rate: 1e-05 || Time: 09:06:3.08
Epoch :: 67 || Loss: 0.41320048 || it_count: 8344 || Val Loss: 0.41701879 || Val it_count: 1107 || Current Learning Rate: 1e-05 || Time: 09:14:25.02
Epoch :: 68 || Loss: 0.41318101 || it_count: 8344 || Val Loss: 0.41701124 || Val it_count: 1107 || Current Learning Rate: 1e-05 || Time: 09:22:46.53
Epoch :: 69 || Loss: 0.41316241 || it_count: 8344 || Val Loss: 0.41700649 || Val it_count: 1107 || Current Learning Rate: 1e-05 || Time: 09:31:8.54
Epoch :: 70 || Loss: 0.41314447 || it_count: 8344 || Val Loss: 0.41700113 || Val it_count: 1107 || Current Learning Rate: 1e-05 || Time: 09:39:30.84
Epoch :: 71 || Loss: 0.41312721 || it_count: 8344 || Val Loss: 0.41699722 || Val it_count: 1107 || Current Learning Rate: 1e-05 || Time: 09:47:52.95
Epoch :: 72 || Loss: 0.41311073 || it_count: 8344 || Val Loss: 0.41699427 || Val it_count: 1107 || Current Learning Rate: 1e-05 || Time: 09:56:14.60
Epoch 00057: reducing learning rate of group 0 to 1.0000e-06.
Epoch :: 73 || Loss: 0.41309499 || it_count: 8344 || Val Loss: 0.41699167 || Val it_count: 1107 || Current Learning Rate: 1.0000000000000002e-06 || Time: 10:04:36.22
Epoch :: 74 || Loss: 0.41324121 || it_count: 8344 || Val Loss: 0.41667172 || Val it_count: 1107 || Current Learning Rate: 1.0000000000000002e-06 || Time: 10:12:58.55
Epoch :: 75 || Loss: 0.41320048 || it_count: 8344 || Val Loss: 0.41664153 || Val it_count: 1107 || Current Learning Rate: 1.0000000000000002e-06 || Time: 10:21:20.99
Epoch :: 76 || Loss: 0.41319481 || it_count: 8344 || Val Loss: 0.41662865 || Val it_count: 1107 || Current Learning Rate: 1.0000000000000002e-06 || Time: 10:29:42.58
Epoch :: 77 || Loss: 0.41319037 || it_count: 8344 || Val Loss: 0.41661960 || Val it_count: 1107 || Current Learning Rate: 1.0000000000000002e-06 || Time: 10:38:5.09
Epoch :: 78 || Loss: 0.41318656 || it_count: 8344 || Val Loss: 0.41661308 || Val it_count: 1107 || Current Learning Rate: 1.0000000000000002e-06 || Time: 10:46:27.14
Epoch :: 79 || Loss: 0.41318326 || it_count: 8344 || Val Loss: 0.41660811 || Val it_count: 1107 || Current Learning Rate: 1.0000000000000002e-06 || Time: 10:54:49.57
Epoch :: 80 || Loss: 0.41318032 || it_count: 8344 || Val Loss: 0.41660415 || Val it_count: 1107 || Current Learning Rate: 1.0000000000000002e-06 || Time: 11:03:11.33
Epoch :: 81 || Loss: 0.41317765 || it_count: 8344 || Val Loss: 0.41660090 || Val it_count: 1107 || Current Learning Rate: 1.0000000000000002e-06 || Time: 11:11:33.47
Epoch 00066: reducing learning rate of group 0 to 1.0000e-07.
Early stopping triggered due to learning rate below threshold.
Done Total time: 11:19:54.67
best_loss: 0.4166009007881818

--------------------Testing--------------------

total_samples :: test_dataset = 139200, test_dataloader = 139200
Epoch ::  1 || Loss: 0.23858566 || it_count: 544 || Time: 00:00:24.80
MAE:  0.2560343
MSE:  0.23860694
RMSE:  0.44437468

--------------------Training--------------------
arch_str :: |lstm_3~0|+|none~0|lstm_2~1|[linear]
model :: 3A
InferCell(
  info :: nodes=3, inC=1, outC=64, [1<-(I0-L0) | 2<-(I0-L1,I1-L2)], genotype_str: lstm_3~0|none~0|lstm_2~1
  linear_layers: [linear]
  (layers): ModuleList(
    (0): LSTM(
      (lstm): LSTM(1, 64, num_layers=3, batch_first=True)
    )
    (1): Zero(C_in=1, C_out=64, stride=1)
    (2): LSTM(
      (lstm): LSTM(64, 64, num_layers=2, batch_first=True)
    )
  )
  (linear_layers): ModuleList(
    (0): Linear(in_features=3072, out_features=1, bias=True)
  )
)
tr_params :: epochs = 100, patience = 20, batch_size = 256, window_size = 48, data_size = 100
Model MACs: 7.339M, Model Params: 153.345K
learning rate scheduling :: (optimizer, mode='min', factor=0.1, patience=5, verbose=True)
total_samples :: train_dataset = 2136000, train_dataloader = 2136000
total_samples :: valid_dataset = 283200, valid_dataloader = 283200
Epoch ::  1 || Loss: 0.44235904 || it_count: 8344 || Val Loss: 0.45179867 || Val it_count: 1107 || Current Learning Rate: 0.001 || Time: 00:06:10.81
Epoch ::  2 || Loss: 0.41897440 || it_count: 8344 || Val Loss: 0.45303860 || Val it_count: 1107 || Current Learning Rate: 0.001 || Time: 00:12:29.47
Epoch ::  3 || Loss: 0.41845113 || it_count: 8344 || Val Loss: 0.45373956 || Val it_count: 1107 || Current Learning Rate: 0.001 || Time: 00:18:39.88
Epoch ::  4 || Loss: 0.41791484 || it_count: 8344 || Val Loss: 0.45315849 || Val it_count: 1107 || Current Learning Rate: 0.001 || Time: 00:24:50.17
Epoch ::  5 || Loss: 0.41791131 || it_count: 8344 || Val Loss: 0.45426340 || Val it_count: 1107 || Current Learning Rate: 0.001 || Time: 00:31:11.18
Epoch ::  6 || Loss: 0.41759071 || it_count: 8344 || Val Loss: 0.45607746 || Val it_count: 1107 || Current Learning Rate: 0.001 || Time: 00:37:26.16
Epoch ::  7 || Loss: 0.41762478 || it_count: 8344 || Val Loss: 0.45740505 || Val it_count: 1107 || Current Learning Rate: 0.001 || Time: 00:43:36.20
Epoch ::  8 || Loss: 0.41746587 || it_count: 8344 || Val Loss: 0.45736650 || Val it_count: 1107 || Current Learning Rate: 0.001 || Time: 00:49:46.14
Epoch ::  9 || Loss: 0.41697997 || it_count: 8344 || Val Loss: 0.45621273 || Val it_count: 1107 || Current Learning Rate: 0.001 || Time: 00:56:8.86
Epoch :: 10 || Loss: 0.41613913 || it_count: 8344 || Val Loss: 0.45568983 || Val it_count: 1107 || Current Learning Rate: 0.001 || Time: 01:02:18.75
Epoch :: 11 || Loss: 0.41512214 || it_count: 8344 || Val Loss: 0.45460824 || Val it_count: 1107 || Current Learning Rate: 0.001 || Time: 01:08:28.19
Epoch :: 12 || Loss: 0.41506292 || it_count: 8344 || Val Loss: 0.45487003 || Val it_count: 1107 || Current Learning Rate: 0.001 || Time: 01:14:47.39
Epoch :: 13 || Loss: 0.41439827 || it_count: 8344 || Val Loss: 0.45457550 || Val it_count: 1107 || Current Learning Rate: 0.001 || Time: 01:21:3.66
Epoch :: 14 || Loss: 0.41352177 || it_count: 8344 || Val Loss: 0.45378877 || Val it_count: 1107 || Current Learning Rate: 0.001 || Time: 01:27:13.03
Epoch :: 15 || Loss: 0.41270161 || it_count: 8344 || Val Loss: 0.45382159 || Val it_count: 1107 || Current Learning Rate: 0.001 || Time: 01:33:22.76
Epoch :: 16 || Loss: 0.41273583 || it_count: 8344 || Val Loss: 0.45160779 || Val it_count: 1107 || Current Learning Rate: 0.001 || Time: 01:39:44.84
Epoch :: 17 || Loss: 0.41176131 || it_count: 8344 || Val Loss: 0.45293575 || Val it_count: 1107 || Current Learning Rate: 0.001 || Time: 01:45:54.21
Epoch :: 18 || Loss: 0.41178606 || it_count: 8344 || Val Loss: 0.45199517 || Val it_count: 1107 || Current Learning Rate: 0.001 || Time: 01:52:3.96
Epoch :: 19 || Loss: 0.41164432 || it_count: 8344 || Val Loss: 0.45202805 || Val it_count: 1107 || Current Learning Rate: 0.001 || Time: 01:58:23.01
Epoch :: 20 || Loss: 0.41155799 || it_count: 8344 || Val Loss: 0.45081828 || Val it_count: 1107 || Current Learning Rate: 0.001 || Time: 02:04:40.91
Epoch :: 21 || Loss: 0.41136624 || it_count: 8344 || Val Loss: 0.44934190 || Val it_count: 1107 || Current Learning Rate: 0.001 || Time: 02:10:51.43
Epoch :: 22 || Loss: 0.41138718 || it_count: 8344 || Val Loss: 0.45283528 || Val it_count: 1107 || Current Learning Rate: 0.001 || Time: 02:17:2.34
Epoch :: 23 || Loss: 0.41091568 || it_count: 8344 || Val Loss: 0.45254561 || Val it_count: 1107 || Current Learning Rate: 0.001 || Time: 02:23:24.77
Epoch :: 24 || Loss: 0.41097626 || it_count: 8344 || Val Loss: 0.45223714 || Val it_count: 1107 || Current Learning Rate: 0.001 || Time: 02:29:34.39
Epoch :: 25 || Loss: 0.41117107 || it_count: 8344 || Val Loss: 0.45293966 || Val it_count: 1107 || Current Learning Rate: 0.001 || Time: 02:35:44.46
Epoch :: 26 || Loss: 0.41175464 || it_count: 8344 || Val Loss: 0.45162354 || Val it_count: 1107 || Current Learning Rate: 0.001 || Time: 02:42:4.10
Epoch 00011: reducing learning rate of group 0 to 1.0000e-04.
Epoch :: 27 || Loss: 0.41097659 || it_count: 8344 || Val Loss: 0.45022273 || Val it_count: 1107 || Current Learning Rate: 0.0001 || Time: 02:48:23.66
Epoch :: 28 || Loss: 0.41507053 || it_count: 8344 || Val Loss: 0.42140640 || Val it_count: 1107 || Current Learning Rate: 0.0001 || Time: 02:54:33.30
Epoch :: 29 || Loss: 0.41082758 || it_count: 8344 || Val Loss: 0.42010632 || Val it_count: 1107 || Current Learning Rate: 0.0001 || Time: 03:00:42.88
Epoch :: 30 || Loss: 0.41025710 || it_count: 8344 || Val Loss: 0.41996823 || Val it_count: 1107 || Current Learning Rate: 0.0001 || Time: 03:07:5.73
Epoch :: 31 || Loss: 0.40979692 || it_count: 8344 || Val Loss: 0.42009001 || Val it_count: 1107 || Current Learning Rate: 0.0001 || Time: 03:13:15.61
Epoch :: 32 || Loss: 0.40935375 || it_count: 8344 || Val Loss: 0.42008937 || Val it_count: 1107 || Current Learning Rate: 0.0001 || Time: 03:19:25.62
Epoch :: 33 || Loss: 0.40897916 || it_count: 8344 || Val Loss: 0.41990364 || Val it_count: 1107 || Current Learning Rate: 0.0001 || Time: 03:25:44.38
Epoch :: 34 || Loss: 0.40870819 || it_count: 8344 || Val Loss: 0.41978994 || Val it_count: 1107 || Current Learning Rate: 0.0001 || Time: 03:32:4.51
Epoch :: 35 || Loss: 0.40835520 || it_count: 8344 || Val Loss: 0.41963075 || Val it_count: 1107 || Current Learning Rate: 0.0001 || Time: 03:38:15.48
Epoch :: 36 || Loss: 0.40802003 || it_count: 8344 || Val Loss: 0.41947478 || Val it_count: 1107 || Current Learning Rate: 0.0001 || Time: 03:44:25.32
Epoch :: 37 || Loss: 0.40773224 || it_count: 8344 || Val Loss: 0.41917207 || Val it_count: 1107 || Current Learning Rate: 0.0001 || Time: 03:50:48.09
Epoch :: 38 || Loss: 0.40744268 || it_count: 8344 || Val Loss: 0.41908965 || Val it_count: 1107 || Current Learning Rate: 0.0001 || Time: 03:56:57.88
Epoch :: 39 || Loss: 0.40717233 || it_count: 8344 || Val Loss: 0.41894467 || Val it_count: 1107 || Current Learning Rate: 0.0001 || Time: 04:03:7.84
Epoch :: 40 || Loss: 0.40693511 || it_count: 8344 || Val Loss: 0.41889407 || Val it_count: 1107 || Current Learning Rate: 0.0001 || Time: 04:09:26.37
Epoch :: 41 || Loss: 0.40670812 || it_count: 8344 || Val Loss: 0.41886127 || Val it_count: 1107 || Current Learning Rate: 0.0001 || Time: 04:15:47.51
Epoch :: 42 || Loss: 0.40652740 || it_count: 8344 || Val Loss: 0.41871230 || Val it_count: 1107 || Current Learning Rate: 0.0001 || Time: 04:21:56.06
Epoch :: 43 || Loss: 0.40629050 || it_count: 8344 || Val Loss: 0.41883409 || Val it_count: 1107 || Current Learning Rate: 0.0001 || Time: 04:28:5.30
Epoch :: 44 || Loss: 0.40612818 || it_count: 8344 || Val Loss: 0.41887045 || Val it_count: 1107 || Current Learning Rate: 0.0001 || Time: 04:34:27.59
Epoch :: 45 || Loss: 0.40596239 || it_count: 8344 || Val Loss: 0.41898984 || Val it_count: 1107 || Current Learning Rate: 0.0001 || Time: 04:40:36.36
Epoch :: 46 || Loss: 0.40579530 || it_count: 8344 || Val Loss: 0.41894102 || Val it_count: 1107 || Current Learning Rate: 0.0001 || Time: 04:46:45.54
Epoch :: 47 || Loss: 0.40564460 || it_count: 8344 || Val Loss: 0.41884754 || Val it_count: 1107 || Current Learning Rate: 0.0001 || Time: 04:53:3.18
Epoch 00032: reducing learning rate of group 0 to 1.0000e-05.
Epoch :: 48 || Loss: 0.40547707 || it_count: 8344 || Val Loss: 0.41904826 || Val it_count: 1107 || Current Learning Rate: 1e-05 || Time: 04:59:23.57
Epoch :: 49 || Loss: 0.40859617 || it_count: 8344 || Val Loss: 0.41222491 || Val it_count: 1107 || Current Learning Rate: 1e-05 || Time: 05:05:32.48
Epoch :: 50 || Loss: 0.40727296 || it_count: 8344 || Val Loss: 0.41163505 || Val it_count: 1107 || Current Learning Rate: 1e-05 || Time: 05:11:40.79
Epoch :: 51 || Loss: 0.40706992 || it_count: 8344 || Val Loss: 0.41151520 || Val it_count: 1107 || Current Learning Rate: 1e-05 || Time: 05:18:4.53
Epoch :: 52 || Loss: 0.40696402 || it_count: 8344 || Val Loss: 0.41142140 || Val it_count: 1107 || Current Learning Rate: 1e-05 || Time: 05:24:13.55
Epoch :: 53 || Loss: 0.40688840 || it_count: 8344 || Val Loss: 0.41136846 || Val it_count: 1107 || Current Learning Rate: 1e-05 || Time: 05:30:22.60
Epoch :: 54 || Loss: 0.40682355 || it_count: 8344 || Val Loss: 0.41134044 || Val it_count: 1107 || Current Learning Rate: 1e-05 || Time: 05:36:40.17
Epoch :: 55 || Loss: 0.40677004 || it_count: 8344 || Val Loss: 0.41130871 || Val it_count: 1107 || Current Learning Rate: 1e-05 || Time: 05:43:0.41
Epoch :: 56 || Loss: 0.40672326 || it_count: 8344 || Val Loss: 0.41128384 || Val it_count: 1107 || Current Learning Rate: 1e-05 || Time: 05:49:9.87
Epoch :: 57 || Loss: 0.40667787 || it_count: 8344 || Val Loss: 0.41126042 || Val it_count: 1107 || Current Learning Rate: 1e-05 || Time: 05:55:18.41
Epoch :: 58 || Loss: 0.40663513 || it_count: 8344 || Val Loss: 0.41123909 || Val it_count: 1107 || Current Learning Rate: 1e-05 || Time: 06:01:40.46
Epoch :: 59 || Loss: 0.40659379 || it_count: 8344 || Val Loss: 0.41121824 || Val it_count: 1107 || Current Learning Rate: 1e-05 || Time: 06:07:49.39
Epoch :: 60 || Loss: 0.40655216 || it_count: 8344 || Val Loss: 0.41119259 || Val it_count: 1107 || Current Learning Rate: 1e-05 || Time: 06:13:57.83
Epoch :: 61 || Loss: 0.40651488 || it_count: 8344 || Val Loss: 0.41118343 || Val it_count: 1107 || Current Learning Rate: 1e-05 || Time: 06:20:15.77
Epoch :: 62 || Loss: 0.40647833 || it_count: 8344 || Val Loss: 0.41116105 || Val it_count: 1107 || Current Learning Rate: 1e-05 || Time: 06:26:34.84
Epoch :: 63 || Loss: 0.40644322 || it_count: 8344 || Val Loss: 0.41114574 || Val it_count: 1107 || Current Learning Rate: 1e-05 || Time: 06:32:43.92
Epoch :: 64 || Loss: 0.40640968 || it_count: 8344 || Val Loss: 0.41113234 || Val it_count: 1107 || Current Learning Rate: 1e-05 || Time: 06:38:53.55
Epoch :: 65 || Loss: 0.40637754 || it_count: 8344 || Val Loss: 0.41112158 || Val it_count: 1107 || Current Learning Rate: 1e-05 || Time: 06:45:16.03
Epoch :: 66 || Loss: 0.40634667 || it_count: 8344 || Val Loss: 0.41111191 || Val it_count: 1107 || Current Learning Rate: 1e-05 || Time: 06:51:25.09
Epoch :: 67 || Loss: 0.40631679 || it_count: 8344 || Val Loss: 0.41110311 || Val it_count: 1107 || Current Learning Rate: 1e-05 || Time: 06:57:33.89
Epoch :: 68 || Loss: 0.40628775 || it_count: 8344 || Val Loss: 0.41109501 || Val it_count: 1107 || Current Learning Rate: 1e-05 || Time: 07:03:52.23
Epoch :: 69 || Loss: 0.40625946 || it_count: 8344 || Val Loss: 0.41108745 || Val it_count: 1107 || Current Learning Rate: 1e-05 || Time: 07:10:12.91
Epoch :: 70 || Loss: 0.40623183 || it_count: 8344 || Val Loss: 0.41108039 || Val it_count: 1107 || Current Learning Rate: 1e-05 || Time: 07:16:23.51
Epoch :: 71 || Loss: 0.40620635 || it_count: 8344 || Val Loss: 0.41108369 || Val it_count: 1107 || Current Learning Rate: 1e-05 || Time: 07:22:33.95
Epoch :: 72 || Loss: 0.40617888 || it_count: 8344 || Val Loss: 0.41106844 || Val it_count: 1107 || Current Learning Rate: 1e-05 || Time: 07:28:56.24
Epoch :: 73 || Loss: 0.40615395 || it_count: 8344 || Val Loss: 0.41107166 || Val it_count: 1107 || Current Learning Rate: 1e-05 || Time: 07:35:6.36
Epoch :: 74 || Loss: 0.40612746 || it_count: 8344 || Val Loss: 0.41105623 || Val it_count: 1107 || Current Learning Rate: 1e-05 || Time: 07:41:16.12
Epoch :: 75 || Loss: 0.40610323 || it_count: 8344 || Val Loss: 0.41105956 || Val it_count: 1107 || Current Learning Rate: 1e-05 || Time: 07:47:33.12
Epoch :: 76 || Loss: 0.40607748 || it_count: 8344 || Val Loss: 0.41104465 || Val it_count: 1107 || Current Learning Rate: 1e-05 || Time: 07:53:54.81
Epoch :: 77 || Loss: 0.40605383 || it_count: 8344 || Val Loss: 0.41104769 || Val it_count: 1107 || Current Learning Rate: 1e-05 || Time: 08:00:4.52
Epoch 00062: reducing learning rate of group 0 to 1.0000e-06.
Epoch :: 78 || Loss: 0.40603006 || it_count: 8344 || Val Loss: 0.41104444 || Val it_count: 1107 || Current Learning Rate: 1.0000000000000002e-06 || Time: 08:06:13.64
Epoch :: 79 || Loss: 0.40631237 || it_count: 8344 || Val Loss: 0.41078001 || Val it_count: 1107 || Current Learning Rate: 1.0000000000000002e-06 || Time: 08:12:36.54
Epoch :: 80 || Loss: 0.40620839 || it_count: 8344 || Val Loss: 0.41070530 || Val it_count: 1107 || Current Learning Rate: 1.0000000000000002e-06 || Time: 08:18:46.70
Epoch :: 81 || Loss: 0.40616692 || it_count: 8344 || Val Loss: 0.41067587 || Val it_count: 1107 || Current Learning Rate: 1.0000000000000002e-06 || Time: 08:24:56.35
Epoch :: 82 || Loss: 0.40614545 || it_count: 8344 || Val Loss: 0.41066008 || Val it_count: 1107 || Current Learning Rate: 1.0000000000000002e-06 || Time: 08:31:13.83
Epoch :: 83 || Loss: 0.40613163 || it_count: 8344 || Val Loss: 0.41064869 || Val it_count: 1107 || Current Learning Rate: 1.0000000000000002e-06 || Time: 08:37:36.61
Epoch :: 84 || Loss: 0.40612159 || it_count: 8344 || Val Loss: 0.41063995 || Val it_count: 1107 || Current Learning Rate: 1.0000000000000002e-06 || Time: 08:43:45.68
Epoch :: 85 || Loss: 0.40611370 || it_count: 8344 || Val Loss: 0.41063305 || Val it_count: 1107 || Current Learning Rate: 1.0000000000000002e-06 || Time: 08:49:54.78
Epoch :: 86 || Loss: 0.40610713 || it_count: 8344 || Val Loss: 0.41062746 || Val it_count: 1107 || Current Learning Rate: 1.0000000000000002e-06 || Time: 08:56:16.80
Epoch :: 87 || Loss: 0.40610142 || it_count: 8344 || Val Loss: 0.41062285 || Val it_count: 1107 || Current Learning Rate: 1.0000000000000002e-06 || Time: 09:02:25.73
Epoch :: 88 || Loss: 0.40609600 || it_count: 8344 || Val Loss: 0.41061807 || Val it_count: 1107 || Current Learning Rate: 1.0000000000000002e-06 || Time: 09:08:35.48
Epoch :: 89 || Loss: 0.40609139 || it_count: 8344 || Val Loss: 0.41061437 || Val it_count: 1107 || Current Learning Rate: 1.0000000000000002e-06 || Time: 09:14:50.27
Epoch :: 90 || Loss: 0.40608682 || it_count: 8344 || Val Loss: 0.41061033 || Val it_count: 1107 || Current Learning Rate: 1.0000000000000002e-06 || Time: 09:21:11.46
Epoch :: 91 || Loss: 0.40608277 || it_count: 8344 || Val Loss: 0.41060716 || Val it_count: 1107 || Current Learning Rate: 1.0000000000000002e-06 || Time: 09:27:20.03
Epoch :: 92 || Loss: 0.40607886 || it_count: 8344 || Val Loss: 0.41060433 || Val it_count: 1107 || Current Learning Rate: 1.0000000000000002e-06 || Time: 09:33:29.31
Epoch :: 93 || Loss: 0.40607507 || it_count: 8344 || Val Loss: 0.41060177 || Val it_count: 1107 || Current Learning Rate: 1.0000000000000002e-06 || Time: 09:39:52.23
Epoch 00078: reducing learning rate of group 0 to 1.0000e-07.
Early stopping triggered due to learning rate below threshold.
Done Total time: 09:46:1.44
best_loss: 0.41060176564442613

--------------------Testing--------------------

total_samples :: test_dataset = 139200, test_dataloader = 139200
Epoch ::  1 || Loss: 0.23524654 || it_count: 544 || Time: 00:00:18.67
MAE:  0.25126898
MSE:  0.23526716
RMSE:  0.44049546

--------------------Training--------------------
arch_str :: |lstm_1~0|+|lstm_2~0|lstm_1~1|[relu->dropout->linear]
model :: 3D
InferCell(
  info :: nodes=3, inC=1, outC=64, [1<-(I0-L0) | 2<-(I0-L1,I1-L2)], genotype_str: lstm_1~0|lstm_2~0|lstm_1~1
  linear_layers: [relu->dropout->linear]
  (layers): ModuleList(
    (0): LSTM(
      (lstm): LSTM(1, 64, batch_first=True)
    )
    (1): LSTM(
      (lstm): LSTM(1, 64, num_layers=2, batch_first=True)
    )
    (2): LSTM(
      (lstm): LSTM(64, 64, batch_first=True)
    )
  )
  (linear_layers): ModuleList(
    (0): ReLU()
    (1): Dropout(p=0.1, inplace=False)
    (2): Linear(in_features=3072, out_features=1, bias=True)
  )
)
tr_params :: epochs = 100, patience = 20, batch_size = 256, window_size = 48, data_size = 100
Model FLOPs: 4.943M, Model Params: 103.937K
learning rate scheduling :: (optimizer, mode='min', factor=0.1, patience=5, verbose=True)
total_samples :: train_dataset = 2136000, train_dataloader = 2136000
total_samples :: valid_dataset = 283200, valid_dataloader = 283200
Epoch ::  1 || Loss: 0.42274246 || it_count: 8344 || Val Loss: 0.44909815 || Val it_count: 1107 || Current Learning Rate: 0.001 || Time: 00:08:0.23
Epoch ::  2 || Loss: 0.41995159 || it_count: 8344 || Val Loss: 0.44672071 || Val it_count: 1107 || Current Learning Rate: 0.001 || Time: 00:15:57.36
Epoch ::  3 || Loss: 0.41882929 || it_count: 8344 || Val Loss: 0.44646646 || Val it_count: 1107 || Current Learning Rate: 0.001 || Time: 00:23:53.93
Epoch ::  4 || Loss: 0.41852752 || it_count: 8344 || Val Loss: 0.44574582 || Val it_count: 1107 || Current Learning Rate: 0.001 || Time: 00:31:50.01
Epoch ::  5 || Loss: 0.41830741 || it_count: 8344 || Val Loss: 0.44605473 || Val it_count: 1107 || Current Learning Rate: 0.001 || Time: 00:39:46.55
Epoch ::  6 || Loss: 0.41782353 || it_count: 8344 || Val Loss: 0.44623604 || Val it_count: 1107 || Current Learning Rate: 0.001 || Time: 00:47:45.08
Epoch ::  7 || Loss: 0.41755346 || it_count: 8344 || Val Loss: 0.44503273 || Val it_count: 1107 || Current Learning Rate: 0.001 || Time: 00:55:43.07
Epoch ::  8 || Loss: 0.41700408 || it_count: 8344 || Val Loss: 0.44432580 || Val it_count: 1107 || Current Learning Rate: 0.001 || Time: 01:03:41.45
Epoch ::  9 || Loss: 0.41687032 || it_count: 8344 || Val Loss: 0.44756403 || Val it_count: 1107 || Current Learning Rate: 0.001 || Time: 01:11:39.62
Epoch :: 10 || Loss: 0.41725355 || it_count: 8344 || Val Loss: 0.44659153 || Val it_count: 1107 || Current Learning Rate: 0.001 || Time: 01:19:36.95
Epoch :: 11 || Loss: 0.41688919 || it_count: 8344 || Val Loss: 0.44735841 || Val it_count: 1107 || Current Learning Rate: 0.001 || Time: 01:27:32.68
Epoch :: 12 || Loss: 0.41676582 || it_count: 8344 || Val Loss: 0.44653982 || Val it_count: 1107 || Current Learning Rate: 0.001 || Time: 01:35:31.01
Epoch :: 13 || Loss: 0.41607100 || it_count: 8344 || Val Loss: 0.44788246 || Val it_count: 1107 || Current Learning Rate: 0.001 || Time: 01:43:29.33
Epoch :: 14 || Loss: 0.41650993 || it_count: 8344 || Val Loss: 0.44695977 || Val it_count: 1107 || Current Learning Rate: 0.001 || Time: 01:51:26.04
Epoch :: 15 || Loss: 0.41622042 || it_count: 8344 || Val Loss: 0.44714734 || Val it_count: 1107 || Current Learning Rate: 0.001 || Time: 01:59:23.09
Epoch :: 16 || Loss: 0.41642851 || it_count: 8344 || Val Loss: 0.44689155 || Val it_count: 1107 || Current Learning Rate: 0.001 || Time: 02:07:21.72
Epoch :: 17 || Loss: 0.41575060 || it_count: 8344 || Val Loss: 0.44658576 || Val it_count: 1107 || Current Learning Rate: 0.001 || Time: 02:15:19.51
Epoch :: 18 || Loss: 0.41538613 || it_count: 8344 || Val Loss: 0.44803413 || Val it_count: 1107 || Current Learning Rate: 0.001 || Time: 02:23:16.12
Epoch :: 19 || Loss: 0.41474054 || it_count: 8344 || Val Loss: 0.44706326 || Val it_count: 1107 || Current Learning Rate: 0.001 || Time: 02:31:14.12
Epoch :: 20 || Loss: 0.41438999 || it_count: 8344 || Val Loss: 0.44521491 || Val it_count: 1107 || Current Learning Rate: 0.001 || Time: 02:39:13.19
Epoch :: 21 || Loss: 0.41356031 || it_count: 8344 || Val Loss: 0.44503157 || Val it_count: 1107 || Current Learning Rate: 0.001 || Time: 02:47:10.00
Epoch :: 22 || Loss: 0.41337532 || it_count: 8344 || Val Loss: 0.44462304 || Val it_count: 1107 || Current Learning Rate: 0.001 || Time: 02:55:7.51
Epoch :: 23 || Loss: 0.41271116 || it_count: 8344 || Val Loss: 0.44623159 || Val it_count: 1107 || Current Learning Rate: 0.001 || Time: 03:03:4.92
Epoch :: 24 || Loss: 0.41227371 || it_count: 8344 || Val Loss: 0.44489198 || Val it_count: 1107 || Current Learning Rate: 0.001 || Time: 03:11:3.07
Epoch :: 25 || Loss: 0.41194845 || it_count: 8344 || Val Loss: 0.44466785 || Val it_count: 1107 || Current Learning Rate: 0.001 || Time: 03:19:3.52
Epoch :: 26 || Loss: 0.41194503 || it_count: 8344 || Val Loss: 0.44417253 || Val it_count: 1107 || Current Learning Rate: 0.001 || Time: 03:27:3.83
Epoch :: 27 || Loss: 0.41139522 || it_count: 8344 || Val Loss: 0.44311876 || Val it_count: 1107 || Current Learning Rate: 0.001 || Time: 03:35:0.71
Epoch :: 28 || Loss: 0.41134372 || it_count: 8344 || Val Loss: 0.44443263 || Val it_count: 1107 || Current Learning Rate: 0.001 || Time: 03:42:58.81
Epoch :: 29 || Loss: 0.41078933 || it_count: 8344 || Val Loss: 0.44455735 || Val it_count: 1107 || Current Learning Rate: 0.001 || Time: 03:50:57.01
Epoch :: 30 || Loss: 0.41064055 || it_count: 8344 || Val Loss: 0.44559559 || Val it_count: 1107 || Current Learning Rate: 0.001 || Time: 03:58:57.04
Epoch :: 31 || Loss: 0.41073536 || it_count: 8344 || Val Loss: 0.44454417 || Val it_count: 1107 || Current Learning Rate: 0.001 || Time: 04:06:55.34
Epoch :: 32 || Loss: 0.41014187 || it_count: 8344 || Val Loss: 0.44508436 || Val it_count: 1107 || Current Learning Rate: 0.001 || Time: 04:14:54.11
Epoch 00017: reducing learning rate of group 0 to 1.0000e-04.
Epoch :: 33 || Loss: 0.41043876 || it_count: 8344 || Val Loss: 0.44671597 || Val it_count: 1107 || Current Learning Rate: 0.0001 || Time: 04:22:53.00
Epoch :: 34 || Loss: 0.41526322 || it_count: 8344 || Val Loss: 0.42208730 || Val it_count: 1107 || Current Learning Rate: 0.0001 || Time: 04:30:52.37
Epoch :: 35 || Loss: 0.41128731 || it_count: 8344 || Val Loss: 0.42009856 || Val it_count: 1107 || Current Learning Rate: 0.0001 || Time: 04:38:48.30
Epoch :: 36 || Loss: 0.41057200 || it_count: 8344 || Val Loss: 0.41939574 || Val it_count: 1107 || Current Learning Rate: 0.0001 || Time: 04:46:38.78
Epoch :: 37 || Loss: 0.41003704 || it_count: 8344 || Val Loss: 0.41898610 || Val it_count: 1107 || Current Learning Rate: 0.0001 || Time: 04:54:27.92
Epoch :: 38 || Loss: 0.40972056 || it_count: 8344 || Val Loss: 0.41870791 || Val it_count: 1107 || Current Learning Rate: 0.0001 || Time: 05:02:18.38
Epoch :: 39 || Loss: 0.40942332 || it_count: 8344 || Val Loss: 0.41841378 || Val it_count: 1107 || Current Learning Rate: 0.0001 || Time: 05:10:9.24
Epoch :: 40 || Loss: 0.40913309 || it_count: 8344 || Val Loss: 0.41822047 || Val it_count: 1107 || Current Learning Rate: 0.0001 || Time: 05:17:59.32
Epoch :: 41 || Loss: 0.40889412 || it_count: 8344 || Val Loss: 0.41800438 || Val it_count: 1107 || Current Learning Rate: 0.0001 || Time: 05:25:50.01
Epoch :: 42 || Loss: 0.40877131 || it_count: 8344 || Val Loss: 0.41798074 || Val it_count: 1107 || Current Learning Rate: 0.0001 || Time: 05:33:38.42
Epoch :: 43 || Loss: 0.40851868 || it_count: 8344 || Val Loss: 0.41789955 || Val it_count: 1107 || Current Learning Rate: 0.0001 || Time: 05:41:29.22
Epoch :: 44 || Loss: 0.40827367 || it_count: 8344 || Val Loss: 0.41787125 || Val it_count: 1107 || Current Learning Rate: 0.0001 || Time: 05:49:18.05
Epoch :: 45 || Loss: 0.40807085 || it_count: 8344 || Val Loss: 0.41778042 || Val it_count: 1107 || Current Learning Rate: 0.0001 || Time: 05:57:8.67
Epoch :: 46 || Loss: 0.40788658 || it_count: 8344 || Val Loss: 0.41771104 || Val it_count: 1107 || Current Learning Rate: 0.0001 || Time: 06:05:6.48
Epoch :: 47 || Loss: 0.40771411 || it_count: 8344 || Val Loss: 0.41773401 || Val it_count: 1107 || Current Learning Rate: 0.0001 || Time: 06:13:4.08
Epoch :: 48 || Loss: 0.40753337 || it_count: 8344 || Val Loss: 0.41768644 || Val it_count: 1107 || Current Learning Rate: 0.0001 || Time: 06:20:59.77
Epoch :: 49 || Loss: 0.40727403 || it_count: 8344 || Val Loss: 0.41787168 || Val it_count: 1107 || Current Learning Rate: 0.0001 || Time: 06:28:58.38
Epoch :: 50 || Loss: 0.40721986 || it_count: 8344 || Val Loss: 0.41771864 || Val it_count: 1107 || Current Learning Rate: 0.0001 || Time: 06:36:57.26
Epoch :: 51 || Loss: 0.40705668 || it_count: 8344 || Val Loss: 0.41768760 || Val it_count: 1107 || Current Learning Rate: 0.0001 || Time: 06:44:54.69
Epoch 00036: reducing learning rate of group 0 to 1.0000e-05.
Epoch :: 52 || Loss: 0.40688278 || it_count: 8344 || Val Loss: 0.41780979 || Val it_count: 1107 || Current Learning Rate: 1e-05 || Time: 06:52:51.74
Epoch :: 53 || Loss: 0.40919225 || it_count: 8344 || Val Loss: 0.41166019 || Val it_count: 1107 || Current Learning Rate: 1e-05 || Time: 07:00:47.33
Epoch :: 54 || Loss: 0.40809068 || it_count: 8344 || Val Loss: 0.41141238 || Val it_count: 1107 || Current Learning Rate: 1e-05 || Time: 07:08:44.89
Epoch :: 55 || Loss: 0.40786932 || it_count: 8344 || Val Loss: 0.41132235 || Val it_count: 1107 || Current Learning Rate: 1e-05 || Time: 07:16:42.38
Epoch :: 56 || Loss: 0.40776569 || it_count: 8344 || Val Loss: 0.41127883 || Val it_count: 1107 || Current Learning Rate: 1e-05 || Time: 07:24:42.01
Epoch :: 57 || Loss: 0.40769214 || it_count: 8344 || Val Loss: 0.41124140 || Val it_count: 1107 || Current Learning Rate: 1e-05 || Time: 07:32:38.86
Epoch :: 58 || Loss: 0.40764638 || it_count: 8344 || Val Loss: 0.41119543 || Val it_count: 1107 || Current Learning Rate: 1e-05 || Time: 07:40:36.84
Epoch :: 59 || Loss: 0.40759949 || it_count: 8344 || Val Loss: 0.41118308 || Val it_count: 1107 || Current Learning Rate: 1e-05 || Time: 07:48:34.83
Epoch :: 60 || Loss: 0.40757862 || it_count: 8344 || Val Loss: 0.41115399 || Val it_count: 1107 || Current Learning Rate: 1e-05 || Time: 07:56:32.61
Epoch :: 61 || Loss: 0.40752372 || it_count: 8344 || Val Loss: 0.41112065 || Val it_count: 1107 || Current Learning Rate: 1e-05 || Time: 08:04:30.98
Epoch :: 62 || Loss: 0.40751053 || it_count: 8344 || Val Loss: 0.41110937 || Val it_count: 1107 || Current Learning Rate: 1e-05 || Time: 08:12:27.27
Epoch :: 63 || Loss: 0.40740119 || it_count: 8344 || Val Loss: 0.41109806 || Val it_count: 1107 || Current Learning Rate: 1e-05 || Time: 08:20:24.84
Epoch :: 64 || Loss: 0.40744714 || it_count: 8344 || Val Loss: 0.41108076 || Val it_count: 1107 || Current Learning Rate: 1e-05 || Time: 08:28:20.86
Epoch :: 65 || Loss: 0.40743399 || it_count: 8344 || Val Loss: 0.41104908 || Val it_count: 1107 || Current Learning Rate: 1e-05 || Time: 08:36:17.48
Epoch :: 66 || Loss: 0.40730559 || it_count: 8344 || Val Loss: 0.41105175 || Val it_count: 1107 || Current Learning Rate: 1e-05 || Time: 08:44:13.61
Epoch :: 67 || Loss: 0.40728966 || it_count: 8344 || Val Loss: 0.41103212 || Val it_count: 1107 || Current Learning Rate: 1e-05 || Time: 08:52:12.12
Epoch :: 68 || Loss: 0.40727129 || it_count: 8344 || Val Loss: 0.41102953 || Val it_count: 1107 || Current Learning Rate: 1e-05 || Time: 09:00:9.18
Epoch :: 69 || Loss: 0.40727177 || it_count: 8344 || Val Loss: 0.41101084 || Val it_count: 1107 || Current Learning Rate: 1e-05 || Time: 09:08:5.22
Epoch :: 70 || Loss: 0.40727420 || it_count: 8344 || Val Loss: 0.41097707 || Val it_count: 1107 || Current Learning Rate: 1e-05 || Time: 09:16:1.24
Epoch :: 71 || Loss: 0.40721500 || it_count: 8344 || Val Loss: 0.41097001 || Val it_count: 1107 || Current Learning Rate: 1e-05 || Time: 09:23:56.92
Epoch :: 72 || Loss: 0.40724394 || it_count: 8344 || Val Loss: 0.41096550 || Val it_count: 1107 || Current Learning Rate: 1e-05 || Time: 09:31:53.64
Epoch :: 73 || Loss: 0.40714164 || it_count: 8344 || Val Loss: 0.41095293 || Val it_count: 1107 || Current Learning Rate: 1e-05 || Time: 09:39:50.07
Epoch :: 74 || Loss: 0.40714835 || it_count: 8344 || Val Loss: 0.41095474 || Val it_count: 1107 || Current Learning Rate: 1e-05 || Time: 09:47:46.29
Epoch :: 75 || Loss: 0.40707474 || it_count: 8344 || Val Loss: 0.41095246 || Val it_count: 1107 || Current Learning Rate: 1e-05 || Time: 09:55:44.21
Epoch 00060: reducing learning rate of group 0 to 1.0000e-06.
Epoch :: 76 || Loss: 0.40704387 || it_count: 8344 || Val Loss: 0.41094219 || Val it_count: 1107 || Current Learning Rate: 1.0000000000000002e-06 || Time: 10:03:41.22
Epoch :: 77 || Loss: 0.40722144 || it_count: 8344 || Val Loss: 0.41076184 || Val it_count: 1107 || Current Learning Rate: 1.0000000000000002e-06 || Time: 10:11:37.72
Epoch :: 78 || Loss: 0.40720401 || it_count: 8344 || Val Loss: 0.41071298 || Val it_count: 1107 || Current Learning Rate: 1.0000000000000002e-06 || Time: 10:19:33.80
Epoch :: 79 || Loss: 0.40714830 || it_count: 8344 || Val Loss: 0.41068835 || Val it_count: 1107 || Current Learning Rate: 1.0000000000000002e-06 || Time: 10:27:29.15
Epoch :: 80 || Loss: 0.40722377 || it_count: 8344 || Val Loss: 0.41067272 || Val it_count: 1107 || Current Learning Rate: 1.0000000000000002e-06 || Time: 10:35:25.38
Epoch :: 81 || Loss: 0.40716528 || it_count: 8344 || Val Loss: 0.41065535 || Val it_count: 1107 || Current Learning Rate: 1.0000000000000002e-06 || Time: 10:43:21.01
Epoch :: 82 || Loss: 0.40714599 || it_count: 8344 || Val Loss: 0.41064441 || Val it_count: 1107 || Current Learning Rate: 1.0000000000000002e-06 || Time: 10:51:17.33
Epoch :: 83 || Loss: 0.40713137 || it_count: 8344 || Val Loss: 0.41063726 || Val it_count: 1107 || Current Learning Rate: 1.0000000000000002e-06 || Time: 10:59:14.99
Epoch :: 84 || Loss: 0.40708200 || it_count: 8344 || Val Loss: 0.41063148 || Val it_count: 1107 || Current Learning Rate: 1.0000000000000002e-06 || Time: 11:07:10.87
Epoch :: 85 || Loss: 0.40709222 || it_count: 8344 || Val Loss: 0.41062428 || Val it_count: 1107 || Current Learning Rate: 1.0000000000000002e-06 || Time: 11:15:7.20
Epoch :: 86 || Loss: 0.40712286 || it_count: 8344 || Val Loss: 0.41061834 || Val it_count: 1107 || Current Learning Rate: 1.0000000000000002e-06 || Time: 11:23:1.71
Epoch :: 87 || Loss: 0.40710401 || it_count: 8344 || Val Loss: 0.41061368 || Val it_count: 1107 || Current Learning Rate: 1.0000000000000002e-06 || Time: 11:30:57.59
Epoch :: 88 || Loss: 0.40711500 || it_count: 8344 || Val Loss: 0.41060764 || Val it_count: 1107 || Current Learning Rate: 1.0000000000000002e-06 || Time: 11:38:52.78
Epoch :: 89 || Loss: 0.40710803 || it_count: 8344 || Val Loss: 0.41060489 || Val it_count: 1107 || Current Learning Rate: 1.0000000000000002e-06 || Time: 11:46:48.29
Epoch :: 90 || Loss: 0.40714247 || it_count: 8344 || Val Loss: 0.41060525 || Val it_count: 1107 || Current Learning Rate: 1.0000000000000002e-06 || Time: 11:54:43.32
Epoch :: 91 || Loss: 0.40711728 || it_count: 8344 || Val Loss: 0.41060069 || Val it_count: 1107 || Current Learning Rate: 1.0000000000000002e-06 || Time: 12:02:38.01
Epoch :: 92 || Loss: 0.40707515 || it_count: 8344 || Val Loss: 0.41059833 || Val it_count: 1107 || Current Learning Rate: 1.0000000000000002e-06 || Time: 12:10:33.19
Epoch 00077: reducing learning rate of group 0 to 1.0000e-07.
Early stopping triggered due to learning rate below threshold.
Done Total time: 12:18:28.88
best_loss: 0.41059833292347325

--------------------Testing--------------------

total_samples :: test_dataset = 139200, test_dataloader = 139200
Epoch ::  1 || Loss: 0.23529471 || it_count: 544 || Time: 00:00:21.64
MAE:  0.25075245
MSE:  0.23531282
RMSE:  0.44068062

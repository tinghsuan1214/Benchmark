--------------------Training--------------------
arch_str :: |lstm_3~0|+|lstm_2~0|lstm_3~1|[dropout->linear]
model :: 3B
InferCell(
  info :: nodes=3, inC=1, outC=64, [1<-(I0-L0) | 2<-(I0-L1,I1-L2)], genotype_str: lstm_3~0|lstm_2~0|lstm_3~1
  linear_layers: [dropout->linear]
  (layers): ModuleList(
    (0): LSTM(
      (lstm): LSTM(1, 64, num_layers=3, batch_first=True)
    )
    (1): LSTM(
      (lstm): LSTM(1, 64, num_layers=2, batch_first=True)
    )
    (2): LSTM(
      (lstm): LSTM(64, 64, num_layers=3, batch_first=True)
    )
  )
  (linear_layers): ModuleList(
    (0): Dropout(p=0.1, inplace=False)
    (1): Linear(in_features=3072, out_features=1, bias=True)
  )
)
tr_params :: epochs = 100, patience = 20, batch_size = 256, window_size = 48, data_size = 100
Model MACs: 11.431M, Model Params: 237.057K
learning rate scheduling :: (optimizer, mode='min', factor=0.1, patience=5, verbose=True)
total_samples :: train_dataset = 2136000, train_dataloader = 2136000
total_samples :: valid_dataset = 283200, valid_dataloader = 283200
Epoch ::  1 || Loss: 0.42243300 || it_count: 8344 || Val Loss: 0.45052620 || Val it_count: 1107 || Current Learning Rate: 0.001 || Time: 00:10:29.89
Epoch ::  2 || Loss: 0.41961123 || it_count: 8344 || Val Loss: 0.44828676 || Val it_count: 1107 || Current Learning Rate: 0.001 || Time: 00:20:59.04
Epoch ::  3 || Loss: 0.41925539 || it_count: 8344 || Val Loss: 0.44817927 || Val it_count: 1107 || Current Learning Rate: 0.001 || Time: 00:31:32.03
Epoch ::  4 || Loss: 0.41876376 || it_count: 8344 || Val Loss: 0.44831328 || Val it_count: 1107 || Current Learning Rate: 0.001 || Time: 00:42:9.06
Epoch ::  5 || Loss: 0.41827957 || it_count: 8344 || Val Loss: 0.44889428 || Val it_count: 1107 || Current Learning Rate: 0.001 || Time: 00:52:45.27
Epoch ::  6 || Loss: 0.41813211 || it_count: 8344 || Val Loss: 0.44869703 || Val it_count: 1107 || Current Learning Rate: 0.001 || Time: 01:03:22.94
Epoch ::  7 || Loss: 0.41773836 || it_count: 8344 || Val Loss: 0.44953039 || Val it_count: 1107 || Current Learning Rate: 0.001 || Time: 01:14:1.17
Epoch ::  8 || Loss: 0.41798896 || it_count: 8344 || Val Loss: 0.44927090 || Val it_count: 1107 || Current Learning Rate: 0.001 || Time: 01:24:40.74
Epoch ::  9 || Loss: 0.41808398 || it_count: 8344 || Val Loss: 0.44628449 || Val it_count: 1107 || Current Learning Rate: 0.001 || Time: 01:35:19.32
Epoch :: 10 || Loss: 0.41739972 || it_count: 8344 || Val Loss: 0.44740894 || Val it_count: 1107 || Current Learning Rate: 0.001 || Time: 01:45:59.37
Epoch :: 11 || Loss: 0.41765484 || it_count: 8344 || Val Loss: 0.44805618 || Val it_count: 1107 || Current Learning Rate: 0.001 || Time: 01:56:38.93
Epoch :: 12 || Loss: 0.41751305 || it_count: 8344 || Val Loss: 0.44801617 || Val it_count: 1107 || Current Learning Rate: 0.001 || Time: 02:07:19.82
Epoch :: 13 || Loss: 0.41724114 || it_count: 8344 || Val Loss: 0.44913378 || Val it_count: 1107 || Current Learning Rate: 0.001 || Time: 02:18:0.15
Epoch :: 14 || Loss: 0.41696046 || it_count: 8344 || Val Loss: 0.44819125 || Val it_count: 1107 || Current Learning Rate: 0.001 || Time: 02:28:40.96
Epoch :: 15 || Loss: 0.41674256 || it_count: 8344 || Val Loss: 0.44695591 || Val it_count: 1107 || Current Learning Rate: 0.001 || Time: 02:39:20.58
Epoch :: 16 || Loss: 0.41657503 || it_count: 8344 || Val Loss: 0.44694492 || Val it_count: 1107 || Current Learning Rate: 0.001 || Time: 02:50:2.00
Epoch :: 17 || Loss: 0.41626934 || it_count: 8344 || Val Loss: 0.44718439 || Val it_count: 1107 || Current Learning Rate: 0.001 || Time: 03:00:42.06
Epoch :: 18 || Loss: 0.41598263 || it_count: 8344 || Val Loss: 0.44900350 || Val it_count: 1107 || Current Learning Rate: 0.001 || Time: 03:11:23.07
Epoch :: 19 || Loss: 0.41573478 || it_count: 8344 || Val Loss: 0.44867256 || Val it_count: 1107 || Current Learning Rate: 0.001 || Time: 03:22:2.96
Epoch :: 20 || Loss: 0.41564501 || it_count: 8344 || Val Loss: 0.44768355 || Val it_count: 1107 || Current Learning Rate: 0.001 || Time: 03:32:44.89
Epoch :: 21 || Loss: 0.41514928 || it_count: 8344 || Val Loss: 0.44542387 || Val it_count: 1107 || Current Learning Rate: 0.001 || Time: 03:43:25.30
Epoch :: 22 || Loss: 0.41533828 || it_count: 8344 || Val Loss: 0.44353142 || Val it_count: 1107 || Current Learning Rate: 0.001 || Time: 03:54:5.86
Epoch :: 23 || Loss: 0.41455920 || it_count: 8344 || Val Loss: 0.44605001 || Val it_count: 1107 || Current Learning Rate: 0.001 || Time: 04:04:47.48
Epoch :: 24 || Loss: 0.41384770 || it_count: 8344 || Val Loss: 0.45199709 || Val it_count: 1107 || Current Learning Rate: 0.001 || Time: 04:15:29.73
Epoch :: 25 || Loss: 0.41355252 || it_count: 8344 || Val Loss: 0.44980390 || Val it_count: 1107 || Current Learning Rate: 0.001 || Time: 04:26:11.72
Epoch :: 26 || Loss: 0.41290896 || it_count: 8344 || Val Loss: 0.45068941 || Val it_count: 1107 || Current Learning Rate: 0.001 || Time: 04:36:54.49
Epoch :: 27 || Loss: 0.41249750 || it_count: 8344 || Val Loss: 0.45106889 || Val it_count: 1107 || Current Learning Rate: 0.001 || Time: 04:47:36.83
Epoch 00012: reducing learning rate of group 0 to 1.0000e-04.
Epoch :: 28 || Loss: 0.41252909 || it_count: 8344 || Val Loss: 0.44771087 || Val it_count: 1107 || Current Learning Rate: 0.0001 || Time: 04:58:17.97
Epoch :: 29 || Loss: 0.41746779 || it_count: 8344 || Val Loss: 0.42416212 || Val it_count: 1107 || Current Learning Rate: 0.0001 || Time: 05:09:0.12
Epoch :: 30 || Loss: 0.41326831 || it_count: 8344 || Val Loss: 0.42224517 || Val it_count: 1107 || Current Learning Rate: 0.0001 || Time: 05:19:41.97
Epoch :: 31 || Loss: 0.41244078 || it_count: 8344 || Val Loss: 0.42165439 || Val it_count: 1107 || Current Learning Rate: 0.0001 || Time: 05:30:24.33
Epoch :: 32 || Loss: 0.41209224 || it_count: 8344 || Val Loss: 0.42145356 || Val it_count: 1107 || Current Learning Rate: 0.0001 || Time: 05:41:7.09
Epoch :: 33 || Loss: 0.41183516 || it_count: 8344 || Val Loss: 0.42131589 || Val it_count: 1107 || Current Learning Rate: 0.0001 || Time: 05:51:49.01
Epoch :: 34 || Loss: 0.41156593 || it_count: 8344 || Val Loss: 0.42114393 || Val it_count: 1107 || Current Learning Rate: 0.0001 || Time: 06:02:30.89
Epoch :: 35 || Loss: 0.41133595 || it_count: 8344 || Val Loss: 0.42111593 || Val it_count: 1107 || Current Learning Rate: 0.0001 || Time: 06:13:13.13
Epoch :: 36 || Loss: 0.41118251 || it_count: 8344 || Val Loss: 0.42092938 || Val it_count: 1107 || Current Learning Rate: 0.0001 || Time: 06:23:53.91
Epoch :: 37 || Loss: 0.41102140 || it_count: 8344 || Val Loss: 0.42095152 || Val it_count: 1107 || Current Learning Rate: 0.0001 || Time: 06:34:35.96
Epoch :: 38 || Loss: 0.41084052 || it_count: 8344 || Val Loss: 0.42090929 || Val it_count: 1107 || Current Learning Rate: 0.0001 || Time: 06:45:17.15
Epoch :: 39 || Loss: 0.41065862 || it_count: 8344 || Val Loss: 0.42078383 || Val it_count: 1107 || Current Learning Rate: 0.0001 || Time: 06:55:58.86
Epoch :: 40 || Loss: 0.41056642 || it_count: 8344 || Val Loss: 0.42080573 || Val it_count: 1107 || Current Learning Rate: 0.0001 || Time: 07:06:40.93
Epoch :: 41 || Loss: 0.41044326 || it_count: 8344 || Val Loss: 0.42075653 || Val it_count: 1107 || Current Learning Rate: 0.0001 || Time: 07:17:22.95
Epoch :: 42 || Loss: 0.41027261 || it_count: 8344 || Val Loss: 0.42055923 || Val it_count: 1107 || Current Learning Rate: 0.0001 || Time: 07:28:4.35
Epoch :: 43 || Loss: 0.41019834 || it_count: 8344 || Val Loss: 0.42087566 || Val it_count: 1107 || Current Learning Rate: 0.0001 || Time: 07:38:46.28
Epoch :: 44 || Loss: 0.41010517 || it_count: 8344 || Val Loss: 0.42049664 || Val it_count: 1107 || Current Learning Rate: 0.0001 || Time: 07:49:27.60
Epoch :: 45 || Loss: 0.40996069 || it_count: 8344 || Val Loss: 0.42068191 || Val it_count: 1107 || Current Learning Rate: 0.0001 || Time: 08:00:8.94
Epoch :: 46 || Loss: 0.40983623 || it_count: 8344 || Val Loss: 0.42071196 || Val it_count: 1107 || Current Learning Rate: 0.0001 || Time: 08:10:51.22
Epoch :: 47 || Loss: 0.40976309 || it_count: 8344 || Val Loss: 0.42086990 || Val it_count: 1107 || Current Learning Rate: 0.0001 || Time: 08:21:32.84
Epoch :: 48 || Loss: 0.40964286 || it_count: 8344 || Val Loss: 0.42066614 || Val it_count: 1107 || Current Learning Rate: 0.0001 || Time: 08:32:15.04
Epoch :: 49 || Loss: 0.40954854 || it_count: 8344 || Val Loss: 0.42048289 || Val it_count: 1107 || Current Learning Rate: 0.0001 || Time: 08:42:56.66
Epoch 00034: reducing learning rate of group 0 to 1.0000e-05.
Epoch :: 50 || Loss: 0.40945580 || it_count: 8344 || Val Loss: 0.42066581 || Val it_count: 1107 || Current Learning Rate: 1e-05 || Time: 08:53:37.65
Epoch :: 51 || Loss: 0.41158347 || it_count: 8344 || Val Loss: 0.41363819 || Val it_count: 1107 || Current Learning Rate: 1e-05 || Time: 09:04:20.28
Epoch :: 52 || Loss: 0.41070453 || it_count: 8344 || Val Loss: 0.41360072 || Val it_count: 1107 || Current Learning Rate: 1e-05 || Time: 09:15:2.74
Epoch :: 53 || Loss: 0.41055144 || it_count: 8344 || Val Loss: 0.41351988 || Val it_count: 1107 || Current Learning Rate: 1e-05 || Time: 09:25:45.57
Epoch :: 54 || Loss: 0.41044918 || it_count: 8344 || Val Loss: 0.41346851 || Val it_count: 1107 || Current Learning Rate: 1e-05 || Time: 09:36:27.23
Epoch :: 55 || Loss: 0.41042547 || it_count: 8344 || Val Loss: 0.41345116 || Val it_count: 1107 || Current Learning Rate: 1e-05 || Time: 09:47:9.05
Epoch :: 56 || Loss: 0.41042890 || it_count: 8344 || Val Loss: 0.41341857 || Val it_count: 1107 || Current Learning Rate: 1e-05 || Time: 09:57:50.42
Epoch :: 57 || Loss: 0.41036011 || it_count: 8344 || Val Loss: 0.41339767 || Val it_count: 1107 || Current Learning Rate: 1e-05 || Time: 10:08:33.53
Epoch :: 58 || Loss: 0.41032845 || it_count: 8344 || Val Loss: 0.41338215 || Val it_count: 1107 || Current Learning Rate: 1e-05 || Time: 10:19:14.72
Epoch :: 59 || Loss: 0.41031922 || it_count: 8344 || Val Loss: 0.41334808 || Val it_count: 1107 || Current Learning Rate: 1e-05 || Time: 10:29:56.53
Epoch :: 60 || Loss: 0.41034016 || it_count: 8344 || Val Loss: 0.41331982 || Val it_count: 1107 || Current Learning Rate: 1e-05 || Time: 10:40:38.36
Epoch :: 61 || Loss: 0.41027886 || it_count: 8344 || Val Loss: 0.41329874 || Val it_count: 1107 || Current Learning Rate: 1e-05 || Time: 10:51:19.39
Epoch :: 62 || Loss: 0.41027851 || it_count: 8344 || Val Loss: 0.41327993 || Val it_count: 1107 || Current Learning Rate: 1e-05 || Time: 11:02:1.02
Epoch :: 63 || Loss: 0.41020834 || it_count: 8344 || Val Loss: 0.41327991 || Val it_count: 1107 || Current Learning Rate: 1e-05 || Time: 11:12:43.76
Epoch :: 64 || Loss: 0.41019324 || it_count: 8344 || Val Loss: 0.41324179 || Val it_count: 1107 || Current Learning Rate: 1e-05 || Time: 11:23:25.08
Epoch :: 65 || Loss: 0.41016063 || it_count: 8344 || Val Loss: 0.41321813 || Val it_count: 1107 || Current Learning Rate: 1e-05 || Time: 11:34:7.06
Epoch :: 66 || Loss: 0.41017667 || it_count: 8344 || Val Loss: 0.41322302 || Val it_count: 1107 || Current Learning Rate: 1e-05 || Time: 11:44:47.58
Epoch :: 67 || Loss: 0.41011614 || it_count: 8344 || Val Loss: 0.41321530 || Val it_count: 1107 || Current Learning Rate: 1e-05 || Time: 11:55:28.37
Epoch :: 68 || Loss: 0.41014849 || it_count: 8344 || Val Loss: 0.41318463 || Val it_count: 1107 || Current Learning Rate: 1e-05 || Time: 12:06:10.45
Epoch :: 69 || Loss: 0.41008723 || it_count: 8344 || Val Loss: 0.41317512 || Val it_count: 1107 || Current Learning Rate: 1e-05 || Time: 12:16:52.66
Epoch :: 70 || Loss: 0.41010564 || it_count: 8344 || Val Loss: 0.41315449 || Val it_count: 1107 || Current Learning Rate: 1e-05 || Time: 12:27:32.78
Epoch :: 71 || Loss: 0.41009057 || it_count: 8344 || Val Loss: 0.41315167 || Val it_count: 1107 || Current Learning Rate: 1e-05 || Time: 12:38:14.21
Epoch :: 72 || Loss: 0.41007071 || it_count: 8344 || Val Loss: 0.41312826 || Val it_count: 1107 || Current Learning Rate: 1e-05 || Time: 12:48:55.77
Epoch :: 73 || Loss: 0.41002869 || it_count: 8344 || Val Loss: 0.41312109 || Val it_count: 1107 || Current Learning Rate: 1e-05 || Time: 12:59:37.56
Epoch :: 74 || Loss: 0.41005671 || it_count: 8344 || Val Loss: 0.41311286 || Val it_count: 1107 || Current Learning Rate: 1e-05 || Time: 13:10:19.54
Epoch :: 75 || Loss: 0.40999552 || it_count: 8344 || Val Loss: 0.41310602 || Val it_count: 1107 || Current Learning Rate: 1e-05 || Time: 13:21:1.14
Epoch :: 76 || Loss: 0.41000097 || it_count: 8344 || Val Loss: 0.41310205 || Val it_count: 1107 || Current Learning Rate: 1e-05 || Time: 13:31:42.94
Epoch :: 77 || Loss: 0.40994335 || it_count: 8344 || Val Loss: 0.41308116 || Val it_count: 1107 || Current Learning Rate: 1e-05 || Time: 13:42:24.90
Epoch :: 78 || Loss: 0.40994274 || it_count: 8344 || Val Loss: 0.41307799 || Val it_count: 1107 || Current Learning Rate: 1e-05 || Time: 13:53:6.71
Epoch :: 79 || Loss: 0.40995826 || it_count: 8344 || Val Loss: 0.41306929 || Val it_count: 1107 || Current Learning Rate: 1e-05 || Time: 14:03:48.68
Epoch :: 80 || Loss: 0.40995199 || it_count: 8344 || Val Loss: 0.41304725 || Val it_count: 1107 || Current Learning Rate: 1e-05 || Time: 14:14:30.50
Epoch :: 81 || Loss: 0.40990662 || it_count: 8344 || Val Loss: 0.41303007 || Val it_count: 1107 || Current Learning Rate: 1e-05 || Time: 14:25:11.59
Epoch :: 82 || Loss: 0.40988133 || it_count: 8344 || Val Loss: 0.41302929 || Val it_count: 1107 || Current Learning Rate: 1e-05 || Time: 14:35:53.28
Epoch :: 83 || Loss: 0.40990990 || it_count: 8344 || Val Loss: 0.41300068 || Val it_count: 1107 || Current Learning Rate: 1e-05 || Time: 14:46:35.10
Epoch :: 84 || Loss: 0.40984742 || it_count: 8344 || Val Loss: 0.41298639 || Val it_count: 1107 || Current Learning Rate: 1e-05 || Time: 14:57:17.89
Epoch :: 85 || Loss: 0.40985439 || it_count: 8344 || Val Loss: 0.41299186 || Val it_count: 1107 || Current Learning Rate: 1e-05 || Time: 15:07:59.77
Epoch :: 86 || Loss: 0.40984863 || it_count: 8344 || Val Loss: 0.41298738 || Val it_count: 1107 || Current Learning Rate: 1e-05 || Time: 15:18:41.74
Epoch :: 87 || Loss: 0.40982913 || it_count: 8344 || Val Loss: 0.41298207 || Val it_count: 1107 || Current Learning Rate: 1e-05 || Time: 15:29:22.50
Epoch :: 88 || Loss: 0.40984126 || it_count: 8344 || Val Loss: 0.41295792 || Val it_count: 1107 || Current Learning Rate: 1e-05 || Time: 15:40:5.11
Epoch :: 89 || Loss: 0.40980540 || it_count: 8344 || Val Loss: 0.41295302 || Val it_count: 1107 || Current Learning Rate: 1e-05 || Time: 15:50:47.04
Epoch :: 90 || Loss: 0.40985663 || it_count: 8344 || Val Loss: 0.41293048 || Val it_count: 1107 || Current Learning Rate: 1e-05 || Time: 16:01:29.46
Epoch :: 91 || Loss: 0.40981796 || it_count: 8344 || Val Loss: 0.41292993 || Val it_count: 1107 || Current Learning Rate: 1e-05 || Time: 16:12:11.24
Epoch :: 92 || Loss: 0.40978046 || it_count: 8344 || Val Loss: 0.41290351 || Val it_count: 1107 || Current Learning Rate: 1e-05 || Time: 16:22:53.57
Epoch :: 93 || Loss: 0.40977936 || it_count: 8344 || Val Loss: 0.41290477 || Val it_count: 1107 || Current Learning Rate: 1e-05 || Time: 16:33:35.43
Epoch :: 94 || Loss: 0.40975270 || it_count: 8344 || Val Loss: 0.41289225 || Val it_count: 1107 || Current Learning Rate: 1e-05 || Time: 16:44:17.81
Epoch :: 95 || Loss: 0.40979446 || it_count: 8344 || Val Loss: 0.41286551 || Val it_count: 1107 || Current Learning Rate: 1e-05 || Time: 16:55:0.55
Epoch :: 96 || Loss: 0.40970225 || it_count: 8344 || Val Loss: 0.41285682 || Val it_count: 1107 || Current Learning Rate: 1e-05 || Time: 17:05:43.88
Epoch :: 97 || Loss: 0.40973448 || it_count: 8344 || Val Loss: 0.41286687 || Val it_count: 1107 || Current Learning Rate: 1e-05 || Time: 17:16:25.39
Epoch :: 98 || Loss: 0.40969821 || it_count: 8344 || Val Loss: 0.41285682 || Val it_count: 1107 || Current Learning Rate: 1e-05 || Time: 17:27:9.13
Epoch :: 99 || Loss: 0.40967022 || it_count: 8344 || Val Loss: 0.41283300 || Val it_count: 1107 || Current Learning Rate: 1e-05 || Time: 17:37:51.36
Epoch :: 100 || Loss: 0.40971695 || it_count: 8344 || Val Loss: 0.41283862 || Val it_count: 1107 || Current Learning Rate: 1e-05 || Time: 17:48:33.47
Done Total time: 17:48:33.47
best_loss: 0.4128330002807567

--------------------Testing--------------------

total_samples :: test_dataset = 139200, test_dataloader = 139200
Epoch ::  1 || Loss: 0.23564550 || it_count: 544 || Time: 00:00:26.31
MAE:  0.25392646
MSE:  0.23566255
RMSE:  0.44182223

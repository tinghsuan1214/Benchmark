--------------------Training--------------------
arch_str :: |lstm_2~0|+|none~0|lstm_2~1|[dropout->linear]
model :: 3B
InferCell(
  info :: nodes=3, inC=1, outC=64, [1<-(I0-L0) | 2<-(I0-L1,I1-L2)], genotype_str: lstm_2~0|none~0|lstm_2~1
  linear_layers: [dropout->linear]
  (layers): ModuleList(
    (0): LSTM(
      (lstm): LSTM(1, 64, num_layers=2, batch_first=True)
    )
    (1): Zero(C_in=1, C_out=64, stride=1)
    (2): LSTM(
      (lstm): LSTM(64, 64, num_layers=2, batch_first=True)
    )
  )
  (linear_layers): ModuleList(
    (0): Dropout(p=0.1, inplace=False)
    (1): Linear(in_features=3072, out_features=1, bias=True)
  )
)
tr_params :: epochs = 100, patience = 20, batch_size = 256, window_size = 48, data_size = 100
Model FLOPs: 5.717M, Model Params: 120.065K
learning rate scheduling :: (optimizer, mode='min', factor=0.1, patience=5, verbose=True)
total_samples :: train_dataset = 2136000, train_dataloader = 2136000
total_samples :: valid_dataset = 283200, valid_dataloader = 283200
Epoch ::  1 || Loss: 0.44633853 || it_count: 8344 || Val Loss: 0.45092735 || Val it_count: 1107 || Current Learning Rate: 0.001 || Time: 00:07:44.43
Epoch ::  2 || Loss: 0.42059780 || it_count: 8344 || Val Loss: 0.45051644 || Val it_count: 1107 || Current Learning Rate: 0.001 || Time: 00:15:20.86
Epoch ::  3 || Loss: 0.41955837 || it_count: 8344 || Val Loss: 0.45164642 || Val it_count: 1107 || Current Learning Rate: 0.001 || Time: 00:23:0.24
Epoch ::  4 || Loss: 0.41899937 || it_count: 8344 || Val Loss: 0.45124352 || Val it_count: 1107 || Current Learning Rate: 0.001 || Time: 00:30:41.27
Epoch ::  5 || Loss: 0.41820143 || it_count: 8344 || Val Loss: 0.45086161 || Val it_count: 1107 || Current Learning Rate: 0.001 || Time: 00:38:22.97
Epoch ::  6 || Loss: 0.41794453 || it_count: 8344 || Val Loss: 0.45157130 || Val it_count: 1107 || Current Learning Rate: 0.001 || Time: 00:46:3.53
Epoch ::  7 || Loss: 0.41824135 || it_count: 8344 || Val Loss: 0.45294813 || Val it_count: 1107 || Current Learning Rate: 0.001 || Time: 00:53:44.65
Epoch ::  8 || Loss: 0.41875877 || it_count: 8344 || Val Loss: 0.45342917 || Val it_count: 1107 || Current Learning Rate: 0.001 || Time: 01:01:26.22
Epoch ::  9 || Loss: 0.41826441 || it_count: 8344 || Val Loss: 0.45446726 || Val it_count: 1107 || Current Learning Rate: 0.001 || Time: 01:09:8.17
Epoch :: 10 || Loss: 0.41758199 || it_count: 8344 || Val Loss: 0.45296393 || Val it_count: 1107 || Current Learning Rate: 0.001 || Time: 01:16:50.61
Epoch :: 11 || Loss: 0.41649954 || it_count: 8344 || Val Loss: 0.45138832 || Val it_count: 1107 || Current Learning Rate: 0.001 || Time: 01:24:32.08
Epoch :: 12 || Loss: 0.41625854 || it_count: 8344 || Val Loss: 0.44813901 || Val it_count: 1107 || Current Learning Rate: 0.001 || Time: 01:32:14.96
Epoch :: 13 || Loss: 0.41630354 || it_count: 8344 || Val Loss: 0.44633170 || Val it_count: 1107 || Current Learning Rate: 0.001 || Time: 01:39:59.13
Epoch :: 14 || Loss: 0.41584586 || it_count: 8344 || Val Loss: 0.44731944 || Val it_count: 1107 || Current Learning Rate: 0.001 || Time: 01:47:42.11
Epoch :: 15 || Loss: 0.41473822 || it_count: 8344 || Val Loss: 0.44781751 || Val it_count: 1107 || Current Learning Rate: 0.001 || Time: 01:55:25.20
Epoch :: 16 || Loss: 0.41423623 || it_count: 8344 || Val Loss: 0.44829223 || Val it_count: 1107 || Current Learning Rate: 0.001 || Time: 02:03:9.24
Epoch :: 17 || Loss: 0.41379307 || it_count: 8344 || Val Loss: 0.44991217 || Val it_count: 1107 || Current Learning Rate: 0.001 || Time: 02:10:52.75
Epoch :: 18 || Loss: 0.41402817 || it_count: 8344 || Val Loss: 0.44962872 || Val it_count: 1107 || Current Learning Rate: 0.001 || Time: 02:18:35.92
Epoch :: 19 || Loss: 0.41304177 || it_count: 8344 || Val Loss: 0.44739477 || Val it_count: 1107 || Current Learning Rate: 0.001 || Time: 02:26:18.90
Epoch :: 20 || Loss: 0.41258868 || it_count: 8344 || Val Loss: 0.44778544 || Val it_count: 1107 || Current Learning Rate: 0.001 || Time: 02:34:2.24
Epoch :: 21 || Loss: 0.41205418 || it_count: 8344 || Val Loss: 0.44681678 || Val it_count: 1107 || Current Learning Rate: 0.001 || Time: 02:41:42.88
Epoch :: 22 || Loss: 0.41112373 || it_count: 8344 || Val Loss: 0.44719243 || Val it_count: 1107 || Current Learning Rate: 0.001 || Time: 02:49:27.08
Epoch :: 23 || Loss: 0.41106478 || it_count: 8344 || Val Loss: 0.44757147 || Val it_count: 1107 || Current Learning Rate: 0.001 || Time: 02:57:9.37
Epoch :: 24 || Loss: 0.41100968 || it_count: 8344 || Val Loss: 0.44740629 || Val it_count: 1107 || Current Learning Rate: 0.001 || Time: 03:04:52.71
Epoch :: 25 || Loss: 0.41091511 || it_count: 8344 || Val Loss: 0.44740945 || Val it_count: 1107 || Current Learning Rate: 0.001 || Time: 03:12:35.33
Epoch :: 26 || Loss: 0.41053420 || it_count: 8344 || Val Loss: 0.44844885 || Val it_count: 1107 || Current Learning Rate: 0.001 || Time: 03:20:19.42
Epoch 00011: reducing learning rate of group 0 to 1.0000e-04.
Epoch :: 27 || Loss: 0.40997398 || it_count: 8344 || Val Loss: 0.44805385 || Val it_count: 1107 || Current Learning Rate: 0.0001 || Time: 03:28:1.90
Epoch :: 28 || Loss: 0.41365218 || it_count: 8344 || Val Loss: 0.42283485 || Val it_count: 1107 || Current Learning Rate: 0.0001 || Time: 03:35:43.27
Epoch :: 29 || Loss: 0.41064568 || it_count: 8344 || Val Loss: 0.42131537 || Val it_count: 1107 || Current Learning Rate: 0.0001 || Time: 03:43:25.00
Epoch :: 30 || Loss: 0.40998224 || it_count: 8344 || Val Loss: 0.42073328 || Val it_count: 1107 || Current Learning Rate: 0.0001 || Time: 03:51:7.36
Epoch :: 31 || Loss: 0.40943352 || it_count: 8344 || Val Loss: 0.42063892 || Val it_count: 1107 || Current Learning Rate: 0.0001 || Time: 03:58:50.55
Epoch :: 32 || Loss: 0.40909366 || it_count: 8344 || Val Loss: 0.42047020 || Val it_count: 1107 || Current Learning Rate: 0.0001 || Time: 04:06:32.30
Epoch :: 33 || Loss: 0.40879267 || it_count: 8344 || Val Loss: 0.42059727 || Val it_count: 1107 || Current Learning Rate: 0.0001 || Time: 04:14:14.96
Epoch :: 34 || Loss: 0.40851875 || it_count: 8344 || Val Loss: 0.42045981 || Val it_count: 1107 || Current Learning Rate: 0.0001 || Time: 04:21:57.11
Epoch :: 35 || Loss: 0.40828662 || it_count: 8344 || Val Loss: 0.42049276 || Val it_count: 1107 || Current Learning Rate: 0.0001 || Time: 04:29:39.63
Epoch :: 36 || Loss: 0.40803066 || it_count: 8344 || Val Loss: 0.42044069 || Val it_count: 1107 || Current Learning Rate: 0.0001 || Time: 04:37:23.53
Epoch :: 37 || Loss: 0.40780250 || it_count: 8344 || Val Loss: 0.42033513 || Val it_count: 1107 || Current Learning Rate: 0.0001 || Time: 04:45:6.75
Epoch :: 38 || Loss: 0.40756906 || it_count: 8344 || Val Loss: 0.42038131 || Val it_count: 1107 || Current Learning Rate: 0.0001 || Time: 04:52:49.31
Epoch :: 39 || Loss: 0.40744341 || it_count: 8344 || Val Loss: 0.42033988 || Val it_count: 1107 || Current Learning Rate: 0.0001 || Time: 05:00:32.54
Epoch :: 40 || Loss: 0.40722591 || it_count: 8344 || Val Loss: 0.42050278 || Val it_count: 1107 || Current Learning Rate: 0.0001 || Time: 05:08:15.16
Epoch :: 41 || Loss: 0.40708968 || it_count: 8344 || Val Loss: 0.42052687 || Val it_count: 1107 || Current Learning Rate: 0.0001 || Time: 05:15:55.90
Epoch :: 42 || Loss: 0.40687015 || it_count: 8344 || Val Loss: 0.42058160 || Val it_count: 1107 || Current Learning Rate: 0.0001 || Time: 05:23:29.01
Epoch 00027: reducing learning rate of group 0 to 1.0000e-05.
Epoch :: 43 || Loss: 0.40675226 || it_count: 8344 || Val Loss: 0.42072434 || Val it_count: 1107 || Current Learning Rate: 1e-05 || Time: 05:31:1.45
Epoch :: 44 || Loss: 0.40879566 || it_count: 8344 || Val Loss: 0.41338686 || Val it_count: 1107 || Current Learning Rate: 1e-05 || Time: 05:38:33.23
Epoch :: 45 || Loss: 0.40792007 || it_count: 8344 || Val Loss: 0.41317018 || Val it_count: 1107 || Current Learning Rate: 1e-05 || Time: 05:46:5.24
Epoch :: 46 || Loss: 0.40770437 || it_count: 8344 || Val Loss: 0.41291027 || Val it_count: 1107 || Current Learning Rate: 1e-05 || Time: 05:53:37.48
Epoch :: 47 || Loss: 0.40760871 || it_count: 8344 || Val Loss: 0.41273383 || Val it_count: 1107 || Current Learning Rate: 1e-05 || Time: 06:01:9.67
Epoch :: 48 || Loss: 0.40750720 || it_count: 8344 || Val Loss: 0.41249872 || Val it_count: 1107 || Current Learning Rate: 1e-05 || Time: 06:08:42.48
Epoch :: 49 || Loss: 0.40743846 || it_count: 8344 || Val Loss: 0.41235960 || Val it_count: 1107 || Current Learning Rate: 1e-05 || Time: 06:16:13.68
Epoch :: 50 || Loss: 0.40737537 || it_count: 8344 || Val Loss: 0.41226358 || Val it_count: 1107 || Current Learning Rate: 1e-05 || Time: 06:23:43.86
Epoch :: 51 || Loss: 0.40734715 || it_count: 8344 || Val Loss: 0.41217225 || Val it_count: 1107 || Current Learning Rate: 1e-05 || Time: 06:31:13.74
Epoch :: 52 || Loss: 0.40725768 || it_count: 8344 || Val Loss: 0.41206083 || Val it_count: 1107 || Current Learning Rate: 1e-05 || Time: 06:38:45.61
Epoch :: 53 || Loss: 0.40722860 || it_count: 8344 || Val Loss: 0.41196667 || Val it_count: 1107 || Current Learning Rate: 1e-05 || Time: 06:46:15.16
Epoch :: 54 || Loss: 0.40718868 || it_count: 8344 || Val Loss: 0.41190833 || Val it_count: 1107 || Current Learning Rate: 1e-05 || Time: 06:53:44.77
Epoch :: 55 || Loss: 0.40712071 || it_count: 8344 || Val Loss: 0.41189380 || Val it_count: 1107 || Current Learning Rate: 1e-05 || Time: 07:01:15.78
Epoch :: 56 || Loss: 0.40711842 || it_count: 8344 || Val Loss: 0.41183223 || Val it_count: 1107 || Current Learning Rate: 1e-05 || Time: 07:08:50.65
Epoch :: 57 || Loss: 0.40711071 || it_count: 8344 || Val Loss: 0.41176472 || Val it_count: 1107 || Current Learning Rate: 1e-05 || Time: 07:16:34.04
Epoch :: 58 || Loss: 0.40703456 || it_count: 8344 || Val Loss: 0.41173954 || Val it_count: 1107 || Current Learning Rate: 1e-05 || Time: 07:24:16.21
Epoch :: 59 || Loss: 0.40702002 || it_count: 8344 || Val Loss: 0.41168203 || Val it_count: 1107 || Current Learning Rate: 1e-05 || Time: 07:31:58.04
Epoch :: 60 || Loss: 0.40699019 || it_count: 8344 || Val Loss: 0.41168276 || Val it_count: 1107 || Current Learning Rate: 1e-05 || Time: 07:39:40.53
Epoch :: 61 || Loss: 0.40691362 || it_count: 8344 || Val Loss: 0.41161343 || Val it_count: 1107 || Current Learning Rate: 1e-05 || Time: 07:47:23.00
Epoch :: 62 || Loss: 0.40692481 || it_count: 8344 || Val Loss: 0.41159203 || Val it_count: 1107 || Current Learning Rate: 1e-05 || Time: 07:55:5.86
Epoch :: 63 || Loss: 0.40688528 || it_count: 8344 || Val Loss: 0.41155457 || Val it_count: 1107 || Current Learning Rate: 1e-05 || Time: 08:02:47.62
Epoch :: 64 || Loss: 0.40682152 || it_count: 8344 || Val Loss: 0.41150606 || Val it_count: 1107 || Current Learning Rate: 1e-05 || Time: 08:10:30.49
Epoch :: 65 || Loss: 0.40681809 || it_count: 8344 || Val Loss: 0.41147168 || Val it_count: 1107 || Current Learning Rate: 1e-05 || Time: 08:18:11.06
Epoch :: 66 || Loss: 0.40678739 || it_count: 8344 || Val Loss: 0.41145280 || Val it_count: 1107 || Current Learning Rate: 1e-05 || Time: 08:25:53.45
Epoch :: 67 || Loss: 0.40677334 || it_count: 8344 || Val Loss: 0.41144917 || Val it_count: 1107 || Current Learning Rate: 1e-05 || Time: 08:33:36.43
Epoch :: 68 || Loss: 0.40673102 || it_count: 8344 || Val Loss: 0.41145840 || Val it_count: 1107 || Current Learning Rate: 1e-05 || Time: 08:41:19.29
Epoch :: 69 || Loss: 0.40668379 || it_count: 8344 || Val Loss: 0.41144860 || Val it_count: 1107 || Current Learning Rate: 1e-05 || Time: 08:49:1.29
Epoch :: 70 || Loss: 0.40666850 || it_count: 8344 || Val Loss: 0.41140543 || Val it_count: 1107 || Current Learning Rate: 1e-05 || Time: 08:56:43.22
Epoch :: 71 || Loss: 0.40666184 || it_count: 8344 || Val Loss: 0.41142617 || Val it_count: 1107 || Current Learning Rate: 1e-05 || Time: 09:04:24.23
Epoch :: 72 || Loss: 0.40662964 || it_count: 8344 || Val Loss: 0.41139137 || Val it_count: 1107 || Current Learning Rate: 1e-05 || Time: 09:12:7.19
Epoch :: 73 || Loss: 0.40660231 || it_count: 8344 || Val Loss: 0.41137796 || Val it_count: 1107 || Current Learning Rate: 1e-05 || Time: 09:19:50.02
Epoch :: 74 || Loss: 0.40656650 || it_count: 8344 || Val Loss: 0.41137226 || Val it_count: 1107 || Current Learning Rate: 1e-05 || Time: 09:27:30.82
Epoch :: 75 || Loss: 0.40656633 || it_count: 8344 || Val Loss: 0.41135943 || Val it_count: 1107 || Current Learning Rate: 1e-05 || Time: 09:35:13.32
Epoch :: 76 || Loss: 0.40650356 || it_count: 8344 || Val Loss: 0.41136337 || Val it_count: 1107 || Current Learning Rate: 1e-05 || Time: 09:42:55.84
Epoch :: 77 || Loss: 0.40648450 || it_count: 8344 || Val Loss: 0.41131445 || Val it_count: 1107 || Current Learning Rate: 1e-05 || Time: 09:50:38.40
Epoch :: 78 || Loss: 0.40648863 || it_count: 8344 || Val Loss: 0.41129673 || Val it_count: 1107 || Current Learning Rate: 1e-05 || Time: 09:58:19.51
Epoch :: 79 || Loss: 0.40641209 || it_count: 8344 || Val Loss: 0.41127664 || Val it_count: 1107 || Current Learning Rate: 1e-05 || Time: 10:06:1.47
Epoch :: 80 || Loss: 0.40641838 || it_count: 8344 || Val Loss: 0.41125730 || Val it_count: 1107 || Current Learning Rate: 1e-05 || Time: 10:13:42.98
Epoch :: 81 || Loss: 0.40639010 || it_count: 8344 || Val Loss: 0.41124909 || Val it_count: 1107 || Current Learning Rate: 1e-05 || Time: 10:21:25.05
Epoch :: 82 || Loss: 0.40636970 || it_count: 8344 || Val Loss: 0.41127443 || Val it_count: 1107 || Current Learning Rate: 1e-05 || Time: 10:29:7.65
Epoch :: 83 || Loss: 0.40635747 || it_count: 8344 || Val Loss: 0.41119130 || Val it_count: 1107 || Current Learning Rate: 1e-05 || Time: 10:36:49.99
Epoch :: 84 || Loss: 0.40630566 || it_count: 8344 || Val Loss: 0.41117785 || Val it_count: 1107 || Current Learning Rate: 1e-05 || Time: 10:44:31.60
Epoch :: 85 || Loss: 0.40629039 || it_count: 8344 || Val Loss: 0.41118416 || Val it_count: 1107 || Current Learning Rate: 1e-05 || Time: 10:52:13.30
Epoch :: 86 || Loss: 0.40625037 || it_count: 8344 || Val Loss: 0.41121271 || Val it_count: 1107 || Current Learning Rate: 1e-05 || Time: 10:59:56.19
Epoch :: 87 || Loss: 0.40627075 || it_count: 8344 || Val Loss: 0.41116154 || Val it_count: 1107 || Current Learning Rate: 1e-05 || Time: 11:07:38.74
Epoch :: 88 || Loss: 0.40622558 || it_count: 8344 || Val Loss: 0.41119576 || Val it_count: 1107 || Current Learning Rate: 1e-05 || Time: 11:15:19.48
Epoch 00073: reducing learning rate of group 0 to 1.0000e-06.
Epoch :: 89 || Loss: 0.40614843 || it_count: 8344 || Val Loss: 0.41117202 || Val it_count: 1107 || Current Learning Rate: 1.0000000000000002e-06 || Time: 11:23:1.91
Epoch :: 90 || Loss: 0.40635019 || it_count: 8344 || Val Loss: 0.41085865 || Val it_count: 1107 || Current Learning Rate: 1.0000000000000002e-06 || Time: 11:30:44.69
Epoch :: 91 || Loss: 0.40632276 || it_count: 8344 || Val Loss: 0.41080719 || Val it_count: 1107 || Current Learning Rate: 1.0000000000000002e-06 || Time: 11:38:26.76
Epoch :: 92 || Loss: 0.40630140 || it_count: 8344 || Val Loss: 0.41078580 || Val it_count: 1107 || Current Learning Rate: 1.0000000000000002e-06 || Time: 11:46:9.46
Epoch :: 93 || Loss: 0.40623977 || it_count: 8344 || Val Loss: 0.41076913 || Val it_count: 1107 || Current Learning Rate: 1.0000000000000002e-06 || Time: 11:53:51.78
Epoch :: 94 || Loss: 0.40622449 || it_count: 8344 || Val Loss: 0.41076131 || Val it_count: 1107 || Current Learning Rate: 1.0000000000000002e-06 || Time: 12:01:32.79
Epoch :: 95 || Loss: 0.40622653 || it_count: 8344 || Val Loss: 0.41075230 || Val it_count: 1107 || Current Learning Rate: 1.0000000000000002e-06 || Time: 12:09:14.80
Epoch :: 96 || Loss: 0.40623850 || it_count: 8344 || Val Loss: 0.41074521 || Val it_count: 1107 || Current Learning Rate: 1.0000000000000002e-06 || Time: 12:16:56.88
Epoch :: 97 || Loss: 0.40625938 || it_count: 8344 || Val Loss: 0.41074734 || Val it_count: 1107 || Current Learning Rate: 1.0000000000000002e-06 || Time: 12:24:38.67
Epoch :: 98 || Loss: 0.40620449 || it_count: 8344 || Val Loss: 0.41074777 || Val it_count: 1107 || Current Learning Rate: 1.0000000000000002e-06 || Time: 12:32:20.49
Epoch :: 99 || Loss: 0.40624021 || it_count: 8344 || Val Loss: 0.41073614 || Val it_count: 1107 || Current Learning Rate: 1.0000000000000002e-06 || Time: 12:40:2.78
Epoch 00084: reducing learning rate of group 0 to 1.0000e-07.
Early stopping triggered due to learning rate below threshold.
Done Total time: 12:47:45.01
best_loss: 0.41073613691253247

--------------------Testing--------------------

total_samples :: test_dataset = 139200, test_dataloader = 139200
Epoch ::  1 || Loss: 0.23511142 || it_count: 544 || Time: 00:00:20.89
MAE:  0.25075963
MSE:  0.23512825
RMSE:  0.44076684

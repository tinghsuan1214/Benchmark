--------------------Training--------------------
arch_str :: |none~0|+|lstm_3~0|skip_connect~1|[relu->linear]
model :: 3C
InferCell(
  info :: nodes=3, inC=1, outC=64, [1<-(I0-L0) | 2<-(I0-L1,I1-L2)], genotype_str: none~0|lstm_3~0|skip_connect~1
  linear_layers: [relu->linear]
  (layers): ModuleList(
    (0): Zero(C_in=1, C_out=64, stride=1)
    (1): LSTM(
      (lstm): LSTM(1, 64, num_layers=3, batch_first=True)
    )
    (2): Identity()
  )
  (linear_layers): ModuleList(
    (0): ReLU()
    (1): Linear(in_features=3072, out_features=1, bias=True)
  )
)
tr_params :: epochs = 100, patience = 20, batch_size = 256, window_size = 48, data_size = 100
Model MACs: 4.095M, Model Params: 86.785K
learning rate scheduling :: (optimizer, mode='min', factor=0.1, patience=5, verbose=True)
total_samples :: train_dataset = 2136000, train_dataloader = 2136000
total_samples :: valid_dataset = 283200, valid_dataloader = 283200
Epoch ::  1 || Loss: 0.42449122 || it_count: 8344 || Val Loss: 0.44966906 || Val it_count: 1107 || Current Learning Rate: 0.001 || Time: 00:04:39.80
Epoch ::  2 || Loss: 0.41788018 || it_count: 8344 || Val Loss: 0.45007288 || Val it_count: 1107 || Current Learning Rate: 0.001 || Time: 00:09:14.21
Epoch ::  3 || Loss: 0.41745039 || it_count: 8344 || Val Loss: 0.44985046 || Val it_count: 1107 || Current Learning Rate: 0.001 || Time: 00:13:50.30
Epoch ::  4 || Loss: 0.41750794 || it_count: 8344 || Val Loss: 0.45053839 || Val it_count: 1107 || Current Learning Rate: 0.001 || Time: 00:18:25.04
Epoch ::  5 || Loss: 0.41693994 || it_count: 8344 || Val Loss: 0.45013553 || Val it_count: 1107 || Current Learning Rate: 0.001 || Time: 00:23:0.92
Epoch ::  6 || Loss: 0.41683441 || it_count: 8344 || Val Loss: 0.45191126 || Val it_count: 1107 || Current Learning Rate: 0.001 || Time: 00:27:36.45
Epoch ::  7 || Loss: 0.41618544 || it_count: 8344 || Val Loss: 0.45176908 || Val it_count: 1107 || Current Learning Rate: 0.001 || Time: 00:32:12.06
Epoch ::  8 || Loss: 0.41578411 || it_count: 8344 || Val Loss: 0.45261029 || Val it_count: 1107 || Current Learning Rate: 0.001 || Time: 00:36:14.26
Epoch ::  9 || Loss: 0.41641701 || it_count: 8344 || Val Loss: 0.45301638 || Val it_count: 1107 || Current Learning Rate: 0.001 || Time: 00:40:13.10
Epoch :: 10 || Loss: 0.41566829 || it_count: 8344 || Val Loss: 0.45323203 || Val it_count: 1107 || Current Learning Rate: 0.001 || Time: 00:44:12.30
Epoch :: 11 || Loss: 0.41507053 || it_count: 8344 || Val Loss: 0.45103169 || Val it_count: 1107 || Current Learning Rate: 0.001 || Time: 00:48:10.79
Epoch :: 12 || Loss: 0.41456848 || it_count: 8344 || Val Loss: 0.45185332 || Val it_count: 1107 || Current Learning Rate: 0.001 || Time: 00:52:9.82
Epoch :: 13 || Loss: 0.41418936 || it_count: 8344 || Val Loss: 0.45043601 || Val it_count: 1107 || Current Learning Rate: 0.001 || Time: 00:56:9.84
Epoch :: 14 || Loss: 0.41380423 || it_count: 8344 || Val Loss: 0.44899999 || Val it_count: 1107 || Current Learning Rate: 0.001 || Time: 01:00:10.69
Epoch :: 15 || Loss: 0.41218224 || it_count: 8344 || Val Loss: 0.44971271 || Val it_count: 1107 || Current Learning Rate: 0.001 || Time: 01:04:8.46
Epoch :: 16 || Loss: 0.41130737 || it_count: 8344 || Val Loss: 0.44786740 || Val it_count: 1107 || Current Learning Rate: 0.001 || Time: 01:08:10.35
Epoch :: 17 || Loss: 0.41095669 || it_count: 8344 || Val Loss: 0.44744282 || Val it_count: 1107 || Current Learning Rate: 0.001 || Time: 01:12:9.96
Epoch :: 18 || Loss: 0.41066863 || it_count: 8344 || Val Loss: 0.44633037 || Val it_count: 1107 || Current Learning Rate: 0.001 || Time: 01:16:11.43
Epoch :: 19 || Loss: 0.40993023 || it_count: 8344 || Val Loss: 0.44820753 || Val it_count: 1107 || Current Learning Rate: 0.001 || Time: 01:20:11.41
Epoch :: 20 || Loss: 0.41000530 || it_count: 8344 || Val Loss: 0.44935014 || Val it_count: 1107 || Current Learning Rate: 0.001 || Time: 01:24:11.80
Epoch :: 21 || Loss: 0.40989300 || it_count: 8344 || Val Loss: 0.44979402 || Val it_count: 1107 || Current Learning Rate: 0.001 || Time: 01:28:13.11
Epoch :: 22 || Loss: 0.41018130 || it_count: 8344 || Val Loss: 0.45009998 || Val it_count: 1107 || Current Learning Rate: 0.001 || Time: 01:32:14.17
Epoch :: 23 || Loss: 0.40922114 || it_count: 8344 || Val Loss: 0.44904620 || Val it_count: 1107 || Current Learning Rate: 0.001 || Time: 01:36:14.38
Epoch 00008: reducing learning rate of group 0 to 1.0000e-04.
Epoch :: 24 || Loss: 0.40925556 || it_count: 8344 || Val Loss: 0.44852891 || Val it_count: 1107 || Current Learning Rate: 0.0001 || Time: 01:40:13.06
Epoch :: 25 || Loss: 0.41451306 || it_count: 8344 || Val Loss: 0.42031481 || Val it_count: 1107 || Current Learning Rate: 0.0001 || Time: 01:44:13.26
Epoch :: 26 || Loss: 0.41030650 || it_count: 8344 || Val Loss: 0.41935163 || Val it_count: 1107 || Current Learning Rate: 0.0001 || Time: 01:48:12.82
Epoch :: 27 || Loss: 0.40951278 || it_count: 8344 || Val Loss: 0.41889141 || Val it_count: 1107 || Current Learning Rate: 0.0001 || Time: 01:52:13.72
Epoch :: 28 || Loss: 0.40898708 || it_count: 8344 || Val Loss: 0.41870379 || Val it_count: 1107 || Current Learning Rate: 0.0001 || Time: 01:56:14.92
Epoch :: 29 || Loss: 0.40857661 || it_count: 8344 || Val Loss: 0.41859120 || Val it_count: 1107 || Current Learning Rate: 0.0001 || Time: 02:00:15.65
Epoch :: 30 || Loss: 0.40818991 || it_count: 8344 || Val Loss: 0.41848174 || Val it_count: 1107 || Current Learning Rate: 0.0001 || Time: 02:04:15.86
Epoch :: 31 || Loss: 0.40784178 || it_count: 8344 || Val Loss: 0.41828038 || Val it_count: 1107 || Current Learning Rate: 0.0001 || Time: 02:08:15.22
Epoch :: 32 || Loss: 0.40751374 || it_count: 8344 || Val Loss: 0.41821511 || Val it_count: 1107 || Current Learning Rate: 0.0001 || Time: 02:12:16.09
Epoch :: 33 || Loss: 0.40719314 || it_count: 8344 || Val Loss: 0.41808661 || Val it_count: 1107 || Current Learning Rate: 0.0001 || Time: 02:16:16.29
Epoch :: 34 || Loss: 0.40689946 || it_count: 8344 || Val Loss: 0.41789116 || Val it_count: 1107 || Current Learning Rate: 0.0001 || Time: 02:20:17.35
Epoch :: 35 || Loss: 0.40664071 || it_count: 8344 || Val Loss: 0.41772409 || Val it_count: 1107 || Current Learning Rate: 0.0001 || Time: 02:24:14.69
Epoch :: 36 || Loss: 0.40641576 || it_count: 8344 || Val Loss: 0.41772626 || Val it_count: 1107 || Current Learning Rate: 0.0001 || Time: 02:28:15.32
Epoch :: 37 || Loss: 0.40618587 || it_count: 8344 || Val Loss: 0.41778460 || Val it_count: 1107 || Current Learning Rate: 0.0001 || Time: 02:32:16.30
Epoch :: 38 || Loss: 0.40596861 || it_count: 8344 || Val Loss: 0.41778104 || Val it_count: 1107 || Current Learning Rate: 0.0001 || Time: 02:36:14.49
Epoch :: 39 || Loss: 0.40575288 || it_count: 8344 || Val Loss: 0.41790117 || Val it_count: 1107 || Current Learning Rate: 0.0001 || Time: 02:40:14.41
Epoch :: 40 || Loss: 0.40555715 || it_count: 8344 || Val Loss: 0.41794333 || Val it_count: 1107 || Current Learning Rate: 0.0001 || Time: 02:44:14.98
Epoch 00025: reducing learning rate of group 0 to 1.0000e-05.
Epoch :: 41 || Loss: 0.40537978 || it_count: 8344 || Val Loss: 0.41803600 || Val it_count: 1107 || Current Learning Rate: 1e-05 || Time: 02:48:14.81
Epoch :: 42 || Loss: 0.40815115 || it_count: 8344 || Val Loss: 0.41165604 || Val it_count: 1107 || Current Learning Rate: 1e-05 || Time: 02:52:13.45
Epoch :: 43 || Loss: 0.40688806 || it_count: 8344 || Val Loss: 0.41146383 || Val it_count: 1107 || Current Learning Rate: 1e-05 || Time: 02:56:13.28
Epoch :: 44 || Loss: 0.40666445 || it_count: 8344 || Val Loss: 0.41136045 || Val it_count: 1107 || Current Learning Rate: 1e-05 || Time: 03:00:14.57
Epoch :: 45 || Loss: 0.40655011 || it_count: 8344 || Val Loss: 0.41128664 || Val it_count: 1107 || Current Learning Rate: 1e-05 || Time: 03:04:15.14
Epoch :: 46 || Loss: 0.40646628 || it_count: 8344 || Val Loss: 0.41123371 || Val it_count: 1107 || Current Learning Rate: 1e-05 || Time: 03:08:13.56
Epoch :: 47 || Loss: 0.40639916 || it_count: 8344 || Val Loss: 0.41118856 || Val it_count: 1107 || Current Learning Rate: 1e-05 || Time: 03:12:13.19
Epoch :: 48 || Loss: 0.40633780 || it_count: 8344 || Val Loss: 0.41114697 || Val it_count: 1107 || Current Learning Rate: 1e-05 || Time: 03:16:12.85
Epoch :: 49 || Loss: 0.40628328 || it_count: 8344 || Val Loss: 0.41111225 || Val it_count: 1107 || Current Learning Rate: 1e-05 || Time: 03:20:12.13
Epoch :: 50 || Loss: 0.40623105 || it_count: 8344 || Val Loss: 0.41108237 || Val it_count: 1107 || Current Learning Rate: 1e-05 || Time: 03:24:8.62
Epoch :: 51 || Loss: 0.40618185 || it_count: 8344 || Val Loss: 0.41105858 || Val it_count: 1107 || Current Learning Rate: 1e-05 || Time: 03:28:6.28
Epoch :: 52 || Loss: 0.40613629 || it_count: 8344 || Val Loss: 0.41103578 || Val it_count: 1107 || Current Learning Rate: 1e-05 || Time: 03:32:6.47
Epoch :: 53 || Loss: 0.40609195 || it_count: 8344 || Val Loss: 0.41101409 || Val it_count: 1107 || Current Learning Rate: 1e-05 || Time: 03:36:6.57
Epoch :: 54 || Loss: 0.40604913 || it_count: 8344 || Val Loss: 0.41099388 || Val it_count: 1107 || Current Learning Rate: 1e-05 || Time: 03:40:4.99
Epoch :: 55 || Loss: 0.40600776 || it_count: 8344 || Val Loss: 0.41097574 || Val it_count: 1107 || Current Learning Rate: 1e-05 || Time: 03:44:3.84
Epoch :: 56 || Loss: 0.40596900 || it_count: 8344 || Val Loss: 0.41095597 || Val it_count: 1107 || Current Learning Rate: 1e-05 || Time: 03:48:4.69
Epoch :: 57 || Loss: 0.40593076 || it_count: 8344 || Val Loss: 0.41093515 || Val it_count: 1107 || Current Learning Rate: 1e-05 || Time: 03:52:5.90
Epoch :: 58 || Loss: 0.40589403 || it_count: 8344 || Val Loss: 0.41091601 || Val it_count: 1107 || Current Learning Rate: 1e-05 || Time: 03:56:4.11
Epoch :: 59 || Loss: 0.40585753 || it_count: 8344 || Val Loss: 0.41090041 || Val it_count: 1107 || Current Learning Rate: 1e-05 || Time: 04:00:0.29
Epoch :: 60 || Loss: 0.40582117 || it_count: 8344 || Val Loss: 0.41088758 || Val it_count: 1107 || Current Learning Rate: 1e-05 || Time: 04:04:0.32
Epoch :: 61 || Loss: 0.40578475 || it_count: 8344 || Val Loss: 0.41087903 || Val it_count: 1107 || Current Learning Rate: 1e-05 || Time: 04:07:57.90
Epoch :: 62 || Loss: 0.40575142 || it_count: 8344 || Val Loss: 0.41086683 || Val it_count: 1107 || Current Learning Rate: 1e-05 || Time: 04:11:57.48
Epoch :: 63 || Loss: 0.40571662 || it_count: 8344 || Val Loss: 0.41085524 || Val it_count: 1107 || Current Learning Rate: 1e-05 || Time: 04:15:54.93
Epoch :: 64 || Loss: 0.40568411 || it_count: 8344 || Val Loss: 0.41084157 || Val it_count: 1107 || Current Learning Rate: 1e-05 || Time: 04:19:52.64
Epoch :: 65 || Loss: 0.40565203 || it_count: 8344 || Val Loss: 0.41082574 || Val it_count: 1107 || Current Learning Rate: 1e-05 || Time: 04:23:48.32
Epoch :: 66 || Loss: 0.40561895 || it_count: 8344 || Val Loss: 0.41081660 || Val it_count: 1107 || Current Learning Rate: 1e-05 || Time: 04:27:46.50
Epoch :: 67 || Loss: 0.40558898 || it_count: 8344 || Val Loss: 0.41080359 || Val it_count: 1107 || Current Learning Rate: 1e-05 || Time: 04:31:42.45
Epoch :: 68 || Loss: 0.40555633 || it_count: 8344 || Val Loss: 0.41079047 || Val it_count: 1107 || Current Learning Rate: 1e-05 || Time: 04:35:40.57
Epoch :: 69 || Loss: 0.40552670 || it_count: 8344 || Val Loss: 0.41078133 || Val it_count: 1107 || Current Learning Rate: 1e-05 || Time: 04:39:40.78
Epoch :: 70 || Loss: 0.40549716 || it_count: 8344 || Val Loss: 0.41077346 || Val it_count: 1107 || Current Learning Rate: 1e-05 || Time: 04:43:34.59
Epoch :: 71 || Loss: 0.40546801 || it_count: 8344 || Val Loss: 0.41076205 || Val it_count: 1107 || Current Learning Rate: 1e-05 || Time: 04:47:29.64
Epoch :: 72 || Loss: 0.40543852 || it_count: 8344 || Val Loss: 0.41075646 || Val it_count: 1107 || Current Learning Rate: 1e-05 || Time: 04:51:25.52
Epoch :: 73 || Loss: 0.40541172 || it_count: 8344 || Val Loss: 0.41074626 || Val it_count: 1107 || Current Learning Rate: 1e-05 || Time: 04:55:22.34
Epoch :: 74 || Loss: 0.40538322 || it_count: 8344 || Val Loss: 0.41074182 || Val it_count: 1107 || Current Learning Rate: 1e-05 || Time: 04:59:19.85
Epoch :: 75 || Loss: 0.40535547 || it_count: 8344 || Val Loss: 0.41073111 || Val it_count: 1107 || Current Learning Rate: 1e-05 || Time: 05:03:22.85
Epoch :: 76 || Loss: 0.40532796 || it_count: 8344 || Val Loss: 0.41071882 || Val it_count: 1107 || Current Learning Rate: 1e-05 || Time: 05:07:21.18
Epoch :: 77 || Loss: 0.40530040 || it_count: 8344 || Val Loss: 0.41071309 || Val it_count: 1107 || Current Learning Rate: 1e-05 || Time: 05:11:15.03
Epoch :: 78 || Loss: 0.40527306 || it_count: 8344 || Val Loss: 0.41070339 || Val it_count: 1107 || Current Learning Rate: 1e-05 || Time: 05:15:13.78
Epoch :: 79 || Loss: 0.40524641 || it_count: 8344 || Val Loss: 0.41069774 || Val it_count: 1107 || Current Learning Rate: 1e-05 || Time: 05:19:12.25
Epoch :: 80 || Loss: 0.40522013 || it_count: 8344 || Val Loss: 0.41068622 || Val it_count: 1107 || Current Learning Rate: 1e-05 || Time: 05:23:9.16
Epoch :: 81 || Loss: 0.40519352 || it_count: 8344 || Val Loss: 0.41068171 || Val it_count: 1107 || Current Learning Rate: 1e-05 || Time: 05:27:6.18
Epoch :: 82 || Loss: 0.40516810 || it_count: 8344 || Val Loss: 0.41067810 || Val it_count: 1107 || Current Learning Rate: 1e-05 || Time: 05:30:59.52
Epoch :: 83 || Loss: 0.40514294 || it_count: 8344 || Val Loss: 0.41067223 || Val it_count: 1107 || Current Learning Rate: 1e-05 || Time: 05:34:53.55
Epoch 00068: reducing learning rate of group 0 to 1.0000e-06.
Epoch :: 84 || Loss: 0.40511820 || it_count: 8344 || Val Loss: 0.41066648 || Val it_count: 1107 || Current Learning Rate: 1.0000000000000002e-06 || Time: 05:38:50.26
Epoch :: 85 || Loss: 0.40537222 || it_count: 8344 || Val Loss: 0.41043733 || Val it_count: 1107 || Current Learning Rate: 1.0000000000000002e-06 || Time: 05:42:46.84
Epoch :: 86 || Loss: 0.40525154 || it_count: 8344 || Val Loss: 0.41037711 || Val it_count: 1107 || Current Learning Rate: 1.0000000000000002e-06 || Time: 05:46:42.09
Epoch :: 87 || Loss: 0.40520658 || it_count: 8344 || Val Loss: 0.41035099 || Val it_count: 1107 || Current Learning Rate: 1.0000000000000002e-06 || Time: 05:50:37.49
Epoch :: 88 || Loss: 0.40518370 || it_count: 8344 || Val Loss: 0.41033658 || Val it_count: 1107 || Current Learning Rate: 1.0000000000000002e-06 || Time: 05:54:29.74
Epoch :: 89 || Loss: 0.40516885 || it_count: 8344 || Val Loss: 0.41032721 || Val it_count: 1107 || Current Learning Rate: 1.0000000000000002e-06 || Time: 05:58:25.81
Epoch :: 90 || Loss: 0.40515818 || it_count: 8344 || Val Loss: 0.41032172 || Val it_count: 1107 || Current Learning Rate: 1.0000000000000002e-06 || Time: 06:02:23.24
Epoch :: 91 || Loss: 0.40515021 || it_count: 8344 || Val Loss: 0.41031780 || Val it_count: 1107 || Current Learning Rate: 1.0000000000000002e-06 || Time: 06:06:20.06
Epoch :: 92 || Loss: 0.40514359 || it_count: 8344 || Val Loss: 0.41031511 || Val it_count: 1107 || Current Learning Rate: 1.0000000000000002e-06 || Time: 06:10:18.39
Epoch :: 93 || Loss: 0.40513790 || it_count: 8344 || Val Loss: 0.41031316 || Val it_count: 1107 || Current Learning Rate: 1.0000000000000002e-06 || Time: 06:14:12.80
Epoch :: 94 || Loss: 0.40513294 || it_count: 8344 || Val Loss: 0.41031151 || Val it_count: 1107 || Current Learning Rate: 1.0000000000000002e-06 || Time: 06:18:9.04
Epoch 00079: reducing learning rate of group 0 to 1.0000e-07.
Early stopping triggered due to learning rate below threshold.
Done Total time: 06:22:7.60
best_loss: 0.410311514881511

--------------------Testing--------------------

total_samples :: test_dataset = 139200, test_dataloader = 139200
Epoch ::  1 || Loss: 0.23589261 || it_count: 544 || Time: 00:00:12.69
MAE:  0.2521844
MSE:  0.23591109
RMSE:  0.44113705

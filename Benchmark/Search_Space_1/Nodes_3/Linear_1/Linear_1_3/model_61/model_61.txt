--------------------Training--------------------
arch_str :: |lstm_3~0|+|lstm_3~0|lstm_1~1|[relu->linear]
model :: 3C
InferCell(
  info :: nodes=3, inC=1, outC=64, [1<-(I0-L0) | 2<-(I0-L1,I1-L2)], genotype_str: lstm_3~0|lstm_3~0|lstm_1~1
  linear_layers: [relu->linear]
  (layers): ModuleList(
    (0-1): 2 x LSTM(
      (lstm): LSTM(1, 64, num_layers=3, batch_first=True)
    )
    (2): LSTM(
      (lstm): LSTM(64, 64, batch_first=True)
    )
  )
  (linear_layers): ModuleList(
    (0): ReLU()
    (1): Linear(in_features=3072, out_features=1, bias=True)
  )
)
tr_params :: epochs = 100, patience = 20, batch_size = 256, window_size = 48, data_size = 100
Model MACs: 9.809M, Model Params: 203.777K
learning rate scheduling :: (optimizer, mode='min', factor=0.1, patience=5, verbose=True)
total_samples :: train_dataset = 2136000, train_dataloader = 2136000
total_samples :: valid_dataset = 283200, valid_dataloader = 283200
Epoch ::  1 || Loss: 0.42575782 || it_count: 8344 || Val Loss: 0.44960424 || Val it_count: 1107 || Current Learning Rate: 0.001 || Time: 00:05:17.75
Epoch ::  2 || Loss: 0.41765443 || it_count: 8344 || Val Loss: 0.44990489 || Val it_count: 1107 || Current Learning Rate: 0.001 || Time: 00:10:34.17
Epoch ::  3 || Loss: 0.41775600 || it_count: 8344 || Val Loss: 0.45002675 || Val it_count: 1107 || Current Learning Rate: 0.001 || Time: 00:15:44.03
Epoch ::  4 || Loss: 0.41718905 || it_count: 8344 || Val Loss: 0.45018327 || Val it_count: 1107 || Current Learning Rate: 0.001 || Time: 00:20:39.17
Epoch ::  5 || Loss: 0.41665986 || it_count: 8344 || Val Loss: 0.45128244 || Val it_count: 1107 || Current Learning Rate: 0.001 || Time: 00:25:35.63
Epoch ::  6 || Loss: 0.41650722 || it_count: 8344 || Val Loss: 0.45193701 || Val it_count: 1107 || Current Learning Rate: 0.001 || Time: 00:30:34.12
Epoch ::  7 || Loss: 0.41655511 || it_count: 8344 || Val Loss: 0.45117696 || Val it_count: 1107 || Current Learning Rate: 0.001 || Time: 00:35:52.75
Epoch ::  8 || Loss: 0.41619534 || it_count: 8344 || Val Loss: 0.45004266 || Val it_count: 1107 || Current Learning Rate: 0.001 || Time: 00:41:11.76
Epoch ::  9 || Loss: 0.41581792 || it_count: 8344 || Val Loss: 0.45144785 || Val it_count: 1107 || Current Learning Rate: 0.001 || Time: 00:46:29.83
Epoch :: 10 || Loss: 0.41526705 || it_count: 8344 || Val Loss: 0.45169897 || Val it_count: 1107 || Current Learning Rate: 0.001 || Time: 00:51:46.77
Epoch :: 11 || Loss: 0.41454661 || it_count: 8344 || Val Loss: 0.45106037 || Val it_count: 1107 || Current Learning Rate: 0.001 || Time: 00:56:43.23
Epoch :: 12 || Loss: 0.41370147 || it_count: 8344 || Val Loss: 0.44893247 || Val it_count: 1107 || Current Learning Rate: 0.001 || Time: 01:01:32.47
Epoch :: 13 || Loss: 0.41292860 || it_count: 8344 || Val Loss: 0.44978109 || Val it_count: 1107 || Current Learning Rate: 0.001 || Time: 01:06:28.72
Epoch :: 14 || Loss: 0.41214666 || it_count: 8344 || Val Loss: 0.44946402 || Val it_count: 1107 || Current Learning Rate: 0.001 || Time: 01:11:26.10
Epoch :: 15 || Loss: 0.41215350 || it_count: 8344 || Val Loss: 0.44787251 || Val it_count: 1107 || Current Learning Rate: 0.001 || Time: 01:16:22.07
Epoch :: 16 || Loss: 0.41187544 || it_count: 8344 || Val Loss: 0.44808990 || Val it_count: 1107 || Current Learning Rate: 0.001 || Time: 01:21:19.18
Epoch :: 17 || Loss: 0.41140813 || it_count: 8344 || Val Loss: 0.44808239 || Val it_count: 1107 || Current Learning Rate: 0.001 || Time: 01:26:15.43
Epoch :: 18 || Loss: 0.41099107 || it_count: 8344 || Val Loss: 0.44777744 || Val it_count: 1107 || Current Learning Rate: 0.001 || Time: 01:31:17.42
Epoch :: 19 || Loss: 0.41369420 || it_count: 8344 || Val Loss: 0.44726301 || Val it_count: 1107 || Current Learning Rate: 0.001 || Time: 01:36:14.93
Epoch :: 20 || Loss: 0.41134383 || it_count: 8344 || Val Loss: 0.44498600 || Val it_count: 1107 || Current Learning Rate: 0.001 || Time: 01:41:14.98
Epoch :: 21 || Loss: 0.41031135 || it_count: 8344 || Val Loss: 0.44746089 || Val it_count: 1107 || Current Learning Rate: 0.001 || Time: 01:46:16.00
Epoch :: 22 || Loss: 0.41031227 || it_count: 8344 || Val Loss: 0.44827318 || Val it_count: 1107 || Current Learning Rate: 0.001 || Time: 01:51:17.72
Epoch :: 23 || Loss: 0.41013080 || it_count: 8344 || Val Loss: 0.44828323 || Val it_count: 1107 || Current Learning Rate: 0.001 || Time: 01:57:33.68
Epoch :: 24 || Loss: 0.40999603 || it_count: 8344 || Val Loss: 0.45079662 || Val it_count: 1107 || Current Learning Rate: 0.001 || Time: 02:04:52.62
Epoch :: 25 || Loss: 0.40947543 || it_count: 8344 || Val Loss: 0.44881183 || Val it_count: 1107 || Current Learning Rate: 0.001 || Time: 02:12:15.97
Epoch 00010: reducing learning rate of group 0 to 1.0000e-04.
Epoch :: 26 || Loss: 0.40941656 || it_count: 8344 || Val Loss: 0.45152817 || Val it_count: 1107 || Current Learning Rate: 0.0001 || Time: 02:19:38.41
Epoch :: 27 || Loss: 0.41445521 || it_count: 8344 || Val Loss: 0.42117072 || Val it_count: 1107 || Current Learning Rate: 0.0001 || Time: 02:27:2.21
Epoch :: 28 || Loss: 0.41050785 || it_count: 8344 || Val Loss: 0.41979364 || Val it_count: 1107 || Current Learning Rate: 0.0001 || Time: 02:34:23.47
Epoch :: 29 || Loss: 0.40974132 || it_count: 8344 || Val Loss: 0.41941984 || Val it_count: 1107 || Current Learning Rate: 0.0001 || Time: 02:41:47.56
Epoch :: 30 || Loss: 0.40914003 || it_count: 8344 || Val Loss: 0.41888946 || Val it_count: 1107 || Current Learning Rate: 0.0001 || Time: 02:49:11.01
Epoch :: 31 || Loss: 0.40868800 || it_count: 8344 || Val Loss: 0.41850879 || Val it_count: 1107 || Current Learning Rate: 0.0001 || Time: 02:56:31.55
Epoch :: 32 || Loss: 0.40829301 || it_count: 8344 || Val Loss: 0.41821136 || Val it_count: 1107 || Current Learning Rate: 0.0001 || Time: 03:03:52.27
Epoch :: 33 || Loss: 0.40791826 || it_count: 8344 || Val Loss: 0.41795638 || Val it_count: 1107 || Current Learning Rate: 0.0001 || Time: 03:11:16.56
Epoch :: 34 || Loss: 0.40755637 || it_count: 8344 || Val Loss: 0.41776741 || Val it_count: 1107 || Current Learning Rate: 0.0001 || Time: 03:18:34.31
Epoch :: 35 || Loss: 0.40725515 || it_count: 8344 || Val Loss: 0.41764055 || Val it_count: 1107 || Current Learning Rate: 0.0001 || Time: 03:25:55.35
Epoch :: 36 || Loss: 0.40694984 || it_count: 8344 || Val Loss: 0.41742783 || Val it_count: 1107 || Current Learning Rate: 0.0001 || Time: 03:33:20.11
Epoch :: 37 || Loss: 0.40669593 || it_count: 8344 || Val Loss: 0.41724591 || Val it_count: 1107 || Current Learning Rate: 0.0001 || Time: 03:40:31.11
Epoch :: 38 || Loss: 0.40644908 || it_count: 8344 || Val Loss: 0.41714715 || Val it_count: 1107 || Current Learning Rate: 0.0001 || Time: 03:47:55.43
Epoch :: 39 || Loss: 0.40622826 || it_count: 8344 || Val Loss: 0.41694706 || Val it_count: 1107 || Current Learning Rate: 0.0001 || Time: 03:55:18.62
Epoch :: 40 || Loss: 0.40601636 || it_count: 8344 || Val Loss: 0.41694628 || Val it_count: 1107 || Current Learning Rate: 0.0001 || Time: 04:02:28.41
Epoch :: 41 || Loss: 0.40581440 || it_count: 8344 || Val Loss: 0.41689162 || Val it_count: 1107 || Current Learning Rate: 0.0001 || Time: 04:09:50.25
Epoch :: 42 || Loss: 0.40562810 || it_count: 8344 || Val Loss: 0.41691548 || Val it_count: 1107 || Current Learning Rate: 0.0001 || Time: 04:17:10.21
Epoch :: 43 || Loss: 0.40548706 || it_count: 8344 || Val Loss: 0.41687003 || Val it_count: 1107 || Current Learning Rate: 0.0001 || Time: 04:24:27.38
Epoch :: 44 || Loss: 0.40523755 || it_count: 8344 || Val Loss: 0.41708742 || Val it_count: 1107 || Current Learning Rate: 0.0001 || Time: 04:31:50.16
Epoch :: 45 || Loss: 0.40509596 || it_count: 8344 || Val Loss: 0.41705075 || Val it_count: 1107 || Current Learning Rate: 0.0001 || Time: 04:39:12.78
Epoch :: 46 || Loss: 0.40489148 || it_count: 8344 || Val Loss: 0.41707607 || Val it_count: 1107 || Current Learning Rate: 0.0001 || Time: 04:46:36.89
Epoch 00031: reducing learning rate of group 0 to 1.0000e-05.
Epoch :: 47 || Loss: 0.40470202 || it_count: 8344 || Val Loss: 0.41716181 || Val it_count: 1107 || Current Learning Rate: 1e-05 || Time: 04:53:52.84
Epoch :: 48 || Loss: 0.40749761 || it_count: 8344 || Val Loss: 0.41143008 || Val it_count: 1107 || Current Learning Rate: 1e-05 || Time: 05:01:15.28
Epoch :: 49 || Loss: 0.40642913 || it_count: 8344 || Val Loss: 0.41100740 || Val it_count: 1107 || Current Learning Rate: 1e-05 || Time: 05:08:38.80
Epoch :: 50 || Loss: 0.40617312 || it_count: 8344 || Val Loss: 0.41086855 || Val it_count: 1107 || Current Learning Rate: 1e-05 || Time: 05:15:45.17
Epoch :: 51 || Loss: 0.40605461 || it_count: 8344 || Val Loss: 0.41079733 || Val it_count: 1107 || Current Learning Rate: 1e-05 || Time: 05:23:6.90
Epoch :: 52 || Loss: 0.40597322 || it_count: 8344 || Val Loss: 0.41077344 || Val it_count: 1107 || Current Learning Rate: 1e-05 || Time: 05:30:28.99
Epoch :: 53 || Loss: 0.40590621 || it_count: 8344 || Val Loss: 0.41075743 || Val it_count: 1107 || Current Learning Rate: 1e-05 || Time: 05:37:54.13
Epoch :: 54 || Loss: 0.40584396 || it_count: 8344 || Val Loss: 0.41074742 || Val it_count: 1107 || Current Learning Rate: 1e-05 || Time: 05:45:17.59
Epoch :: 55 || Loss: 0.40579091 || it_count: 8344 || Val Loss: 0.41073416 || Val it_count: 1107 || Current Learning Rate: 1e-05 || Time: 05:52:41.11
Epoch :: 56 || Loss: 0.40574266 || it_count: 8344 || Val Loss: 0.41072339 || Val it_count: 1107 || Current Learning Rate: 1e-05 || Time: 06:00:3.83
Epoch :: 57 || Loss: 0.40569684 || it_count: 8344 || Val Loss: 0.41070870 || Val it_count: 1107 || Current Learning Rate: 1e-05 || Time: 06:07:15.04
Epoch :: 58 || Loss: 0.40565217 || it_count: 8344 || Val Loss: 0.41069626 || Val it_count: 1107 || Current Learning Rate: 1e-05 || Time: 06:14:40.58
Epoch :: 59 || Loss: 0.40561277 || it_count: 8344 || Val Loss: 0.41068307 || Val it_count: 1107 || Current Learning Rate: 1e-05 || Time: 06:22:4.07
Epoch :: 60 || Loss: 0.40557251 || it_count: 8344 || Val Loss: 0.41067329 || Val it_count: 1107 || Current Learning Rate: 1e-05 || Time: 06:29:13.82
Epoch :: 61 || Loss: 0.40553375 || it_count: 8344 || Val Loss: 0.41066403 || Val it_count: 1107 || Current Learning Rate: 1e-05 || Time: 06:36:37.64
Epoch :: 62 || Loss: 0.40549588 || it_count: 8344 || Val Loss: 0.41065822 || Val it_count: 1107 || Current Learning Rate: 1e-05 || Time: 06:43:59.80
Epoch :: 63 || Loss: 0.40545928 || it_count: 8344 || Val Loss: 0.41064777 || Val it_count: 1107 || Current Learning Rate: 1e-05 || Time: 06:51:24.59
Epoch :: 64 || Loss: 0.40542250 || it_count: 8344 || Val Loss: 0.41064443 || Val it_count: 1107 || Current Learning Rate: 1e-05 || Time: 06:58:49.16
Epoch :: 65 || Loss: 0.40538862 || it_count: 8344 || Val Loss: 0.41063761 || Val it_count: 1107 || Current Learning Rate: 1e-05 || Time: 07:06:14.14
Epoch :: 66 || Loss: 0.40535444 || it_count: 8344 || Val Loss: 0.41063352 || Val it_count: 1107 || Current Learning Rate: 1e-05 || Time: 07:13:38.98
Epoch :: 67 || Loss: 0.40532246 || it_count: 8344 || Val Loss: 0.41063133 || Val it_count: 1107 || Current Learning Rate: 1e-05 || Time: 07:20:52.17
Epoch :: 68 || Loss: 0.40528780 || it_count: 8344 || Val Loss: 0.41062668 || Val it_count: 1107 || Current Learning Rate: 1e-05 || Time: 07:28:18.23
Epoch 00053: reducing learning rate of group 0 to 1.0000e-06.
Epoch :: 69 || Loss: 0.40525512 || it_count: 8344 || Val Loss: 0.41062368 || Val it_count: 1107 || Current Learning Rate: 1.0000000000000002e-06 || Time: 07:35:40.60
Epoch :: 70 || Loss: 0.40561729 || it_count: 8344 || Val Loss: 0.41047128 || Val it_count: 1107 || Current Learning Rate: 1.0000000000000002e-06 || Time: 07:42:50.54
Epoch :: 71 || Loss: 0.40553444 || it_count: 8344 || Val Loss: 0.41041438 || Val it_count: 1107 || Current Learning Rate: 1.0000000000000002e-06 || Time: 07:50:15.17
Epoch :: 72 || Loss: 0.40549639 || it_count: 8344 || Val Loss: 0.41037931 || Val it_count: 1107 || Current Learning Rate: 1.0000000000000002e-06 || Time: 07:57:37.64
Epoch :: 73 || Loss: 0.40547297 || it_count: 8344 || Val Loss: 0.41035891 || Val it_count: 1107 || Current Learning Rate: 1.0000000000000002e-06 || Time: 08:05:3.04
Epoch :: 74 || Loss: 0.40545707 || it_count: 8344 || Val Loss: 0.41034634 || Val it_count: 1107 || Current Learning Rate: 1.0000000000000002e-06 || Time: 08:12:27.19
Epoch :: 75 || Loss: 0.40544549 || it_count: 8344 || Val Loss: 0.41033836 || Val it_count: 1107 || Current Learning Rate: 1.0000000000000002e-06 || Time: 08:19:50.47
Epoch :: 76 || Loss: 0.40543621 || it_count: 8344 || Val Loss: 0.41033233 || Val it_count: 1107 || Current Learning Rate: 1.0000000000000002e-06 || Time: 08:27:14.20
Epoch :: 77 || Loss: 0.40542787 || it_count: 8344 || Val Loss: 0.41032876 || Val it_count: 1107 || Current Learning Rate: 1.0000000000000002e-06 || Time: 08:34:28.08
Epoch :: 78 || Loss: 0.40542136 || it_count: 8344 || Val Loss: 0.41032512 || Val it_count: 1107 || Current Learning Rate: 1.0000000000000002e-06 || Time: 08:41:53.31
Epoch 00063: reducing learning rate of group 0 to 1.0000e-07.
Early stopping triggered due to learning rate below threshold.
Done Total time: 08:49:17.38
best_loss: 0.4103251212428578

--------------------Testing--------------------

total_samples :: test_dataset = 139200, test_dataloader = 139200
Epoch ::  1 || Loss: 0.23545396 || it_count: 544 || Time: 00:00:17.03
MAE:  0.25217253
MSE:  0.2354751
RMSE:  0.44110715

--------------------Training--------------------
arch_str :: |none~0|+|lstm_2~0|none~1|[relu->linear]
model :: 3C
InferCell(
  info :: nodes=3, inC=1, outC=64, [1<-(I0-L0) | 2<-(I0-L1,I1-L2)], genotype_str: none~0|lstm_2~0|none~1
  linear_layers: [relu->linear]
  (layers): ModuleList(
    (0): Zero(C_in=1, C_out=64, stride=1)
    (1): LSTM(
      (lstm): LSTM(1, 64, num_layers=2, batch_first=True)
    )
    (2): Zero(C_in=64, C_out=64, stride=1)
  )
  (linear_layers): ModuleList(
    (0): ReLU()
    (1): Linear(in_features=3072, out_features=1, bias=True)
  )
)
tr_params :: epochs = 100, patience = 20, batch_size = 256, window_size = 48, data_size = 100
Model MACs: 2.473M, Model Params: 53.505K
learning rate scheduling :: (optimizer, mode='min', factor=0.1, patience=5, verbose=True)
total_samples :: train_dataset = 2136000, train_dataloader = 2136000
total_samples :: valid_dataset = 283200, valid_dataloader = 283200
Epoch ::  1 || Loss: 0.42235258 || it_count: 8344 || Val Loss: 0.44790406 || Val it_count: 1107 || Current Learning Rate: 0.001 || Time: 00:03:39.29
Epoch ::  2 || Loss: 0.41820071 || it_count: 8344 || Val Loss: 0.44826941 || Val it_count: 1107 || Current Learning Rate: 0.001 || Time: 00:07:15.23
Epoch ::  3 || Loss: 0.41756156 || it_count: 8344 || Val Loss: 0.44707653 || Val it_count: 1107 || Current Learning Rate: 0.001 || Time: 00:10:52.80
Epoch ::  4 || Loss: 0.41739398 || it_count: 8344 || Val Loss: 0.44811964 || Val it_count: 1107 || Current Learning Rate: 0.001 || Time: 00:14:29.73
Epoch ::  5 || Loss: 0.41670653 || it_count: 8344 || Val Loss: 0.44897904 || Val it_count: 1107 || Current Learning Rate: 0.001 || Time: 00:18:5.12
Epoch ::  6 || Loss: 0.41693189 || it_count: 8344 || Val Loss: 0.44923530 || Val it_count: 1107 || Current Learning Rate: 0.001 || Time: 00:21:41.78
Epoch ::  7 || Loss: 0.41625339 || it_count: 8344 || Val Loss: 0.44939099 || Val it_count: 1107 || Current Learning Rate: 0.001 || Time: 00:25:19.34
Epoch ::  8 || Loss: 0.41613297 || it_count: 8344 || Val Loss: 0.45013687 || Val it_count: 1107 || Current Learning Rate: 0.001 || Time: 00:28:56.26
Epoch ::  9 || Loss: 0.41590958 || it_count: 8344 || Val Loss: 0.45043539 || Val it_count: 1107 || Current Learning Rate: 0.001 || Time: 00:32:33.15
Epoch :: 10 || Loss: 0.41577757 || it_count: 8344 || Val Loss: 0.45051313 || Val it_count: 1107 || Current Learning Rate: 0.001 || Time: 00:36:10.34
Epoch :: 11 || Loss: 0.41519809 || it_count: 8344 || Val Loss: 0.45093822 || Val it_count: 1107 || Current Learning Rate: 0.001 || Time: 00:39:47.87
Epoch :: 12 || Loss: 0.41496785 || it_count: 8344 || Val Loss: 0.45047581 || Val it_count: 1107 || Current Learning Rate: 0.001 || Time: 00:43:25.27
Epoch :: 13 || Loss: 0.41471353 || it_count: 8344 || Val Loss: 0.45007776 || Val it_count: 1107 || Current Learning Rate: 0.001 || Time: 00:47:7.79
Epoch :: 14 || Loss: 0.41468593 || it_count: 8344 || Val Loss: 0.44996169 || Val it_count: 1107 || Current Learning Rate: 0.001 || Time: 00:50:45.35
Epoch :: 15 || Loss: 0.41443863 || it_count: 8344 || Val Loss: 0.44828313 || Val it_count: 1107 || Current Learning Rate: 0.001 || Time: 00:54:19.75
Epoch :: 16 || Loss: 0.41415311 || it_count: 8344 || Val Loss: 0.44874225 || Val it_count: 1107 || Current Learning Rate: 0.001 || Time: 00:57:56.88
Epoch :: 17 || Loss: 0.41396873 || it_count: 8344 || Val Loss: 0.44875944 || Val it_count: 1107 || Current Learning Rate: 0.001 || Time: 01:01:36.62
Epoch :: 18 || Loss: 0.41377113 || it_count: 8344 || Val Loss: 0.44839712 || Val it_count: 1107 || Current Learning Rate: 0.001 || Time: 01:05:14.99
Epoch :: 19 || Loss: 0.41357401 || it_count: 8344 || Val Loss: 0.44736622 || Val it_count: 1107 || Current Learning Rate: 0.001 || Time: 01:08:49.76
Epoch :: 20 || Loss: 0.41330738 || it_count: 8344 || Val Loss: 0.44718942 || Val it_count: 1107 || Current Learning Rate: 0.001 || Time: 01:12:25.49
Epoch :: 21 || Loss: 0.41284312 || it_count: 8344 || Val Loss: 0.44616338 || Val it_count: 1107 || Current Learning Rate: 0.001 || Time: 01:16:2.98
Epoch :: 22 || Loss: 0.41323952 || it_count: 8344 || Val Loss: 0.44702023 || Val it_count: 1107 || Current Learning Rate: 0.001 || Time: 01:19:39.55
Epoch :: 23 || Loss: 0.41328787 || it_count: 8344 || Val Loss: 0.44836710 || Val it_count: 1107 || Current Learning Rate: 0.001 || Time: 01:23:16.84
Epoch :: 24 || Loss: 0.41249308 || it_count: 8344 || Val Loss: 0.44741752 || Val it_count: 1107 || Current Learning Rate: 0.001 || Time: 01:26:53.48
Epoch :: 25 || Loss: 0.41254187 || it_count: 8344 || Val Loss: 0.44747764 || Val it_count: 1107 || Current Learning Rate: 0.001 || Time: 01:30:30.52
Epoch :: 26 || Loss: 0.41174847 || it_count: 8344 || Val Loss: 0.44672150 || Val it_count: 1107 || Current Learning Rate: 0.001 || Time: 01:34:7.71
Epoch :: 27 || Loss: 0.41111516 || it_count: 8344 || Val Loss: 0.44346538 || Val it_count: 1107 || Current Learning Rate: 0.001 || Time: 01:37:44.71
Epoch :: 28 || Loss: 0.41109907 || it_count: 8344 || Val Loss: 0.44492161 || Val it_count: 1107 || Current Learning Rate: 0.001 || Time: 01:41:21.72
Epoch :: 29 || Loss: 0.41046239 || it_count: 8344 || Val Loss: 0.44670352 || Val it_count: 1107 || Current Learning Rate: 0.001 || Time: 01:44:59.71
Epoch :: 30 || Loss: 0.41000039 || it_count: 8344 || Val Loss: 0.44680168 || Val it_count: 1107 || Current Learning Rate: 0.001 || Time: 01:48:36.90
Epoch :: 31 || Loss: 0.40961206 || it_count: 8344 || Val Loss: 0.44598742 || Val it_count: 1107 || Current Learning Rate: 0.001 || Time: 01:52:14.12
Epoch :: 32 || Loss: 0.40920192 || it_count: 8344 || Val Loss: 0.44555582 || Val it_count: 1107 || Current Learning Rate: 0.001 || Time: 01:55:49.15
Epoch 00017: reducing learning rate of group 0 to 1.0000e-04.
Epoch :: 33 || Loss: 0.40912756 || it_count: 8344 || Val Loss: 0.44430043 || Val it_count: 1107 || Current Learning Rate: 0.0001 || Time: 01:59:22.92
Epoch :: 34 || Loss: 0.41347269 || it_count: 8344 || Val Loss: 0.41924597 || Val it_count: 1107 || Current Learning Rate: 0.0001 || Time: 02:03:0.77
Epoch :: 35 || Loss: 0.41021119 || it_count: 8344 || Val Loss: 0.41912419 || Val it_count: 1107 || Current Learning Rate: 0.0001 || Time: 02:06:38.45
Epoch :: 36 || Loss: 0.40943691 || it_count: 8344 || Val Loss: 0.41886758 || Val it_count: 1107 || Current Learning Rate: 0.0001 || Time: 02:10:16.48
Epoch :: 37 || Loss: 0.40904798 || it_count: 8344 || Val Loss: 0.41850721 || Val it_count: 1107 || Current Learning Rate: 0.0001 || Time: 02:13:54.28
Epoch :: 38 || Loss: 0.40876569 || it_count: 8344 || Val Loss: 0.41824697 || Val it_count: 1107 || Current Learning Rate: 0.0001 || Time: 02:17:31.48
Epoch :: 39 || Loss: 0.40853587 || it_count: 8344 || Val Loss: 0.41811098 || Val it_count: 1107 || Current Learning Rate: 0.0001 || Time: 02:21:8.49
Epoch :: 40 || Loss: 0.40831811 || it_count: 8344 || Val Loss: 0.41795871 || Val it_count: 1107 || Current Learning Rate: 0.0001 || Time: 02:24:45.46
Epoch :: 41 || Loss: 0.40812786 || it_count: 8344 || Val Loss: 0.41786391 || Val it_count: 1107 || Current Learning Rate: 0.0001 || Time: 02:28:22.95
Epoch :: 42 || Loss: 0.40793496 || it_count: 8344 || Val Loss: 0.41776570 || Val it_count: 1107 || Current Learning Rate: 0.0001 || Time: 02:31:59.71
Epoch :: 43 || Loss: 0.40774664 || it_count: 8344 || Val Loss: 0.41769179 || Val it_count: 1107 || Current Learning Rate: 0.0001 || Time: 02:35:36.50
Epoch :: 44 || Loss: 0.40759130 || it_count: 8344 || Val Loss: 0.41763661 || Val it_count: 1107 || Current Learning Rate: 0.0001 || Time: 02:39:12.06
Epoch :: 45 || Loss: 0.40742436 || it_count: 8344 || Val Loss: 0.41778386 || Val it_count: 1107 || Current Learning Rate: 0.0001 || Time: 02:42:49.70
Epoch :: 46 || Loss: 0.40731546 || it_count: 8344 || Val Loss: 0.41783703 || Val it_count: 1107 || Current Learning Rate: 0.0001 || Time: 02:46:27.32
Epoch :: 47 || Loss: 0.40717379 || it_count: 8344 || Val Loss: 0.41795800 || Val it_count: 1107 || Current Learning Rate: 0.0001 || Time: 02:50:5.31
Epoch :: 48 || Loss: 0.40700422 || it_count: 8344 || Val Loss: 0.41807441 || Val it_count: 1107 || Current Learning Rate: 0.0001 || Time: 02:53:41.99
Epoch :: 49 || Loss: 0.40686811 || it_count: 8344 || Val Loss: 0.41812319 || Val it_count: 1107 || Current Learning Rate: 0.0001 || Time: 02:57:20.41
Epoch 00034: reducing learning rate of group 0 to 1.0000e-05.
Epoch :: 50 || Loss: 0.40665907 || it_count: 8344 || Val Loss: 0.41811476 || Val it_count: 1107 || Current Learning Rate: 1e-05 || Time: 03:00:58.22
Epoch :: 51 || Loss: 0.40857801 || it_count: 8344 || Val Loss: 0.41255481 || Val it_count: 1107 || Current Learning Rate: 1e-05 || Time: 03:04:33.48
Epoch :: 52 || Loss: 0.40749260 || it_count: 8344 || Val Loss: 0.41236061 || Val it_count: 1107 || Current Learning Rate: 1e-05 || Time: 03:08:11.10
Epoch :: 53 || Loss: 0.40733114 || it_count: 8344 || Val Loss: 0.41229527 || Val it_count: 1107 || Current Learning Rate: 1e-05 || Time: 03:11:48.21
Epoch :: 54 || Loss: 0.40724916 || it_count: 8344 || Val Loss: 0.41223696 || Val it_count: 1107 || Current Learning Rate: 1e-05 || Time: 03:15:26.43
Epoch :: 55 || Loss: 0.40719176 || it_count: 8344 || Val Loss: 0.41219267 || Val it_count: 1107 || Current Learning Rate: 1e-05 || Time: 03:19:4.25
Epoch :: 56 || Loss: 0.40714750 || it_count: 8344 || Val Loss: 0.41214716 || Val it_count: 1107 || Current Learning Rate: 1e-05 || Time: 03:22:41.37
Epoch :: 57 || Loss: 0.40710549 || it_count: 8344 || Val Loss: 0.41211579 || Val it_count: 1107 || Current Learning Rate: 1e-05 || Time: 03:26:17.48
Epoch :: 58 || Loss: 0.40706934 || it_count: 8344 || Val Loss: 0.41209049 || Val it_count: 1107 || Current Learning Rate: 1e-05 || Time: 03:29:56.26
Epoch :: 59 || Loss: 0.40703594 || it_count: 8344 || Val Loss: 0.41207042 || Val it_count: 1107 || Current Learning Rate: 1e-05 || Time: 03:33:34.08
Epoch :: 60 || Loss: 0.40700599 || it_count: 8344 || Val Loss: 0.41204311 || Val it_count: 1107 || Current Learning Rate: 1e-05 || Time: 03:37:11.59
Epoch :: 61 || Loss: 0.40697729 || it_count: 8344 || Val Loss: 0.41202513 || Val it_count: 1107 || Current Learning Rate: 1e-05 || Time: 03:40:49.82
Epoch :: 62 || Loss: 0.40695075 || it_count: 8344 || Val Loss: 0.41201430 || Val it_count: 1107 || Current Learning Rate: 1e-05 || Time: 03:44:27.00
Epoch :: 63 || Loss: 0.40692471 || it_count: 8344 || Val Loss: 0.41200404 || Val it_count: 1107 || Current Learning Rate: 1e-05 || Time: 03:48:4.89
Epoch :: 64 || Loss: 0.40689901 || it_count: 8344 || Val Loss: 0.41198817 || Val it_count: 1107 || Current Learning Rate: 1e-05 || Time: 03:51:41.83
Epoch :: 65 || Loss: 0.40687509 || it_count: 8344 || Val Loss: 0.41197646 || Val it_count: 1107 || Current Learning Rate: 1e-05 || Time: 03:55:20.04
Epoch :: 66 || Loss: 0.40685158 || it_count: 8344 || Val Loss: 0.41196724 || Val it_count: 1107 || Current Learning Rate: 1e-05 || Time: 03:58:57.75
Epoch :: 67 || Loss: 0.40682885 || it_count: 8344 || Val Loss: 0.41195857 || Val it_count: 1107 || Current Learning Rate: 1e-05 || Time: 04:02:34.67
Epoch :: 68 || Loss: 0.40680584 || it_count: 8344 || Val Loss: 0.41195677 || Val it_count: 1107 || Current Learning Rate: 1e-05 || Time: 04:06:11.28
Epoch :: 69 || Loss: 0.40678442 || it_count: 8344 || Val Loss: 0.41195598 || Val it_count: 1107 || Current Learning Rate: 1e-05 || Time: 04:09:49.26
Epoch :: 70 || Loss: 0.40676310 || it_count: 8344 || Val Loss: 0.41194577 || Val it_count: 1107 || Current Learning Rate: 1e-05 || Time: 04:13:29.12
Epoch :: 71 || Loss: 0.40674214 || it_count: 8344 || Val Loss: 0.41194696 || Val it_count: 1107 || Current Learning Rate: 1e-05 || Time: 04:17:6.76
Epoch :: 72 || Loss: 0.40672232 || it_count: 8344 || Val Loss: 0.41193890 || Val it_count: 1107 || Current Learning Rate: 1e-05 || Time: 04:20:45.31
Epoch :: 73 || Loss: 0.40670258 || it_count: 8344 || Val Loss: 0.41194150 || Val it_count: 1107 || Current Learning Rate: 1e-05 || Time: 04:24:23.91
Epoch :: 74 || Loss: 0.40668187 || it_count: 8344 || Val Loss: 0.41193687 || Val it_count: 1107 || Current Learning Rate: 1e-05 || Time: 04:28:1.54
Epoch :: 75 || Loss: 0.40666198 || it_count: 8344 || Val Loss: 0.41193396 || Val it_count: 1107 || Current Learning Rate: 1e-05 || Time: 04:31:39.27
Epoch 00060: reducing learning rate of group 0 to 1.0000e-06.
Epoch :: 76 || Loss: 0.40664332 || it_count: 8344 || Val Loss: 0.41193035 || Val it_count: 1107 || Current Learning Rate: 1.0000000000000002e-06 || Time: 04:35:17.82
Epoch :: 77 || Loss: 0.40686795 || it_count: 8344 || Val Loss: 0.41163093 || Val it_count: 1107 || Current Learning Rate: 1.0000000000000002e-06 || Time: 04:38:56.47
Epoch :: 78 || Loss: 0.40676888 || it_count: 8344 || Val Loss: 0.41155903 || Val it_count: 1107 || Current Learning Rate: 1.0000000000000002e-06 || Time: 04:42:34.92
Epoch :: 79 || Loss: 0.40673295 || it_count: 8344 || Val Loss: 0.41152895 || Val it_count: 1107 || Current Learning Rate: 1.0000000000000002e-06 || Time: 04:46:12.17
Epoch :: 80 || Loss: 0.40671501 || it_count: 8344 || Val Loss: 0.41151464 || Val it_count: 1107 || Current Learning Rate: 1.0000000000000002e-06 || Time: 04:49:48.90
Epoch :: 81 || Loss: 0.40670335 || it_count: 8344 || Val Loss: 0.41150466 || Val it_count: 1107 || Current Learning Rate: 1.0000000000000002e-06 || Time: 04:53:25.55
Epoch :: 82 || Loss: 0.40669496 || it_count: 8344 || Val Loss: 0.41149715 || Val it_count: 1107 || Current Learning Rate: 1.0000000000000002e-06 || Time: 04:57:3.68
Epoch :: 83 || Loss: 0.40668854 || it_count: 8344 || Val Loss: 0.41149090 || Val it_count: 1107 || Current Learning Rate: 1.0000000000000002e-06 || Time: 05:00:41.04
Epoch :: 84 || Loss: 0.40668331 || it_count: 8344 || Val Loss: 0.41148590 || Val it_count: 1107 || Current Learning Rate: 1.0000000000000002e-06 || Time: 05:04:18.31
Epoch :: 85 || Loss: 0.40667877 || it_count: 8344 || Val Loss: 0.41148106 || Val it_count: 1107 || Current Learning Rate: 1.0000000000000002e-06 || Time: 05:07:52.99
Epoch 00070: reducing learning rate of group 0 to 1.0000e-07.
Early stopping triggered due to learning rate below threshold.
Done Total time: 05:11:27.54
best_loss: 0.411481058372504

--------------------Testing--------------------

total_samples :: test_dataset = 139200, test_dataloader = 139200
Epoch ::  1 || Loss: 0.23591527 || it_count: 544 || Time: 00:00:11.73
MAE:  0.2523822
MSE:  0.23592941
RMSE:  0.44122684

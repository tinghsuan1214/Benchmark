--------------------Training--------------------
arch_str :: |skip_connect~0|+|lstm_2~0|none~1|[relu->linear]
model :: 3C
InferCell(
  info :: nodes=3, inC=1, outC=64, [1<-(I0-L0) | 2<-(I0-L1,I1-L2)], genotype_str: skip_connect~0|lstm_2~0|none~1
  linear_layers: [relu->linear]
  (layers): ModuleList(
    (0): FactorizedReduce(
      C_in=1, C_out=64, stride=1
      (relu): ReLU()
      (conv): Conv1d(1, 64, kernel_size=(1,), stride=(1,), bias=False)
      (bn): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (1): LSTM(
      (lstm): LSTM(1, 64, num_layers=2, batch_first=True)
    )
    (2): Zero(C_in=64, C_out=64, stride=1)
  )
  (linear_layers): ModuleList(
    (0): ReLU()
    (1): Linear(in_features=3072, out_features=1, bias=True)
  )
)
tr_params :: epochs = 100, patience = 20, batch_size = 256, window_size = 48, data_size = 100
Model FLOPs: 2.488M, Model Params: 53.697K
learning rate scheduling :: (optimizer, mode='min', factor=0.1, patience=5, verbose=True)
total_samples :: train_dataset = 2136000, train_dataloader = 2136000
total_samples :: valid_dataset = 283200, valid_dataloader = 283200
Epoch ::  1 || Loss: 0.42151627 || it_count: 8344 || Val Loss: 0.44834591 || Val it_count: 1107 || Current Learning Rate: 0.001 || Time: 00:04:16.78
Epoch ::  2 || Loss: 0.41782516 || it_count: 8344 || Val Loss: 0.44846166 || Val it_count: 1107 || Current Learning Rate: 0.001 || Time: 00:08:29.00
Epoch ::  3 || Loss: 0.41741540 || it_count: 8344 || Val Loss: 0.44800360 || Val it_count: 1107 || Current Learning Rate: 0.001 || Time: 00:12:40.94
Epoch ::  4 || Loss: 0.41718043 || it_count: 8344 || Val Loss: 0.44747004 || Val it_count: 1107 || Current Learning Rate: 0.001 || Time: 00:16:51.84
Epoch ::  5 || Loss: 0.41679019 || it_count: 8344 || Val Loss: 0.44826208 || Val it_count: 1107 || Current Learning Rate: 0.001 || Time: 00:21:4.13
Epoch ::  6 || Loss: 0.41637897 || it_count: 8344 || Val Loss: 0.44771461 || Val it_count: 1107 || Current Learning Rate: 0.001 || Time: 00:25:16.10
Epoch ::  7 || Loss: 0.41643450 || it_count: 8344 || Val Loss: 0.44976811 || Val it_count: 1107 || Current Learning Rate: 0.001 || Time: 00:29:27.90
Epoch ::  8 || Loss: 0.41627674 || it_count: 8344 || Val Loss: 0.44986218 || Val it_count: 1107 || Current Learning Rate: 0.001 || Time: 00:33:40.54
Epoch ::  9 || Loss: 0.41569118 || it_count: 8344 || Val Loss: 0.44939374 || Val it_count: 1107 || Current Learning Rate: 0.001 || Time: 00:37:53.00
Epoch :: 10 || Loss: 0.41608338 || it_count: 8344 || Val Loss: 0.44886502 || Val it_count: 1107 || Current Learning Rate: 0.001 || Time: 00:42:5.33
Epoch :: 11 || Loss: 0.41574481 || it_count: 8344 || Val Loss: 0.44981588 || Val it_count: 1107 || Current Learning Rate: 0.001 || Time: 00:46:18.11
Epoch :: 12 || Loss: 0.41556793 || it_count: 8344 || Val Loss: 0.44900931 || Val it_count: 1107 || Current Learning Rate: 0.001 || Time: 00:50:29.94
Epoch :: 13 || Loss: 0.41532050 || it_count: 8344 || Val Loss: 0.45017641 || Val it_count: 1107 || Current Learning Rate: 0.001 || Time: 00:54:41.25
Epoch :: 14 || Loss: 0.41526248 || it_count: 8344 || Val Loss: 0.44760045 || Val it_count: 1107 || Current Learning Rate: 0.001 || Time: 00:58:52.40
Epoch :: 15 || Loss: 0.41459194 || it_count: 8344 || Val Loss: 0.44853325 || Val it_count: 1107 || Current Learning Rate: 0.001 || Time: 01:03:4.11
Epoch :: 16 || Loss: 0.41439605 || it_count: 8344 || Val Loss: 0.44656635 || Val it_count: 1107 || Current Learning Rate: 0.001 || Time: 01:07:15.34
Epoch :: 17 || Loss: 0.41410814 || it_count: 8344 || Val Loss: 0.44624529 || Val it_count: 1107 || Current Learning Rate: 0.001 || Time: 01:11:27.38
Epoch :: 18 || Loss: 0.41404072 || it_count: 8344 || Val Loss: 0.44573862 || Val it_count: 1107 || Current Learning Rate: 0.001 || Time: 01:15:38.36
Epoch :: 19 || Loss: 0.41373100 || it_count: 8344 || Val Loss: 0.44677089 || Val it_count: 1107 || Current Learning Rate: 0.001 || Time: 01:19:49.32
Epoch :: 20 || Loss: 0.41342576 || it_count: 8344 || Val Loss: 0.44692842 || Val it_count: 1107 || Current Learning Rate: 0.001 || Time: 01:24:1.03
Epoch :: 21 || Loss: 0.41313291 || it_count: 8344 || Val Loss: 0.44507658 || Val it_count: 1107 || Current Learning Rate: 0.001 || Time: 01:28:12.83
Epoch :: 22 || Loss: 0.41268210 || it_count: 8344 || Val Loss: 0.44419628 || Val it_count: 1107 || Current Learning Rate: 0.001 || Time: 01:32:25.02
Epoch :: 23 || Loss: 0.41245422 || it_count: 8344 || Val Loss: 0.44249617 || Val it_count: 1107 || Current Learning Rate: 0.001 || Time: 01:36:37.07
Epoch :: 24 || Loss: 0.41204288 || it_count: 8344 || Val Loss: 0.44449279 || Val it_count: 1107 || Current Learning Rate: 0.001 || Time: 01:40:49.53
Epoch :: 25 || Loss: 0.41174801 || it_count: 8344 || Val Loss: 0.44285168 || Val it_count: 1107 || Current Learning Rate: 0.001 || Time: 01:45:1.04
Epoch :: 26 || Loss: 0.41102899 || it_count: 8344 || Val Loss: 0.44362704 || Val it_count: 1107 || Current Learning Rate: 0.001 || Time: 01:49:13.80
Epoch :: 27 || Loss: 0.41065751 || it_count: 8344 || Val Loss: 0.44194246 || Val it_count: 1107 || Current Learning Rate: 0.001 || Time: 01:53:26.20
Epoch :: 28 || Loss: 0.41010686 || it_count: 8344 || Val Loss: 0.44270199 || Val it_count: 1107 || Current Learning Rate: 0.001 || Time: 01:57:36.35
Epoch :: 29 || Loss: 0.40980083 || it_count: 8344 || Val Loss: 0.44313709 || Val it_count: 1107 || Current Learning Rate: 0.001 || Time: 02:01:46.48
Epoch :: 30 || Loss: 0.40940714 || it_count: 8344 || Val Loss: 0.44276009 || Val it_count: 1107 || Current Learning Rate: 0.001 || Time: 02:05:56.64
Epoch :: 31 || Loss: 0.40914328 || it_count: 8344 || Val Loss: 0.44413935 || Val it_count: 1107 || Current Learning Rate: 0.001 || Time: 02:10:7.14
Epoch :: 32 || Loss: 0.40902101 || it_count: 8344 || Val Loss: 0.44206504 || Val it_count: 1107 || Current Learning Rate: 0.001 || Time: 02:14:18.55
Epoch 00017: reducing learning rate of group 0 to 1.0000e-04.
Epoch :: 33 || Loss: 0.40883507 || it_count: 8344 || Val Loss: 0.44489910 || Val it_count: 1107 || Current Learning Rate: 0.0001 || Time: 02:18:30.00
Epoch :: 34 || Loss: 0.41372682 || it_count: 8344 || Val Loss: 0.41740038 || Val it_count: 1107 || Current Learning Rate: 0.0001 || Time: 02:22:40.58
Epoch :: 35 || Loss: 0.40961271 || it_count: 8344 || Val Loss: 0.41719712 || Val it_count: 1107 || Current Learning Rate: 0.0001 || Time: 02:26:50.44
Epoch :: 36 || Loss: 0.40900093 || it_count: 8344 || Val Loss: 0.41711952 || Val it_count: 1107 || Current Learning Rate: 0.0001 || Time: 02:31:0.86
Epoch :: 37 || Loss: 0.40857573 || it_count: 8344 || Val Loss: 0.41706702 || Val it_count: 1107 || Current Learning Rate: 0.0001 || Time: 02:35:11.43
Epoch :: 38 || Loss: 0.40822819 || it_count: 8344 || Val Loss: 0.41707061 || Val it_count: 1107 || Current Learning Rate: 0.0001 || Time: 02:39:22.84
Epoch :: 39 || Loss: 0.40793486 || it_count: 8344 || Val Loss: 0.41701210 || Val it_count: 1107 || Current Learning Rate: 0.0001 || Time: 02:43:32.80
Epoch :: 40 || Loss: 0.40768052 || it_count: 8344 || Val Loss: 0.41699211 || Val it_count: 1107 || Current Learning Rate: 0.0001 || Time: 02:47:43.21
Epoch :: 41 || Loss: 0.40744809 || it_count: 8344 || Val Loss: 0.41698347 || Val it_count: 1107 || Current Learning Rate: 0.0001 || Time: 02:51:52.73
Epoch :: 42 || Loss: 0.40721879 || it_count: 8344 || Val Loss: 0.41693683 || Val it_count: 1107 || Current Learning Rate: 0.0001 || Time: 02:56:2.39
Epoch :: 43 || Loss: 0.40701307 || it_count: 8344 || Val Loss: 0.41692529 || Val it_count: 1107 || Current Learning Rate: 0.0001 || Time: 03:00:12.23
Epoch :: 44 || Loss: 0.40681410 || it_count: 8344 || Val Loss: 0.41688668 || Val it_count: 1107 || Current Learning Rate: 0.0001 || Time: 03:04:22.90
Epoch :: 45 || Loss: 0.40662049 || it_count: 8344 || Val Loss: 0.41689122 || Val it_count: 1107 || Current Learning Rate: 0.0001 || Time: 03:08:32.86
Epoch :: 46 || Loss: 0.40643356 || it_count: 8344 || Val Loss: 0.41692974 || Val it_count: 1107 || Current Learning Rate: 0.0001 || Time: 03:12:43.57
Epoch :: 47 || Loss: 0.40626602 || it_count: 8344 || Val Loss: 0.41697491 || Val it_count: 1107 || Current Learning Rate: 0.0001 || Time: 03:16:54.18
Epoch :: 48 || Loss: 0.40611133 || it_count: 8344 || Val Loss: 0.41695026 || Val it_count: 1107 || Current Learning Rate: 0.0001 || Time: 03:21:4.71
Epoch :: 49 || Loss: 0.40594788 || it_count: 8344 || Val Loss: 0.41700849 || Val it_count: 1107 || Current Learning Rate: 0.0001 || Time: 03:25:16.11
Epoch 00034: reducing learning rate of group 0 to 1.0000e-05.
Epoch :: 50 || Loss: 0.40579092 || it_count: 8344 || Val Loss: 0.41707119 || Val it_count: 1107 || Current Learning Rate: 1e-05 || Time: 03:29:26.01
Epoch :: 51 || Loss: 0.40782690 || it_count: 8344 || Val Loss: 0.41182761 || Val it_count: 1107 || Current Learning Rate: 1e-05 || Time: 03:33:35.98
Epoch :: 52 || Loss: 0.40691998 || it_count: 8344 || Val Loss: 0.41161004 || Val it_count: 1107 || Current Learning Rate: 1e-05 || Time: 03:37:46.73
Epoch :: 53 || Loss: 0.40675393 || it_count: 8344 || Val Loss: 0.41154313 || Val it_count: 1107 || Current Learning Rate: 1e-05 || Time: 03:41:43.74
Epoch :: 54 || Loss: 0.40667709 || it_count: 8344 || Val Loss: 0.41149548 || Val it_count: 1107 || Current Learning Rate: 1e-05 || Time: 03:45:35.68
Epoch :: 55 || Loss: 0.40662208 || it_count: 8344 || Val Loss: 0.41145867 || Val it_count: 1107 || Current Learning Rate: 1e-05 || Time: 03:49:28.85
Epoch :: 56 || Loss: 0.40657732 || it_count: 8344 || Val Loss: 0.41143262 || Val it_count: 1107 || Current Learning Rate: 1e-05 || Time: 03:53:23.42
Epoch :: 57 || Loss: 0.40653871 || it_count: 8344 || Val Loss: 0.41141627 || Val it_count: 1107 || Current Learning Rate: 1e-05 || Time: 03:57:15.16
Epoch :: 58 || Loss: 0.40650291 || it_count: 8344 || Val Loss: 0.41140387 || Val it_count: 1107 || Current Learning Rate: 1e-05 || Time: 04:01:3.57
Epoch :: 59 || Loss: 0.40647087 || it_count: 8344 || Val Loss: 0.41139191 || Val it_count: 1107 || Current Learning Rate: 1e-05 || Time: 04:04:57.06
Epoch :: 60 || Loss: 0.40643782 || it_count: 8344 || Val Loss: 0.41137750 || Val it_count: 1107 || Current Learning Rate: 1e-05 || Time: 04:08:48.35
Epoch :: 61 || Loss: 0.40640935 || it_count: 8344 || Val Loss: 0.41136911 || Val it_count: 1107 || Current Learning Rate: 1e-05 || Time: 04:12:39.22
Epoch :: 62 || Loss: 0.40638176 || it_count: 8344 || Val Loss: 0.41136001 || Val it_count: 1107 || Current Learning Rate: 1e-05 || Time: 04:16:33.31
Epoch :: 63 || Loss: 0.40635533 || it_count: 8344 || Val Loss: 0.41135485 || Val it_count: 1107 || Current Learning Rate: 1e-05 || Time: 04:20:23.26
Epoch :: 64 || Loss: 0.40632861 || it_count: 8344 || Val Loss: 0.41135090 || Val it_count: 1107 || Current Learning Rate: 1e-05 || Time: 04:24:16.60
Epoch :: 65 || Loss: 0.40630447 || it_count: 8344 || Val Loss: 0.41134517 || Val it_count: 1107 || Current Learning Rate: 1e-05 || Time: 04:28:5.31
Epoch 00050: reducing learning rate of group 0 to 1.0000e-06.
Epoch :: 66 || Loss: 0.40627936 || it_count: 8344 || Val Loss: 0.41133882 || Val it_count: 1107 || Current Learning Rate: 1.0000000000000002e-06 || Time: 04:31:58.41
Epoch :: 67 || Loss: 0.40652302 || it_count: 8344 || Val Loss: 0.41117008 || Val it_count: 1107 || Current Learning Rate: 1.0000000000000002e-06 || Time: 04:35:51.32
Epoch :: 68 || Loss: 0.40641399 || it_count: 8344 || Val Loss: 0.41112198 || Val it_count: 1107 || Current Learning Rate: 1.0000000000000002e-06 || Time: 04:39:41.46
Epoch :: 69 || Loss: 0.40636219 || it_count: 8344 || Val Loss: 0.41110088 || Val it_count: 1107 || Current Learning Rate: 1.0000000000000002e-06 || Time: 04:43:35.55
Epoch :: 70 || Loss: 0.40633194 || it_count: 8344 || Val Loss: 0.41109257 || Val it_count: 1107 || Current Learning Rate: 1.0000000000000002e-06 || Time: 04:47:27.65
Epoch :: 71 || Loss: 0.40631180 || it_count: 8344 || Val Loss: 0.41108837 || Val it_count: 1107 || Current Learning Rate: 1.0000000000000002e-06 || Time: 04:51:19.90
Epoch :: 72 || Loss: 0.40629724 || it_count: 8344 || Val Loss: 0.41108590 || Val it_count: 1107 || Current Learning Rate: 1.0000000000000002e-06 || Time: 04:55:10.53
Epoch :: 73 || Loss: 0.40628657 || it_count: 8344 || Val Loss: 0.41108394 || Val it_count: 1107 || Current Learning Rate: 1.0000000000000002e-06 || Time: 04:59:2.95
Epoch 00058: reducing learning rate of group 0 to 1.0000e-07.
Early stopping triggered due to learning rate below threshold.
Done Total time: 05:02:53.76
best_loss: 0.41108393934163395

--------------------Testing--------------------

total_samples :: test_dataset = 139200, test_dataloader = 139200
Epoch ::  1 || Loss: 0.23629594 || it_count: 544 || Time: 00:00:12.36
MAE:  0.25236556
MSE:  0.2363119
RMSE:  0.44183064

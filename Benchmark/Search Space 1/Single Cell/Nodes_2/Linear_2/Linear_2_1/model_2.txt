--------------------Training--------------------
arch_str :: |lstm_2~0|[linear->linear]
model :: 2E
InferCell(
  info :: nodes=2, inC=1, outC=64, [1<-(I0-L0)], genotype_str: lstm_2~0
  linear_layers: [linear->linear]
  (layers): ModuleList(
    (0): LSTM(
      (lstm): LSTM(1, 64, num_layers=2, batch_first=True)
    )
  )
  (linear_layers): ModuleList(
    (0): Linear(in_features=3072, out_features=1536, bias=True)
    (1): Linear(in_features=1536, out_features=1, bias=True)
  )
)
tr_params :: epochs = 100, patience = 20, batch_size = 256, window_size = 48, data_size = 100
Model FLOPs: 7.190M, Model Params: 4.772M
learning rate scheduling :: (optimizer, mode='min', factor=0.1, patience=5, verbose=True)
total_samples :: train_dataset = 2136000, train_dataloader = 2136000
total_samples :: valid_dataset = 283200, valid_dataloader = 283200
Epoch ::  1 || Loss: 0.42308832 || it_count: 8344 || Val Loss: 0.45108476 || Val it_count: 1107 || Current Learning Rate: 0.001 || Time: 00:07:22.64
Epoch ::  2 || Loss: 0.41668247 || it_count: 8344 || Val Loss: 0.44798910 || Val it_count: 1107 || Current Learning Rate: 0.001 || Time: 00:14:41.25
Epoch ::  3 || Loss: 0.41589098 || it_count: 8344 || Val Loss: 0.44702813 || Val it_count: 1107 || Current Learning Rate: 0.001 || Time: 00:22:12.25
Epoch ::  4 || Loss: 0.41526947 || it_count: 8344 || Val Loss: 0.44826561 || Val it_count: 1107 || Current Learning Rate: 0.001 || Time: 00:30:22.56
Epoch ::  5 || Loss: 0.41505780 || it_count: 8344 || Val Loss: 0.44916100 || Val it_count: 1107 || Current Learning Rate: 0.001 || Time: 00:38:30.09
Epoch ::  6 || Loss: 0.41468237 || it_count: 8344 || Val Loss: 0.44899896 || Val it_count: 1107 || Current Learning Rate: 0.001 || Time: 00:46:28.47
Epoch ::  7 || Loss: 0.41445176 || it_count: 8344 || Val Loss: 0.44843682 || Val it_count: 1107 || Current Learning Rate: 0.001 || Time: 00:54:34.03
Epoch ::  8 || Loss: 0.41427261 || it_count: 8344 || Val Loss: 0.44726342 || Val it_count: 1107 || Current Learning Rate: 0.001 || Time: 01:02:41.35
Epoch ::  9 || Loss: 0.41395265 || it_count: 8344 || Val Loss: 0.44625212 || Val it_count: 1107 || Current Learning Rate: 0.001 || Time: 01:10:50.54
Epoch :: 10 || Loss: 0.41360007 || it_count: 8344 || Val Loss: 0.44607139 || Val it_count: 1107 || Current Learning Rate: 0.001 || Time: 01:19:4.48
Epoch :: 11 || Loss: 0.41352143 || it_count: 8344 || Val Loss: 0.44550976 || Val it_count: 1107 || Current Learning Rate: 0.001 || Time: 01:27:19.98
Epoch :: 12 || Loss: 0.41308380 || it_count: 8344 || Val Loss: 0.44522404 || Val it_count: 1107 || Current Learning Rate: 0.001 || Time: 01:35:29.30
Epoch :: 13 || Loss: 0.41264442 || it_count: 8344 || Val Loss: 0.44443895 || Val it_count: 1107 || Current Learning Rate: 0.001 || Time: 01:43:40.72
Epoch :: 14 || Loss: 0.41217754 || it_count: 8344 || Val Loss: 0.44435672 || Val it_count: 1107 || Current Learning Rate: 0.001 || Time: 01:51:50.68
Epoch :: 15 || Loss: 0.41171637 || it_count: 8344 || Val Loss: 0.44532636 || Val it_count: 1107 || Current Learning Rate: 0.001 || Time: 02:00:0.58
Epoch :: 16 || Loss: 0.41135738 || it_count: 8344 || Val Loss: 0.44548684 || Val it_count: 1107 || Current Learning Rate: 0.001 || Time: 02:08:9.01
Epoch :: 17 || Loss: 0.41091720 || it_count: 8344 || Val Loss: 0.44574561 || Val it_count: 1107 || Current Learning Rate: 0.001 || Time: 02:16:11.25
Epoch :: 18 || Loss: 0.41069788 || it_count: 8344 || Val Loss: 0.44551033 || Val it_count: 1107 || Current Learning Rate: 0.001 || Time: 02:23:56.30
Epoch :: 19 || Loss: 0.41032223 || it_count: 8344 || Val Loss: 0.44465700 || Val it_count: 1107 || Current Learning Rate: 0.001 || Time: 02:31:42.63
Epoch :: 20 || Loss: 0.40997559 || it_count: 8344 || Val Loss: 0.44381408 || Val it_count: 1107 || Current Learning Rate: 0.001 || Time: 02:39:45.10
Epoch :: 21 || Loss: 0.40916854 || it_count: 8344 || Val Loss: 0.44243764 || Val it_count: 1107 || Current Learning Rate: 0.001 || Time: 02:47:58.58
Epoch :: 22 || Loss: 0.40865719 || it_count: 8344 || Val Loss: 0.44162434 || Val it_count: 1107 || Current Learning Rate: 0.001 || Time: 02:56:10.27
Epoch :: 23 || Loss: 0.40765241 || it_count: 8344 || Val Loss: 0.44139517 || Val it_count: 1107 || Current Learning Rate: 0.001 || Time: 03:03:47.44
Epoch :: 24 || Loss: 0.40683580 || it_count: 8344 || Val Loss: 0.44211915 || Val it_count: 1107 || Current Learning Rate: 0.001 || Time: 03:11:36.12
Epoch :: 25 || Loss: 0.40627700 || it_count: 8344 || Val Loss: 0.44238176 || Val it_count: 1107 || Current Learning Rate: 0.001 || Time: 03:19:6.04
Epoch :: 26 || Loss: 0.40573990 || it_count: 8344 || Val Loss: 0.44240503 || Val it_count: 1107 || Current Learning Rate: 0.001 || Time: 03:26:57.84
Epoch :: 27 || Loss: 0.40495301 || it_count: 8344 || Val Loss: 0.44295322 || Val it_count: 1107 || Current Learning Rate: 0.001 || Time: 03:34:52.54
Epoch :: 28 || Loss: 0.40425433 || it_count: 8344 || Val Loss: 0.44398694 || Val it_count: 1107 || Current Learning Rate: 0.001 || Time: 03:42:38.85
Epoch 00013: reducing learning rate of group 0 to 1.0000e-04.
Epoch :: 29 || Loss: 0.40379043 || it_count: 8344 || Val Loss: 0.44372757 || Val it_count: 1107 || Current Learning Rate: 0.0001 || Time: 03:51:1.87
Epoch :: 30 || Loss: 0.41324924 || it_count: 8344 || Val Loss: 0.42702199 || Val it_count: 1107 || Current Learning Rate: 0.0001 || Time: 03:59:31.65
Epoch :: 31 || Loss: 0.41060904 || it_count: 8344 || Val Loss: 0.42667636 || Val it_count: 1107 || Current Learning Rate: 0.0001 || Time: 04:07:54.63
Epoch :: 32 || Loss: 0.40994172 || it_count: 8344 || Val Loss: 0.42638706 || Val it_count: 1107 || Current Learning Rate: 0.0001 || Time: 04:16:5.18
Epoch :: 33 || Loss: 0.40950217 || it_count: 8344 || Val Loss: 0.42617551 || Val it_count: 1107 || Current Learning Rate: 0.0001 || Time: 04:24:9.03
Epoch :: 34 || Loss: 0.40917722 || it_count: 8344 || Val Loss: 0.42608393 || Val it_count: 1107 || Current Learning Rate: 0.0001 || Time: 04:32:26.12
Epoch :: 35 || Loss: 0.40890878 || it_count: 8344 || Val Loss: 0.42606618 || Val it_count: 1107 || Current Learning Rate: 0.0001 || Time: 04:40:28.07
Epoch :: 36 || Loss: 0.40868740 || it_count: 8344 || Val Loss: 0.42606460 || Val it_count: 1107 || Current Learning Rate: 0.0001 || Time: 04:48:39.70
Epoch :: 37 || Loss: 0.40849550 || it_count: 8344 || Val Loss: 0.42605369 || Val it_count: 1107 || Current Learning Rate: 0.0001 || Time: 04:56:45.33
Epoch :: 38 || Loss: 0.40832316 || it_count: 8344 || Val Loss: 0.42603184 || Val it_count: 1107 || Current Learning Rate: 0.0001 || Time: 05:04:51.47
Epoch :: 39 || Loss: 0.40816485 || it_count: 8344 || Val Loss: 0.42600313 || Val it_count: 1107 || Current Learning Rate: 0.0001 || Time: 05:12:59.07
Epoch :: 40 || Loss: 0.40801774 || it_count: 8344 || Val Loss: 0.42597054 || Val it_count: 1107 || Current Learning Rate: 0.0001 || Time: 05:20:59.27
Epoch :: 41 || Loss: 0.40787993 || it_count: 8344 || Val Loss: 0.42593264 || Val it_count: 1107 || Current Learning Rate: 0.0001 || Time: 05:29:10.24
Epoch :: 42 || Loss: 0.40775016 || it_count: 8344 || Val Loss: 0.42588872 || Val it_count: 1107 || Current Learning Rate: 0.0001 || Time: 05:37:9.06
Epoch :: 43 || Loss: 0.40762721 || it_count: 8344 || Val Loss: 0.42584022 || Val it_count: 1107 || Current Learning Rate: 0.0001 || Time: 05:45:14.39
Epoch :: 44 || Loss: 0.40752097 || it_count: 8344 || Val Loss: 0.42576178 || Val it_count: 1107 || Current Learning Rate: 0.0001 || Time: 05:53:15.39
Epoch :: 45 || Loss: 0.40741052 || it_count: 8344 || Val Loss: 0.42571052 || Val it_count: 1107 || Current Learning Rate: 0.0001 || Time: 06:01:35.61
Epoch :: 46 || Loss: 0.40730197 || it_count: 8344 || Val Loss: 0.42565429 || Val it_count: 1107 || Current Learning Rate: 0.0001 || Time: 06:09:55.50
Epoch :: 47 || Loss: 0.40719763 || it_count: 8344 || Val Loss: 0.42559131 || Val it_count: 1107 || Current Learning Rate: 0.0001 || Time: 06:18:26.52
Epoch :: 48 || Loss: 0.40709690 || it_count: 8344 || Val Loss: 0.42551943 || Val it_count: 1107 || Current Learning Rate: 0.0001 || Time: 06:26:45.04
Epoch :: 49 || Loss: 0.40699902 || it_count: 8344 || Val Loss: 0.42543771 || Val it_count: 1107 || Current Learning Rate: 0.0001 || Time: 06:35:6.31
Epoch :: 50 || Loss: 0.40690328 || it_count: 8344 || Val Loss: 0.42534763 || Val it_count: 1107 || Current Learning Rate: 0.0001 || Time: 06:43:39.02
Epoch :: 51 || Loss: 0.40680923 || it_count: 8344 || Val Loss: 0.42525156 || Val it_count: 1107 || Current Learning Rate: 0.0001 || Time: 06:52:5.10
Epoch :: 52 || Loss: 0.40671672 || it_count: 8344 || Val Loss: 0.42515142 || Val it_count: 1107 || Current Learning Rate: 0.0001 || Time: 07:00:29.76
Epoch :: 53 || Loss: 0.40662568 || it_count: 8344 || Val Loss: 0.42505035 || Val it_count: 1107 || Current Learning Rate: 0.0001 || Time: 07:08:51.63
Epoch :: 54 || Loss: 0.40653619 || it_count: 8344 || Val Loss: 0.42495160 || Val it_count: 1107 || Current Learning Rate: 0.0001 || Time: 07:17:19.76
Epoch :: 55 || Loss: 0.40644828 || it_count: 8344 || Val Loss: 0.42485643 || Val it_count: 1107 || Current Learning Rate: 0.0001 || Time: 07:25:41.68
Epoch :: 56 || Loss: 0.40636170 || it_count: 8344 || Val Loss: 0.42476620 || Val it_count: 1107 || Current Learning Rate: 0.0001 || Time: 07:34:3.95
Epoch :: 57 || Loss: 0.40627625 || it_count: 8344 || Val Loss: 0.42468217 || Val it_count: 1107 || Current Learning Rate: 0.0001 || Time: 07:42:25.95
Epoch :: 58 || Loss: 0.40619190 || it_count: 8344 || Val Loss: 0.42460449 || Val it_count: 1107 || Current Learning Rate: 0.0001 || Time: 07:50:32.61
Epoch :: 59 || Loss: 0.40610860 || it_count: 8344 || Val Loss: 0.42453289 || Val it_count: 1107 || Current Learning Rate: 0.0001 || Time: 07:58:44.29
Epoch :: 60 || Loss: 0.40602649 || it_count: 8344 || Val Loss: 0.42446784 || Val it_count: 1107 || Current Learning Rate: 0.0001 || Time: 08:06:57.59
Epoch :: 61 || Loss: 0.40594968 || it_count: 8344 || Val Loss: 0.42441256 || Val it_count: 1107 || Current Learning Rate: 0.0001 || Time: 08:14:40.73
Epoch :: 62 || Loss: 0.40587015 || it_count: 8344 || Val Loss: 0.42435497 || Val it_count: 1107 || Current Learning Rate: 0.0001 || Time: 08:22:41.68
Epoch :: 63 || Loss: 0.40579047 || it_count: 8344 || Val Loss: 0.42430026 || Val it_count: 1107 || Current Learning Rate: 0.0001 || Time: 08:30:37.71
Epoch :: 64 || Loss: 0.40571226 || it_count: 8344 || Val Loss: 0.42424774 || Val it_count: 1107 || Current Learning Rate: 0.0001 || Time: 08:38:58.73
Epoch :: 65 || Loss: 0.40563535 || it_count: 8344 || Val Loss: 0.42419677 || Val it_count: 1107 || Current Learning Rate: 0.0001 || Time: 08:47:5.74
Epoch :: 66 || Loss: 0.40555962 || it_count: 8344 || Val Loss: 0.42414720 || Val it_count: 1107 || Current Learning Rate: 0.0001 || Time: 08:55:19.91
Epoch :: 67 || Loss: 0.40548495 || it_count: 8344 || Val Loss: 0.42409871 || Val it_count: 1107 || Current Learning Rate: 0.0001 || Time: 09:03:29.01
Epoch :: 68 || Loss: 0.40541129 || it_count: 8344 || Val Loss: 0.42405073 || Val it_count: 1107 || Current Learning Rate: 0.0001 || Time: 09:11:28.18
Epoch :: 69 || Loss: 0.40533857 || it_count: 8344 || Val Loss: 0.42400292 || Val it_count: 1107 || Current Learning Rate: 0.0001 || Time: 09:19:25.51
Epoch :: 70 || Loss: 0.40526678 || it_count: 8344 || Val Loss: 0.42395516 || Val it_count: 1107 || Current Learning Rate: 0.0001 || Time: 09:27:38.04
Epoch :: 71 || Loss: 0.40519584 || it_count: 8344 || Val Loss: 0.42390800 || Val it_count: 1107 || Current Learning Rate: 0.0001 || Time: 09:35:34.32
Epoch :: 72 || Loss: 0.40512568 || it_count: 8344 || Val Loss: 0.42386273 || Val it_count: 1107 || Current Learning Rate: 0.0001 || Time: 09:43:36.67
Epoch :: 73 || Loss: 0.40505626 || it_count: 8344 || Val Loss: 0.42382073 || Val it_count: 1107 || Current Learning Rate: 0.0001 || Time: 09:51:27.38
Epoch :: 74 || Loss: 0.40498748 || it_count: 8344 || Val Loss: 0.42378278 || Val it_count: 1107 || Current Learning Rate: 0.0001 || Time: 09:59:5.81
Epoch :: 75 || Loss: 0.40491933 || it_count: 8344 || Val Loss: 0.42374980 || Val it_count: 1107 || Current Learning Rate: 0.0001 || Time: 10:06:37.25
Epoch :: 76 || Loss: 0.40485185 || it_count: 8344 || Val Loss: 0.42372201 || Val it_count: 1107 || Current Learning Rate: 0.0001 || Time: 10:14:42.74
Epoch :: 77 || Loss: 0.40475854 || it_count: 8344 || Val Loss: 0.42374404 || Val it_count: 1107 || Current Learning Rate: 0.0001 || Time: 10:22:43.03
Epoch :: 78 || Loss: 0.40470291 || it_count: 8344 || Val Loss: 0.42372983 || Val it_count: 1107 || Current Learning Rate: 0.0001 || Time: 10:30:51.06
Epoch :: 79 || Loss: 0.40465592 || it_count: 8344 || Val Loss: 0.42367843 || Val it_count: 1107 || Current Learning Rate: 0.0001 || Time: 10:38:59.56
Epoch :: 80 || Loss: 0.40460316 || it_count: 8344 || Val Loss: 0.42366137 || Val it_count: 1107 || Current Learning Rate: 0.0001 || Time: 10:46:59.78
Epoch :: 81 || Loss: 0.40450782 || it_count: 8344 || Val Loss: 0.42371169 || Val it_count: 1107 || Current Learning Rate: 0.0001 || Time: 10:55:12.34
Epoch :: 82 || Loss: 0.40447036 || it_count: 8344 || Val Loss: 0.42367364 || Val it_count: 1107 || Current Learning Rate: 0.0001 || Time: 11:03:22.63
Epoch :: 83 || Loss: 0.40440679 || it_count: 8344 || Val Loss: 0.42368748 || Val it_count: 1107 || Current Learning Rate: 0.0001 || Time: 11:11:39.74
Epoch :: 84 || Loss: 0.40433478 || it_count: 8344 || Val Loss: 0.42373384 || Val it_count: 1107 || Current Learning Rate: 0.0001 || Time: 11:19:49.12
Epoch 00069: reducing learning rate of group 0 to 1.0000e-05.
Epoch :: 85 || Loss: 0.40429312 || it_count: 8344 || Val Loss: 0.42370344 || Val it_count: 1107 || Current Learning Rate: 1e-05 || Time: 11:27:50.83
Epoch :: 86 || Loss: 0.41041365 || it_count: 8344 || Val Loss: 0.41440242 || Val it_count: 1107 || Current Learning Rate: 1e-05 || Time: 11:35:58.77
Epoch :: 87 || Loss: 0.40764665 || it_count: 8344 || Val Loss: 0.41365886 || Val it_count: 1107 || Current Learning Rate: 1e-05 || Time: 11:44:11.70
Epoch :: 88 || Loss: 0.40725592 || it_count: 8344 || Val Loss: 0.41349036 || Val it_count: 1107 || Current Learning Rate: 1e-05 || Time: 11:52:13.87
Epoch :: 89 || Loss: 0.40708492 || it_count: 8344 || Val Loss: 0.41342083 || Val it_count: 1107 || Current Learning Rate: 1e-05 || Time: 12:00:18.48
Epoch :: 90 || Loss: 0.40697240 || it_count: 8344 || Val Loss: 0.41338382 || Val it_count: 1107 || Current Learning Rate: 1e-05 || Time: 12:08:25.40
Epoch :: 91 || Loss: 0.40688600 || it_count: 8344 || Val Loss: 0.41336404 || Val it_count: 1107 || Current Learning Rate: 1e-05 || Time: 12:16:39.46
Epoch :: 92 || Loss: 0.40681645 || it_count: 8344 || Val Loss: 0.41335509 || Val it_count: 1107 || Current Learning Rate: 1e-05 || Time: 12:24:44.37
Epoch :: 93 || Loss: 0.40675860 || it_count: 8344 || Val Loss: 0.41335409 || Val it_count: 1107 || Current Learning Rate: 1e-05 || Time: 12:32:55.14
Epoch :: 94 || Loss: 0.40671008 || it_count: 8344 || Val Loss: 0.41335410 || Val it_count: 1107 || Current Learning Rate: 1e-05 || Time: 12:41:11.02
Epoch :: 95 || Loss: 0.40666835 || it_count: 8344 || Val Loss: 0.41335858 || Val it_count: 1107 || Current Learning Rate: 1e-05 || Time: 12:49:22.56
Epoch :: 96 || Loss: 0.40663142 || it_count: 8344 || Val Loss: 0.41336617 || Val it_count: 1107 || Current Learning Rate: 1e-05 || Time: 12:57:29.15
Epoch 00081: reducing learning rate of group 0 to 1.0000e-06.
Epoch :: 97 || Loss: 0.40659825 || it_count: 8344 || Val Loss: 0.41337562 || Val it_count: 1107 || Current Learning Rate: 1.0000000000000002e-06 || Time: 13:05:31.01
Epoch :: 98 || Loss: 0.40705754 || it_count: 8344 || Val Loss: 0.41294489 || Val it_count: 1107 || Current Learning Rate: 1.0000000000000002e-06 || Time: 13:13:40.07
Epoch :: 99 || Loss: 0.40692247 || it_count: 8344 || Val Loss: 0.41282721 || Val it_count: 1107 || Current Learning Rate: 1.0000000000000002e-06 || Time: 13:21:49.58
Epoch :: 100 || Loss: 0.40685100 || it_count: 8344 || Val Loss: 0.41275739 || Val it_count: 1107 || Current Learning Rate: 1.0000000000000002e-06 || Time: 13:29:59.15
Done Total time: 13:29:59.26
best_loss: 0.41275738739160706

--------------------Testing--------------------

total_samples :: test_dataset = 139200, test_dataloader = 139200
Epoch ::  1 || Loss: 0.23916969 || it_count: 544 || Time: 00:00:19.81
MAE:  0.2544457
MSE:  0.2391903
RMSE:  0.4435008

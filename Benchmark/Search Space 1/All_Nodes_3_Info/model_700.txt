--------------------Training--------------------
arch_str :: |lstm_3~0|+|none~0|skip_connect~1|[linear->dropout->linear]
model :: 3F
InferCell(
  info :: nodes=3, inC=1, outC=64, [1<-(I0-L0) | 2<-(I0-L1,I1-L2)], genotype_str: lstm_3~0|none~0|skip_connect~1
  linear_layers: [linear->dropout->linear]
  (layers): ModuleList(
    (0): LSTM(
      (lstm): LSTM(1, 64, num_layers=3, batch_first=True)
    )
    (1): Zero(C_in=1, C_out=64, stride=1)
    (2): Identity()
  )
  (linear_layers): ModuleList(
    (0): Linear(in_features=3072, out_features=1536, bias=True)
    (1): Dropout(p=0.1, inplace=False)
    (2): Linear(in_features=1536, out_features=1, bias=True)
  )
)
tr_params :: epochs = 100, patience = 20, batch_size = 256, window_size = 48, data_size = 100
Model FLOPs: 8.812M, Model Params: 4.805M
learning rate scheduling :: (optimizer, mode='min', factor=0.1, patience=5, verbose=True)
total_samples :: train_dataset = 2136000, train_dataloader = 2136000
total_samples :: valid_dataset = 283200, valid_dataloader = 283200
Epoch ::  1 || Loss: 0.42594011 || it_count: 8344 || Val Loss: 0.45251276 || Val it_count: 1107 || Current Learning Rate: 0.001 || Time: 00:04:24.82
Epoch ::  2 || Loss: 0.41776335 || it_count: 8344 || Val Loss: 0.45024010 || Val it_count: 1107 || Current Learning Rate: 0.001 || Time: 00:08:42.40
Epoch ::  3 || Loss: 0.41704084 || it_count: 8344 || Val Loss: 0.44974600 || Val it_count: 1107 || Current Learning Rate: 0.001 || Time: 00:13:2.24
Epoch ::  4 || Loss: 0.41720084 || it_count: 8344 || Val Loss: 0.44986731 || Val it_count: 1107 || Current Learning Rate: 0.001 || Time: 00:17:21.76
Epoch ::  5 || Loss: 0.41682662 || it_count: 8344 || Val Loss: 0.44960756 || Val it_count: 1107 || Current Learning Rate: 0.001 || Time: 00:21:41.65
Epoch ::  6 || Loss: 0.41648426 || it_count: 8344 || Val Loss: 0.44978961 || Val it_count: 1107 || Current Learning Rate: 0.001 || Time: 00:26:1.77
Epoch ::  7 || Loss: 0.41590569 || it_count: 8344 || Val Loss: 0.44947111 || Val it_count: 1107 || Current Learning Rate: 0.001 || Time: 00:30:14.87
Epoch ::  8 || Loss: 0.41578667 || it_count: 8344 || Val Loss: 0.44965713 || Val it_count: 1107 || Current Learning Rate: 0.001 || Time: 00:34:33.93
Epoch ::  9 || Loss: 0.41572572 || it_count: 8344 || Val Loss: 0.44933117 || Val it_count: 1107 || Current Learning Rate: 0.001 || Time: 00:38:55.53
Epoch :: 10 || Loss: 0.41574668 || it_count: 8344 || Val Loss: 0.44919999 || Val it_count: 1107 || Current Learning Rate: 0.001 || Time: 00:43:16.23
Epoch :: 11 || Loss: 0.41557377 || it_count: 8344 || Val Loss: 0.44880253 || Val it_count: 1107 || Current Learning Rate: 0.001 || Time: 00:47:34.82
Epoch :: 12 || Loss: 0.41569590 || it_count: 8344 || Val Loss: 0.44842163 || Val it_count: 1107 || Current Learning Rate: 0.001 || Time: 00:51:57.06
Epoch :: 13 || Loss: 0.41555853 || it_count: 8344 || Val Loss: 0.44983143 || Val it_count: 1107 || Current Learning Rate: 0.001 || Time: 00:56:19.67
Epoch :: 14 || Loss: 0.41485859 || it_count: 8344 || Val Loss: 0.45064002 || Val it_count: 1107 || Current Learning Rate: 0.001 || Time: 01:00:40.30
Epoch :: 15 || Loss: 0.41471520 || it_count: 8344 || Val Loss: 0.44963102 || Val it_count: 1107 || Current Learning Rate: 0.001 || Time: 01:04:58.17
Epoch :: 16 || Loss: 0.41440625 || it_count: 8344 || Val Loss: 0.44938583 || Val it_count: 1107 || Current Learning Rate: 0.001 || Time: 01:09:18.00
Epoch :: 17 || Loss: 0.41428414 || it_count: 8344 || Val Loss: 0.44955371 || Val it_count: 1107 || Current Learning Rate: 0.001 || Time: 01:13:40.36
Epoch :: 18 || Loss: 0.41335280 || it_count: 8344 || Val Loss: 0.45027014 || Val it_count: 1107 || Current Learning Rate: 0.001 || Time: 01:18:0.64
Epoch :: 19 || Loss: 0.41337891 || it_count: 8344 || Val Loss: 0.44999860 || Val it_count: 1107 || Current Learning Rate: 0.001 || Time: 01:22:18.67
Epoch :: 20 || Loss: 0.41322716 || it_count: 8344 || Val Loss: 0.45025251 || Val it_count: 1107 || Current Learning Rate: 0.001 || Time: 01:26:37.97
Epoch :: 21 || Loss: 0.41237304 || it_count: 8344 || Val Loss: 0.44944434 || Val it_count: 1107 || Current Learning Rate: 0.001 || Time: 01:30:51.68
Epoch :: 22 || Loss: 0.41188472 || it_count: 8344 || Val Loss: 0.44712331 || Val it_count: 1107 || Current Learning Rate: 0.001 || Time: 01:35:4.95
Epoch :: 23 || Loss: 0.41118313 || it_count: 8344 || Val Loss: 0.44790469 || Val it_count: 1107 || Current Learning Rate: 0.001 || Time: 01:39:14.75
Epoch :: 24 || Loss: 0.41073153 || it_count: 8344 || Val Loss: 0.44946904 || Val it_count: 1107 || Current Learning Rate: 0.001 || Time: 01:43:26.77
Epoch :: 25 || Loss: 0.41062321 || it_count: 8344 || Val Loss: 0.44914167 || Val it_count: 1107 || Current Learning Rate: 0.001 || Time: 01:47:39.56
Epoch :: 26 || Loss: 0.40982901 || it_count: 8344 || Val Loss: 0.44879631 || Val it_count: 1107 || Current Learning Rate: 0.001 || Time: 01:51:49.57
Epoch :: 27 || Loss: 0.40926820 || it_count: 8344 || Val Loss: 0.44884322 || Val it_count: 1107 || Current Learning Rate: 0.001 || Time: 01:56:2.63
Epoch 00012: reducing learning rate of group 0 to 1.0000e-04.
Epoch :: 28 || Loss: 0.40854022 || it_count: 8344 || Val Loss: 0.44784997 || Val it_count: 1107 || Current Learning Rate: 0.0001 || Time: 02:00:13.97
Epoch :: 29 || Loss: 0.41368447 || it_count: 8344 || Val Loss: 0.42822958 || Val it_count: 1107 || Current Learning Rate: 0.0001 || Time: 02:04:27.38
Epoch :: 30 || Loss: 0.41081961 || it_count: 8344 || Val Loss: 0.42735921 || Val it_count: 1107 || Current Learning Rate: 0.0001 || Time: 02:08:39.89
Epoch :: 31 || Loss: 0.40987066 || it_count: 8344 || Val Loss: 0.42685897 || Val it_count: 1107 || Current Learning Rate: 0.0001 || Time: 02:12:52.35
Epoch :: 32 || Loss: 0.40923580 || it_count: 8344 || Val Loss: 0.42638595 || Val it_count: 1107 || Current Learning Rate: 0.0001 || Time: 02:16:59.04
Epoch :: 33 || Loss: 0.40872135 || it_count: 8344 || Val Loss: 0.42622275 || Val it_count: 1107 || Current Learning Rate: 0.0001 || Time: 02:21:6.94
Epoch :: 34 || Loss: 0.40832824 || it_count: 8344 || Val Loss: 0.42605618 || Val it_count: 1107 || Current Learning Rate: 0.0001 || Time: 02:25:16.86
Epoch :: 35 || Loss: 0.40795812 || it_count: 8344 || Val Loss: 0.42583601 || Val it_count: 1107 || Current Learning Rate: 0.0001 || Time: 02:29:28.10
Epoch :: 36 || Loss: 0.40764290 || it_count: 8344 || Val Loss: 0.42556443 || Val it_count: 1107 || Current Learning Rate: 0.0001 || Time: 02:33:37.88
Epoch :: 37 || Loss: 0.40726636 || it_count: 8344 || Val Loss: 0.42547127 || Val it_count: 1107 || Current Learning Rate: 0.0001 || Time: 02:37:49.09
Epoch :: 38 || Loss: 0.40697181 || it_count: 8344 || Val Loss: 0.42517233 || Val it_count: 1107 || Current Learning Rate: 0.0001 || Time: 02:42:0.99
Epoch :: 39 || Loss: 0.40669902 || it_count: 8344 || Val Loss: 0.42521030 || Val it_count: 1107 || Current Learning Rate: 0.0001 || Time: 02:46:13.14
Epoch :: 40 || Loss: 0.40644092 || it_count: 8344 || Val Loss: 0.42496402 || Val it_count: 1107 || Current Learning Rate: 0.0001 || Time: 02:50:23.34
Epoch :: 41 || Loss: 0.40615063 || it_count: 8344 || Val Loss: 0.42483430 || Val it_count: 1107 || Current Learning Rate: 0.0001 || Time: 02:54:37.18
Epoch :: 42 || Loss: 0.40591828 || it_count: 8344 || Val Loss: 0.42462594 || Val it_count: 1107 || Current Learning Rate: 0.0001 || Time: 02:58:47.33
Epoch :: 43 || Loss: 0.40564336 || it_count: 8344 || Val Loss: 0.42450801 || Val it_count: 1107 || Current Learning Rate: 0.0001 || Time: 03:02:57.83
Epoch :: 44 || Loss: 0.40539075 || it_count: 8344 || Val Loss: 0.42416758 || Val it_count: 1107 || Current Learning Rate: 0.0001 || Time: 03:07:7.29
Epoch :: 45 || Loss: 0.40522168 || it_count: 8344 || Val Loss: 0.42407650 || Val it_count: 1107 || Current Learning Rate: 0.0001 || Time: 03:11:20.13
Epoch :: 46 || Loss: 0.40498764 || it_count: 8344 || Val Loss: 0.42394098 || Val it_count: 1107 || Current Learning Rate: 0.0001 || Time: 03:15:29.09
Epoch :: 47 || Loss: 0.40480655 || it_count: 8344 || Val Loss: 0.42371512 || Val it_count: 1107 || Current Learning Rate: 0.0001 || Time: 03:19:37.99
Epoch :: 48 || Loss: 0.40461646 || it_count: 8344 || Val Loss: 0.42359258 || Val it_count: 1107 || Current Learning Rate: 0.0001 || Time: 03:23:46.98
Epoch :: 49 || Loss: 0.40446547 || it_count: 8344 || Val Loss: 0.42337198 || Val it_count: 1107 || Current Learning Rate: 0.0001 || Time: 03:27:55.54
Epoch :: 50 || Loss: 0.40428626 || it_count: 8344 || Val Loss: 0.42313482 || Val it_count: 1107 || Current Learning Rate: 0.0001 || Time: 03:32:4.53
Epoch :: 51 || Loss: 0.40413490 || it_count: 8344 || Val Loss: 0.42302548 || Val it_count: 1107 || Current Learning Rate: 0.0001 || Time: 03:36:16.75
Epoch :: 52 || Loss: 0.40394719 || it_count: 8344 || Val Loss: 0.42296699 || Val it_count: 1107 || Current Learning Rate: 0.0001 || Time: 03:40:27.77
Epoch :: 53 || Loss: 0.40378435 || it_count: 8344 || Val Loss: 0.42289045 || Val it_count: 1107 || Current Learning Rate: 0.0001 || Time: 03:44:33.38
Epoch :: 54 || Loss: 0.40359670 || it_count: 8344 || Val Loss: 0.42298915 || Val it_count: 1107 || Current Learning Rate: 0.0001 || Time: 03:48:40.66
Epoch :: 55 || Loss: 0.40343856 || it_count: 8344 || Val Loss: 0.42306582 || Val it_count: 1107 || Current Learning Rate: 0.0001 || Time: 03:52:44.83
Epoch :: 56 || Loss: 0.40331108 || it_count: 8344 || Val Loss: 0.42306474 || Val it_count: 1107 || Current Learning Rate: 0.0001 || Time: 03:56:57.20
Epoch :: 57 || Loss: 0.40318732 || it_count: 8344 || Val Loss: 0.42319387 || Val it_count: 1107 || Current Learning Rate: 0.0001 || Time: 04:01:6.55
Epoch :: 58 || Loss: 0.40302290 || it_count: 8344 || Val Loss: 0.42340974 || Val it_count: 1107 || Current Learning Rate: 0.0001 || Time: 04:05:13.93
Epoch 00043: reducing learning rate of group 0 to 1.0000e-05.
Epoch :: 59 || Loss: 0.40281627 || it_count: 8344 || Val Loss: 0.42333231 || Val it_count: 1107 || Current Learning Rate: 1e-05 || Time: 04:09:23.38
Epoch :: 60 || Loss: 0.40760359 || it_count: 8344 || Val Loss: 0.41239047 || Val it_count: 1107 || Current Learning Rate: 1e-05 || Time: 04:13:31.33
Epoch :: 61 || Loss: 0.40583401 || it_count: 8344 || Val Loss: 0.41193234 || Val it_count: 1107 || Current Learning Rate: 1e-05 || Time: 04:17:39.66
Epoch :: 62 || Loss: 0.40549906 || it_count: 8344 || Val Loss: 0.41193501 || Val it_count: 1107 || Current Learning Rate: 1e-05 || Time: 04:21:47.41
Epoch :: 63 || Loss: 0.40544053 || it_count: 8344 || Val Loss: 0.41196870 || Val it_count: 1107 || Current Learning Rate: 1e-05 || Time: 04:25:55.76
Epoch :: 64 || Loss: 0.40532026 || it_count: 8344 || Val Loss: 0.41199113 || Val it_count: 1107 || Current Learning Rate: 1e-05 || Time: 04:30:7.50
Epoch :: 65 || Loss: 0.40524111 || it_count: 8344 || Val Loss: 0.41202660 || Val it_count: 1107 || Current Learning Rate: 1e-05 || Time: 04:34:20.11
Epoch :: 66 || Loss: 0.40516439 || it_count: 8344 || Val Loss: 0.41205696 || Val it_count: 1107 || Current Learning Rate: 1e-05 || Time: 04:38:32.31
Epoch 00051: reducing learning rate of group 0 to 1.0000e-06.
Epoch :: 67 || Loss: 0.40510038 || it_count: 8344 || Val Loss: 0.41208011 || Val it_count: 1107 || Current Learning Rate: 1.0000000000000002e-06 || Time: 04:42:44.37
Epoch :: 68 || Loss: 0.40567392 || it_count: 8344 || Val Loss: 0.41081717 || Val it_count: 1107 || Current Learning Rate: 1.0000000000000002e-06 || Time: 04:46:57.40
Epoch :: 69 || Loss: 0.40537308 || it_count: 8344 || Val Loss: 0.41071127 || Val it_count: 1107 || Current Learning Rate: 1.0000000000000002e-06 || Time: 04:51:7.70
Epoch :: 70 || Loss: 0.40532599 || it_count: 8344 || Val Loss: 0.41066108 || Val it_count: 1107 || Current Learning Rate: 1.0000000000000002e-06 || Time: 04:55:19.07
Epoch :: 71 || Loss: 0.40525993 || it_count: 8344 || Val Loss: 0.41062534 || Val it_count: 1107 || Current Learning Rate: 1.0000000000000002e-06 || Time: 04:59:31.78
Epoch :: 72 || Loss: 0.40525904 || it_count: 8344 || Val Loss: 0.41060132 || Val it_count: 1107 || Current Learning Rate: 1.0000000000000002e-06 || Time: 05:03:42.35
Epoch :: 73 || Loss: 0.40522941 || it_count: 8344 || Val Loss: 0.41058504 || Val it_count: 1107 || Current Learning Rate: 1.0000000000000002e-06 || Time: 05:07:53.95
Epoch :: 74 || Loss: 0.40518718 || it_count: 8344 || Val Loss: 0.41057113 || Val it_count: 1107 || Current Learning Rate: 1.0000000000000002e-06 || Time: 05:12:6.84
Epoch :: 75 || Loss: 0.40520255 || it_count: 8344 || Val Loss: 0.41055427 || Val it_count: 1107 || Current Learning Rate: 1.0000000000000002e-06 || Time: 05:16:18.95
Epoch :: 76 || Loss: 0.40517177 || it_count: 8344 || Val Loss: 0.41054233 || Val it_count: 1107 || Current Learning Rate: 1.0000000000000002e-06 || Time: 05:20:30.64
Epoch :: 77 || Loss: 0.40515275 || it_count: 8344 || Val Loss: 0.41053617 || Val it_count: 1107 || Current Learning Rate: 1.0000000000000002e-06 || Time: 05:24:43.05
Epoch :: 78 || Loss: 0.40515770 || it_count: 8344 || Val Loss: 0.41052695 || Val it_count: 1107 || Current Learning Rate: 1.0000000000000002e-06 || Time: 05:28:53.47
Epoch :: 79 || Loss: 0.40513889 || it_count: 8344 || Val Loss: 0.41052191 || Val it_count: 1107 || Current Learning Rate: 1.0000000000000002e-06 || Time: 05:33:5.74
Epoch :: 80 || Loss: 0.40511477 || it_count: 8344 || Val Loss: 0.41051568 || Val it_count: 1107 || Current Learning Rate: 1.0000000000000002e-06 || Time: 05:37:17.86
Epoch :: 81 || Loss: 0.40515163 || it_count: 8344 || Val Loss: 0.41051209 || Val it_count: 1107 || Current Learning Rate: 1.0000000000000002e-06 || Time: 05:41:29.85
Epoch :: 82 || Loss: 0.40509488 || it_count: 8344 || Val Loss: 0.41050611 || Val it_count: 1107 || Current Learning Rate: 1.0000000000000002e-06 || Time: 05:45:40.51
Epoch :: 83 || Loss: 0.40512997 || it_count: 8344 || Val Loss: 0.41049892 || Val it_count: 1107 || Current Learning Rate: 1.0000000000000002e-06 || Time: 05:49:53.29
Epoch :: 84 || Loss: 0.40510806 || it_count: 8344 || Val Loss: 0.41049543 || Val it_count: 1107 || Current Learning Rate: 1.0000000000000002e-06 || Time: 05:54:4.90
Epoch :: 85 || Loss: 0.40508045 || it_count: 8344 || Val Loss: 0.41048867 || Val it_count: 1107 || Current Learning Rate: 1.0000000000000002e-06 || Time: 05:58:17.69
Epoch :: 86 || Loss: 0.40507997 || it_count: 8344 || Val Loss: 0.41048378 || Val it_count: 1107 || Current Learning Rate: 1.0000000000000002e-06 || Time: 06:02:30.58
Epoch 00071: reducing learning rate of group 0 to 1.0000e-07.
Early stopping triggered due to learning rate below threshold.
Done Total time: 06:06:42.88
best_loss: 0.41048377640984834

--------------------Testing--------------------

total_samples :: test_dataset = 139200, test_dataloader = 139200
Epoch ::  1 || Loss: 0.23519516 || it_count: 544 || Time: 00:00:13.21
MAE:  0.25167695
MSE:  0.23521654
RMSE:  0.44066307

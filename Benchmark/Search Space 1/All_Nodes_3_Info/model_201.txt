--------------------Training--------------------
arch_str :: |skip_connect~0|+|lstm_1~0|lstm_3~1|[dropout->linear]
model :: 3B
InferCell(
  info :: nodes=3, inC=1, outC=64, [1<-(I0-L0) | 2<-(I0-L1,I1-L2)], genotype_str: skip_connect~0|lstm_1~0|lstm_3~1
  linear_layers: [dropout->linear]
  (layers): ModuleList(
    (0): FactorizedReduce(
      C_in=1, C_out=64, stride=1
      (relu): ReLU()
      (conv): Conv1d(1, 64, kernel_size=(1,), stride=(1,), bias=False)
      (bn): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (1): LSTM(
      (lstm): LSTM(1, 64, batch_first=True)
    )
    (2): LSTM(
      (lstm): LSTM(64, 64, num_layers=3, batch_first=True)
    )
  )
  (linear_layers): ModuleList(
    (0): Dropout(p=0.1, inplace=False)
    (1): Linear(in_features=3072, out_features=1, bias=True)
  )
)
tr_params :: epochs = 100, patience = 20, batch_size = 256, window_size = 48, data_size = 100
Model FLOPs: 5.732M, Model Params: 120.257K
learning rate scheduling :: (optimizer, mode='min', factor=0.1, patience=5, verbose=True)
total_samples :: train_dataset = 2136000, train_dataloader = 2136000
total_samples :: valid_dataset = 283200, valid_dataloader = 283200
Epoch ::  1 || Loss: 0.41861395 || it_count: 8344 || Val Loss: 0.46334349 || Val it_count: 1107 || Current Learning Rate: 0.001 || Time: 00:07:54.70
Epoch ::  2 || Loss: 0.41573334 || it_count: 8344 || Val Loss: 0.45624264 || Val it_count: 1107 || Current Learning Rate: 0.001 || Time: 00:15:45.14
Epoch ::  3 || Loss: 0.41475521 || it_count: 8344 || Val Loss: 0.45162235 || Val it_count: 1107 || Current Learning Rate: 0.001 || Time: 00:23:38.69
Epoch ::  4 || Loss: 0.41470746 || it_count: 8344 || Val Loss: 0.45131148 || Val it_count: 1107 || Current Learning Rate: 0.001 || Time: 00:31:30.47
Epoch ::  5 || Loss: 0.41521351 || it_count: 8344 || Val Loss: 0.44829751 || Val it_count: 1107 || Current Learning Rate: 0.001 || Time: 00:39:23.26
Epoch ::  6 || Loss: 0.41390587 || it_count: 8344 || Val Loss: 0.44880885 || Val it_count: 1107 || Current Learning Rate: 0.001 || Time: 00:47:15.35
Epoch ::  7 || Loss: 0.41343625 || it_count: 8344 || Val Loss: 0.44950819 || Val it_count: 1107 || Current Learning Rate: 0.001 || Time: 00:55:7.97
Epoch ::  8 || Loss: 0.41250771 || it_count: 8344 || Val Loss: 0.44914934 || Val it_count: 1107 || Current Learning Rate: 0.001 || Time: 01:02:58.92
Epoch ::  9 || Loss: 0.41163483 || it_count: 8344 || Val Loss: 0.45097092 || Val it_count: 1107 || Current Learning Rate: 0.001 || Time: 01:10:51.33
Epoch :: 10 || Loss: 0.41098268 || it_count: 8344 || Val Loss: 0.45003720 || Val it_count: 1107 || Current Learning Rate: 0.001 || Time: 01:18:45.35
Epoch :: 11 || Loss: 0.41071164 || it_count: 8344 || Val Loss: 0.44950009 || Val it_count: 1107 || Current Learning Rate: 0.001 || Time: 01:26:37.75
Epoch :: 12 || Loss: 0.41058840 || it_count: 8344 || Val Loss: 0.44920974 || Val it_count: 1107 || Current Learning Rate: 0.001 || Time: 01:34:30.04
Epoch :: 13 || Loss: 0.40943443 || it_count: 8344 || Val Loss: 0.44773589 || Val it_count: 1107 || Current Learning Rate: 0.001 || Time: 01:42:23.83
Epoch :: 14 || Loss: 0.40907002 || it_count: 8344 || Val Loss: 0.44798792 || Val it_count: 1107 || Current Learning Rate: 0.001 || Time: 01:50:15.85
Epoch :: 15 || Loss: 0.40885777 || it_count: 8344 || Val Loss: 0.44735339 || Val it_count: 1107 || Current Learning Rate: 0.001 || Time: 01:58:9.00
Epoch :: 16 || Loss: 0.40899626 || it_count: 8344 || Val Loss: 0.44787097 || Val it_count: 1107 || Current Learning Rate: 0.001 || Time: 02:06:3.51
Epoch :: 17 || Loss: 0.40851097 || it_count: 8344 || Val Loss: 0.44641889 || Val it_count: 1107 || Current Learning Rate: 0.001 || Time: 02:13:57.46
Epoch :: 18 || Loss: 0.40868574 || it_count: 8344 || Val Loss: 0.44556353 || Val it_count: 1107 || Current Learning Rate: 0.001 || Time: 02:21:50.68
Epoch :: 19 || Loss: 0.40910315 || it_count: 8344 || Val Loss: 0.44858609 || Val it_count: 1107 || Current Learning Rate: 0.001 || Time: 02:29:42.29
Epoch :: 20 || Loss: 0.41280361 || it_count: 8344 || Val Loss: 0.44794300 || Val it_count: 1107 || Current Learning Rate: 0.001 || Time: 02:37:34.63
Epoch :: 21 || Loss: 0.41193982 || it_count: 8344 || Val Loss: 0.44838985 || Val it_count: 1107 || Current Learning Rate: 0.001 || Time: 02:45:26.10
Epoch :: 22 || Loss: 0.41175419 || it_count: 8344 || Val Loss: 0.45191545 || Val it_count: 1107 || Current Learning Rate: 0.001 || Time: 02:53:18.40
Epoch :: 23 || Loss: 0.41111511 || it_count: 8344 || Val Loss: 0.44871070 || Val it_count: 1107 || Current Learning Rate: 0.001 || Time: 03:01:11.04
Epoch 00008: reducing learning rate of group 0 to 1.0000e-04.
Epoch :: 24 || Loss: 0.41184907 || it_count: 8344 || Val Loss: 0.44893130 || Val it_count: 1107 || Current Learning Rate: 0.0001 || Time: 03:09:2.71
Epoch :: 25 || Loss: 0.41352550 || it_count: 8344 || Val Loss: 0.44032148 || Val it_count: 1107 || Current Learning Rate: 0.0001 || Time: 03:16:55.80
Epoch :: 26 || Loss: 0.40990387 || it_count: 8344 || Val Loss: 0.44009826 || Val it_count: 1107 || Current Learning Rate: 0.0001 || Time: 03:24:49.03
Epoch :: 27 || Loss: 0.40894315 || it_count: 8344 || Val Loss: 0.43957699 || Val it_count: 1107 || Current Learning Rate: 0.0001 || Time: 03:32:42.50
Epoch :: 28 || Loss: 0.40835367 || it_count: 8344 || Val Loss: 0.43969492 || Val it_count: 1107 || Current Learning Rate: 0.0001 || Time: 03:40:35.72
Epoch :: 29 || Loss: 0.40780705 || it_count: 8344 || Val Loss: 0.44045798 || Val it_count: 1107 || Current Learning Rate: 0.0001 || Time: 03:48:28.09
Epoch :: 30 || Loss: 0.40741762 || it_count: 8344 || Val Loss: 0.44136134 || Val it_count: 1107 || Current Learning Rate: 0.0001 || Time: 03:56:21.42
Epoch :: 31 || Loss: 0.40700362 || it_count: 8344 || Val Loss: 0.44182963 || Val it_count: 1107 || Current Learning Rate: 0.0001 || Time: 04:04:14.13
Epoch :: 32 || Loss: 0.40669694 || it_count: 8344 || Val Loss: 0.44227549 || Val it_count: 1107 || Current Learning Rate: 0.0001 || Time: 04:12:7.30
Epoch 00017: reducing learning rate of group 0 to 1.0000e-05.
Epoch :: 33 || Loss: 0.40638760 || it_count: 8344 || Val Loss: 0.44171664 || Val it_count: 1107 || Current Learning Rate: 1e-05 || Time: 04:20:2.28
Epoch :: 34 || Loss: 0.40809080 || it_count: 8344 || Val Loss: 0.44184655 || Val it_count: 1107 || Current Learning Rate: 1e-05 || Time: 04:27:55.63
Epoch :: 35 || Loss: 0.40755298 || it_count: 8344 || Val Loss: 0.44174129 || Val it_count: 1107 || Current Learning Rate: 1e-05 || Time: 04:35:50.75
Epoch :: 36 || Loss: 0.40744251 || it_count: 8344 || Val Loss: 0.44183513 || Val it_count: 1107 || Current Learning Rate: 1e-05 || Time: 04:43:43.36
Epoch :: 37 || Loss: 0.40739218 || it_count: 8344 || Val Loss: 0.44189405 || Val it_count: 1107 || Current Learning Rate: 1e-05 || Time: 04:51:36.41
Epoch :: 38 || Loss: 0.40728310 || it_count: 8344 || Val Loss: 0.44196549 || Val it_count: 1107 || Current Learning Rate: 1e-05 || Time: 04:59:28.45
Epoch 00023: reducing learning rate of group 0 to 1.0000e-06.
Epoch :: 39 || Loss: 0.40722936 || it_count: 8344 || Val Loss: 0.44195700 || Val it_count: 1107 || Current Learning Rate: 1.0000000000000002e-06 || Time: 05:07:21.55
Epoch :: 40 || Loss: 0.40752093 || it_count: 8344 || Val Loss: 0.44170599 || Val it_count: 1107 || Current Learning Rate: 1.0000000000000002e-06 || Time: 05:15:14.95
Epoch :: 41 || Loss: 0.40734468 || it_count: 8344 || Val Loss: 0.44147595 || Val it_count: 1107 || Current Learning Rate: 1.0000000000000002e-06 || Time: 05:23:8.55
Epoch :: 42 || Loss: 0.40736695 || it_count: 8344 || Val Loss: 0.44135867 || Val it_count: 1107 || Current Learning Rate: 1.0000000000000002e-06 || Time: 05:30:59.11
Epoch :: 43 || Loss: 0.40729035 || it_count: 8344 || Val Loss: 0.44128752 || Val it_count: 1107 || Current Learning Rate: 1.0000000000000002e-06 || Time: 05:38:51.98
Epoch :: 44 || Loss: 0.40729136 || it_count: 8344 || Val Loss: 0.44127852 || Val it_count: 1107 || Current Learning Rate: 1.0000000000000002e-06 || Time: 05:46:44.29
Epoch 00029: reducing learning rate of group 0 to 1.0000e-07.
Early stopping triggered due to learning rate below threshold.
Done Total time: 05:54:36.87
best_loss: 0.4395769867732337

--------------------Testing--------------------

total_samples :: test_dataset = 139200, test_dataloader = 139200
Epoch ::  1 || Loss: 0.28372333 || it_count: 544 || Time: 00:00:20.72
MAE:  0.2786731
MSE:  0.2837721
RMSE:  0.47212234

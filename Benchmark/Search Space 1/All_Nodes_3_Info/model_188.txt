--------------------Training--------------------
arch_str :: |lstm_2~0|+|lstm_3~0|skip_connect~1|[dropout->linear]
model :: 3B
InferCell(
  info :: nodes=3, inC=1, outC=64, [1<-(I0-L0) | 2<-(I0-L1,I1-L2)], genotype_str: lstm_2~0|lstm_3~0|skip_connect~1
  linear_layers: [dropout->linear]
  (layers): ModuleList(
    (0): LSTM(
      (lstm): LSTM(1, 64, num_layers=2, batch_first=True)
    )
    (1): LSTM(
      (lstm): LSTM(1, 64, num_layers=3, batch_first=True)
    )
    (2): Identity()
  )
  (linear_layers): ModuleList(
    (0): Dropout(p=0.1, inplace=False)
    (1): Linear(in_features=3072, out_features=1, bias=True)
  )
)
tr_params :: epochs = 100, patience = 20, batch_size = 256, window_size = 48, data_size = 100
Model FLOPs: 6.565M, Model Params: 137.217K
learning rate scheduling :: (optimizer, mode='min', factor=0.1, patience=5, verbose=True)
total_samples :: train_dataset = 2136000, train_dataloader = 2136000
total_samples :: valid_dataset = 283200, valid_dataloader = 283200
Epoch ::  1 || Loss: 0.42251995 || it_count: 8344 || Val Loss: 0.44948336 || Val it_count: 1107 || Current Learning Rate: 0.001 || Time: 00:08:10.99
Epoch ::  2 || Loss: 0.41955354 || it_count: 8344 || Val Loss: 0.44761234 || Val it_count: 1107 || Current Learning Rate: 0.001 || Time: 00:16:22.64
Epoch ::  3 || Loss: 0.41884461 || it_count: 8344 || Val Loss: 0.44739676 || Val it_count: 1107 || Current Learning Rate: 0.001 || Time: 00:24:34.64
Epoch ::  4 || Loss: 0.41831315 || it_count: 8344 || Val Loss: 0.44818114 || Val it_count: 1107 || Current Learning Rate: 0.001 || Time: 00:32:46.73
Epoch ::  5 || Loss: 0.41807030 || it_count: 8344 || Val Loss: 0.44814204 || Val it_count: 1107 || Current Learning Rate: 0.001 || Time: 00:41:0.10
Epoch ::  6 || Loss: 0.41789767 || it_count: 8344 || Val Loss: 0.44703731 || Val it_count: 1107 || Current Learning Rate: 0.001 || Time: 00:49:12.76
Epoch ::  7 || Loss: 0.41783119 || it_count: 8344 || Val Loss: 0.44733479 || Val it_count: 1107 || Current Learning Rate: 0.001 || Time: 00:57:25.69
Epoch ::  8 || Loss: 0.41746260 || it_count: 8344 || Val Loss: 0.44793985 || Val it_count: 1107 || Current Learning Rate: 0.001 || Time: 01:05:38.31
Epoch ::  9 || Loss: 0.41753859 || it_count: 8344 || Val Loss: 0.44682456 || Val it_count: 1107 || Current Learning Rate: 0.001 || Time: 01:13:51.15
Epoch :: 10 || Loss: 0.41707463 || it_count: 8344 || Val Loss: 0.44624154 || Val it_count: 1107 || Current Learning Rate: 0.001 || Time: 01:22:3.59
Epoch :: 11 || Loss: 0.41708645 || it_count: 8344 || Val Loss: 0.44587899 || Val it_count: 1107 || Current Learning Rate: 0.001 || Time: 01:30:13.73
Epoch :: 12 || Loss: 0.41704428 || it_count: 8344 || Val Loss: 0.44558202 || Val it_count: 1107 || Current Learning Rate: 0.001 || Time: 01:38:26.72
Epoch :: 13 || Loss: 0.41720009 || it_count: 8344 || Val Loss: 0.44568024 || Val it_count: 1107 || Current Learning Rate: 0.001 || Time: 01:46:39.32
Epoch :: 14 || Loss: 0.41686633 || it_count: 8344 || Val Loss: 0.44551845 || Val it_count: 1107 || Current Learning Rate: 0.001 || Time: 01:54:53.48
Epoch :: 15 || Loss: 0.41633237 || it_count: 8344 || Val Loss: 0.44540595 || Val it_count: 1107 || Current Learning Rate: 0.001 || Time: 02:03:7.97
Epoch :: 16 || Loss: 0.41662398 || it_count: 8344 || Val Loss: 0.44492606 || Val it_count: 1107 || Current Learning Rate: 0.001 || Time: 02:11:21.85
Epoch :: 17 || Loss: 0.41640459 || it_count: 8344 || Val Loss: 0.44492946 || Val it_count: 1107 || Current Learning Rate: 0.001 || Time: 02:19:36.13
Epoch :: 18 || Loss: 0.41618130 || it_count: 8344 || Val Loss: 0.44519762 || Val it_count: 1107 || Current Learning Rate: 0.001 || Time: 02:27:50.12
Epoch :: 19 || Loss: 0.41588506 || it_count: 8344 || Val Loss: 0.44602520 || Val it_count: 1107 || Current Learning Rate: 0.001 || Time: 02:36:5.58
Epoch :: 20 || Loss: 0.41555581 || it_count: 8344 || Val Loss: 0.44469192 || Val it_count: 1107 || Current Learning Rate: 0.001 || Time: 02:44:21.95
Epoch :: 21 || Loss: 0.41528022 || it_count: 8344 || Val Loss: 0.44482271 || Val it_count: 1107 || Current Learning Rate: 0.001 || Time: 02:52:37.00
Epoch :: 22 || Loss: 0.41437266 || it_count: 8344 || Val Loss: 0.44423180 || Val it_count: 1107 || Current Learning Rate: 0.001 || Time: 03:00:52.02
Epoch :: 23 || Loss: 0.41421270 || it_count: 8344 || Val Loss: 0.44329385 || Val it_count: 1107 || Current Learning Rate: 0.001 || Time: 03:09:9.67
Epoch :: 24 || Loss: 0.41395033 || it_count: 8344 || Val Loss: 0.44408830 || Val it_count: 1107 || Current Learning Rate: 0.001 || Time: 03:17:25.27
Epoch :: 25 || Loss: 0.41300297 || it_count: 8344 || Val Loss: 0.44410434 || Val it_count: 1107 || Current Learning Rate: 0.001 || Time: 03:25:42.37
Epoch :: 26 || Loss: 0.41269852 || it_count: 8344 || Val Loss: 0.44479394 || Val it_count: 1107 || Current Learning Rate: 0.001 || Time: 03:33:58.85
Epoch :: 27 || Loss: 0.41246622 || it_count: 8344 || Val Loss: 0.44397254 || Val it_count: 1107 || Current Learning Rate: 0.001 || Time: 03:42:15.32
Epoch :: 28 || Loss: 0.41286961 || it_count: 8344 || Val Loss: 0.44380644 || Val it_count: 1107 || Current Learning Rate: 0.001 || Time: 03:50:32.10
Epoch 00013: reducing learning rate of group 0 to 1.0000e-04.
Epoch :: 29 || Loss: 0.41252885 || it_count: 8344 || Val Loss: 0.44382251 || Val it_count: 1107 || Current Learning Rate: 0.0001 || Time: 03:58:48.94
Epoch :: 30 || Loss: 0.41749555 || it_count: 8344 || Val Loss: 0.42342868 || Val it_count: 1107 || Current Learning Rate: 0.0001 || Time: 04:07:4.29
Epoch :: 31 || Loss: 0.41318625 || it_count: 8344 || Val Loss: 0.42183099 || Val it_count: 1107 || Current Learning Rate: 0.0001 || Time: 04:15:21.40
Epoch :: 32 || Loss: 0.41224233 || it_count: 8344 || Val Loss: 0.42137702 || Val it_count: 1107 || Current Learning Rate: 0.0001 || Time: 04:23:38.48
Epoch :: 33 || Loss: 0.41181660 || it_count: 8344 || Val Loss: 0.42119124 || Val it_count: 1107 || Current Learning Rate: 0.0001 || Time: 04:31:56.83
Epoch :: 34 || Loss: 0.41156152 || it_count: 8344 || Val Loss: 0.42106990 || Val it_count: 1107 || Current Learning Rate: 0.0001 || Time: 04:40:13.92
Epoch :: 35 || Loss: 0.41135136 || it_count: 8344 || Val Loss: 0.42095194 || Val it_count: 1107 || Current Learning Rate: 0.0001 || Time: 04:48:32.00
Epoch :: 36 || Loss: 0.41118047 || it_count: 8344 || Val Loss: 0.42086065 || Val it_count: 1107 || Current Learning Rate: 0.0001 || Time: 04:56:50.05
Epoch :: 37 || Loss: 0.41096655 || it_count: 8344 || Val Loss: 0.42091217 || Val it_count: 1107 || Current Learning Rate: 0.0001 || Time: 05:05:8.00
Epoch :: 38 || Loss: 0.41076614 || it_count: 8344 || Val Loss: 0.42075929 || Val it_count: 1107 || Current Learning Rate: 0.0001 || Time: 05:13:25.90
Epoch :: 39 || Loss: 0.41060577 || it_count: 8344 || Val Loss: 0.42071360 || Val it_count: 1107 || Current Learning Rate: 0.0001 || Time: 05:21:44.66
Epoch :: 40 || Loss: 0.41049637 || it_count: 8344 || Val Loss: 0.42061676 || Val it_count: 1107 || Current Learning Rate: 0.0001 || Time: 05:30:3.06
Epoch :: 41 || Loss: 0.41041488 || it_count: 8344 || Val Loss: 0.42050036 || Val it_count: 1107 || Current Learning Rate: 0.0001 || Time: 05:38:19.55
Epoch :: 42 || Loss: 0.41023157 || it_count: 8344 || Val Loss: 0.42062539 || Val it_count: 1107 || Current Learning Rate: 0.0001 || Time: 05:46:37.07
Epoch :: 43 || Loss: 0.41011330 || it_count: 8344 || Val Loss: 0.42039916 || Val it_count: 1107 || Current Learning Rate: 0.0001 || Time: 05:54:54.20
Epoch :: 44 || Loss: 0.40997037 || it_count: 8344 || Val Loss: 0.42042686 || Val it_count: 1107 || Current Learning Rate: 0.0001 || Time: 06:03:11.85
Epoch :: 45 || Loss: 0.40984626 || it_count: 8344 || Val Loss: 0.42022527 || Val it_count: 1107 || Current Learning Rate: 0.0001 || Time: 06:11:27.92
Epoch :: 46 || Loss: 0.40970387 || it_count: 8344 || Val Loss: 0.42026676 || Val it_count: 1107 || Current Learning Rate: 0.0001 || Time: 06:19:44.44
Epoch :: 47 || Loss: 0.40950551 || it_count: 8344 || Val Loss: 0.42009846 || Val it_count: 1107 || Current Learning Rate: 0.0001 || Time: 06:28:1.43
Epoch :: 48 || Loss: 0.40942466 || it_count: 8344 || Val Loss: 0.42004980 || Val it_count: 1107 || Current Learning Rate: 0.0001 || Time: 06:36:19.72
Epoch :: 49 || Loss: 0.40933208 || it_count: 8344 || Val Loss: 0.41982542 || Val it_count: 1107 || Current Learning Rate: 0.0001 || Time: 06:44:37.50
Epoch :: 50 || Loss: 0.40922560 || it_count: 8344 || Val Loss: 0.41975973 || Val it_count: 1107 || Current Learning Rate: 0.0001 || Time: 06:52:53.98
Epoch :: 51 || Loss: 0.40909772 || it_count: 8344 || Val Loss: 0.41978191 || Val it_count: 1107 || Current Learning Rate: 0.0001 || Time: 07:01:11.38
Epoch :: 52 || Loss: 0.40899881 || it_count: 8344 || Val Loss: 0.41956788 || Val it_count: 1107 || Current Learning Rate: 0.0001 || Time: 07:09:30.74
Epoch :: 53 || Loss: 0.40893938 || it_count: 8344 || Val Loss: 0.41949205 || Val it_count: 1107 || Current Learning Rate: 0.0001 || Time: 07:17:47.22
Epoch :: 54 || Loss: 0.40877883 || it_count: 8344 || Val Loss: 0.41955302 || Val it_count: 1107 || Current Learning Rate: 0.0001 || Time: 07:26:4.45
Epoch :: 55 || Loss: 0.40871725 || it_count: 8344 || Val Loss: 0.41940070 || Val it_count: 1107 || Current Learning Rate: 0.0001 || Time: 07:34:22.30
Epoch :: 56 || Loss: 0.40860407 || it_count: 8344 || Val Loss: 0.41947859 || Val it_count: 1107 || Current Learning Rate: 0.0001 || Time: 07:42:39.21
Epoch :: 57 || Loss: 0.40850862 || it_count: 8344 || Val Loss: 0.41939035 || Val it_count: 1107 || Current Learning Rate: 0.0001 || Time: 07:50:55.36
Epoch :: 58 || Loss: 0.40844148 || it_count: 8344 || Val Loss: 0.41930566 || Val it_count: 1107 || Current Learning Rate: 0.0001 || Time: 07:59:13.33
Epoch :: 59 || Loss: 0.40831924 || it_count: 8344 || Val Loss: 0.41940158 || Val it_count: 1107 || Current Learning Rate: 0.0001 || Time: 08:07:31.26
Epoch :: 60 || Loss: 0.40826019 || it_count: 8344 || Val Loss: 0.41922433 || Val it_count: 1107 || Current Learning Rate: 0.0001 || Time: 08:15:47.31
Epoch :: 61 || Loss: 0.40816230 || it_count: 8344 || Val Loss: 0.41940401 || Val it_count: 1107 || Current Learning Rate: 0.0001 || Time: 08:24:4.18
Epoch :: 62 || Loss: 0.40807814 || it_count: 8344 || Val Loss: 0.41950244 || Val it_count: 1107 || Current Learning Rate: 0.0001 || Time: 08:32:21.31
Epoch :: 63 || Loss: 0.40796818 || it_count: 8344 || Val Loss: 0.41966251 || Val it_count: 1107 || Current Learning Rate: 0.0001 || Time: 08:40:37.58
Epoch :: 64 || Loss: 0.40791498 || it_count: 8344 || Val Loss: 0.41958222 || Val it_count: 1107 || Current Learning Rate: 0.0001 || Time: 08:48:55.17
Epoch :: 65 || Loss: 0.40780298 || it_count: 8344 || Val Loss: 0.41947678 || Val it_count: 1107 || Current Learning Rate: 0.0001 || Time: 08:57:12.01
Epoch 00050: reducing learning rate of group 0 to 1.0000e-05.
Epoch :: 66 || Loss: 0.40767678 || it_count: 8344 || Val Loss: 0.41965727 || Val it_count: 1107 || Current Learning Rate: 1e-05 || Time: 09:05:29.13
Epoch :: 67 || Loss: 0.41036585 || it_count: 8344 || Val Loss: 0.41237174 || Val it_count: 1107 || Current Learning Rate: 1e-05 || Time: 09:13:46.95
Epoch :: 68 || Loss: 0.40909202 || it_count: 8344 || Val Loss: 0.41222700 || Val it_count: 1107 || Current Learning Rate: 1e-05 || Time: 09:22:2.54
Epoch :: 69 || Loss: 0.40901214 || it_count: 8344 || Val Loss: 0.41213372 || Val it_count: 1107 || Current Learning Rate: 1e-05 || Time: 09:30:19.78
Epoch :: 70 || Loss: 0.40881860 || it_count: 8344 || Val Loss: 0.41207970 || Val it_count: 1107 || Current Learning Rate: 1e-05 || Time: 09:38:36.35
Epoch :: 71 || Loss: 0.40881729 || it_count: 8344 || Val Loss: 0.41205706 || Val it_count: 1107 || Current Learning Rate: 1e-05 || Time: 09:46:54.45
Epoch :: 72 || Loss: 0.40872225 || it_count: 8344 || Val Loss: 0.41202149 || Val it_count: 1107 || Current Learning Rate: 1e-05 || Time: 09:55:12.46
Epoch :: 73 || Loss: 0.40869102 || it_count: 8344 || Val Loss: 0.41198522 || Val it_count: 1107 || Current Learning Rate: 1e-05 || Time: 10:03:30.13
Epoch :: 74 || Loss: 0.40863842 || it_count: 8344 || Val Loss: 0.41198434 || Val it_count: 1107 || Current Learning Rate: 1e-05 || Time: 10:11:47.66
Epoch :: 75 || Loss: 0.40862574 || it_count: 8344 || Val Loss: 0.41196305 || Val it_count: 1107 || Current Learning Rate: 1e-05 || Time: 10:20:5.79
Epoch :: 76 || Loss: 0.40856511 || it_count: 8344 || Val Loss: 0.41196164 || Val it_count: 1107 || Current Learning Rate: 1e-05 || Time: 10:28:20.42
Epoch :: 77 || Loss: 0.40858747 || it_count: 8344 || Val Loss: 0.41193921 || Val it_count: 1107 || Current Learning Rate: 1e-05 || Time: 10:36:37.77
Epoch :: 78 || Loss: 0.40851408 || it_count: 8344 || Val Loss: 0.41193508 || Val it_count: 1107 || Current Learning Rate: 1e-05 || Time: 10:44:54.34
Epoch :: 79 || Loss: 0.40854201 || it_count: 8344 || Val Loss: 0.41192964 || Val it_count: 1107 || Current Learning Rate: 1e-05 || Time: 10:53:12.75
Epoch :: 80 || Loss: 0.40847360 || it_count: 8344 || Val Loss: 0.41194135 || Val it_count: 1107 || Current Learning Rate: 1e-05 || Time: 11:01:27.91
Epoch 00065: reducing learning rate of group 0 to 1.0000e-06.
Epoch :: 81 || Loss: 0.40845801 || it_count: 8344 || Val Loss: 0.41193732 || Val it_count: 1107 || Current Learning Rate: 1.0000000000000002e-06 || Time: 11:09:44.66
Epoch :: 82 || Loss: 0.40885176 || it_count: 8344 || Val Loss: 0.41148222 || Val it_count: 1107 || Current Learning Rate: 1.0000000000000002e-06 || Time: 11:18:2.13
Epoch :: 83 || Loss: 0.40874662 || it_count: 8344 || Val Loss: 0.41143129 || Val it_count: 1107 || Current Learning Rate: 1.0000000000000002e-06 || Time: 11:26:19.40
Epoch :: 84 || Loss: 0.40866481 || it_count: 8344 || Val Loss: 0.41140357 || Val it_count: 1107 || Current Learning Rate: 1.0000000000000002e-06 || Time: 11:34:37.07
Epoch :: 85 || Loss: 0.40873631 || it_count: 8344 || Val Loss: 0.41138532 || Val it_count: 1107 || Current Learning Rate: 1.0000000000000002e-06 || Time: 11:42:54.78
Epoch :: 86 || Loss: 0.40868097 || it_count: 8344 || Val Loss: 0.41137035 || Val it_count: 1107 || Current Learning Rate: 1.0000000000000002e-06 || Time: 11:51:11.91
Epoch :: 87 || Loss: 0.40866105 || it_count: 8344 || Val Loss: 0.41136157 || Val it_count: 1107 || Current Learning Rate: 1.0000000000000002e-06 || Time: 11:59:28.12
Epoch :: 88 || Loss: 0.40861513 || it_count: 8344 || Val Loss: 0.41135518 || Val it_count: 1107 || Current Learning Rate: 1.0000000000000002e-06 || Time: 12:07:46.05
Epoch :: 89 || Loss: 0.40867089 || it_count: 8344 || Val Loss: 0.41134576 || Val it_count: 1107 || Current Learning Rate: 1.0000000000000002e-06 || Time: 12:16:2.55
Epoch :: 90 || Loss: 0.40868287 || it_count: 8344 || Val Loss: 0.41134399 || Val it_count: 1107 || Current Learning Rate: 1.0000000000000002e-06 || Time: 12:24:18.34
Epoch :: 91 || Loss: 0.40865148 || it_count: 8344 || Val Loss: 0.41133768 || Val it_count: 1107 || Current Learning Rate: 1.0000000000000002e-06 || Time: 12:32:35.21
Epoch :: 92 || Loss: 0.40868398 || it_count: 8344 || Val Loss: 0.41133715 || Val it_count: 1107 || Current Learning Rate: 1.0000000000000002e-06 || Time: 12:40:52.87
Epoch :: 93 || Loss: 0.40860729 || it_count: 8344 || Val Loss: 0.41133765 || Val it_count: 1107 || Current Learning Rate: 1.0000000000000002e-06 || Time: 12:49:9.90
Epoch :: 94 || Loss: 0.40862409 || it_count: 8344 || Val Loss: 0.41133317 || Val it_count: 1107 || Current Learning Rate: 1.0000000000000002e-06 || Time: 12:57:27.07
Epoch :: 95 || Loss: 0.40863460 || it_count: 8344 || Val Loss: 0.41132633 || Val it_count: 1107 || Current Learning Rate: 1.0000000000000002e-06 || Time: 13:05:43.25
Epoch 00080: reducing learning rate of group 0 to 1.0000e-07.
Early stopping triggered due to learning rate below threshold.
Done Total time: 13:14:1.34
best_loss: 0.4113263343283802

--------------------Testing--------------------

total_samples :: test_dataset = 139200, test_dataloader = 139200
Epoch ::  1 || Loss: 0.23543839 || it_count: 544 || Time: 00:00:21.55
MAE:  0.25192404
MSE:  0.23545615
RMSE:  0.44132674

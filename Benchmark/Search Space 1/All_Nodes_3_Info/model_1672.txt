--------------------Training--------------------
arch_str :: |skip_connect~0|+|lstm_3~0|none~1|[relu->linear->dropout->linear]
model :: 3N
InferCell(
  info :: nodes=3, inC=1, outC=64, [1<-(I0-L0) | 2<-(I0-L1,I1-L2)], genotype_str: skip_connect~0|lstm_3~0|none~1
  linear_layers: [relu->linear->dropout->linear]
  (layers): ModuleList(
    (0): FactorizedReduce(
      C_in=1, C_out=64, stride=1
      (relu): ReLU()
      (conv): Conv1d(1, 64, kernel_size=(1,), stride=(1,), bias=False)
      (bn): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (1): LSTM(
      (lstm): LSTM(1, 64, num_layers=3, batch_first=True)
    )
    (2): Zero(C_in=64, C_out=64, stride=1)
  )
  (linear_layers): ModuleList(
    (0): ReLU()
    (1): Linear(in_features=3072, out_features=1536, bias=True)
    (2): Dropout(p=0.1, inplace=False)
    (3): Linear(in_features=1536, out_features=1, bias=True)
  )
)
tr_params :: epochs = 100, patience = 20, batch_size = 256, window_size = 48, data_size = 100
Model FLOPs: 8.827M, Model Params: 4.806M
learning rate scheduling :: (optimizer, mode='min', factor=0.1, patience=5, verbose=True)
total_samples :: train_dataset = 2136000, train_dataloader = 2136000
total_samples :: valid_dataset = 283200, valid_dataloader = 283200
Epoch ::  1 || Loss: 0.42456223 || it_count: 8344 || Val Loss: 0.45938005 || Val it_count: 1107 || Current Learning Rate: 0.001 || Time: 00:07:24.20
Epoch ::  2 || Loss: 0.41852537 || it_count: 8344 || Val Loss: 0.45388358 || Val it_count: 1107 || Current Learning Rate: 0.001 || Time: 00:14:42.50
Epoch ::  3 || Loss: 0.41720914 || it_count: 8344 || Val Loss: 0.45801418 || Val it_count: 1107 || Current Learning Rate: 0.001 || Time: 00:22:0.87
Epoch ::  4 || Loss: 0.41706222 || it_count: 8344 || Val Loss: 0.45277059 || Val it_count: 1107 || Current Learning Rate: 0.001 || Time: 00:29:21.05
Epoch ::  5 || Loss: 0.41751184 || it_count: 8344 || Val Loss: 0.45394461 || Val it_count: 1107 || Current Learning Rate: 0.001 || Time: 00:36:42.41
Epoch ::  6 || Loss: 0.41711671 || it_count: 8344 || Val Loss: 0.45485552 || Val it_count: 1107 || Current Learning Rate: 0.001 || Time: 00:44:2.39
Epoch ::  7 || Loss: 0.41672953 || it_count: 8344 || Val Loss: 0.45415900 || Val it_count: 1107 || Current Learning Rate: 0.001 || Time: 00:51:22.33
Epoch ::  8 || Loss: 0.41601489 || it_count: 8344 || Val Loss: 0.45365884 || Val it_count: 1107 || Current Learning Rate: 0.001 || Time: 00:58:43.25
Epoch ::  9 || Loss: 0.41619560 || it_count: 8344 || Val Loss: 0.45378221 || Val it_count: 1107 || Current Learning Rate: 0.001 || Time: 01:06:4.22
Epoch :: 10 || Loss: 0.41648397 || it_count: 8344 || Val Loss: 0.45356579 || Val it_count: 1107 || Current Learning Rate: 0.001 || Time: 01:13:24.58
Epoch :: 11 || Loss: 0.41615093 || it_count: 8344 || Val Loss: 0.45338483 || Val it_count: 1107 || Current Learning Rate: 0.001 || Time: 01:20:44.26
Epoch :: 12 || Loss: 0.41593060 || it_count: 8344 || Val Loss: 0.45214969 || Val it_count: 1107 || Current Learning Rate: 0.001 || Time: 01:28:6.29
Epoch :: 13 || Loss: 0.41555997 || it_count: 8344 || Val Loss: 0.45215296 || Val it_count: 1107 || Current Learning Rate: 0.001 || Time: 01:35:29.38
Epoch :: 14 || Loss: 0.41555009 || it_count: 8344 || Val Loss: 0.45026642 || Val it_count: 1107 || Current Learning Rate: 0.001 || Time: 01:42:51.38
Epoch :: 15 || Loss: 0.41510942 || it_count: 8344 || Val Loss: 0.45178516 || Val it_count: 1107 || Current Learning Rate: 0.001 || Time: 01:50:14.96
Epoch :: 16 || Loss: 0.41505519 || it_count: 8344 || Val Loss: 0.45225154 || Val it_count: 1107 || Current Learning Rate: 0.001 || Time: 01:57:37.23
Epoch :: 17 || Loss: 0.41419481 || it_count: 8344 || Val Loss: 0.45085104 || Val it_count: 1107 || Current Learning Rate: 0.001 || Time: 02:04:58.58
Epoch :: 18 || Loss: 0.41320952 || it_count: 8344 || Val Loss: 0.45093177 || Val it_count: 1107 || Current Learning Rate: 0.001 || Time: 02:12:20.80
Epoch :: 19 || Loss: 0.41248762 || it_count: 8344 || Val Loss: 0.44894955 || Val it_count: 1107 || Current Learning Rate: 0.001 || Time: 02:19:41.59
Epoch :: 20 || Loss: 0.41214883 || it_count: 8344 || Val Loss: 0.44890064 || Val it_count: 1107 || Current Learning Rate: 0.001 || Time: 02:27:2.99
Epoch :: 21 || Loss: 0.41114954 || it_count: 8344 || Val Loss: 0.44831677 || Val it_count: 1107 || Current Learning Rate: 0.001 || Time: 02:34:23.39
Epoch :: 22 || Loss: 0.41107396 || it_count: 8344 || Val Loss: 0.44783872 || Val it_count: 1107 || Current Learning Rate: 0.001 || Time: 02:41:44.70
Epoch :: 23 || Loss: 0.41080657 || it_count: 8344 || Val Loss: 0.45024744 || Val it_count: 1107 || Current Learning Rate: 0.001 || Time: 02:49:6.01
Epoch :: 24 || Loss: 0.41055551 || it_count: 8344 || Val Loss: 0.45057791 || Val it_count: 1107 || Current Learning Rate: 0.001 || Time: 02:56:27.42
Epoch :: 25 || Loss: 0.41005617 || it_count: 8344 || Val Loss: 0.45126449 || Val it_count: 1107 || Current Learning Rate: 0.001 || Time: 03:03:50.11
Epoch :: 26 || Loss: 0.40971651 || it_count: 8344 || Val Loss: 0.45077111 || Val it_count: 1107 || Current Learning Rate: 0.001 || Time: 03:11:12.34
Epoch :: 27 || Loss: 0.40942054 || it_count: 8344 || Val Loss: 0.44950964 || Val it_count: 1107 || Current Learning Rate: 0.001 || Time: 03:18:34.48
Epoch 00012: reducing learning rate of group 0 to 1.0000e-04.
Epoch :: 28 || Loss: 0.40890341 || it_count: 8344 || Val Loss: 0.45070269 || Val it_count: 1107 || Current Learning Rate: 0.0001 || Time: 03:25:56.30
Epoch :: 29 || Loss: 0.41492962 || it_count: 8344 || Val Loss: 0.43177671 || Val it_count: 1107 || Current Learning Rate: 0.0001 || Time: 03:33:18.39
Epoch :: 30 || Loss: 0.41169463 || it_count: 8344 || Val Loss: 0.43070935 || Val it_count: 1107 || Current Learning Rate: 0.0001 || Time: 03:40:41.28
Epoch :: 31 || Loss: 0.41074816 || it_count: 8344 || Val Loss: 0.43006602 || Val it_count: 1107 || Current Learning Rate: 0.0001 || Time: 03:48:4.07
Epoch :: 32 || Loss: 0.41005616 || it_count: 8344 || Val Loss: 0.42989555 || Val it_count: 1107 || Current Learning Rate: 0.0001 || Time: 03:55:26.70
Epoch :: 33 || Loss: 0.40951495 || it_count: 8344 || Val Loss: 0.42960659 || Val it_count: 1107 || Current Learning Rate: 0.0001 || Time: 04:02:50.95
Epoch :: 34 || Loss: 0.40905030 || it_count: 8344 || Val Loss: 0.42949957 || Val it_count: 1107 || Current Learning Rate: 0.0001 || Time: 04:10:12.78
Epoch :: 35 || Loss: 0.40868348 || it_count: 8344 || Val Loss: 0.42948619 || Val it_count: 1107 || Current Learning Rate: 0.0001 || Time: 04:17:34.40
Epoch :: 36 || Loss: 0.40823348 || it_count: 8344 || Val Loss: 0.42949929 || Val it_count: 1107 || Current Learning Rate: 0.0001 || Time: 04:24:56.85
Epoch :: 37 || Loss: 0.40789916 || it_count: 8344 || Val Loss: 0.42963584 || Val it_count: 1107 || Current Learning Rate: 0.0001 || Time: 04:32:20.50
Epoch :: 38 || Loss: 0.40761990 || it_count: 8344 || Val Loss: 0.42943657 || Val it_count: 1107 || Current Learning Rate: 0.0001 || Time: 04:39:43.99
Epoch :: 39 || Loss: 0.40734194 || it_count: 8344 || Val Loss: 0.42932573 || Val it_count: 1107 || Current Learning Rate: 0.0001 || Time: 04:47:6.39
Epoch :: 40 || Loss: 0.40708039 || it_count: 8344 || Val Loss: 0.42919859 || Val it_count: 1107 || Current Learning Rate: 0.0001 || Time: 04:54:29.21
Epoch :: 41 || Loss: 0.40683008 || it_count: 8344 || Val Loss: 0.42929959 || Val it_count: 1107 || Current Learning Rate: 0.0001 || Time: 05:01:52.15
Epoch :: 42 || Loss: 0.40660907 || it_count: 8344 || Val Loss: 0.42893100 || Val it_count: 1107 || Current Learning Rate: 0.0001 || Time: 05:09:14.77
Epoch :: 43 || Loss: 0.40631079 || it_count: 8344 || Val Loss: 0.42914020 || Val it_count: 1107 || Current Learning Rate: 0.0001 || Time: 05:16:37.77
Epoch :: 44 || Loss: 0.40617025 || it_count: 8344 || Val Loss: 0.42896552 || Val it_count: 1107 || Current Learning Rate: 0.0001 || Time: 05:23:59.33
Epoch :: 45 || Loss: 0.40597844 || it_count: 8344 || Val Loss: 0.42898116 || Val it_count: 1107 || Current Learning Rate: 0.0001 || Time: 05:31:22.74
Epoch :: 46 || Loss: 0.40570223 || it_count: 8344 || Val Loss: 0.42922145 || Val it_count: 1107 || Current Learning Rate: 0.0001 || Time: 05:38:44.86
Epoch :: 47 || Loss: 0.40555359 || it_count: 8344 || Val Loss: 0.42900356 || Val it_count: 1107 || Current Learning Rate: 0.0001 || Time: 05:46:6.81
Epoch 00032: reducing learning rate of group 0 to 1.0000e-05.
Epoch :: 48 || Loss: 0.40538282 || it_count: 8344 || Val Loss: 0.42915504 || Val it_count: 1107 || Current Learning Rate: 1e-05 || Time: 05:53:29.09
Epoch :: 49 || Loss: 0.41030567 || it_count: 8344 || Val Loss: 0.41392355 || Val it_count: 1107 || Current Learning Rate: 1e-05 || Time: 06:00:50.81
Epoch :: 50 || Loss: 0.40777666 || it_count: 8344 || Val Loss: 0.41363442 || Val it_count: 1107 || Current Learning Rate: 1e-05 || Time: 06:08:12.47
Epoch :: 51 || Loss: 0.40743879 || it_count: 8344 || Val Loss: 0.41359030 || Val it_count: 1107 || Current Learning Rate: 1e-05 || Time: 06:15:35.41
Epoch :: 52 || Loss: 0.40727788 || it_count: 8344 || Val Loss: 0.41355594 || Val it_count: 1107 || Current Learning Rate: 1e-05 || Time: 06:22:58.67
Epoch :: 53 || Loss: 0.40716522 || it_count: 8344 || Val Loss: 0.41345448 || Val it_count: 1107 || Current Learning Rate: 1e-05 || Time: 06:30:21.15
Epoch :: 54 || Loss: 0.40705244 || it_count: 8344 || Val Loss: 0.41348654 || Val it_count: 1107 || Current Learning Rate: 1e-05 || Time: 06:37:44.63
Epoch :: 55 || Loss: 0.40698939 || it_count: 8344 || Val Loss: 0.41341224 || Val it_count: 1107 || Current Learning Rate: 1e-05 || Time: 06:45:7.57
Epoch :: 56 || Loss: 0.40694025 || it_count: 8344 || Val Loss: 0.41337650 || Val it_count: 1107 || Current Learning Rate: 1e-05 || Time: 06:52:31.22
Epoch :: 57 || Loss: 0.40691935 || it_count: 8344 || Val Loss: 0.41336306 || Val it_count: 1107 || Current Learning Rate: 1e-05 || Time: 06:59:53.37
Epoch :: 58 || Loss: 0.40681943 || it_count: 8344 || Val Loss: 0.41333487 || Val it_count: 1107 || Current Learning Rate: 1e-05 || Time: 07:07:15.23
Epoch :: 59 || Loss: 0.40679073 || it_count: 8344 || Val Loss: 0.41331787 || Val it_count: 1107 || Current Learning Rate: 1e-05 || Time: 07:14:36.78
Epoch :: 60 || Loss: 0.40672135 || it_count: 8344 || Val Loss: 0.41328637 || Val it_count: 1107 || Current Learning Rate: 1e-05 || Time: 07:21:59.55
Epoch :: 61 || Loss: 0.40671174 || it_count: 8344 || Val Loss: 0.41328537 || Val it_count: 1107 || Current Learning Rate: 1e-05 || Time: 07:29:22.91
Epoch :: 62 || Loss: 0.40663546 || it_count: 8344 || Val Loss: 0.41326791 || Val it_count: 1107 || Current Learning Rate: 1e-05 || Time: 07:36:46.44
Epoch :: 63 || Loss: 0.40660452 || it_count: 8344 || Val Loss: 0.41318997 || Val it_count: 1107 || Current Learning Rate: 1e-05 || Time: 07:44:9.35
Epoch :: 64 || Loss: 0.40654159 || it_count: 8344 || Val Loss: 0.41320897 || Val it_count: 1107 || Current Learning Rate: 1e-05 || Time: 07:51:34.59
Epoch :: 65 || Loss: 0.40655423 || it_count: 8344 || Val Loss: 0.41321760 || Val it_count: 1107 || Current Learning Rate: 1e-05 || Time: 07:58:57.92
Epoch :: 66 || Loss: 0.40648688 || it_count: 8344 || Val Loss: 0.41322221 || Val it_count: 1107 || Current Learning Rate: 1e-05 || Time: 08:06:21.97
Epoch :: 67 || Loss: 0.40644977 || it_count: 8344 || Val Loss: 0.41319941 || Val it_count: 1107 || Current Learning Rate: 1e-05 || Time: 08:13:43.58
Epoch :: 68 || Loss: 0.40637216 || it_count: 8344 || Val Loss: 0.41321452 || Val it_count: 1107 || Current Learning Rate: 1e-05 || Time: 08:21:5.79
Epoch 00053: reducing learning rate of group 0 to 1.0000e-06.
Epoch :: 69 || Loss: 0.40639795 || it_count: 8344 || Val Loss: 0.41321609 || Val it_count: 1107 || Current Learning Rate: 1.0000000000000002e-06 || Time: 08:28:29.54
Epoch :: 70 || Loss: 0.40698656 || it_count: 8344 || Val Loss: 0.41162485 || Val it_count: 1107 || Current Learning Rate: 1.0000000000000002e-06 || Time: 08:35:52.87
Epoch :: 71 || Loss: 0.40670171 || it_count: 8344 || Val Loss: 0.41140914 || Val it_count: 1107 || Current Learning Rate: 1.0000000000000002e-06 || Time: 08:43:15.00
Epoch :: 72 || Loss: 0.40662890 || it_count: 8344 || Val Loss: 0.41134405 || Val it_count: 1107 || Current Learning Rate: 1.0000000000000002e-06 || Time: 08:50:39.16
Epoch :: 73 || Loss: 0.40660011 || it_count: 8344 || Val Loss: 0.41132202 || Val it_count: 1107 || Current Learning Rate: 1.0000000000000002e-06 || Time: 08:58:2.16
Epoch :: 74 || Loss: 0.40658456 || it_count: 8344 || Val Loss: 0.41131120 || Val it_count: 1107 || Current Learning Rate: 1.0000000000000002e-06 || Time: 09:05:26.85
Epoch :: 75 || Loss: 0.40657732 || it_count: 8344 || Val Loss: 0.41129513 || Val it_count: 1107 || Current Learning Rate: 1.0000000000000002e-06 || Time: 09:12:50.17
Epoch :: 76 || Loss: 0.40655732 || it_count: 8344 || Val Loss: 0.41129567 || Val it_count: 1107 || Current Learning Rate: 1.0000000000000002e-06 || Time: 09:20:14.15
Epoch :: 77 || Loss: 0.40653330 || it_count: 8344 || Val Loss: 0.41130696 || Val it_count: 1107 || Current Learning Rate: 1.0000000000000002e-06 || Time: 09:27:37.81
Epoch :: 78 || Loss: 0.40656629 || it_count: 8344 || Val Loss: 0.41129873 || Val it_count: 1107 || Current Learning Rate: 1.0000000000000002e-06 || Time: 09:35:2.73
Epoch :: 79 || Loss: 0.40653037 || it_count: 8344 || Val Loss: 0.41130206 || Val it_count: 1107 || Current Learning Rate: 1.0000000000000002e-06 || Time: 09:42:26.90
Epoch :: 80 || Loss: 0.40653475 || it_count: 8344 || Val Loss: 0.41128639 || Val it_count: 1107 || Current Learning Rate: 1.0000000000000002e-06 || Time: 09:49:49.73
Epoch 00065: reducing learning rate of group 0 to 1.0000e-07.
Early stopping triggered due to learning rate below threshold.
Done Total time: 09:57:13.25
best_loss: 0.4112863904680201

--------------------Testing--------------------

total_samples :: test_dataset = 139200, test_dataloader = 139200
Epoch ::  1 || Loss: 0.23664610 || it_count: 544 || Time: 00:00:20.64
MAE:  0.25371975
MSE:  0.23666187
RMSE:  0.4418858

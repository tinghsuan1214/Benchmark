--------------------Training--------------------
arch_str :: |lstm_2~0|+|lstm_2~0|lstm_1~1|[relu->dropout->linear->relu->dropout->linear]
model :: 3T
InferCell(
  info :: nodes=3, inC=1, outC=64, [1<-(I0-L0) | 2<-(I0-L1,I1-L2)], genotype_str: lstm_2~0|lstm_2~0|lstm_1~1
  linear_layers: [relu->dropout->linear->relu->dropout->linear]
  (layers): ModuleList(
    (0-1): 2 x LSTM(
      (lstm): LSTM(1, 64, num_layers=2, batch_first=True)
    )
    (2): LSTM(
      (lstm): LSTM(64, 64, batch_first=True)
    )
  )
  (linear_layers): ModuleList(
    (0): ReLU()
    (1): Dropout(p=0.1, inplace=False)
    (2): Linear(in_features=3072, out_features=1536, bias=True)
    (3): ReLU()
    (4): Dropout(p=0.1, inplace=False)
    (5): Linear(in_features=1536, out_features=1, bias=True)
  )
)
tr_params :: epochs = 100, patience = 20, batch_size = 256, window_size = 48, data_size = 100
Model FLOPs: 11.282M, Model Params: 4.856M
learning rate scheduling :: (optimizer, mode='min', factor=0.1, patience=5, verbose=True)
total_samples :: train_dataset = 2136000, train_dataloader = 2136000
total_samples :: valid_dataset = 283200, valid_dataloader = 283200
Epoch ::  1 || Loss: 0.42290880 || it_count: 8344 || Val Loss: 0.45252236 || Val it_count: 1107 || Current Learning Rate: 0.001 || Time: 00:04:36.86
Epoch ::  2 || Loss: 0.41788587 || it_count: 8344 || Val Loss: 0.45167379 || Val it_count: 1107 || Current Learning Rate: 0.001 || Time: 00:09:12.76
Epoch ::  3 || Loss: 0.41603709 || it_count: 8344 || Val Loss: 0.45084761 || Val it_count: 1107 || Current Learning Rate: 0.001 || Time: 00:13:49.11
Epoch ::  4 || Loss: 0.41438954 || it_count: 8344 || Val Loss: 0.44799098 || Val it_count: 1107 || Current Learning Rate: 0.001 || Time: 00:18:25.44
Epoch ::  5 || Loss: 0.41389732 || it_count: 8344 || Val Loss: 0.44771151 || Val it_count: 1107 || Current Learning Rate: 0.001 || Time: 00:23:2.75
Epoch ::  6 || Loss: 0.41313091 || it_count: 8344 || Val Loss: 0.44897842 || Val it_count: 1107 || Current Learning Rate: 0.001 || Time: 00:27:38.89
Epoch ::  7 || Loss: 0.41197498 || it_count: 8344 || Val Loss: 0.45032430 || Val it_count: 1107 || Current Learning Rate: 0.001 || Time: 00:32:16.27
Epoch ::  8 || Loss: 0.41092353 || it_count: 8344 || Val Loss: 0.44749774 || Val it_count: 1107 || Current Learning Rate: 0.001 || Time: 00:36:50.98
Epoch ::  9 || Loss: 0.41032240 || it_count: 8344 || Val Loss: 0.44909120 || Val it_count: 1107 || Current Learning Rate: 0.001 || Time: 00:41:26.37
Epoch :: 10 || Loss: 0.40954590 || it_count: 8344 || Val Loss: 0.45184871 || Val it_count: 1107 || Current Learning Rate: 0.001 || Time: 00:46:2.66
Epoch :: 11 || Loss: 0.40872893 || it_count: 8344 || Val Loss: 0.44928573 || Val it_count: 1107 || Current Learning Rate: 0.001 || Time: 00:50:38.79
Epoch :: 12 || Loss: 0.40807218 || it_count: 8344 || Val Loss: 0.44972932 || Val it_count: 1107 || Current Learning Rate: 0.001 || Time: 00:55:15.97
Epoch :: 13 || Loss: 0.40725967 || it_count: 8344 || Val Loss: 0.44813648 || Val it_count: 1107 || Current Learning Rate: 0.001 || Time: 00:59:53.20
Epoch :: 14 || Loss: 0.40657923 || it_count: 8344 || Val Loss: 0.45035050 || Val it_count: 1107 || Current Learning Rate: 0.001 || Time: 01:04:28.46
Epoch :: 15 || Loss: 0.40554284 || it_count: 8344 || Val Loss: 0.45165653 || Val it_count: 1107 || Current Learning Rate: 0.001 || Time: 01:09:3.12
Epoch :: 16 || Loss: 0.40475994 || it_count: 8344 || Val Loss: 0.45272169 || Val it_count: 1107 || Current Learning Rate: 0.001 || Time: 01:13:39.50
Epoch :: 17 || Loss: 0.40407616 || it_count: 8344 || Val Loss: 0.44939152 || Val it_count: 1107 || Current Learning Rate: 0.001 || Time: 01:18:17.45
Epoch :: 18 || Loss: 0.40318316 || it_count: 8344 || Val Loss: 0.45202854 || Val it_count: 1107 || Current Learning Rate: 0.001 || Time: 01:22:54.13
Epoch :: 19 || Loss: 0.40226254 || it_count: 8344 || Val Loss: 0.44852997 || Val it_count: 1107 || Current Learning Rate: 0.001 || Time: 01:27:31.55
Epoch :: 20 || Loss: 0.40125417 || it_count: 8344 || Val Loss: 0.44885928 || Val it_count: 1107 || Current Learning Rate: 0.001 || Time: 01:32:8.44
Epoch :: 21 || Loss: 0.40074445 || it_count: 8344 || Val Loss: 0.44990636 || Val it_count: 1107 || Current Learning Rate: 0.001 || Time: 01:36:46.47
Epoch :: 22 || Loss: 0.39979521 || it_count: 8344 || Val Loss: 0.44702983 || Val it_count: 1107 || Current Learning Rate: 0.001 || Time: 01:41:23.02
Epoch :: 23 || Loss: 0.39917399 || it_count: 8344 || Val Loss: 0.44645418 || Val it_count: 1107 || Current Learning Rate: 0.001 || Time: 01:45:59.28
Epoch :: 24 || Loss: 0.39875999 || it_count: 8344 || Val Loss: 0.44775547 || Val it_count: 1107 || Current Learning Rate: 0.001 || Time: 01:50:34.83
Epoch :: 25 || Loss: 0.39761967 || it_count: 8344 || Val Loss: 0.45051597 || Val it_count: 1107 || Current Learning Rate: 0.001 || Time: 01:55:10.25
Epoch :: 26 || Loss: 0.39722737 || it_count: 8344 || Val Loss: 0.44758120 || Val it_count: 1107 || Current Learning Rate: 0.001 || Time: 01:59:47.24
Epoch :: 27 || Loss: 0.39629331 || it_count: 8344 || Val Loss: 0.45128368 || Val it_count: 1107 || Current Learning Rate: 0.001 || Time: 02:04:22.82
Epoch :: 28 || Loss: 0.39515217 || it_count: 8344 || Val Loss: 0.44751309 || Val it_count: 1107 || Current Learning Rate: 0.001 || Time: 02:08:59.56
Epoch :: 29 || Loss: 0.39413175 || it_count: 8344 || Val Loss: 0.44595664 || Val it_count: 1107 || Current Learning Rate: 0.001 || Time: 02:13:35.55
Epoch :: 30 || Loss: 0.39325000 || it_count: 8344 || Val Loss: 0.45406949 || Val it_count: 1107 || Current Learning Rate: 0.001 || Time: 02:18:11.84
Epoch :: 31 || Loss: 0.39211304 || it_count: 8344 || Val Loss: 0.45155977 || Val it_count: 1107 || Current Learning Rate: 0.001 || Time: 02:22:48.61
Epoch :: 32 || Loss: 0.39083181 || it_count: 8344 || Val Loss: 0.45406680 || Val it_count: 1107 || Current Learning Rate: 0.001 || Time: 02:27:25.25
Epoch :: 33 || Loss: 0.39033335 || it_count: 8344 || Val Loss: 0.45332786 || Val it_count: 1107 || Current Learning Rate: 0.001 || Time: 02:32:2.94
Epoch :: 34 || Loss: 0.38929598 || it_count: 8344 || Val Loss: 0.45264850 || Val it_count: 1107 || Current Learning Rate: 0.001 || Time: 02:36:39.52
Epoch :: 35 || Loss: 0.38785112 || it_count: 8344 || Val Loss: 0.45780589 || Val it_count: 1107 || Current Learning Rate: 0.0001 || Time: 02:41:17.93
Epoch :: 36 || Loss: 0.40259899 || it_count: 8344 || Val Loss: 0.42779638 || Val it_count: 1107 || Current Learning Rate: 0.0001 || Time: 02:45:54.89
Epoch :: 37 || Loss: 0.39707857 || it_count: 8344 || Val Loss: 0.42670710 || Val it_count: 1107 || Current Learning Rate: 0.0001 || Time: 02:50:32.24
Epoch :: 38 || Loss: 0.39476617 || it_count: 8344 || Val Loss: 0.42694583 || Val it_count: 1107 || Current Learning Rate: 0.0001 || Time: 02:55:10.22
Epoch :: 39 || Loss: 0.39268928 || it_count: 8344 || Val Loss: 0.42798433 || Val it_count: 1107 || Current Learning Rate: 0.0001 || Time: 02:59:48.83
Epoch :: 40 || Loss: 0.39118236 || it_count: 8344 || Val Loss: 0.42822161 || Val it_count: 1107 || Current Learning Rate: 0.0001 || Time: 03:04:26.52
Epoch :: 41 || Loss: 0.38982156 || it_count: 8344 || Val Loss: 0.42933179 || Val it_count: 1107 || Current Learning Rate: 0.0001 || Time: 03:09:3.06
Epoch :: 42 || Loss: 0.38845042 || it_count: 8344 || Val Loss: 0.42976420 || Val it_count: 1107 || Current Learning Rate: 0.0001 || Time: 03:13:40.51
Epoch :: 43 || Loss: 0.38673201 || it_count: 8344 || Val Loss: 0.43043123 || Val it_count: 1107 || Current Learning Rate: 1e-05 || Time: 03:18:17.27
Epoch :: 44 || Loss: 0.39841570 || it_count: 8344 || Val Loss: 0.41981434 || Val it_count: 1107 || Current Learning Rate: 1e-05 || Time: 03:22:55.40
Epoch :: 45 || Loss: 0.39453611 || it_count: 8344 || Val Loss: 0.41901494 || Val it_count: 1107 || Current Learning Rate: 1e-05 || Time: 03:27:33.59
Epoch :: 46 || Loss: 0.39370024 || it_count: 8344 || Val Loss: 0.41844379 || Val it_count: 1107 || Current Learning Rate: 1e-05 || Time: 03:32:12.15
Epoch :: 47 || Loss: 0.39329445 || it_count: 8344 || Val Loss: 0.41833162 || Val it_count: 1107 || Current Learning Rate: 1e-05 || Time: 03:36:49.75
Epoch :: 48 || Loss: 0.39275801 || it_count: 8344 || Val Loss: 0.41836788 || Val it_count: 1107 || Current Learning Rate: 1e-05 || Time: 03:41:27.72
Epoch :: 49 || Loss: 0.39233122 || it_count: 8344 || Val Loss: 0.41842107 || Val it_count: 1107 || Current Learning Rate: 1e-05 || Time: 03:46:4.98
Epoch :: 50 || Loss: 0.39209004 || it_count: 8344 || Val Loss: 0.41843319 || Val it_count: 1107 || Current Learning Rate: 1e-05 || Time: 03:50:42.72
Epoch :: 51 || Loss: 0.39160928 || it_count: 8344 || Val Loss: 0.41851426 || Val it_count: 1107 || Current Learning Rate: 1e-05 || Time: 03:55:19.89
Epoch :: 52 || Loss: 0.39152515 || it_count: 8344 || Val Loss: 0.41850526 || Val it_count: 1107 || Current Learning Rate: 1e-05 || Time: 03:59:57.72
Epoch :: 53 || Loss: 0.39117634 || it_count: 8344 || Val Loss: 0.41858970 || Val it_count: 1107 || Current Learning Rate: 1.0000000000000002e-06 || Time: 04:04:35.09
Epoch :: 54 || Loss: 0.39400201 || it_count: 8344 || Val Loss: 0.41912504 || Val it_count: 1107 || Current Learning Rate: 1.0000000000000002e-06 || Time: 04:09:11.55
Epoch :: 55 || Loss: 0.39358122 || it_count: 8344 || Val Loss: 0.41900178 || Val it_count: 1107 || Current Learning Rate: 1.0000000000000002e-06 || Time: 04:13:49.14
Epoch :: 56 || Loss: 0.39345909 || it_count: 8344 || Val Loss: 0.41880695 || Val it_count: 1107 || Current Learning Rate: 1.0000000000000002e-06 || Time: 04:18:27.82
Epoch :: 57 || Loss: 0.39343962 || it_count: 8344 || Val Loss: 0.41881076 || Val it_count: 1107 || Current Learning Rate: 1.0000000000000002e-06 || Time: 04:23:5.34
Epoch :: 58 || Loss: 0.39341078 || it_count: 8344 || Val Loss: 0.41867134 || Val it_count: 1107 || Current Learning Rate: 1.0000000000000002e-06 || Time: 04:27:43.91
Early stopping triggered due to learning rate below threshold.
Done Total time: 04:32:21.75
best_loss: 0.41833162029348814

--------------------Testing--------------------

total_samples :: test_dataset = 139200, test_dataloader = 139200
Epoch ::  1 || Loss: 0.24522319 || it_count: 544 || Time: 00:00:13.75
MAE:  0.25612304
MSE:  0.24524596
RMSE:  0.44967812

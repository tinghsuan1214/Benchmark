--------------------Training--------------------
arch_str :: |lstm_3~0|+|none~0|skip_connect~1|[relu->dropout->linear->linear]
model :: 3Q
InferCell(
  info :: nodes=3, inC=1, outC=64, [1<-(I0-L0) | 2<-(I0-L1,I1-L2)], genotype_str: lstm_3~0|none~0|skip_connect~1
  linear_layers: [relu->dropout->linear->linear]
  (layers): ModuleList(
    (0): LSTM(
      (lstm): LSTM(1, 64, num_layers=3, batch_first=True)
    )
    (1): Zero(C_in=1, C_out=64, stride=1)
    (2): Identity()
  )
  (linear_layers): ModuleList(
    (0): ReLU()
    (1): Dropout(p=0.1, inplace=False)
    (2): Linear(in_features=3072, out_features=1536, bias=True)
    (3): Linear(in_features=1536, out_features=1, bias=True)
  )
)
tr_params :: epochs = 100, patience = 20, batch_size = 256, window_size = 48, data_size = 100
Model FLOPs: 8.812M, Model Params: 4.805M
learning rate scheduling :: (optimizer, mode='min', factor=0.1, patience=5, verbose=True)
total_samples :: train_dataset = 2136000, train_dataloader = 2136000
total_samples :: valid_dataset = 283200, valid_dataloader = 283200
Epoch ::  1 || Loss: 0.42617805 || it_count: 8344 || Val Loss: 0.45642573 || Val it_count: 1107 || Current Learning Rate: 0.001 || Time: 00:04:12.42
Epoch ::  2 || Loss: 0.41945735 || it_count: 8344 || Val Loss: 0.45133900 || Val it_count: 1107 || Current Learning Rate: 0.001 || Time: 00:08:21.48
Epoch ::  3 || Loss: 0.41875851 || it_count: 8344 || Val Loss: 0.44800253 || Val it_count: 1107 || Current Learning Rate: 0.001 || Time: 00:12:25.62
Epoch ::  4 || Loss: 0.41849288 || it_count: 8344 || Val Loss: 0.44819832 || Val it_count: 1107 || Current Learning Rate: 0.001 || Time: 00:16:32.66
Epoch ::  5 || Loss: 0.41805972 || it_count: 8344 || Val Loss: 0.44807987 || Val it_count: 1107 || Current Learning Rate: 0.001 || Time: 00:20:40.43
Epoch ::  6 || Loss: 0.41739957 || it_count: 8344 || Val Loss: 0.44758704 || Val it_count: 1107 || Current Learning Rate: 0.001 || Time: 00:24:45.77
Epoch ::  7 || Loss: 0.41721667 || it_count: 8344 || Val Loss: 0.44746545 || Val it_count: 1107 || Current Learning Rate: 0.001 || Time: 00:28:55.66
Epoch ::  8 || Loss: 0.41699920 || it_count: 8344 || Val Loss: 0.44791181 || Val it_count: 1107 || Current Learning Rate: 0.001 || Time: 00:33:0.99
Epoch ::  9 || Loss: 0.41698433 || it_count: 8344 || Val Loss: 0.44804511 || Val it_count: 1107 || Current Learning Rate: 0.001 || Time: 00:37:8.29
Epoch :: 10 || Loss: 0.41700554 || it_count: 8344 || Val Loss: 0.44860980 || Val it_count: 1107 || Current Learning Rate: 0.001 || Time: 00:41:16.22
Epoch :: 11 || Loss: 0.41672020 || it_count: 8344 || Val Loss: 0.44936746 || Val it_count: 1107 || Current Learning Rate: 0.001 || Time: 00:45:14.04
Epoch :: 12 || Loss: 0.41599345 || it_count: 8344 || Val Loss: 0.45150184 || Val it_count: 1107 || Current Learning Rate: 0.001 || Time: 00:49:6.67
Epoch :: 13 || Loss: 0.41607400 || it_count: 8344 || Val Loss: 0.45239572 || Val it_count: 1107 || Current Learning Rate: 0.001 || Time: 00:52:57.54
Epoch :: 14 || Loss: 0.41555891 || it_count: 8344 || Val Loss: 0.45055119 || Val it_count: 1107 || Current Learning Rate: 0.001 || Time: 00:56:49.47
Epoch :: 15 || Loss: 0.41526079 || it_count: 8344 || Val Loss: 0.45128119 || Val it_count: 1107 || Current Learning Rate: 0.001 || Time: 01:00:41.84
Epoch :: 16 || Loss: 0.41506375 || it_count: 8344 || Val Loss: 0.45306847 || Val it_count: 1107 || Current Learning Rate: 0.001 || Time: 01:04:34.16
Epoch :: 17 || Loss: 0.41503900 || it_count: 8344 || Val Loss: 0.45283095 || Val it_count: 1107 || Current Learning Rate: 0.001 || Time: 01:08:26.57
Epoch :: 18 || Loss: 0.41427371 || it_count: 8344 || Val Loss: 0.45295076 || Val it_count: 1107 || Current Learning Rate: 0.001 || Time: 01:12:18.56
Epoch :: 19 || Loss: 0.41406778 || it_count: 8344 || Val Loss: 0.45200185 || Val it_count: 1107 || Current Learning Rate: 0.001 || Time: 01:16:12.59
Epoch :: 20 || Loss: 0.41326696 || it_count: 8344 || Val Loss: 0.45128866 || Val it_count: 1107 || Current Learning Rate: 0.001 || Time: 01:20:9.70
Epoch :: 21 || Loss: 0.41253550 || it_count: 8344 || Val Loss: 0.44874571 || Val it_count: 1107 || Current Learning Rate: 0.001 || Time: 01:24:4.28
Epoch :: 22 || Loss: 0.41183618 || it_count: 8344 || Val Loss: 0.44906224 || Val it_count: 1107 || Current Learning Rate: 0.001 || Time: 01:28:9.74
Epoch :: 23 || Loss: 0.41151738 || it_count: 8344 || Val Loss: 0.44911053 || Val it_count: 1107 || Current Learning Rate: 0.001 || Time: 01:32:18.83
Epoch :: 24 || Loss: 0.41028063 || it_count: 8344 || Val Loss: 0.44819396 || Val it_count: 1107 || Current Learning Rate: 0.001 || Time: 01:36:45.54
Epoch :: 25 || Loss: 0.41036338 || it_count: 8344 || Val Loss: 0.44737695 || Val it_count: 1107 || Current Learning Rate: 0.001 || Time: 01:41:16.19
Epoch :: 26 || Loss: 0.41079163 || it_count: 8344 || Val Loss: 0.44593796 || Val it_count: 1107 || Current Learning Rate: 0.001 || Time: 01:45:20.78
Epoch :: 27 || Loss: 0.40981655 || it_count: 8344 || Val Loss: 0.44410373 || Val it_count: 1107 || Current Learning Rate: 0.001 || Time: 01:49:26.87
Epoch :: 28 || Loss: 0.40877942 || it_count: 8344 || Val Loss: 0.44563981 || Val it_count: 1107 || Current Learning Rate: 0.001 || Time: 01:53:33.78
Epoch :: 29 || Loss: 0.40843461 || it_count: 8344 || Val Loss: 0.44728651 || Val it_count: 1107 || Current Learning Rate: 0.001 || Time: 01:57:36.72
Epoch :: 30 || Loss: 0.40810977 || it_count: 8344 || Val Loss: 0.44628752 || Val it_count: 1107 || Current Learning Rate: 0.001 || Time: 02:01:34.74
Epoch :: 31 || Loss: 0.40767429 || it_count: 8344 || Val Loss: 0.44704769 || Val it_count: 1107 || Current Learning Rate: 0.001 || Time: 02:05:27.62
Epoch :: 32 || Loss: 0.40741116 || it_count: 8344 || Val Loss: 0.44720731 || Val it_count: 1107 || Current Learning Rate: 0.001 || Time: 02:09:23.58
Epoch :: 33 || Loss: 0.40701700 || it_count: 8344 || Val Loss: 0.44752839 || Val it_count: 1107 || Current Learning Rate: 0.0001 || Time: 02:13:17.89
Epoch :: 34 || Loss: 0.41449779 || it_count: 8344 || Val Loss: 0.43317745 || Val it_count: 1107 || Current Learning Rate: 0.0001 || Time: 02:17:11.33
Epoch :: 35 || Loss: 0.41099325 || it_count: 8344 || Val Loss: 0.43163788 || Val it_count: 1107 || Current Learning Rate: 0.0001 || Time: 02:21:6.15
Epoch :: 36 || Loss: 0.41014213 || it_count: 8344 || Val Loss: 0.43112363 || Val it_count: 1107 || Current Learning Rate: 0.0001 || Time: 02:24:58.67
Epoch :: 37 || Loss: 0.40967576 || it_count: 8344 || Val Loss: 0.42991317 || Val it_count: 1107 || Current Learning Rate: 0.0001 || Time: 02:28:51.82
Epoch :: 38 || Loss: 0.40928883 || it_count: 8344 || Val Loss: 0.42997838 || Val it_count: 1107 || Current Learning Rate: 0.0001 || Time: 02:32:43.74
Epoch :: 39 || Loss: 0.40890296 || it_count: 8344 || Val Loss: 0.42940259 || Val it_count: 1107 || Current Learning Rate: 0.0001 || Time: 02:36:36.47
Epoch :: 40 || Loss: 0.40858020 || it_count: 8344 || Val Loss: 0.42885860 || Val it_count: 1107 || Current Learning Rate: 0.0001 || Time: 02:40:30.73
Epoch :: 41 || Loss: 0.40836578 || it_count: 8344 || Val Loss: 0.42815121 || Val it_count: 1107 || Current Learning Rate: 0.0001 || Time: 02:44:22.21
Epoch :: 42 || Loss: 0.40809152 || it_count: 8344 || Val Loss: 0.42852011 || Val it_count: 1107 || Current Learning Rate: 0.0001 || Time: 02:48:18.24
Epoch :: 43 || Loss: 0.40788380 || it_count: 8344 || Val Loss: 0.42773188 || Val it_count: 1107 || Current Learning Rate: 0.0001 || Time: 02:52:11.69
Epoch :: 44 || Loss: 0.40765000 || it_count: 8344 || Val Loss: 0.42828371 || Val it_count: 1107 || Current Learning Rate: 0.0001 || Time: 02:56:22.05
Epoch :: 45 || Loss: 0.40742086 || it_count: 8344 || Val Loss: 0.42840217 || Val it_count: 1107 || Current Learning Rate: 0.0001 || Time: 03:00:15.48
Epoch :: 46 || Loss: 0.40721501 || it_count: 8344 || Val Loss: 0.42827893 || Val it_count: 1107 || Current Learning Rate: 0.0001 || Time: 03:04:9.22
Epoch :: 47 || Loss: 0.40699544 || it_count: 8344 || Val Loss: 0.42789627 || Val it_count: 1107 || Current Learning Rate: 0.0001 || Time: 03:08:7.74
Epoch :: 48 || Loss: 0.40677258 || it_count: 8344 || Val Loss: 0.42801697 || Val it_count: 1107 || Current Learning Rate: 0.0001 || Time: 03:12:9.66
Epoch :: 49 || Loss: 0.40670715 || it_count: 8344 || Val Loss: 0.42808748 || Val it_count: 1107 || Current Learning Rate: 1e-05 || Time: 03:16:5.80
Epoch :: 50 || Loss: 0.41134528 || it_count: 8344 || Val Loss: 0.41393659 || Val it_count: 1107 || Current Learning Rate: 1e-05 || Time: 03:20:13.70
Epoch :: 51 || Loss: 0.40925361 || it_count: 8344 || Val Loss: 0.41377245 || Val it_count: 1107 || Current Learning Rate: 1e-05 || Time: 03:24:25.37
Epoch :: 52 || Loss: 0.40902210 || it_count: 8344 || Val Loss: 0.41354767 || Val it_count: 1107 || Current Learning Rate: 1e-05 || Time: 03:28:26.06
Epoch :: 53 || Loss: 0.40878837 || it_count: 8344 || Val Loss: 0.41360461 || Val it_count: 1107 || Current Learning Rate: 1e-05 || Time: 03:32:20.05
Epoch :: 54 || Loss: 0.40864769 || it_count: 8344 || Val Loss: 0.41357846 || Val it_count: 1107 || Current Learning Rate: 1e-05 || Time: 03:36:14.38
Epoch :: 55 || Loss: 0.40852930 || it_count: 8344 || Val Loss: 0.41360948 || Val it_count: 1107 || Current Learning Rate: 1e-05 || Time: 03:40:8.04
Epoch :: 56 || Loss: 0.40852188 || it_count: 8344 || Val Loss: 0.41368383 || Val it_count: 1107 || Current Learning Rate: 1e-05 || Time: 03:44:3.29
Epoch :: 57 || Loss: 0.40843451 || it_count: 8344 || Val Loss: 0.41365851 || Val it_count: 1107 || Current Learning Rate: 1e-05 || Time: 03:48:7.36
Epoch :: 58 || Loss: 0.40836989 || it_count: 8344 || Val Loss: 0.41365153 || Val it_count: 1107 || Current Learning Rate: 1.0000000000000002e-06 || Time: 03:52:19.39
Epoch :: 59 || Loss: 0.40884165 || it_count: 8344 || Val Loss: 0.41263800 || Val it_count: 1107 || Current Learning Rate: 1.0000000000000002e-06 || Time: 03:56:33.78
Epoch :: 60 || Loss: 0.40860970 || it_count: 8344 || Val Loss: 0.41245990 || Val it_count: 1107 || Current Learning Rate: 1.0000000000000002e-06 || Time: 04:00:45.82
Epoch :: 61 || Loss: 0.40852726 || it_count: 8344 || Val Loss: 0.41239643 || Val it_count: 1107 || Current Learning Rate: 1.0000000000000002e-06 || Time: 04:05:0.07
Epoch :: 62 || Loss: 0.40847552 || it_count: 8344 || Val Loss: 0.41236757 || Val it_count: 1107 || Current Learning Rate: 1.0000000000000002e-06 || Time: 04:09:5.54
Epoch :: 63 || Loss: 0.40846306 || it_count: 8344 || Val Loss: 0.41232956 || Val it_count: 1107 || Current Learning Rate: 1.0000000000000002e-06 || Time: 04:12:57.75
Epoch :: 64 || Loss: 0.40850715 || it_count: 8344 || Val Loss: 0.41230554 || Val it_count: 1107 || Current Learning Rate: 1.0000000000000002e-06 || Time: 04:16:53.80
Epoch :: 65 || Loss: 0.40845982 || it_count: 8344 || Val Loss: 0.41229756 || Val it_count: 1107 || Current Learning Rate: 1.0000000000000002e-06 || Time: 04:20:57.71
Epoch :: 66 || Loss: 0.40847559 || it_count: 8344 || Val Loss: 0.41228376 || Val it_count: 1107 || Current Learning Rate: 1.0000000000000002e-06 || Time: 04:25:11.16
Epoch :: 67 || Loss: 0.40839427 || it_count: 8344 || Val Loss: 0.41226456 || Val it_count: 1107 || Current Learning Rate: 1.0000000000000002e-06 || Time: 04:29:25.84
Epoch :: 68 || Loss: 0.40841940 || it_count: 8344 || Val Loss: 0.41223986 || Val it_count: 1107 || Current Learning Rate: 1.0000000000000002e-06 || Time: 04:33:37.18
Epoch :: 69 || Loss: 0.40839705 || it_count: 8344 || Val Loss: 0.41223817 || Val it_count: 1107 || Current Learning Rate: 1.0000000000000002e-06 || Time: 04:37:52.36
Epoch :: 70 || Loss: 0.40838288 || it_count: 8344 || Val Loss: 0.41224412 || Val it_count: 1107 || Current Learning Rate: 1.0000000000000002e-06 || Time: 04:42:2.33
Epoch :: 71 || Loss: 0.40833835 || it_count: 8344 || Val Loss: 0.41223168 || Val it_count: 1107 || Current Learning Rate: 1.0000000000000002e-06 || Time: 04:46:15.51
Epoch :: 72 || Loss: 0.40838382 || it_count: 8344 || Val Loss: 0.41222298 || Val it_count: 1107 || Current Learning Rate: 1.0000000000000002e-06 || Time: 04:50:8.55
Epoch :: 73 || Loss: 0.40839353 || it_count: 8344 || Val Loss: 0.41222182 || Val it_count: 1107 || Current Learning Rate: 1.0000000000000002e-06 || Time: 04:54:1.17
Early stopping triggered due to learning rate below threshold.
Done Total time: 04:57:54.73
best_loss: 0.4122218206004376

--------------------Testing--------------------

total_samples :: test_dataset = 139200, test_dataloader = 139200
Epoch ::  1 || Loss: 0.23580386 || it_count: 544 || Time: 00:00:12.48
MAE:  0.2521404
MSE:  0.23581807
RMSE:  0.44122106

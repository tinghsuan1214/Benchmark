--------------------Training--------------------
arch_str :: |lstm_2~0|+|skip_connect~0|skip_connect~1|[relu->dropout->linear->dropout->linear]
model :: 3R
InferCell(
  info :: nodes=3, inC=1, outC=64, [1<-(I0-L0) | 2<-(I0-L1,I1-L2)], genotype_str: lstm_2~0|skip_connect~0|skip_connect~1
  linear_layers: [relu->dropout->linear->dropout->linear]
  (layers): ModuleList(
    (0): LSTM(
      (lstm): LSTM(1, 64, num_layers=2, batch_first=True)
    )
    (1): FactorizedReduce(
      C_in=1, C_out=64, stride=1
      (relu): ReLU()
      (conv): Conv1d(1, 64, kernel_size=(1,), stride=(1,), bias=False)
      (bn): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (2): Identity()
  )
  (linear_layers): ModuleList(
    (0): ReLU()
    (1): Dropout(p=0.1, inplace=False)
    (2): Linear(in_features=3072, out_features=1536, bias=True)
    (3): Dropout(p=0.1, inplace=False)
    (4): Linear(in_features=1536, out_features=1, bias=True)
  )
)
tr_params :: epochs = 100, patience = 20, batch_size = 256, window_size = 48, data_size = 100
Model FLOPs: 7.205M, Model Params: 4.772M
learning rate scheduling :: (optimizer, mode='min', factor=0.1, patience=5, verbose=True)
total_samples :: train_dataset = 2136000, train_dataloader = 2136000
total_samples :: valid_dataset = 283200, valid_dataloader = 283200
Epoch ::  1 || Loss: 0.47499656 || it_count: 8344 || Val Loss: 0.47651805 || Val it_count: 1107 || Current Learning Rate: 0.001 || Time: 00:03:50.66
Epoch ::  2 || Loss: 0.44420286 || it_count: 8344 || Val Loss: 0.49355767 || Val it_count: 1107 || Current Learning Rate: 0.001 || Time: 00:07:36.85
Epoch ::  3 || Loss: 0.42833289 || it_count: 8344 || Val Loss: 0.46962587 || Val it_count: 1107 || Current Learning Rate: 0.001 || Time: 00:11:21.39
Epoch ::  4 || Loss: 0.42564580 || it_count: 8344 || Val Loss: 0.46938834 || Val it_count: 1107 || Current Learning Rate: 0.001 || Time: 00:15:6.99
Epoch ::  5 || Loss: 0.42637901 || it_count: 8344 || Val Loss: 0.47011309 || Val it_count: 1107 || Current Learning Rate: 0.001 || Time: 00:18:52.58
Epoch ::  6 || Loss: 0.42715560 || it_count: 8344 || Val Loss: 0.46502541 || Val it_count: 1107 || Current Learning Rate: 0.001 || Time: 00:22:39.23
Epoch ::  7 || Loss: 0.42649552 || it_count: 8344 || Val Loss: 0.47156921 || Val it_count: 1107 || Current Learning Rate: 0.001 || Time: 00:26:24.72
Epoch ::  8 || Loss: 0.42680516 || it_count: 8344 || Val Loss: 0.47162088 || Val it_count: 1107 || Current Learning Rate: 0.001 || Time: 00:30:9.84
Epoch ::  9 || Loss: 0.42515558 || it_count: 8344 || Val Loss: 0.47075101 || Val it_count: 1107 || Current Learning Rate: 0.001 || Time: 00:33:55.78
Epoch :: 10 || Loss: 0.42550813 || it_count: 8344 || Val Loss: 0.46790709 || Val it_count: 1107 || Current Learning Rate: 0.001 || Time: 00:37:40.67
Epoch :: 11 || Loss: 0.42179684 || it_count: 8344 || Val Loss: 0.47495183 || Val it_count: 1107 || Current Learning Rate: 0.001 || Time: 00:41:27.00
Epoch :: 12 || Loss: 0.42389032 || it_count: 8344 || Val Loss: 0.47224434 || Val it_count: 1107 || Current Learning Rate: 0.001 || Time: 00:45:13.61
Epoch :: 13 || Loss: 0.41989036 || it_count: 8344 || Val Loss: 0.46411548 || Val it_count: 1107 || Current Learning Rate: 0.001 || Time: 00:48:59.13
Epoch :: 14 || Loss: 0.41969304 || it_count: 8344 || Val Loss: 0.46632835 || Val it_count: 1107 || Current Learning Rate: 0.001 || Time: 00:52:43.97
Epoch :: 15 || Loss: 0.42826284 || it_count: 8344 || Val Loss: 0.45646745 || Val it_count: 1107 || Current Learning Rate: 0.001 || Time: 00:56:28.74
Epoch :: 16 || Loss: 0.42099525 || it_count: 8344 || Val Loss: 0.46660429 || Val it_count: 1107 || Current Learning Rate: 0.001 || Time: 01:00:13.99
Epoch :: 17 || Loss: 0.41914007 || it_count: 8344 || Val Loss: 0.46424459 || Val it_count: 1107 || Current Learning Rate: 0.001 || Time: 01:04:0.66
Epoch :: 18 || Loss: 0.41909806 || it_count: 8344 || Val Loss: 0.46118629 || Val it_count: 1107 || Current Learning Rate: 0.001 || Time: 01:07:44.85
Epoch :: 19 || Loss: 0.41747542 || it_count: 8344 || Val Loss: 0.46375524 || Val it_count: 1107 || Current Learning Rate: 0.001 || Time: 01:11:30.49
Epoch :: 20 || Loss: 0.41812027 || it_count: 8344 || Val Loss: 0.46504330 || Val it_count: 1107 || Current Learning Rate: 0.001 || Time: 01:15:15.64
Epoch :: 21 || Loss: 0.41665191 || it_count: 8344 || Val Loss: 0.46354781 || Val it_count: 1107 || Current Learning Rate: 0.001 || Time: 01:19:1.81
Epoch :: 22 || Loss: 0.41800627 || it_count: 8344 || Val Loss: 0.46692491 || Val it_count: 1107 || Current Learning Rate: 0.001 || Time: 01:22:46.61
Epoch :: 23 || Loss: 0.41778014 || it_count: 8344 || Val Loss: 0.46236250 || Val it_count: 1107 || Current Learning Rate: 0.001 || Time: 01:26:31.63
Epoch :: 24 || Loss: 0.41674054 || it_count: 8344 || Val Loss: 0.46797246 || Val it_count: 1107 || Current Learning Rate: 0.0001 || Time: 01:30:16.04
Epoch :: 25 || Loss: 0.41990602 || it_count: 8344 || Val Loss: 0.44981194 || Val it_count: 1107 || Current Learning Rate: 0.0001 || Time: 01:34:0.97
Epoch :: 26 || Loss: 0.41603658 || it_count: 8344 || Val Loss: 0.44725557 || Val it_count: 1107 || Current Learning Rate: 0.0001 || Time: 01:37:45.02
Epoch :: 27 || Loss: 0.41507357 || it_count: 8344 || Val Loss: 0.44673983 || Val it_count: 1107 || Current Learning Rate: 0.0001 || Time: 01:41:30.95
Epoch :: 28 || Loss: 0.41420131 || it_count: 8344 || Val Loss: 0.44925623 || Val it_count: 1107 || Current Learning Rate: 0.0001 || Time: 01:45:16.03
Epoch :: 29 || Loss: 0.41383498 || it_count: 8344 || Val Loss: 0.44948342 || Val it_count: 1107 || Current Learning Rate: 0.0001 || Time: 01:49:1.76
Epoch :: 30 || Loss: 0.41337779 || it_count: 8344 || Val Loss: 0.44922815 || Val it_count: 1107 || Current Learning Rate: 0.0001 || Time: 01:52:47.96
Epoch :: 31 || Loss: 0.41282620 || it_count: 8344 || Val Loss: 0.44917940 || Val it_count: 1107 || Current Learning Rate: 0.0001 || Time: 01:56:34.50
Epoch :: 32 || Loss: 0.41254575 || it_count: 8344 || Val Loss: 0.44862216 || Val it_count: 1107 || Current Learning Rate: 0.0001 || Time: 02:00:20.53
Epoch :: 33 || Loss: 0.41201003 || it_count: 8344 || Val Loss: 0.45067084 || Val it_count: 1107 || Current Learning Rate: 1e-05 || Time: 02:04:3.38
Epoch :: 34 || Loss: 0.41411619 || it_count: 8344 || Val Loss: 0.44247988 || Val it_count: 1107 || Current Learning Rate: 1e-05 || Time: 02:07:47.24
Epoch :: 35 || Loss: 0.41275984 || it_count: 8344 || Val Loss: 0.44225785 || Val it_count: 1107 || Current Learning Rate: 1e-05 || Time: 02:11:34.25
Epoch :: 36 || Loss: 0.41248429 || it_count: 8344 || Val Loss: 0.44178203 || Val it_count: 1107 || Current Learning Rate: 1e-05 || Time: 02:15:20.64
Epoch :: 37 || Loss: 0.41252064 || it_count: 8344 || Val Loss: 0.44143709 || Val it_count: 1107 || Current Learning Rate: 1e-05 || Time: 02:19:5.67
Epoch :: 38 || Loss: 0.41233979 || it_count: 8344 || Val Loss: 0.44148453 || Val it_count: 1107 || Current Learning Rate: 1e-05 || Time: 02:22:51.10
Epoch :: 39 || Loss: 0.41214332 || it_count: 8344 || Val Loss: 0.44113117 || Val it_count: 1107 || Current Learning Rate: 1e-05 || Time: 02:26:36.63
Epoch :: 40 || Loss: 0.41225689 || it_count: 8344 || Val Loss: 0.44098893 || Val it_count: 1107 || Current Learning Rate: 1e-05 || Time: 02:30:22.61
Epoch :: 41 || Loss: 0.41206438 || it_count: 8344 || Val Loss: 0.44122956 || Val it_count: 1107 || Current Learning Rate: 1e-05 || Time: 02:34:8.46
Epoch :: 42 || Loss: 0.41201456 || it_count: 8344 || Val Loss: 0.44103450 || Val it_count: 1107 || Current Learning Rate: 1e-05 || Time: 02:37:53.68
Epoch :: 43 || Loss: 0.41199176 || it_count: 8344 || Val Loss: 0.44068232 || Val it_count: 1107 || Current Learning Rate: 1e-05 || Time: 02:41:40.59
Epoch :: 44 || Loss: 0.41191498 || it_count: 8344 || Val Loss: 0.44114171 || Val it_count: 1107 || Current Learning Rate: 1e-05 || Time: 02:45:26.39
Epoch :: 45 || Loss: 0.41168801 || it_count: 8344 || Val Loss: 0.44153802 || Val it_count: 1107 || Current Learning Rate: 1e-05 || Time: 02:49:11.99
Epoch :: 46 || Loss: 0.41179420 || it_count: 8344 || Val Loss: 0.44114888 || Val it_count: 1107 || Current Learning Rate: 1e-05 || Time: 02:52:57.69
Epoch :: 47 || Loss: 0.41172357 || it_count: 8344 || Val Loss: 0.44147391 || Val it_count: 1107 || Current Learning Rate: 1e-05 || Time: 02:56:42.85
Epoch :: 48 || Loss: 0.41162927 || it_count: 8344 || Val Loss: 0.44147920 || Val it_count: 1107 || Current Learning Rate: 1e-05 || Time: 03:00:27.24
Epoch :: 49 || Loss: 0.41152107 || it_count: 8344 || Val Loss: 0.44124248 || Val it_count: 1107 || Current Learning Rate: 1.0000000000000002e-06 || Time: 03:04:13.42
Epoch :: 50 || Loss: 0.41165603 || it_count: 8344 || Val Loss: 0.43954276 || Val it_count: 1107 || Current Learning Rate: 1.0000000000000002e-06 || Time: 03:07:59.11
Epoch :: 51 || Loss: 0.41166238 || it_count: 8344 || Val Loss: 0.43913877 || Val it_count: 1107 || Current Learning Rate: 1.0000000000000002e-06 || Time: 03:11:42.92
Epoch :: 52 || Loss: 0.41168484 || it_count: 8344 || Val Loss: 0.43896625 || Val it_count: 1107 || Current Learning Rate: 1.0000000000000002e-06 || Time: 03:15:29.02
Epoch :: 53 || Loss: 0.41160637 || it_count: 8344 || Val Loss: 0.43885451 || Val it_count: 1107 || Current Learning Rate: 1.0000000000000002e-06 || Time: 03:19:14.52
Epoch :: 54 || Loss: 0.41148209 || it_count: 8344 || Val Loss: 0.43881053 || Val it_count: 1107 || Current Learning Rate: 1.0000000000000002e-06 || Time: 03:23:1.29
Epoch :: 55 || Loss: 0.41160321 || it_count: 8344 || Val Loss: 0.43873097 || Val it_count: 1107 || Current Learning Rate: 1.0000000000000002e-06 || Time: 03:26:46.43
Epoch :: 56 || Loss: 0.41166995 || it_count: 8344 || Val Loss: 0.43862603 || Val it_count: 1107 || Current Learning Rate: 1.0000000000000002e-06 || Time: 03:30:31.51
Epoch :: 57 || Loss: 0.41147181 || it_count: 8344 || Val Loss: 0.43863243 || Val it_count: 1107 || Current Learning Rate: 1.0000000000000002e-06 || Time: 03:34:17.92
Epoch :: 58 || Loss: 0.41165225 || it_count: 8344 || Val Loss: 0.43857256 || Val it_count: 1107 || Current Learning Rate: 1.0000000000000002e-06 || Time: 03:38:4.12
Epoch :: 59 || Loss: 0.41159318 || it_count: 8344 || Val Loss: 0.43862460 || Val it_count: 1107 || Current Learning Rate: 1.0000000000000002e-06 || Time: 03:41:50.85
Epoch :: 60 || Loss: 0.41152742 || it_count: 8344 || Val Loss: 0.43855956 || Val it_count: 1107 || Current Learning Rate: 1.0000000000000002e-06 || Time: 03:45:37.35
Epoch :: 61 || Loss: 0.41146179 || it_count: 8344 || Val Loss: 0.43859949 || Val it_count: 1107 || Current Learning Rate: 1.0000000000000002e-06 || Time: 03:49:23.13
Epoch :: 62 || Loss: 0.41134385 || it_count: 8344 || Val Loss: 0.43853294 || Val it_count: 1107 || Current Learning Rate: 1.0000000000000002e-06 || Time: 03:53:9.33
Epoch :: 63 || Loss: 0.41151685 || it_count: 8344 || Val Loss: 0.43860419 || Val it_count: 1107 || Current Learning Rate: 1.0000000000000002e-06 || Time: 03:56:56.77
Early stopping triggered due to learning rate below threshold.
Done Total time: 04:00:41.25
best_loss: 0.4385329369302015

--------------------Testing--------------------

total_samples :: test_dataset = 139200, test_dataloader = 139200
Epoch ::  1 || Loss: 0.33868818 || it_count: 544 || Time: 00:00:11.99
MAE:  0.2883533
MSE:  0.33875236
RMSE:  0.4883575

--------------------Training--------------------
arch_str :: |lstm_1~0|+|skip_connect~0|lstm_2~1|[relu->dropout->linear->linear]
model :: 3Q
InferCell(
  info :: nodes=3, inC=1, outC=64, [1<-(I0-L0) | 2<-(I0-L1,I1-L2)], genotype_str: lstm_1~0|skip_connect~0|lstm_2~1
  linear_layers: [relu->dropout->linear->linear]
  (layers): ModuleList(
    (0): LSTM(
      (lstm): LSTM(1, 64, batch_first=True)
    )
    (1): FactorizedReduce(
      C_in=1, C_out=64, stride=1
      (relu): ReLU()
      (conv): Conv1d(1, 64, kernel_size=(1,), stride=(1,), bias=False)
      (bn): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (2): LSTM(
      (lstm): LSTM(64, 64, num_layers=2, batch_first=True)
    )
  )
  (linear_layers): ModuleList(
    (0): ReLU()
    (1): Dropout(p=0.1, inplace=False)
    (2): Linear(in_features=3072, out_features=1536, bias=True)
    (3): Linear(in_features=1536, out_features=1, bias=True)
  )
)
tr_params :: epochs = 100, patience = 20, batch_size = 256, window_size = 48, data_size = 100
Model FLOPs: 8.827M, Model Params: 4.806M
learning rate scheduling :: (optimizer, mode='min', factor=0.1, patience=5, verbose=True)
total_samples :: train_dataset = 2136000, train_dataloader = 2136000
total_samples :: valid_dataset = 283200, valid_dataloader = 283200
Epoch ::  1 || Loss: 0.47065593 || it_count: 8344 || Val Loss: 0.50656170 || Val it_count: 1107 || Current Learning Rate: 0.001 || Time: 00:04:20.15
Epoch ::  2 || Loss: 0.45461054 || it_count: 8344 || Val Loss: 0.48374123 || Val it_count: 1107 || Current Learning Rate: 0.001 || Time: 00:08:33.78
Epoch ::  3 || Loss: 0.46252518 || it_count: 8344 || Val Loss: 0.52104445 || Val it_count: 1107 || Current Learning Rate: 0.001 || Time: 00:12:52.37
Epoch ::  4 || Loss: 0.44849770 || it_count: 8344 || Val Loss: 0.49127155 || Val it_count: 1107 || Current Learning Rate: 0.001 || Time: 00:17:14.05
Epoch ::  5 || Loss: 0.43246256 || it_count: 8344 || Val Loss: 0.48279527 || Val it_count: 1107 || Current Learning Rate: 0.001 || Time: 00:21:34.04
Epoch ::  6 || Loss: 0.42758435 || it_count: 8344 || Val Loss: 0.46529888 || Val it_count: 1107 || Current Learning Rate: 0.001 || Time: 00:25:52.12
Epoch ::  7 || Loss: 0.42573495 || it_count: 8344 || Val Loss: 0.46409278 || Val it_count: 1107 || Current Learning Rate: 0.001 || Time: 00:30:13.55
Epoch ::  8 || Loss: 0.42385918 || it_count: 8344 || Val Loss: 0.46157837 || Val it_count: 1107 || Current Learning Rate: 0.001 || Time: 00:34:31.65
Epoch ::  9 || Loss: 0.42107861 || it_count: 8344 || Val Loss: 0.46917898 || Val it_count: 1107 || Current Learning Rate: 0.001 || Time: 00:38:47.00
Epoch :: 10 || Loss: 0.41779795 || it_count: 8344 || Val Loss: 0.46426278 || Val it_count: 1107 || Current Learning Rate: 0.001 || Time: 00:43:3.32
Epoch :: 11 || Loss: 0.41643437 || it_count: 8344 || Val Loss: 0.46295465 || Val it_count: 1107 || Current Learning Rate: 0.001 || Time: 00:47:24.95
Epoch :: 12 || Loss: 0.41633298 || it_count: 8344 || Val Loss: 0.46236287 || Val it_count: 1107 || Current Learning Rate: 0.001 || Time: 00:51:39.50
Epoch :: 13 || Loss: 0.41607278 || it_count: 8344 || Val Loss: 0.46141518 || Val it_count: 1107 || Current Learning Rate: 0.001 || Time: 00:55:57.89
Epoch :: 14 || Loss: 0.41563878 || it_count: 8344 || Val Loss: 0.46453759 || Val it_count: 1107 || Current Learning Rate: 0.001 || Time: 01:00:19.68
Epoch :: 15 || Loss: 0.41528253 || it_count: 8344 || Val Loss: 0.46356602 || Val it_count: 1107 || Current Learning Rate: 0.001 || Time: 01:04:42.98
Epoch :: 16 || Loss: 0.41560643 || it_count: 8344 || Val Loss: 0.46251789 || Val it_count: 1107 || Current Learning Rate: 0.001 || Time: 01:09:0.57
Epoch :: 17 || Loss: 0.41440712 || it_count: 8344 || Val Loss: 0.46187154 || Val it_count: 1107 || Current Learning Rate: 0.001 || Time: 01:13:12.99
Epoch :: 18 || Loss: 0.41394465 || it_count: 8344 || Val Loss: 0.46060803 || Val it_count: 1107 || Current Learning Rate: 0.001 || Time: 01:17:24.32
Epoch :: 19 || Loss: 0.41335932 || it_count: 8344 || Val Loss: 0.46192386 || Val it_count: 1107 || Current Learning Rate: 0.001 || Time: 01:21:38.70
Epoch :: 20 || Loss: 0.41304148 || it_count: 8344 || Val Loss: 0.46630046 || Val it_count: 1107 || Current Learning Rate: 0.001 || Time: 01:25:56.74
Epoch :: 21 || Loss: 0.41206159 || it_count: 8344 || Val Loss: 0.46101568 || Val it_count: 1107 || Current Learning Rate: 0.001 || Time: 01:30:16.51
Epoch :: 22 || Loss: 0.41213395 || it_count: 8344 || Val Loss: 0.46210356 || Val it_count: 1107 || Current Learning Rate: 0.001 || Time: 01:34:31.82
Epoch :: 23 || Loss: 0.41150458 || it_count: 8344 || Val Loss: 0.46247050 || Val it_count: 1107 || Current Learning Rate: 0.001 || Time: 01:38:46.51
Epoch :: 24 || Loss: 0.41154453 || it_count: 8344 || Val Loss: 0.46926550 || Val it_count: 1107 || Current Learning Rate: 0.0001 || Time: 01:42:57.27
Epoch :: 25 || Loss: 0.41459872 || it_count: 8344 || Val Loss: 0.45732469 || Val it_count: 1107 || Current Learning Rate: 0.0001 || Time: 01:47:19.89
Epoch :: 26 || Loss: 0.41214078 || it_count: 8344 || Val Loss: 0.45487412 || Val it_count: 1107 || Current Learning Rate: 0.0001 || Time: 01:51:40.19
Epoch :: 27 || Loss: 0.41103950 || it_count: 8344 || Val Loss: 0.45949948 || Val it_count: 1107 || Current Learning Rate: 0.0001 || Time: 01:56:3.24
Epoch :: 28 || Loss: 0.41042380 || it_count: 8344 || Val Loss: 0.45756419 || Val it_count: 1107 || Current Learning Rate: 0.0001 || Time: 02:00:19.41
Epoch :: 29 || Loss: 0.41006829 || it_count: 8344 || Val Loss: 0.45960950 || Val it_count: 1107 || Current Learning Rate: 0.0001 || Time: 02:04:43.57
Epoch :: 30 || Loss: 0.40981783 || it_count: 8344 || Val Loss: 0.45645432 || Val it_count: 1107 || Current Learning Rate: 0.0001 || Time: 02:08:57.07
Epoch :: 31 || Loss: 0.40928677 || it_count: 8344 || Val Loss: 0.45655351 || Val it_count: 1107 || Current Learning Rate: 0.0001 || Time: 02:13:5.50
Epoch :: 32 || Loss: 0.40869427 || it_count: 8344 || Val Loss: 0.46065973 || Val it_count: 1107 || Current Learning Rate: 1e-05 || Time: 02:17:17.34
Epoch :: 33 || Loss: 0.41072866 || it_count: 8344 || Val Loss: 0.44781395 || Val it_count: 1107 || Current Learning Rate: 1e-05 || Time: 02:21:35.88
Epoch :: 34 || Loss: 0.40936747 || it_count: 8344 || Val Loss: 0.44925985 || Val it_count: 1107 || Current Learning Rate: 1e-05 || Time: 02:25:48.78
Epoch :: 35 || Loss: 0.40909181 || it_count: 8344 || Val Loss: 0.45060348 || Val it_count: 1107 || Current Learning Rate: 1e-05 || Time: 02:30:4.14
Epoch :: 36 || Loss: 0.40888378 || it_count: 8344 || Val Loss: 0.45134742 || Val it_count: 1107 || Current Learning Rate: 1e-05 || Time: 02:34:26.91
Epoch :: 37 || Loss: 0.40859480 || it_count: 8344 || Val Loss: 0.45154054 || Val it_count: 1107 || Current Learning Rate: 1e-05 || Time: 02:38:39.71
Epoch :: 38 || Loss: 0.40846880 || it_count: 8344 || Val Loss: 0.45160297 || Val it_count: 1107 || Current Learning Rate: 1e-05 || Time: 02:42:58.85
Epoch :: 39 || Loss: 0.40818103 || it_count: 8344 || Val Loss: 0.45182285 || Val it_count: 1107 || Current Learning Rate: 1.0000000000000002e-06 || Time: 02:47:15.57
Epoch :: 40 || Loss: 0.40846385 || it_count: 8344 || Val Loss: 0.44730614 || Val it_count: 1107 || Current Learning Rate: 1.0000000000000002e-06 || Time: 02:51:29.59
Epoch :: 41 || Loss: 0.40812214 || it_count: 8344 || Val Loss: 0.44632408 || Val it_count: 1107 || Current Learning Rate: 1.0000000000000002e-06 || Time: 02:55:40.04
Epoch :: 42 || Loss: 0.40792195 || it_count: 8344 || Val Loss: 0.44607035 || Val it_count: 1107 || Current Learning Rate: 1.0000000000000002e-06 || Time: 02:59:57.31
Epoch :: 43 || Loss: 0.40814526 || it_count: 8344 || Val Loss: 0.44593252 || Val it_count: 1107 || Current Learning Rate: 1.0000000000000002e-06 || Time: 03:04:21.21
Epoch :: 44 || Loss: 0.40810050 || it_count: 8344 || Val Loss: 0.44578633 || Val it_count: 1107 || Current Learning Rate: 1.0000000000000002e-06 || Time: 03:08:40.08
Epoch :: 45 || Loss: 0.40796657 || it_count: 8344 || Val Loss: 0.44584740 || Val it_count: 1107 || Current Learning Rate: 1.0000000000000002e-06 || Time: 03:12:56.87
Epoch :: 46 || Loss: 0.40792920 || it_count: 8344 || Val Loss: 0.44583461 || Val it_count: 1107 || Current Learning Rate: 1.0000000000000002e-06 || Time: 03:17:12.44
Epoch :: 47 || Loss: 0.40788900 || it_count: 8344 || Val Loss: 0.44582174 || Val it_count: 1107 || Current Learning Rate: 1.0000000000000002e-06 || Time: 03:21:25.79
Epoch :: 48 || Loss: 0.40785702 || it_count: 8344 || Val Loss: 0.44579417 || Val it_count: 1107 || Current Learning Rate: 1.0000000000000002e-06 || Time: 03:25:38.17
Epoch :: 49 || Loss: 0.40796823 || it_count: 8344 || Val Loss: 0.44579130 || Val it_count: 1107 || Current Learning Rate: 1.0000000000000002e-06 || Time: 03:29:59.06
Early stopping triggered due to learning rate below threshold.
Done Total time: 03:34:18.24
best_loss: 0.44578633283624725

--------------------Testing--------------------

total_samples :: test_dataset = 139200, test_dataloader = 139200
Epoch ::  1 || Loss: 0.35532545 || it_count: 544 || Time: 00:00:13.24
MAE:  0.29221264
MSE:  0.35540086
RMSE:  0.49384427

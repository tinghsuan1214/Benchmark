--------------------Training--------------------
arch_str :: |skip_connect~0|+|lstm_3~0|none~1|[relu->linear->relu->dropout->linear]
model :: 3P
InferCell(
  info :: nodes=3, inC=1, outC=64, [1<-(I0-L0) | 2<-(I0-L1,I1-L2)], genotype_str: skip_connect~0|lstm_3~0|none~1
  linear_layers: [relu->linear->relu->dropout->linear]
  (layers): ModuleList(
    (0): FactorizedReduce(
      C_in=1, C_out=64, stride=1
      (relu): ReLU()
      (conv): Conv1d(1, 64, kernel_size=(1,), stride=(1,), bias=False)
      (bn): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (1): LSTM(
      (lstm): LSTM(1, 64, num_layers=3, batch_first=True)
    )
    (2): Zero(C_in=64, C_out=64, stride=1)
  )
  (linear_layers): ModuleList(
    (0): ReLU()
    (1): Linear(in_features=3072, out_features=1536, bias=True)
    (2): ReLU()
    (3): Dropout(p=0.1, inplace=False)
    (4): Linear(in_features=1536, out_features=1, bias=True)
  )
)
tr_params :: epochs = 100, patience = 20, batch_size = 256, window_size = 48, data_size = 100
Model FLOPs: 8.827M, Model Params: 4.806M
learning rate scheduling :: (optimizer, mode='min', factor=0.1, patience=5, verbose=True)
total_samples :: train_dataset = 2136000, train_dataloader = 2136000
total_samples :: valid_dataset = 283200, valid_dataloader = 283200
Epoch ::  1 || Loss: 0.42102588 || it_count: 8344 || Val Loss: 0.45141029 || Val it_count: 1107 || Current Learning Rate: 0.001 || Time: 00:08:48.97
Epoch ::  2 || Loss: 0.41501285 || it_count: 8344 || Val Loss: 0.45357962 || Val it_count: 1107 || Current Learning Rate: 0.001 || Time: 00:17:37.72
Epoch ::  3 || Loss: 0.41342535 || it_count: 8344 || Val Loss: 0.45345823 || Val it_count: 1107 || Current Learning Rate: 0.001 || Time: 00:26:25.73
Epoch ::  4 || Loss: 0.41226212 || it_count: 8344 || Val Loss: 0.45361850 || Val it_count: 1107 || Current Learning Rate: 0.001 || Time: 00:35:10.25
Epoch ::  5 || Loss: 0.41109153 || it_count: 8344 || Val Loss: 0.45116302 || Val it_count: 1107 || Current Learning Rate: 0.001 || Time: 00:44:1.67
Epoch ::  6 || Loss: 0.41043854 || it_count: 8344 || Val Loss: 0.45206469 || Val it_count: 1107 || Current Learning Rate: 0.001 || Time: 00:52:52.09
Epoch ::  7 || Loss: 0.40935151 || it_count: 8344 || Val Loss: 0.45253045 || Val it_count: 1107 || Current Learning Rate: 0.001 || Time: 01:01:42.88
Epoch ::  8 || Loss: 0.40853203 || it_count: 8344 || Val Loss: 0.45365096 || Val it_count: 1107 || Current Learning Rate: 0.001 || Time: 01:10:35.14
Epoch ::  9 || Loss: 0.40735109 || it_count: 8344 || Val Loss: 0.45393489 || Val it_count: 1107 || Current Learning Rate: 0.001 || Time: 01:19:25.71
Epoch :: 10 || Loss: 0.40600851 || it_count: 8344 || Val Loss: 0.45328358 || Val it_count: 1107 || Current Learning Rate: 0.001 || Time: 01:28:17.68
Epoch :: 11 || Loss: 0.40447591 || it_count: 8344 || Val Loss: 0.45099920 || Val it_count: 1107 || Current Learning Rate: 0.001 || Time: 01:37:8.50
Epoch :: 12 || Loss: 0.40314148 || it_count: 8344 || Val Loss: 0.44823502 || Val it_count: 1107 || Current Learning Rate: 0.001 || Time: 01:45:55.99
Epoch :: 13 || Loss: 0.40142467 || it_count: 8344 || Val Loss: 0.44753093 || Val it_count: 1107 || Current Learning Rate: 0.001 || Time: 01:54:49.21
Epoch :: 14 || Loss: 0.39928464 || it_count: 8344 || Val Loss: 0.44685785 || Val it_count: 1107 || Current Learning Rate: 0.001 || Time: 02:03:42.17
Epoch :: 15 || Loss: 0.39716541 || it_count: 8344 || Val Loss: 0.44515767 || Val it_count: 1107 || Current Learning Rate: 0.001 || Time: 02:12:34.93
Epoch :: 16 || Loss: 0.39441867 || it_count: 8344 || Val Loss: 0.44423660 || Val it_count: 1107 || Current Learning Rate: 0.001 || Time: 02:21:29.08
Epoch :: 17 || Loss: 0.39130630 || it_count: 8344 || Val Loss: 0.44478935 || Val it_count: 1107 || Current Learning Rate: 0.001 || Time: 02:30:23.79
Epoch :: 18 || Loss: 0.38796449 || it_count: 8344 || Val Loss: 0.44585792 || Val it_count: 1107 || Current Learning Rate: 0.001 || Time: 02:39:17.87
Epoch :: 19 || Loss: 0.38459895 || it_count: 8344 || Val Loss: 0.45053923 || Val it_count: 1107 || Current Learning Rate: 0.001 || Time: 02:48:12.16
Epoch :: 20 || Loss: 0.38105669 || it_count: 8344 || Val Loss: 0.45409699 || Val it_count: 1107 || Current Learning Rate: 0.001 || Time: 02:57:3.44
Epoch :: 21 || Loss: 0.37760883 || it_count: 8344 || Val Loss: 0.46437107 || Val it_count: 1107 || Current Learning Rate: 0.001 || Time: 03:05:59.95
Epoch :: 22 || Loss: 0.37422625 || it_count: 8344 || Val Loss: 0.46955927 || Val it_count: 1107 || Current Learning Rate: 0.001 || Time: 03:14:55.10
Epoch 00007: reducing learning rate of group 0 to 1.0000e-04.
Epoch :: 23 || Loss: 0.37070452 || it_count: 8344 || Val Loss: 0.47444775 || Val it_count: 1107 || Current Learning Rate: 0.0001 || Time: 03:23:48.42
Epoch :: 24 || Loss: 0.39800349 || it_count: 8344 || Val Loss: 0.44605707 || Val it_count: 1107 || Current Learning Rate: 0.0001 || Time: 03:32:43.59
Epoch :: 25 || Loss: 0.38903701 || it_count: 8344 || Val Loss: 0.44538392 || Val it_count: 1107 || Current Learning Rate: 0.0001 || Time: 03:41:36.15
Epoch :: 26 || Loss: 0.38423849 || it_count: 8344 || Val Loss: 0.44613228 || Val it_count: 1107 || Current Learning Rate: 0.0001 || Time: 03:50:29.56
Epoch :: 27 || Loss: 0.38076320 || it_count: 8344 || Val Loss: 0.44642440 || Val it_count: 1107 || Current Learning Rate: 0.0001 || Time: 03:59:24.01
Epoch :: 28 || Loss: 0.37741068 || it_count: 8344 || Val Loss: 0.44716955 || Val it_count: 1107 || Current Learning Rate: 0.0001 || Time: 04:08:14.09
Epoch 00013: reducing learning rate of group 0 to 1.0000e-05.
Epoch :: 29 || Loss: 0.37442395 || it_count: 8344 || Val Loss: 0.44827759 || Val it_count: 1107 || Current Learning Rate: 1e-05 || Time: 04:17:9.53
Epoch :: 30 || Loss: 0.39695224 || it_count: 8344 || Val Loss: 0.42839685 || Val it_count: 1107 || Current Learning Rate: 1e-05 || Time: 04:26:5.37
Epoch :: 31 || Loss: 0.39273788 || it_count: 8344 || Val Loss: 0.42718800 || Val it_count: 1107 || Current Learning Rate: 1e-05 || Time: 04:35:0.55
Epoch :: 32 || Loss: 0.39160155 || it_count: 8344 || Val Loss: 0.42664638 || Val it_count: 1107 || Current Learning Rate: 1e-05 || Time: 04:43:55.36
Epoch :: 33 || Loss: 0.39082354 || it_count: 8344 || Val Loss: 0.42637510 || Val it_count: 1107 || Current Learning Rate: 1e-05 || Time: 04:52:49.78
Epoch :: 34 || Loss: 0.39015151 || it_count: 8344 || Val Loss: 0.42645619 || Val it_count: 1107 || Current Learning Rate: 1e-05 || Time: 05:01:44.45
Epoch :: 35 || Loss: 0.38954865 || it_count: 8344 || Val Loss: 0.42643181 || Val it_count: 1107 || Current Learning Rate: 1e-05 || Time: 05:10:38.82
Epoch :: 36 || Loss: 0.38902454 || it_count: 8344 || Val Loss: 0.42667888 || Val it_count: 1107 || Current Learning Rate: 1e-05 || Time: 05:19:28.44
Epoch :: 37 || Loss: 0.38866599 || it_count: 8344 || Val Loss: 0.42669696 || Val it_count: 1107 || Current Learning Rate: 1e-05 || Time: 05:28:24.64
Epoch :: 38 || Loss: 0.38798133 || it_count: 8344 || Val Loss: 0.42676899 || Val it_count: 1107 || Current Learning Rate: 1e-05 || Time: 05:37:19.16
Epoch 00023: reducing learning rate of group 0 to 1.0000e-06.
Epoch :: 39 || Loss: 0.38752048 || it_count: 8344 || Val Loss: 0.42680872 || Val it_count: 1107 || Current Learning Rate: 1.0000000000000002e-06 || Time: 05:46:14.33
Epoch :: 40 || Loss: 0.39114515 || it_count: 8344 || Val Loss: 0.42513517 || Val it_count: 1107 || Current Learning Rate: 1.0000000000000002e-06 || Time: 05:55:8.16
Epoch :: 41 || Loss: 0.39055108 || it_count: 8344 || Val Loss: 0.42474762 || Val it_count: 1107 || Current Learning Rate: 1.0000000000000002e-06 || Time: 06:04:2.00
Epoch :: 42 || Loss: 0.39023387 || it_count: 8344 || Val Loss: 0.42452049 || Val it_count: 1107 || Current Learning Rate: 1.0000000000000002e-06 || Time: 06:12:57.18
Epoch :: 43 || Loss: 0.38996500 || it_count: 8344 || Val Loss: 0.42438538 || Val it_count: 1107 || Current Learning Rate: 1.0000000000000002e-06 || Time: 06:21:50.82
Epoch :: 44 || Loss: 0.38977189 || it_count: 8344 || Val Loss: 0.42431700 || Val it_count: 1107 || Current Learning Rate: 1.0000000000000002e-06 || Time: 06:30:40.63
Epoch :: 45 || Loss: 0.38982990 || it_count: 8344 || Val Loss: 0.42424173 || Val it_count: 1107 || Current Learning Rate: 1.0000000000000002e-06 || Time: 06:39:36.87
Epoch :: 46 || Loss: 0.38974380 || it_count: 8344 || Val Loss: 0.42419211 || Val it_count: 1107 || Current Learning Rate: 1.0000000000000002e-06 || Time: 06:48:31.47
Epoch :: 47 || Loss: 0.38955361 || it_count: 8344 || Val Loss: 0.42417906 || Val it_count: 1107 || Current Learning Rate: 1.0000000000000002e-06 || Time: 06:57:26.51
Epoch :: 48 || Loss: 0.38965276 || it_count: 8344 || Val Loss: 0.42413106 || Val it_count: 1107 || Current Learning Rate: 1.0000000000000002e-06 || Time: 07:06:21.75
Epoch :: 49 || Loss: 0.38939796 || it_count: 8344 || Val Loss: 0.42409443 || Val it_count: 1107 || Current Learning Rate: 1.0000000000000002e-06 || Time: 07:15:15.42
Epoch :: 50 || Loss: 0.38955666 || it_count: 8344 || Val Loss: 0.42404087 || Val it_count: 1107 || Current Learning Rate: 1.0000000000000002e-06 || Time: 07:24:11.17
Epoch :: 51 || Loss: 0.38946687 || it_count: 8344 || Val Loss: 0.42404113 || Val it_count: 1107 || Current Learning Rate: 1.0000000000000002e-06 || Time: 07:33:5.19
Epoch :: 52 || Loss: 0.38940859 || it_count: 8344 || Val Loss: 0.42398810 || Val it_count: 1107 || Current Learning Rate: 1.0000000000000002e-06 || Time: 07:41:56.38
Epoch :: 53 || Loss: 0.38927496 || it_count: 8344 || Val Loss: 0.42397266 || Val it_count: 1107 || Current Learning Rate: 1.0000000000000002e-06 || Time: 07:50:52.62
Epoch :: 54 || Loss: 0.38928456 || it_count: 8344 || Val Loss: 0.42397400 || Val it_count: 1107 || Current Learning Rate: 1.0000000000000002e-06 || Time: 07:59:48.40
Epoch :: 55 || Loss: 0.38918414 || it_count: 8344 || Val Loss: 0.42394773 || Val it_count: 1107 || Current Learning Rate: 1.0000000000000002e-06 || Time: 08:08:42.07
Epoch :: 56 || Loss: 0.38908626 || it_count: 8344 || Val Loss: 0.42394641 || Val it_count: 1107 || Current Learning Rate: 1.0000000000000002e-06 || Time: 08:17:36.88
Epoch :: 57 || Loss: 0.38904166 || it_count: 8344 || Val Loss: 0.42395365 || Val it_count: 1107 || Current Learning Rate: 1.0000000000000002e-06 || Time: 08:26:30.97
Epoch :: 58 || Loss: 0.38892756 || it_count: 8344 || Val Loss: 0.42394156 || Val it_count: 1107 || Current Learning Rate: 1.0000000000000002e-06 || Time: 08:35:25.70
Epoch :: 59 || Loss: 0.38899930 || it_count: 8344 || Val Loss: 0.42392633 || Val it_count: 1107 || Current Learning Rate: 1.0000000000000002e-06 || Time: 08:44:20.71
Epoch :: 60 || Loss: 0.38898769 || it_count: 8344 || Val Loss: 0.42388263 || Val it_count: 1107 || Current Learning Rate: 1.0000000000000002e-06 || Time: 08:53:10.18
Epoch :: 61 || Loss: 0.38889312 || it_count: 8344 || Val Loss: 0.42386592 || Val it_count: 1107 || Current Learning Rate: 1.0000000000000002e-06 || Time: 09:02:5.87
Epoch :: 62 || Loss: 0.38887653 || it_count: 8344 || Val Loss: 0.42389413 || Val it_count: 1107 || Current Learning Rate: 1.0000000000000002e-06 || Time: 09:11:1.67
Epoch :: 63 || Loss: 0.38880518 || it_count: 8344 || Val Loss: 0.42387610 || Val it_count: 1107 || Current Learning Rate: 1.0000000000000002e-06 || Time: 09:19:56.65
Epoch :: 64 || Loss: 0.38879013 || it_count: 8344 || Val Loss: 0.42386047 || Val it_count: 1107 || Current Learning Rate: 1.0000000000000002e-06 || Time: 09:28:50.82
Epoch :: 65 || Loss: 0.38862721 || it_count: 8344 || Val Loss: 0.42385440 || Val it_count: 1107 || Current Learning Rate: 1.0000000000000002e-06 || Time: 09:37:44.14
Epoch 00050: reducing learning rate of group 0 to 1.0000e-07.
Early stopping triggered due to learning rate below threshold.
Done Total time: 09:46:38.09
best_loss: 0.4238544045574341

--------------------Testing--------------------

total_samples :: test_dataset = 139200, test_dataloader = 139200
Epoch ::  1 || Loss: 0.25554066 || it_count: 544 || Time: 00:00:24.61
MAE:  0.26223728
MSE:  0.25554684
RMSE:  0.45749244

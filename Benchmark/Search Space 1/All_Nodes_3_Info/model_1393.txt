--------------------Training--------------------
arch_str :: |skip_connect~0|+|lstm_1~0|none~1|[dropout->linear->relu->dropout->linear]
model :: 3L
InferCell(
  info :: nodes=3, inC=1, outC=64, [1<-(I0-L0) | 2<-(I0-L1,I1-L2)], genotype_str: skip_connect~0|lstm_1~0|none~1
  linear_layers: [dropout->linear->relu->dropout->linear]
  (layers): ModuleList(
    (0): FactorizedReduce(
      C_in=1, C_out=64, stride=1
      (relu): ReLU()
      (conv): Conv1d(1, 64, kernel_size=(1,), stride=(1,), bias=False)
      (bn): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (1): LSTM(
      (lstm): LSTM(1, 64, batch_first=True)
    )
    (2): Zero(C_in=64, C_out=64, stride=1)
  )
  (linear_layers): ModuleList(
    (0): Dropout(p=0.1, inplace=False)
    (1): Linear(in_features=3072, out_features=1536, bias=True)
    (2): ReLU()
    (3): Dropout(p=0.1, inplace=False)
    (4): Linear(in_features=1536, out_features=1, bias=True)
  )
)
tr_params :: epochs = 100, patience = 20, batch_size = 256, window_size = 48, data_size = 100
Model FLOPs: 5.583M, Model Params: 4.739M
learning rate scheduling :: (optimizer, mode='min', factor=0.1, patience=5, verbose=True)
total_samples :: train_dataset = 2136000, train_dataloader = 2136000
total_samples :: valid_dataset = 283200, valid_dataloader = 283200
Epoch ::  1 || Loss: 0.41809026 || it_count: 8344 || Val Loss: 0.44805220 || Val it_count: 1107 || Current Learning Rate: 0.001 || Time: 00:03:33.70
Epoch ::  2 || Loss: 0.41492981 || it_count: 8344 || Val Loss: 0.44689503 || Val it_count: 1107 || Current Learning Rate: 0.001 || Time: 00:07:1.44
Epoch ::  3 || Loss: 0.41388837 || it_count: 8344 || Val Loss: 0.44843233 || Val it_count: 1107 || Current Learning Rate: 0.001 || Time: 00:10:30.10
Epoch ::  4 || Loss: 0.41305002 || it_count: 8344 || Val Loss: 0.44728601 || Val it_count: 1107 || Current Learning Rate: 0.001 || Time: 00:13:58.68
Epoch ::  5 || Loss: 0.41198942 || it_count: 8344 || Val Loss: 0.44588017 || Val it_count: 1107 || Current Learning Rate: 0.001 || Time: 00:17:27.87
Epoch ::  6 || Loss: 0.41101085 || it_count: 8344 || Val Loss: 0.44663292 || Val it_count: 1107 || Current Learning Rate: 0.001 || Time: 00:20:55.48
Epoch ::  7 || Loss: 0.41029411 || it_count: 8344 || Val Loss: 0.44544470 || Val it_count: 1107 || Current Learning Rate: 0.001 || Time: 00:24:24.76
Epoch ::  8 || Loss: 0.40959461 || it_count: 8344 || Val Loss: 0.44561408 || Val it_count: 1107 || Current Learning Rate: 0.001 || Time: 00:27:53.96
Epoch ::  9 || Loss: 0.40898452 || it_count: 8344 || Val Loss: 0.44684607 || Val it_count: 1107 || Current Learning Rate: 0.001 || Time: 00:31:22.64
Epoch :: 10 || Loss: 0.40813198 || it_count: 8344 || Val Loss: 0.44380308 || Val it_count: 1107 || Current Learning Rate: 0.001 || Time: 00:34:52.26
Epoch :: 11 || Loss: 0.40760619 || it_count: 8344 || Val Loss: 0.44486123 || Val it_count: 1107 || Current Learning Rate: 0.001 || Time: 00:38:21.14
Epoch :: 12 || Loss: 0.40713659 || it_count: 8344 || Val Loss: 0.44649943 || Val it_count: 1107 || Current Learning Rate: 0.001 || Time: 00:41:52.45
Epoch :: 13 || Loss: 0.40660914 || it_count: 8344 || Val Loss: 0.44741775 || Val it_count: 1107 || Current Learning Rate: 0.001 || Time: 00:45:23.05
Epoch :: 14 || Loss: 0.40568663 || it_count: 8344 || Val Loss: 0.44508892 || Val it_count: 1107 || Current Learning Rate: 0.001 || Time: 00:48:53.57
Epoch :: 15 || Loss: 0.40498097 || it_count: 8344 || Val Loss: 0.44703302 || Val it_count: 1107 || Current Learning Rate: 0.001 || Time: 00:52:25.35
Epoch :: 16 || Loss: 0.40445985 || it_count: 8344 || Val Loss: 0.44672774 || Val it_count: 1107 || Current Learning Rate: 0.001 || Time: 00:55:57.66
Epoch :: 17 || Loss: 0.40376650 || it_count: 8344 || Val Loss: 0.44739626 || Val it_count: 1107 || Current Learning Rate: 0.001 || Time: 00:59:28.15
Epoch :: 18 || Loss: 0.40321231 || it_count: 8344 || Val Loss: 0.44603122 || Val it_count: 1107 || Current Learning Rate: 0.001 || Time: 01:02:57.40
Epoch :: 19 || Loss: 0.40243362 || it_count: 8344 || Val Loss: 0.44490566 || Val it_count: 1107 || Current Learning Rate: 0.001 || Time: 01:06:26.34
Epoch :: 20 || Loss: 0.40178240 || it_count: 8344 || Val Loss: 0.44691568 || Val it_count: 1107 || Current Learning Rate: 0.001 || Time: 01:09:55.69
Epoch :: 21 || Loss: 0.40123819 || it_count: 8344 || Val Loss: 0.44667540 || Val it_count: 1107 || Current Learning Rate: 0.001 || Time: 01:13:26.88
Epoch :: 22 || Loss: 0.40049992 || it_count: 8344 || Val Loss: 0.44893143 || Val it_count: 1107 || Current Learning Rate: 0.001 || Time: 01:16:57.40
Epoch :: 23 || Loss: 0.39999623 || it_count: 8344 || Val Loss: 0.44691426 || Val it_count: 1107 || Current Learning Rate: 0.001 || Time: 01:20:27.71
Epoch :: 24 || Loss: 0.39900182 || it_count: 8344 || Val Loss: 0.44708298 || Val it_count: 1107 || Current Learning Rate: 0.001 || Time: 01:23:55.91
Epoch :: 25 || Loss: 0.39863466 || it_count: 8344 || Val Loss: 0.44627070 || Val it_count: 1107 || Current Learning Rate: 0.0001 || Time: 01:27:25.72
Epoch :: 26 || Loss: 0.40633711 || it_count: 8344 || Val Loss: 0.42112929 || Val it_count: 1107 || Current Learning Rate: 0.0001 || Time: 01:30:56.41
Epoch :: 27 || Loss: 0.40266773 || it_count: 8344 || Val Loss: 0.42005458 || Val it_count: 1107 || Current Learning Rate: 0.0001 || Time: 01:34:26.49
Epoch :: 28 || Loss: 0.40126532 || it_count: 8344 || Val Loss: 0.41986713 || Val it_count: 1107 || Current Learning Rate: 0.0001 || Time: 01:37:56.66
Epoch :: 29 || Loss: 0.40025433 || it_count: 8344 || Val Loss: 0.42001914 || Val it_count: 1107 || Current Learning Rate: 0.0001 || Time: 01:41:27.23
Epoch :: 30 || Loss: 0.39958067 || it_count: 8344 || Val Loss: 0.42016246 || Val it_count: 1107 || Current Learning Rate: 0.0001 || Time: 01:44:57.52
Epoch :: 31 || Loss: 0.39890185 || it_count: 8344 || Val Loss: 0.42062866 || Val it_count: 1107 || Current Learning Rate: 0.0001 || Time: 01:48:27.21
Epoch :: 32 || Loss: 0.39839177 || it_count: 8344 || Val Loss: 0.42031665 || Val it_count: 1107 || Current Learning Rate: 0.0001 || Time: 01:51:57.06
Epoch :: 33 || Loss: 0.39773400 || it_count: 8344 || Val Loss: 0.42073073 || Val it_count: 1107 || Current Learning Rate: 0.0001 || Time: 01:55:28.01
Epoch :: 34 || Loss: 0.39717945 || it_count: 8344 || Val Loss: 0.42129628 || Val it_count: 1107 || Current Learning Rate: 1e-05 || Time: 01:58:57.05
Epoch :: 35 || Loss: 0.40217921 || it_count: 8344 || Val Loss: 0.41491951 || Val it_count: 1107 || Current Learning Rate: 1e-05 || Time: 02:02:27.79
Epoch :: 36 || Loss: 0.39990401 || it_count: 8344 || Val Loss: 0.41481175 || Val it_count: 1107 || Current Learning Rate: 1e-05 || Time: 02:05:59.00
Epoch :: 37 || Loss: 0.39964554 || it_count: 8344 || Val Loss: 0.41472270 || Val it_count: 1107 || Current Learning Rate: 1e-05 || Time: 02:09:29.05
Epoch :: 38 || Loss: 0.39930750 || it_count: 8344 || Val Loss: 0.41468393 || Val it_count: 1107 || Current Learning Rate: 1e-05 || Time: 02:13:4.49
Epoch :: 39 || Loss: 0.39931264 || it_count: 8344 || Val Loss: 0.41464248 || Val it_count: 1107 || Current Learning Rate: 1e-05 || Time: 02:16:41.10
Epoch :: 40 || Loss: 0.39911981 || it_count: 8344 || Val Loss: 0.41462565 || Val it_count: 1107 || Current Learning Rate: 1e-05 || Time: 02:20:18.18
Epoch :: 41 || Loss: 0.39900677 || it_count: 8344 || Val Loss: 0.41462289 || Val it_count: 1107 || Current Learning Rate: 1e-05 || Time: 02:23:56.44
Epoch :: 42 || Loss: 0.39890334 || it_count: 8344 || Val Loss: 0.41468208 || Val it_count: 1107 || Current Learning Rate: 1e-05 || Time: 02:27:33.96
Epoch :: 43 || Loss: 0.39889511 || it_count: 8344 || Val Loss: 0.41469950 || Val it_count: 1107 || Current Learning Rate: 1e-05 || Time: 02:31:12.75
Epoch :: 44 || Loss: 0.39876342 || it_count: 8344 || Val Loss: 0.41474322 || Val it_count: 1107 || Current Learning Rate: 1e-05 || Time: 02:34:47.21
Epoch :: 45 || Loss: 0.39872645 || it_count: 8344 || Val Loss: 0.41468843 || Val it_count: 1107 || Current Learning Rate: 1.0000000000000002e-06 || Time: 02:38:23.23
Epoch :: 46 || Loss: 0.39901228 || it_count: 8344 || Val Loss: 0.41450375 || Val it_count: 1107 || Current Learning Rate: 1.0000000000000002e-06 || Time: 02:41:59.45
Epoch :: 47 || Loss: 0.39879106 || it_count: 8344 || Val Loss: 0.41456876 || Val it_count: 1107 || Current Learning Rate: 1.0000000000000002e-06 || Time: 02:45:35.83
Epoch :: 48 || Loss: 0.39876927 || it_count: 8344 || Val Loss: 0.41461264 || Val it_count: 1107 || Current Learning Rate: 1.0000000000000002e-06 || Time: 02:49:13.36
Epoch :: 49 || Loss: 0.39868594 || it_count: 8344 || Val Loss: 0.41463811 || Val it_count: 1107 || Current Learning Rate: 1.0000000000000002e-06 || Time: 02:52:49.60
Epoch :: 50 || Loss: 0.39869806 || it_count: 8344 || Val Loss: 0.41463908 || Val it_count: 1107 || Current Learning Rate: 1.0000000000000002e-06 || Time: 02:56:25.67
Epoch :: 51 || Loss: 0.39865901 || it_count: 8344 || Val Loss: 0.41462212 || Val it_count: 1107 || Current Learning Rate: 1.0000000000000002e-06 || Time: 03:00:2.56
Early stopping triggered due to learning rate below threshold.
Done Total time: 03:03:38.95
best_loss: 0.41450374735236767

--------------------Testing--------------------

total_samples :: test_dataset = 139200, test_dataloader = 139200
Epoch ::  1 || Loss: 0.23914126 || it_count: 544 || Time: 00:00:11.80
MAE:  0.25306526
MSE:  0.23915824
RMSE:  0.4445578

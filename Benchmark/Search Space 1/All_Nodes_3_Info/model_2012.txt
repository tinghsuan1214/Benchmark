--------------------Training--------------------
arch_str :: |lstm_2~0|+|none~0|lstm_2~1|[relu->dropout->linear->linear]
model :: 3Q
InferCell(
  info :: nodes=3, inC=1, outC=64, [1<-(I0-L0) | 2<-(I0-L1,I1-L2)], genotype_str: lstm_2~0|none~0|lstm_2~1
  linear_layers: [relu->dropout->linear->linear]
  (layers): ModuleList(
    (0): LSTM(
      (lstm): LSTM(1, 64, num_layers=2, batch_first=True)
    )
    (1): Zero(C_in=1, C_out=64, stride=1)
    (2): LSTM(
      (lstm): LSTM(64, 64, num_layers=2, batch_first=True)
    )
  )
  (linear_layers): ModuleList(
    (0): ReLU()
    (1): Dropout(p=0.1, inplace=False)
    (2): Linear(in_features=3072, out_features=1536, bias=True)
    (3): Linear(in_features=1536, out_features=1, bias=True)
  )
)
tr_params :: epochs = 100, patience = 20, batch_size = 256, window_size = 48, data_size = 100
Model FLOPs: 10.434M, Model Params: 4.839M
learning rate scheduling :: (optimizer, mode='min', factor=0.1, patience=5, verbose=True)
total_samples :: train_dataset = 2136000, train_dataloader = 2136000
total_samples :: valid_dataset = 283200, valid_dataloader = 283200
Epoch ::  1 || Loss: 0.42868483 || it_count: 8344 || Val Loss: 0.45773091 || Val it_count: 1107 || Current Learning Rate: 0.001 || Time: 00:04:15.43
Epoch ::  2 || Loss: 0.42046339 || it_count: 8344 || Val Loss: 0.45451509 || Val it_count: 1107 || Current Learning Rate: 0.001 || Time: 00:08:28.25
Epoch ::  3 || Loss: 0.41945397 || it_count: 8344 || Val Loss: 0.45588916 || Val it_count: 1107 || Current Learning Rate: 0.001 || Time: 00:12:39.08
Epoch ::  4 || Loss: 0.41922218 || it_count: 8344 || Val Loss: 0.45534564 || Val it_count: 1107 || Current Learning Rate: 0.001 || Time: 00:16:51.18
Epoch ::  5 || Loss: 0.41855461 || it_count: 8344 || Val Loss: 0.45439222 || Val it_count: 1107 || Current Learning Rate: 0.001 || Time: 00:21:4.33
Epoch ::  6 || Loss: 0.41823607 || it_count: 8344 || Val Loss: 0.45468634 || Val it_count: 1107 || Current Learning Rate: 0.001 || Time: 00:25:18.44
Epoch ::  7 || Loss: 0.41796268 || it_count: 8344 || Val Loss: 0.45216306 || Val it_count: 1107 || Current Learning Rate: 0.001 || Time: 00:29:33.62
Epoch ::  8 || Loss: 0.41768241 || it_count: 8344 || Val Loss: 0.45325833 || Val it_count: 1107 || Current Learning Rate: 0.001 || Time: 00:33:45.75
Epoch ::  9 || Loss: 0.41737208 || it_count: 8344 || Val Loss: 0.45379704 || Val it_count: 1107 || Current Learning Rate: 0.001 || Time: 00:37:59.72
Epoch :: 10 || Loss: 0.41705523 || it_count: 8344 || Val Loss: 0.45275246 || Val it_count: 1107 || Current Learning Rate: 0.001 || Time: 00:42:13.62
Epoch :: 11 || Loss: 0.41695647 || it_count: 8344 || Val Loss: 0.45133713 || Val it_count: 1107 || Current Learning Rate: 0.001 || Time: 00:46:25.78
Epoch :: 12 || Loss: 0.41683640 || it_count: 8344 || Val Loss: 0.45255789 || Val it_count: 1107 || Current Learning Rate: 0.001 || Time: 00:50:39.92
Epoch :: 13 || Loss: 0.41658594 || it_count: 8344 || Val Loss: 0.45374886 || Val it_count: 1107 || Current Learning Rate: 0.001 || Time: 00:54:53.21
Epoch :: 14 || Loss: 0.41617846 || it_count: 8344 || Val Loss: 0.45413552 || Val it_count: 1107 || Current Learning Rate: 0.001 || Time: 00:59:8.90
Epoch :: 15 || Loss: 0.41562917 || it_count: 8344 || Val Loss: 0.45061418 || Val it_count: 1107 || Current Learning Rate: 0.001 || Time: 01:03:26.80
Epoch :: 16 || Loss: 0.41526529 || it_count: 8344 || Val Loss: 0.45326984 || Val it_count: 1107 || Current Learning Rate: 0.001 || Time: 01:07:39.88
Epoch :: 17 || Loss: 0.41512333 || it_count: 8344 || Val Loss: 0.45243834 || Val it_count: 1107 || Current Learning Rate: 0.001 || Time: 01:11:50.37
Epoch :: 18 || Loss: 0.41422014 || it_count: 8344 || Val Loss: 0.45049278 || Val it_count: 1107 || Current Learning Rate: 0.001 || Time: 01:16:1.95
Epoch :: 19 || Loss: 0.41365804 || it_count: 8344 || Val Loss: 0.45054789 || Val it_count: 1107 || Current Learning Rate: 0.001 || Time: 01:20:21.80
Epoch :: 20 || Loss: 0.41277751 || it_count: 8344 || Val Loss: 0.45330177 || Val it_count: 1107 || Current Learning Rate: 0.001 || Time: 01:24:32.87
Epoch :: 21 || Loss: 0.41225147 || it_count: 8344 || Val Loss: 0.45343898 || Val it_count: 1107 || Current Learning Rate: 0.001 || Time: 01:28:43.69
Epoch :: 22 || Loss: 0.41175508 || it_count: 8344 || Val Loss: 0.45155332 || Val it_count: 1107 || Current Learning Rate: 0.001 || Time: 01:32:54.89
Epoch :: 23 || Loss: 0.41146862 || it_count: 8344 || Val Loss: 0.45195071 || Val it_count: 1107 || Current Learning Rate: 0.001 || Time: 01:37:9.14
Epoch :: 24 || Loss: 0.41074007 || it_count: 8344 || Val Loss: 0.45120247 || Val it_count: 1107 || Current Learning Rate: 0.0001 || Time: 01:41:25.85
Epoch :: 25 || Loss: 0.41562249 || it_count: 8344 || Val Loss: 0.43263821 || Val it_count: 1107 || Current Learning Rate: 0.0001 || Time: 01:45:39.72
Epoch :: 26 || Loss: 0.41328788 || it_count: 8344 || Val Loss: 0.43087697 || Val it_count: 1107 || Current Learning Rate: 0.0001 || Time: 01:49:52.66
Epoch :: 27 || Loss: 0.41255943 || it_count: 8344 || Val Loss: 0.43020140 || Val it_count: 1107 || Current Learning Rate: 0.0001 || Time: 01:54:4.10
Epoch :: 28 || Loss: 0.41192192 || it_count: 8344 || Val Loss: 0.42999185 || Val it_count: 1107 || Current Learning Rate: 0.0001 || Time: 01:58:17.60
Epoch :: 29 || Loss: 0.41161924 || it_count: 8344 || Val Loss: 0.42956710 || Val it_count: 1107 || Current Learning Rate: 0.0001 || Time: 02:02:31.52
Epoch :: 30 || Loss: 0.41123677 || it_count: 8344 || Val Loss: 0.42896714 || Val it_count: 1107 || Current Learning Rate: 0.0001 || Time: 02:06:43.88
Epoch :: 31 || Loss: 0.41085262 || it_count: 8344 || Val Loss: 0.42889242 || Val it_count: 1107 || Current Learning Rate: 0.0001 || Time: 02:11:0.35
Epoch :: 32 || Loss: 0.41057985 || it_count: 8344 || Val Loss: 0.42884888 || Val it_count: 1107 || Current Learning Rate: 0.0001 || Time: 02:15:13.81
Epoch :: 33 || Loss: 0.41032643 || it_count: 8344 || Val Loss: 0.42834136 || Val it_count: 1107 || Current Learning Rate: 0.0001 || Time: 02:19:27.06
Epoch :: 34 || Loss: 0.41013386 || it_count: 8344 || Val Loss: 0.42833269 || Val it_count: 1107 || Current Learning Rate: 0.0001 || Time: 02:23:40.94
Epoch :: 35 || Loss: 0.40982337 || it_count: 8344 || Val Loss: 0.42807369 || Val it_count: 1107 || Current Learning Rate: 0.0001 || Time: 02:27:56.90
Epoch :: 36 || Loss: 0.40952546 || it_count: 8344 || Val Loss: 0.42844511 || Val it_count: 1107 || Current Learning Rate: 0.0001 || Time: 02:32:9.61
Epoch :: 37 || Loss: 0.40924730 || it_count: 8344 || Val Loss: 0.42837927 || Val it_count: 1107 || Current Learning Rate: 0.0001 || Time: 02:36:23.37
Epoch :: 38 || Loss: 0.40891587 || it_count: 8344 || Val Loss: 0.42825801 || Val it_count: 1107 || Current Learning Rate: 0.0001 || Time: 02:40:35.26
Epoch :: 39 || Loss: 0.40872694 || it_count: 8344 || Val Loss: 0.42802824 || Val it_count: 1107 || Current Learning Rate: 0.0001 || Time: 02:44:51.74
Epoch :: 40 || Loss: 0.40838236 || it_count: 8344 || Val Loss: 0.42804144 || Val it_count: 1107 || Current Learning Rate: 0.0001 || Time: 02:49:4.24
Epoch :: 41 || Loss: 0.40816276 || it_count: 8344 || Val Loss: 0.42851062 || Val it_count: 1107 || Current Learning Rate: 0.0001 || Time: 02:53:14.53
Epoch :: 42 || Loss: 0.40797521 || it_count: 8344 || Val Loss: 0.42884550 || Val it_count: 1107 || Current Learning Rate: 0.0001 || Time: 02:57:32.46
Epoch :: 43 || Loss: 0.40789923 || it_count: 8344 || Val Loss: 0.42846985 || Val it_count: 1107 || Current Learning Rate: 0.0001 || Time: 03:01:46.67
Epoch :: 44 || Loss: 0.40756502 || it_count: 8344 || Val Loss: 0.42927562 || Val it_count: 1107 || Current Learning Rate: 0.0001 || Time: 03:06:4.60
Epoch :: 45 || Loss: 0.40741065 || it_count: 8344 || Val Loss: 0.42894226 || Val it_count: 1107 || Current Learning Rate: 1e-05 || Time: 03:10:22.01
Epoch :: 46 || Loss: 0.41216749 || it_count: 8344 || Val Loss: 0.41428858 || Val it_count: 1107 || Current Learning Rate: 1e-05 || Time: 03:14:38.61
Epoch :: 47 || Loss: 0.40959224 || it_count: 8344 || Val Loss: 0.41341724 || Val it_count: 1107 || Current Learning Rate: 1e-05 || Time: 03:18:53.60
Epoch :: 48 || Loss: 0.40932414 || it_count: 8344 || Val Loss: 0.41325792 || Val it_count: 1107 || Current Learning Rate: 1e-05 || Time: 03:23:5.94
Epoch :: 49 || Loss: 0.40925114 || it_count: 8344 || Val Loss: 0.41321270 || Val it_count: 1107 || Current Learning Rate: 1e-05 || Time: 03:27:15.03
Epoch :: 50 || Loss: 0.40906939 || it_count: 8344 || Val Loss: 0.41326999 || Val it_count: 1107 || Current Learning Rate: 1e-05 || Time: 03:31:29.91
Epoch :: 51 || Loss: 0.40896258 || it_count: 8344 || Val Loss: 0.41324784 || Val it_count: 1107 || Current Learning Rate: 1e-05 || Time: 03:35:44.98
Epoch :: 52 || Loss: 0.40897562 || it_count: 8344 || Val Loss: 0.41320401 || Val it_count: 1107 || Current Learning Rate: 1e-05 || Time: 03:39:57.19
Epoch :: 53 || Loss: 0.40881595 || it_count: 8344 || Val Loss: 0.41326008 || Val it_count: 1107 || Current Learning Rate: 1e-05 || Time: 03:44:10.71
Epoch :: 54 || Loss: 0.40883384 || it_count: 8344 || Val Loss: 0.41323979 || Val it_count: 1107 || Current Learning Rate: 1e-05 || Time: 03:48:31.02
Epoch :: 55 || Loss: 0.40875152 || it_count: 8344 || Val Loss: 0.41321143 || Val it_count: 1107 || Current Learning Rate: 1.0000000000000002e-06 || Time: 03:52:44.12
Epoch :: 56 || Loss: 0.40929415 || it_count: 8344 || Val Loss: 0.41223557 || Val it_count: 1107 || Current Learning Rate: 1.0000000000000002e-06 || Time: 03:57:1.22
Epoch :: 57 || Loss: 0.40904580 || it_count: 8344 || Val Loss: 0.41210041 || Val it_count: 1107 || Current Learning Rate: 1.0000000000000002e-06 || Time: 04:01:19.83
Epoch :: 58 || Loss: 0.40898077 || it_count: 8344 || Val Loss: 0.41205894 || Val it_count: 1107 || Current Learning Rate: 1.0000000000000002e-06 || Time: 04:05:31.79
Epoch :: 59 || Loss: 0.40890999 || it_count: 8344 || Val Loss: 0.41203530 || Val it_count: 1107 || Current Learning Rate: 1.0000000000000002e-06 || Time: 04:09:44.56
Epoch :: 60 || Loss: 0.40892131 || it_count: 8344 || Val Loss: 0.41201942 || Val it_count: 1107 || Current Learning Rate: 1.0000000000000002e-06 || Time: 04:13:58.62
Epoch :: 61 || Loss: 0.40886729 || it_count: 8344 || Val Loss: 0.41201455 || Val it_count: 1107 || Current Learning Rate: 1.0000000000000002e-06 || Time: 04:18:8.59
Epoch :: 62 || Loss: 0.40891354 || it_count: 8344 || Val Loss: 0.41200964 || Val it_count: 1107 || Current Learning Rate: 1.0000000000000002e-06 || Time: 04:22:27.12
Epoch :: 63 || Loss: 0.40887261 || it_count: 8344 || Val Loss: 0.41199867 || Val it_count: 1107 || Current Learning Rate: 1.0000000000000002e-06 || Time: 04:26:37.90
Epoch :: 64 || Loss: 0.40882860 || it_count: 8344 || Val Loss: 0.41198394 || Val it_count: 1107 || Current Learning Rate: 1.0000000000000002e-06 || Time: 04:30:47.66
Epoch :: 65 || Loss: 0.40886738 || it_count: 8344 || Val Loss: 0.41199284 || Val it_count: 1107 || Current Learning Rate: 1.0000000000000002e-06 || Time: 04:35:5.83
Epoch :: 66 || Loss: 0.40886225 || it_count: 8344 || Val Loss: 0.41198607 || Val it_count: 1107 || Current Learning Rate: 1.0000000000000002e-06 || Time: 04:39:25.02
Early stopping triggered due to learning rate below threshold.
Done Total time: 04:43:38.48
best_loss: 0.4119839386935221

--------------------Testing--------------------

total_samples :: test_dataset = 139200, test_dataloader = 139200
Epoch ::  1 || Loss: 0.23581579 || it_count: 544 || Time: 00:00:13.44
MAE:  0.25277388
MSE:  0.23583254
RMSE:  0.44146815

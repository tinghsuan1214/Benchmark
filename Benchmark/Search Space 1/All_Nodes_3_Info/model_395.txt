--------------------Training--------------------
arch_str :: |none~0|+|none~0|lstm_1~1|[relu->dropout->linear]
model :: 3D
InferCell(
  info :: nodes=3, inC=1, outC=64, [1<-(I0-L0) | 2<-(I0-L1,I1-L2)], genotype_str: none~0|none~0|lstm_1~1
  linear_layers: [relu->dropout->linear]
  (layers): ModuleList(
    (0-1): 2 x Zero(C_in=1, C_out=64, stride=1)
    (2): LSTM(
      (lstm): LSTM(64, 64, batch_first=True)
    )
  )
  (linear_layers): ModuleList(
    (0): ReLU()
    (1): Dropout(p=0.1, inplace=False)
    (2): Linear(in_features=3072, out_features=1, bias=True)
  )
)
tr_params :: epochs = 100, patience = 20, batch_size = 256, window_size = 48, data_size = 100
Model FLOPs: 1.625M, Model Params: 36.353K
learning rate scheduling :: (optimizer, mode='min', factor=0.1, patience=5, verbose=True)
total_samples :: train_dataset = 2136000, train_dataloader = 2136000
total_samples :: valid_dataset = 283200, valid_dataloader = 283200
Epoch ::  1 || Loss: 0.58262274 || it_count: 8344 || Val Loss: 0.65309143 || Val it_count: 1107 || Current Learning Rate: 0.001 || Time: 00:03:22.66
Epoch ::  2 || Loss: 0.59056507 || it_count: 8344 || Val Loss: 0.65740143 || Val it_count: 1107 || Current Learning Rate: 0.001 || Time: 00:06:41.72
Epoch ::  3 || Loss: 0.59409366 || it_count: 8344 || Val Loss: 0.65393989 || Val it_count: 1107 || Current Learning Rate: 0.001 || Time: 00:09:59.79
Epoch ::  4 || Loss: 0.60432358 || it_count: 8344 || Val Loss: 0.65307440 || Val it_count: 1107 || Current Learning Rate: 0.001 || Time: 00:13:17.57
Epoch ::  5 || Loss: 0.60591505 || it_count: 8344 || Val Loss: 0.65329971 || Val it_count: 1107 || Current Learning Rate: 0.001 || Time: 00:16:35.14
Epoch ::  6 || Loss: 0.60660140 || it_count: 8344 || Val Loss: 0.65313634 || Val it_count: 1107 || Current Learning Rate: 0.001 || Time: 00:19:53.45
Epoch ::  7 || Loss: 0.60536952 || it_count: 8344 || Val Loss: 0.65306173 || Val it_count: 1107 || Current Learning Rate: 0.001 || Time: 00:23:12.34
Epoch ::  8 || Loss: 0.60940351 || it_count: 8344 || Val Loss: 0.65319190 || Val it_count: 1107 || Current Learning Rate: 0.001 || Time: 00:26:29.79
Epoch ::  9 || Loss: 0.60752955 || it_count: 8344 || Val Loss: 0.65314036 || Val it_count: 1107 || Current Learning Rate: 0.001 || Time: 00:29:47.55
Epoch :: 10 || Loss: 0.60874371 || it_count: 8344 || Val Loss: 0.65306873 || Val it_count: 1107 || Current Learning Rate: 0.001 || Time: 00:33:4.99
Epoch :: 11 || Loss: 0.60833516 || it_count: 8344 || Val Loss: 0.65314722 || Val it_count: 1107 || Current Learning Rate: 0.001 || Time: 00:36:22.99
Epoch :: 12 || Loss: 0.60842848 || it_count: 8344 || Val Loss: 0.65314478 || Val it_count: 1107 || Current Learning Rate: 0.001 || Time: 00:39:39.40
Epoch :: 13 || Loss: 0.60332549 || it_count: 8344 || Val Loss: 0.65313537 || Val it_count: 1107 || Current Learning Rate: 0.001 || Time: 00:42:58.61
Epoch :: 14 || Loss: 0.60590857 || it_count: 8344 || Val Loss: 0.65306278 || Val it_count: 1107 || Current Learning Rate: 0.001 || Time: 00:46:17.86
Epoch :: 15 || Loss: 0.60716655 || it_count: 8344 || Val Loss: 0.65311674 || Val it_count: 1107 || Current Learning Rate: 0.001 || Time: 00:49:35.52
Epoch :: 16 || Loss: 0.61128828 || it_count: 8344 || Val Loss: 0.65344733 || Val it_count: 1107 || Current Learning Rate: 0.001 || Time: 00:52:54.42
Epoch :: 17 || Loss: 0.60931980 || it_count: 8344 || Val Loss: 0.65306574 || Val it_count: 1107 || Current Learning Rate: 0.001 || Time: 00:56:12.53
Epoch :: 18 || Loss: 0.60568431 || it_count: 8344 || Val Loss: 0.65313702 || Val it_count: 1107 || Current Learning Rate: 0.001 || Time: 00:59:30.67
Epoch :: 19 || Loss: 0.60695860 || it_count: 8344 || Val Loss: 0.65312005 || Val it_count: 1107 || Current Learning Rate: 0.001 || Time: 01:02:48.78
Epoch :: 20 || Loss: 0.60777797 || it_count: 8344 || Val Loss: 0.65306136 || Val it_count: 1107 || Current Learning Rate: 0.001 || Time: 01:06:6.97
Epoch :: 21 || Loss: 0.60772818 || it_count: 8344 || Val Loss: 0.65314568 || Val it_count: 1107 || Current Learning Rate: 0.001 || Time: 01:09:25.72
Epoch :: 22 || Loss: 0.60583516 || it_count: 8344 || Val Loss: 0.65315383 || Val it_count: 1107 || Current Learning Rate: 0.001 || Time: 01:12:44.96
Epoch :: 23 || Loss: 0.60686409 || it_count: 8344 || Val Loss: 0.65311276 || Val it_count: 1107 || Current Learning Rate: 0.0001 || Time: 01:16:3.20
Epoch :: 24 || Loss: 0.61938646 || it_count: 8344 || Val Loss: 0.65313209 || Val it_count: 1107 || Current Learning Rate: 0.0001 || Time: 01:19:22.56
Epoch :: 25 || Loss: 0.61917463 || it_count: 8344 || Val Loss: 0.65306936 || Val it_count: 1107 || Current Learning Rate: 0.0001 || Time: 01:22:42.14
Epoch :: 26 || Loss: 0.61852360 || it_count: 8344 || Val Loss: 0.65307685 || Val it_count: 1107 || Current Learning Rate: 0.0001 || Time: 01:26:1.76
Epoch :: 27 || Loss: 0.61739565 || it_count: 8344 || Val Loss: 0.65308778 || Val it_count: 1107 || Current Learning Rate: 0.0001 || Time: 01:29:20.11
Epoch :: 28 || Loss: 0.61758171 || it_count: 8344 || Val Loss: 0.65308160 || Val it_count: 1107 || Current Learning Rate: 0.0001 || Time: 01:32:38.67
Epoch :: 29 || Loss: 0.61773133 || it_count: 8344 || Val Loss: 0.65307566 || Val it_count: 1107 || Current Learning Rate: 1e-05 || Time: 01:35:57.83
Epoch :: 30 || Loss: 0.62004769 || it_count: 8344 || Val Loss: 0.65362178 || Val it_count: 1107 || Current Learning Rate: 1e-05 || Time: 01:39:16.60
Epoch :: 31 || Loss: 0.61982282 || it_count: 8344 || Val Loss: 0.65380308 || Val it_count: 1107 || Current Learning Rate: 1e-05 || Time: 01:42:34.59
Epoch :: 32 || Loss: 0.61980294 || it_count: 8344 || Val Loss: 0.65382520 || Val it_count: 1107 || Current Learning Rate: 1e-05 || Time: 01:45:53.77
Epoch :: 33 || Loss: 0.61981561 || it_count: 8344 || Val Loss: 0.65381666 || Val it_count: 1107 || Current Learning Rate: 1e-05 || Time: 01:49:13.06
Epoch :: 34 || Loss: 0.61980389 || it_count: 8344 || Val Loss: 0.65380778 || Val it_count: 1107 || Current Learning Rate: 1e-05 || Time: 01:52:33.10
Epoch :: 35 || Loss: 0.61980085 || it_count: 8344 || Val Loss: 0.65379613 || Val it_count: 1107 || Current Learning Rate: 1.0000000000000002e-06 || Time: 01:55:52.55
Epoch :: 36 || Loss: 0.61977820 || it_count: 8344 || Val Loss: 0.65381750 || Val it_count: 1107 || Current Learning Rate: 1.0000000000000002e-06 || Time: 01:59:11.09
Epoch :: 37 || Loss: 0.61978498 || it_count: 8344 || Val Loss: 0.65383357 || Val it_count: 1107 || Current Learning Rate: 1.0000000000000002e-06 || Time: 02:02:29.28
Epoch :: 38 || Loss: 0.61977877 || it_count: 8344 || Val Loss: 0.65384650 || Val it_count: 1107 || Current Learning Rate: 1.0000000000000002e-06 || Time: 02:06:1.96
Epoch :: 39 || Loss: 0.61976391 || it_count: 8344 || Val Loss: 0.65385652 || Val it_count: 1107 || Current Learning Rate: 1.0000000000000002e-06 || Time: 02:09:42.86
Epoch :: 40 || Loss: 0.61976626 || it_count: 8344 || Val Loss: 0.65386425 || Val it_count: 1107 || Current Learning Rate: 1.0000000000000002e-06 || Time: 02:13:2.18
Early stopping triggered due to patience exceeded.
Done Total time: 02:13:2.18
best_loss: 0.6530613596685452

--------------------Testing--------------------

total_samples :: test_dataset = 139200, test_dataloader = 139200
Epoch ::  1 || Loss: 1.03369600 || it_count: 544 || Time: 00:00:10.72
MAE:  0.54765904
MSE:  1.0339985
RMSE:  0.80803657

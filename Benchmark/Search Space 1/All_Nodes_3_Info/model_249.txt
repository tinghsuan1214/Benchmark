--------------------Training--------------------
arch_str :: |skip_connect~0|+|lstm_3~0|lstm_2~1|[dropout->linear]
model :: 3B
InferCell(
  info :: nodes=3, inC=1, outC=64, [1<-(I0-L0) | 2<-(I0-L1,I1-L2)], genotype_str: skip_connect~0|lstm_3~0|lstm_2~1
  linear_layers: [dropout->linear]
  (layers): ModuleList(
    (0): FactorizedReduce(
      C_in=1, C_out=64, stride=1
      (relu): ReLU()
      (conv): Conv1d(1, 64, kernel_size=(1,), stride=(1,), bias=False)
      (bn): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (1): LSTM(
      (lstm): LSTM(1, 64, num_layers=3, batch_first=True)
    )
    (2): LSTM(
      (lstm): LSTM(64, 64, num_layers=2, batch_first=True)
    )
  )
  (linear_layers): ModuleList(
    (0): Dropout(p=0.1, inplace=False)
    (1): Linear(in_features=3072, out_features=1, bias=True)
  )
)
tr_params :: epochs = 100, patience = 20, batch_size = 256, window_size = 48, data_size = 100
Model FLOPs: 7.354M, Model Params: 153.537K
learning rate scheduling :: (optimizer, mode='min', factor=0.1, patience=5, verbose=True)
total_samples :: train_dataset = 2136000, train_dataloader = 2136000
total_samples :: valid_dataset = 283200, valid_dataloader = 283200
Epoch ::  1 || Loss: 0.42638524 || it_count: 8344 || Val Loss: 0.45593158 || Val it_count: 1107 || Current Learning Rate: 0.001 || Time: 00:08:35.74
Epoch ::  2 || Loss: 0.41656216 || it_count: 8344 || Val Loss: 0.45239913 || Val it_count: 1107 || Current Learning Rate: 0.001 || Time: 00:17:7.65
Epoch ::  3 || Loss: 0.41397384 || it_count: 8344 || Val Loss: 0.45018760 || Val it_count: 1107 || Current Learning Rate: 0.001 || Time: 00:25:41.53
Epoch ::  4 || Loss: 0.41268985 || it_count: 8344 || Val Loss: 0.44988134 || Val it_count: 1107 || Current Learning Rate: 0.001 || Time: 00:34:15.03
Epoch ::  5 || Loss: 0.41279598 || it_count: 8344 || Val Loss: 0.44918933 || Val it_count: 1107 || Current Learning Rate: 0.001 || Time: 00:42:49.23
Epoch ::  6 || Loss: 0.41168187 || it_count: 8344 || Val Loss: 0.44821245 || Val it_count: 1107 || Current Learning Rate: 0.001 || Time: 00:51:24.13
Epoch ::  7 || Loss: 0.41053602 || it_count: 8344 || Val Loss: 0.44954461 || Val it_count: 1107 || Current Learning Rate: 0.001 || Time: 00:59:57.92
Epoch ::  8 || Loss: 0.40958124 || it_count: 8344 || Val Loss: 0.45158365 || Val it_count: 1107 || Current Learning Rate: 0.001 || Time: 01:08:30.87
Epoch ::  9 || Loss: 0.40953620 || it_count: 8344 || Val Loss: 0.44904593 || Val it_count: 1107 || Current Learning Rate: 0.001 || Time: 01:17:3.96
Epoch :: 10 || Loss: 0.40868385 || it_count: 8344 || Val Loss: 0.44904397 || Val it_count: 1107 || Current Learning Rate: 0.001 || Time: 01:25:35.76
Epoch :: 11 || Loss: 0.40840538 || it_count: 8344 || Val Loss: 0.44912004 || Val it_count: 1107 || Current Learning Rate: 0.001 || Time: 01:34:8.30
Epoch :: 12 || Loss: 0.41022784 || it_count: 8344 || Val Loss: 0.45062137 || Val it_count: 1107 || Current Learning Rate: 0.001 || Time: 01:42:42.20
Epoch :: 13 || Loss: 0.40954577 || it_count: 8344 || Val Loss: 0.44907474 || Val it_count: 1107 || Current Learning Rate: 0.001 || Time: 01:51:15.23
Epoch :: 14 || Loss: 0.40830366 || it_count: 8344 || Val Loss: 0.44820089 || Val it_count: 1107 || Current Learning Rate: 0.001 || Time: 01:59:48.19
Epoch :: 15 || Loss: 0.40769183 || it_count: 8344 || Val Loss: 0.44855635 || Val it_count: 1107 || Current Learning Rate: 0.001 || Time: 02:08:22.38
Epoch :: 16 || Loss: 0.40751242 || it_count: 8344 || Val Loss: 0.44802847 || Val it_count: 1107 || Current Learning Rate: 0.001 || Time: 02:16:54.98
Epoch :: 17 || Loss: 0.40678359 || it_count: 8344 || Val Loss: 0.44872595 || Val it_count: 1107 || Current Learning Rate: 0.001 || Time: 02:25:27.95
Epoch :: 18 || Loss: 0.40639002 || it_count: 8344 || Val Loss: 0.44888971 || Val it_count: 1107 || Current Learning Rate: 0.001 || Time: 02:34:2.21
Epoch :: 19 || Loss: 0.40593180 || it_count: 8344 || Val Loss: 0.45011196 || Val it_count: 1107 || Current Learning Rate: 0.001 || Time: 02:42:36.08
Epoch :: 20 || Loss: 0.40604487 || it_count: 8344 || Val Loss: 0.44970563 || Val it_count: 1107 || Current Learning Rate: 0.001 || Time: 02:51:8.73
Epoch :: 21 || Loss: 0.40614664 || it_count: 8344 || Val Loss: 0.44711592 || Val it_count: 1107 || Current Learning Rate: 0.001 || Time: 02:59:41.22
Epoch :: 22 || Loss: 0.40542367 || it_count: 8344 || Val Loss: 0.44873755 || Val it_count: 1107 || Current Learning Rate: 0.001 || Time: 03:08:13.50
Epoch :: 23 || Loss: 0.40648081 || it_count: 8344 || Val Loss: 0.45114160 || Val it_count: 1107 || Current Learning Rate: 0.001 || Time: 03:16:47.56
Epoch :: 24 || Loss: 0.40600027 || it_count: 8344 || Val Loss: 0.44855642 || Val it_count: 1107 || Current Learning Rate: 0.001 || Time: 03:25:20.94
Epoch :: 25 || Loss: 0.40505481 || it_count: 8344 || Val Loss: 0.44845238 || Val it_count: 1107 || Current Learning Rate: 0.001 || Time: 03:33:54.57
Epoch :: 26 || Loss: 0.40493847 || it_count: 8344 || Val Loss: 0.45036723 || Val it_count: 1107 || Current Learning Rate: 0.001 || Time: 03:42:28.50
Epoch 00011: reducing learning rate of group 0 to 1.0000e-04.
Epoch :: 27 || Loss: 0.40550674 || it_count: 8344 || Val Loss: 0.44793766 || Val it_count: 1107 || Current Learning Rate: 0.0001 || Time: 03:51:1.60
Epoch :: 28 || Loss: 0.40880002 || it_count: 8344 || Val Loss: 0.44268848 || Val it_count: 1107 || Current Learning Rate: 0.0001 || Time: 03:59:34.74
Epoch :: 29 || Loss: 0.40553330 || it_count: 8344 || Val Loss: 0.44271377 || Val it_count: 1107 || Current Learning Rate: 0.0001 || Time: 04:08:9.15
Epoch :: 30 || Loss: 0.40445726 || it_count: 8344 || Val Loss: 0.44318255 || Val it_count: 1107 || Current Learning Rate: 0.0001 || Time: 04:16:42.67
Epoch :: 31 || Loss: 0.40386371 || it_count: 8344 || Val Loss: 0.44321869 || Val it_count: 1107 || Current Learning Rate: 0.0001 || Time: 04:25:8.59
Epoch :: 32 || Loss: 0.40351663 || it_count: 8344 || Val Loss: 0.44306428 || Val it_count: 1107 || Current Learning Rate: 0.0001 || Time: 04:33:33.10
Epoch :: 33 || Loss: 0.40312045 || it_count: 8344 || Val Loss: 0.44323422 || Val it_count: 1107 || Current Learning Rate: 0.0001 || Time: 04:41:59.98
Epoch 00018: reducing learning rate of group 0 to 1.0000e-05.
Epoch :: 34 || Loss: 0.40276559 || it_count: 8344 || Val Loss: 0.44324135 || Val it_count: 1107 || Current Learning Rate: 1e-05 || Time: 04:50:25.32
Epoch :: 35 || Loss: 0.40449831 || it_count: 8344 || Val Loss: 0.44093403 || Val it_count: 1107 || Current Learning Rate: 1e-05 || Time: 04:58:50.48
Epoch :: 36 || Loss: 0.40365492 || it_count: 8344 || Val Loss: 0.44063276 || Val it_count: 1107 || Current Learning Rate: 1e-05 || Time: 05:07:15.48
Epoch :: 37 || Loss: 0.40345883 || it_count: 8344 || Val Loss: 0.44058065 || Val it_count: 1107 || Current Learning Rate: 1e-05 || Time: 05:15:39.93
Epoch :: 38 || Loss: 0.40333715 || it_count: 8344 || Val Loss: 0.44059440 || Val it_count: 1107 || Current Learning Rate: 1e-05 || Time: 05:24:5.30
Epoch :: 39 || Loss: 0.40327474 || it_count: 8344 || Val Loss: 0.44073043 || Val it_count: 1107 || Current Learning Rate: 1e-05 || Time: 05:32:31.10
Epoch :: 40 || Loss: 0.40319608 || it_count: 8344 || Val Loss: 0.44103144 || Val it_count: 1107 || Current Learning Rate: 1e-05 || Time: 05:40:56.61
Epoch :: 41 || Loss: 0.40315494 || it_count: 8344 || Val Loss: 0.44100835 || Val it_count: 1107 || Current Learning Rate: 1e-05 || Time: 05:49:22.40
Epoch :: 42 || Loss: 0.40314966 || it_count: 8344 || Val Loss: 0.44125193 || Val it_count: 1107 || Current Learning Rate: 1e-05 || Time: 05:57:47.70
Epoch 00027: reducing learning rate of group 0 to 1.0000e-06.
Epoch :: 43 || Loss: 0.40307355 || it_count: 8344 || Val Loss: 0.44132522 || Val it_count: 1107 || Current Learning Rate: 1.0000000000000002e-06 || Time: 06:06:12.75
Epoch :: 44 || Loss: 0.40318596 || it_count: 8344 || Val Loss: 0.44059391 || Val it_count: 1107 || Current Learning Rate: 1.0000000000000002e-06 || Time: 06:14:39.42
Epoch :: 45 || Loss: 0.40319316 || it_count: 8344 || Val Loss: 0.44035248 || Val it_count: 1107 || Current Learning Rate: 1.0000000000000002e-06 || Time: 06:23:5.14
Epoch :: 46 || Loss: 0.40308492 || it_count: 8344 || Val Loss: 0.44028727 || Val it_count: 1107 || Current Learning Rate: 1.0000000000000002e-06 || Time: 06:31:31.32
Epoch :: 47 || Loss: 0.40303994 || it_count: 8344 || Val Loss: 0.44030273 || Val it_count: 1107 || Current Learning Rate: 1.0000000000000002e-06 || Time: 06:39:55.93
Epoch :: 48 || Loss: 0.40315929 || it_count: 8344 || Val Loss: 0.44030185 || Val it_count: 1107 || Current Learning Rate: 1.0000000000000002e-06 || Time: 06:48:21.60
Epoch :: 49 || Loss: 0.40300941 || it_count: 8344 || Val Loss: 0.44033081 || Val it_count: 1107 || Current Learning Rate: 1.0000000000000002e-06 || Time: 06:56:46.46
Epoch :: 50 || Loss: 0.40308980 || it_count: 8344 || Val Loss: 0.44037228 || Val it_count: 1107 || Current Learning Rate: 1.0000000000000002e-06 || Time: 07:05:12.29
Epoch :: 51 || Loss: 0.40301260 || it_count: 8344 || Val Loss: 0.44041229 || Val it_count: 1107 || Current Learning Rate: 1.0000000000000002e-06 || Time: 07:13:38.06
Epoch 00036: reducing learning rate of group 0 to 1.0000e-07.
Early stopping triggered due to learning rate below threshold.
Done Total time: 07:22:1.91
best_loss: 0.4402872729951797

--------------------Testing--------------------

total_samples :: test_dataset = 139200, test_dataloader = 139200
Epoch ::  1 || Loss: 0.32845668 || it_count: 544 || Time: 00:00:21.86
MAE:  0.28356594
MSE:  0.32851794
RMSE:  0.480991

--------------------Training--------------------
arch_str :: |none~0|+|skip_connect~0|skip_connect~1|[linear]
model :: 3A
InferCell(
  info :: nodes=3, inC=1, outC=64, [1<-(I0-L0) | 2<-(I0-L1,I1-L2)], genotype_str: none~0|skip_connect~0|skip_connect~1
  linear_layers: [linear]
  (layers): ModuleList(
    (0): Zero(C_in=1, C_out=64, stride=1)
    (1): FactorizedReduce(
      C_in=1, C_out=64, stride=1
      (relu): ReLU()
      (conv): Conv1d(1, 64, kernel_size=(1,), stride=(1,), bias=False)
      (bn): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (2): Identity()
  )
  (linear_layers): ModuleList(
    (0): Linear(in_features=3072, out_features=1, bias=True)
  )
)
tr_params :: epochs = 100, patience = 20, batch_size = 256, window_size = 48, data_size = 100
Model FLOPs: 18.432K, Model Params: 3.265K
learning rate scheduling :: (optimizer, mode='min', factor=0.1, patience=5, verbose=True)
total_samples :: train_dataset = 2136000, train_dataloader = 2136000
total_samples :: valid_dataset = 283200, valid_dataloader = 283200
Epoch ::  1 || Loss: 0.49630931 || it_count: 8344 || Val Loss: 0.47533710 || Val it_count: 1107 || Current Learning Rate: 0.001 || Time: 00:03:14.26
Epoch ::  2 || Loss: 0.47945503 || it_count: 8344 || Val Loss: 0.47277229 || Val it_count: 1107 || Current Learning Rate: 0.001 || Time: 00:06:24.65
Epoch ::  3 || Loss: 0.47627881 || it_count: 8344 || Val Loss: 0.47218417 || Val it_count: 1107 || Current Learning Rate: 0.001 || Time: 00:09:35.87
Epoch ::  4 || Loss: 0.47588863 || it_count: 8344 || Val Loss: 0.46977097 || Val it_count: 1107 || Current Learning Rate: 0.001 || Time: 00:12:47.69
Epoch ::  5 || Loss: 0.47624147 || it_count: 8344 || Val Loss: 0.47513429 || Val it_count: 1107 || Current Learning Rate: 0.001 || Time: 00:15:57.52
Epoch ::  6 || Loss: 0.47621661 || it_count: 8344 || Val Loss: 0.47305400 || Val it_count: 1107 || Current Learning Rate: 0.001 || Time: 00:19:10.03
Epoch ::  7 || Loss: 0.47640895 || it_count: 8344 || Val Loss: 0.47364140 || Val it_count: 1107 || Current Learning Rate: 0.001 || Time: 00:22:21.12
Epoch ::  8 || Loss: 0.47661461 || it_count: 8344 || Val Loss: 0.47857884 || Val it_count: 1107 || Current Learning Rate: 0.001 || Time: 00:25:32.29
Epoch ::  9 || Loss: 0.47678663 || it_count: 8344 || Val Loss: 0.47077034 || Val it_count: 1107 || Current Learning Rate: 0.001 || Time: 00:28:43.95
Epoch :: 10 || Loss: 0.47669777 || it_count: 8344 || Val Loss: 0.47392822 || Val it_count: 1107 || Current Learning Rate: 0.001 || Time: 00:31:56.62
Epoch :: 11 || Loss: 0.47601986 || it_count: 8344 || Val Loss: 0.47389549 || Val it_count: 1107 || Current Learning Rate: 0.001 || Time: 00:35:6.99
Epoch :: 12 || Loss: 0.47656453 || it_count: 8344 || Val Loss: 0.47235532 || Val it_count: 1107 || Current Learning Rate: 0.001 || Time: 00:38:18.53
Epoch :: 13 || Loss: 0.47614836 || it_count: 8344 || Val Loss: 0.46886830 || Val it_count: 1107 || Current Learning Rate: 0.001 || Time: 00:41:28.12
Epoch :: 14 || Loss: 0.47675180 || it_count: 8344 || Val Loss: 0.46851644 || Val it_count: 1107 || Current Learning Rate: 0.001 || Time: 00:44:39.70
Epoch :: 15 || Loss: 0.47667471 || it_count: 8344 || Val Loss: 0.47364388 || Val it_count: 1107 || Current Learning Rate: 0.001 || Time: 00:47:50.81
Epoch :: 16 || Loss: 0.47542569 || it_count: 8344 || Val Loss: 0.47107675 || Val it_count: 1107 || Current Learning Rate: 0.001 || Time: 00:51:1.78
Epoch :: 17 || Loss: 0.47705881 || it_count: 8344 || Val Loss: 0.47864489 || Val it_count: 1107 || Current Learning Rate: 0.001 || Time: 00:54:12.09
Epoch :: 18 || Loss: 0.47631627 || it_count: 8344 || Val Loss: 0.47234115 || Val it_count: 1107 || Current Learning Rate: 0.001 || Time: 00:57:22.79
Epoch :: 19 || Loss: 0.47612602 || it_count: 8344 || Val Loss: 0.47542616 || Val it_count: 1107 || Current Learning Rate: 0.001 || Time: 01:00:34.18
Epoch :: 20 || Loss: 0.47556243 || it_count: 8344 || Val Loss: 0.46770230 || Val it_count: 1107 || Current Learning Rate: 0.001 || Time: 01:03:45.47
Epoch :: 21 || Loss: 0.47669350 || it_count: 8344 || Val Loss: 0.48034621 || Val it_count: 1107 || Current Learning Rate: 0.001 || Time: 01:06:56.12
Epoch :: 22 || Loss: 0.47669857 || it_count: 8344 || Val Loss: 0.47068945 || Val it_count: 1107 || Current Learning Rate: 0.001 || Time: 01:10:7.31
Epoch :: 23 || Loss: 0.47592390 || it_count: 8344 || Val Loss: 0.47036449 || Val it_count: 1107 || Current Learning Rate: 0.001 || Time: 01:13:18.87
Epoch :: 24 || Loss: 0.47696476 || it_count: 8344 || Val Loss: 0.47406119 || Val it_count: 1107 || Current Learning Rate: 0.001 || Time: 01:16:31.02
Epoch :: 25 || Loss: 0.47554690 || it_count: 8344 || Val Loss: 0.47722165 || Val it_count: 1107 || Current Learning Rate: 0.001 || Time: 01:19:44.15
Epoch 00010: reducing learning rate of group 0 to 1.0000e-04.
Epoch :: 26 || Loss: 0.47643293 || it_count: 8344 || Val Loss: 0.47139475 || Val it_count: 1107 || Current Learning Rate: 0.0001 || Time: 01:22:55.99
Epoch :: 27 || Loss: 0.51366533 || it_count: 8344 || Val Loss: 0.45947148 || Val it_count: 1107 || Current Learning Rate: 0.0001 || Time: 01:26:6.13
Epoch :: 28 || Loss: 0.51063247 || it_count: 8344 || Val Loss: 0.45347017 || Val it_count: 1107 || Current Learning Rate: 0.0001 || Time: 01:29:18.19
Epoch :: 29 || Loss: 0.50931585 || it_count: 8344 || Val Loss: 0.45830167 || Val it_count: 1107 || Current Learning Rate: 0.0001 || Time: 01:32:31.02
Epoch :: 30 || Loss: 0.50889727 || it_count: 8344 || Val Loss: 0.45586651 || Val it_count: 1107 || Current Learning Rate: 0.0001 || Time: 01:35:42.35
Epoch :: 31 || Loss: 0.50861239 || it_count: 8344 || Val Loss: 0.45452365 || Val it_count: 1107 || Current Learning Rate: 0.0001 || Time: 01:38:52.95
Epoch :: 32 || Loss: 0.50818209 || it_count: 8344 || Val Loss: 0.45720539 || Val it_count: 1107 || Current Learning Rate: 0.0001 || Time: 01:42:4.19
Epoch :: 33 || Loss: 0.50818527 || it_count: 8344 || Val Loss: 0.45607450 || Val it_count: 1107 || Current Learning Rate: 0.0001 || Time: 01:45:14.91
Epoch 00018: reducing learning rate of group 0 to 1.0000e-05.
Epoch :: 34 || Loss: 0.50725185 || it_count: 8344 || Val Loss: 0.45849934 || Val it_count: 1107 || Current Learning Rate: 1e-05 || Time: 01:48:27.22
Epoch :: 35 || Loss: 0.51712604 || it_count: 8344 || Val Loss: 0.45944728 || Val it_count: 1107 || Current Learning Rate: 1e-05 || Time: 01:51:38.87
Epoch :: 36 || Loss: 0.51653222 || it_count: 8344 || Val Loss: 0.45874351 || Val it_count: 1107 || Current Learning Rate: 1e-05 || Time: 01:54:49.81
Epoch :: 37 || Loss: 0.51623699 || it_count: 8344 || Val Loss: 0.45851722 || Val it_count: 1107 || Current Learning Rate: 1e-05 || Time: 01:58:0.61
Epoch :: 38 || Loss: 0.51600101 || it_count: 8344 || Val Loss: 0.45841691 || Val it_count: 1107 || Current Learning Rate: 1e-05 || Time: 02:01:11.75
Epoch :: 39 || Loss: 0.51581139 || it_count: 8344 || Val Loss: 0.45835279 || Val it_count: 1107 || Current Learning Rate: 1e-05 || Time: 02:04:22.50
Epoch 00024: reducing learning rate of group 0 to 1.0000e-06.
Epoch :: 40 || Loss: 0.51563392 || it_count: 8344 || Val Loss: 0.45826241 || Val it_count: 1107 || Current Learning Rate: 1.0000000000000002e-06 || Time: 02:07:34.44
Epoch :: 41 || Loss: 0.51770157 || it_count: 8344 || Val Loss: 0.46545025 || Val it_count: 1107 || Current Learning Rate: 1.0000000000000002e-06 || Time: 02:10:47.29
Epoch :: 42 || Loss: 0.51738764 || it_count: 8344 || Val Loss: 0.46636295 || Val it_count: 1107 || Current Learning Rate: 1.0000000000000002e-06 || Time: 02:13:57.94
Epoch :: 43 || Loss: 0.51734243 || it_count: 8344 || Val Loss: 0.46652782 || Val it_count: 1107 || Current Learning Rate: 1.0000000000000002e-06 || Time: 02:17:9.40
Epoch :: 44 || Loss: 0.51732024 || it_count: 8344 || Val Loss: 0.46652429 || Val it_count: 1107 || Current Learning Rate: 1.0000000000000002e-06 || Time: 02:20:20.58
Epoch :: 45 || Loss: 0.51730140 || it_count: 8344 || Val Loss: 0.46649195 || Val it_count: 1107 || Current Learning Rate: 1.0000000000000002e-06 || Time: 02:23:31.14
Epoch 00030: reducing learning rate of group 0 to 1.0000e-07.
Early stopping triggered due to learning rate below threshold.
Done Total time: 02:26:42.42
best_loss: 0.45347017126960676

--------------------Testing--------------------

total_samples :: test_dataset = 139200, test_dataloader = 139200
Epoch ::  1 || Loss: 0.34118237 || it_count: 544 || Time: 00:00:10.80
MAE:  0.31443265
MSE:  0.34125555
RMSE:  0.51166445

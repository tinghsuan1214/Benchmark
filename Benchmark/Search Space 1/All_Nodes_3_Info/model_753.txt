--------------------Training--------------------
arch_str :: |lstm_3~0|+|lstm_1~0|lstm_2~1|[linear->relu->linear]
model :: 3G
InferCell(
  info :: nodes=3, inC=1, outC=64, [1<-(I0-L0) | 2<-(I0-L1,I1-L2)], genotype_str: lstm_3~0|lstm_1~0|lstm_2~1
  linear_layers: [linear->relu->linear]
  (layers): ModuleList(
    (0): LSTM(
      (lstm): LSTM(1, 64, num_layers=3, batch_first=True)
    )
    (1): LSTM(
      (lstm): LSTM(1, 64, batch_first=True)
    )
    (2): LSTM(
      (lstm): LSTM(64, 64, num_layers=2, batch_first=True)
    )
  )
  (linear_layers): ModuleList(
    (0): Linear(in_features=3072, out_features=1536, bias=True)
    (1): ReLU()
    (2): Linear(in_features=1536, out_features=1, bias=True)
  )
)
tr_params :: epochs = 100, patience = 20, batch_size = 256, window_size = 48, data_size = 100
Model FLOPs: 12.904M, Model Params: 4.889M
learning rate scheduling :: (optimizer, mode='min', factor=0.1, patience=5, verbose=True)
total_samples :: train_dataset = 2136000, train_dataloader = 2136000
total_samples :: valid_dataset = 283200, valid_dataloader = 283200
Epoch ::  1 || Loss: 0.41599936 || it_count: 8344 || Val Loss: 0.45400812 || Val it_count: 1107 || Current Learning Rate: 0.001 || Time: 00:05:6.00
Epoch ::  2 || Loss: 0.41299253 || it_count: 8344 || Val Loss: 0.44514074 || Val it_count: 1107 || Current Learning Rate: 0.001 || Time: 00:10:5.50
Epoch ::  3 || Loss: 0.41181937 || it_count: 8344 || Val Loss: 0.44688603 || Val it_count: 1107 || Current Learning Rate: 0.001 || Time: 00:15:13.23
Epoch ::  4 || Loss: 0.41106368 || it_count: 8344 || Val Loss: 0.44462875 || Val it_count: 1107 || Current Learning Rate: 0.001 || Time: 00:20:22.98
Epoch ::  5 || Loss: 0.40987576 || it_count: 8344 || Val Loss: 0.44686966 || Val it_count: 1107 || Current Learning Rate: 0.001 || Time: 00:25:24.64
Epoch ::  6 || Loss: 0.40900306 || it_count: 8344 || Val Loss: 0.44595326 || Val it_count: 1107 || Current Learning Rate: 0.001 || Time: 00:30:36.39
Epoch ::  7 || Loss: 0.40783703 || it_count: 8344 || Val Loss: 0.44483480 || Val it_count: 1107 || Current Learning Rate: 0.001 || Time: 00:35:47.61
Epoch ::  8 || Loss: 0.40721979 || it_count: 8344 || Val Loss: 0.44084572 || Val it_count: 1107 || Current Learning Rate: 0.001 || Time: 00:40:58.87
Epoch ::  9 || Loss: 0.40635105 || it_count: 8344 || Val Loss: 0.44427921 || Val it_count: 1107 || Current Learning Rate: 0.001 || Time: 00:46:10.28
Epoch :: 10 || Loss: 0.40553993 || it_count: 8344 || Val Loss: 0.44235017 || Val it_count: 1107 || Current Learning Rate: 0.001 || Time: 00:51:17.29
Epoch :: 11 || Loss: 0.40441209 || it_count: 8344 || Val Loss: 0.44258054 || Val it_count: 1107 || Current Learning Rate: 0.001 || Time: 00:56:16.83
Epoch :: 12 || Loss: 0.40363739 || it_count: 8344 || Val Loss: 0.44222757 || Val it_count: 1107 || Current Learning Rate: 0.001 || Time: 01:01:15.34
Epoch :: 13 || Loss: 0.40262621 || it_count: 8344 || Val Loss: 0.44170657 || Val it_count: 1107 || Current Learning Rate: 0.001 || Time: 01:06:17.96
Epoch :: 14 || Loss: 0.40173249 || it_count: 8344 || Val Loss: 0.44203541 || Val it_count: 1107 || Current Learning Rate: 0.001 || Time: 01:11:13.86
Epoch :: 15 || Loss: 0.40049547 || it_count: 8344 || Val Loss: 0.44572936 || Val it_count: 1107 || Current Learning Rate: 0.001 || Time: 01:16:17.73
Epoch :: 16 || Loss: 0.39950748 || it_count: 8344 || Val Loss: 0.44857375 || Val it_count: 1107 || Current Learning Rate: 0.001 || Time: 01:21:25.19
Epoch :: 17 || Loss: 0.39806323 || it_count: 8344 || Val Loss: 0.44634098 || Val it_count: 1107 || Current Learning Rate: 0.001 || Time: 01:26:27.83
Epoch :: 18 || Loss: 0.39659590 || it_count: 8344 || Val Loss: 0.45148811 || Val it_count: 1107 || Current Learning Rate: 0.001 || Time: 01:31:34.16
Epoch :: 19 || Loss: 0.39532089 || it_count: 8344 || Val Loss: 0.45530176 || Val it_count: 1107 || Current Learning Rate: 0.001 || Time: 01:36:29.53
Epoch :: 20 || Loss: 0.39327545 || it_count: 8344 || Val Loss: 0.45468287 || Val it_count: 1107 || Current Learning Rate: 0.001 || Time: 01:41:31.18
Epoch :: 21 || Loss: 0.39148052 || it_count: 8344 || Val Loss: 0.45641327 || Val it_count: 1107 || Current Learning Rate: 0.001 || Time: 01:46:40.25
Epoch :: 22 || Loss: 0.38959807 || it_count: 8344 || Val Loss: 0.46069262 || Val it_count: 1107 || Current Learning Rate: 0.001 || Time: 01:51:43.95
Epoch 00007: reducing learning rate of group 0 to 1.0000e-04.
Epoch :: 23 || Loss: 0.38764508 || it_count: 8344 || Val Loss: 0.45953399 || Val it_count: 1107 || Current Learning Rate: 0.0001 || Time: 01:56:51.19
Epoch :: 24 || Loss: 0.39942085 || it_count: 8344 || Val Loss: 0.42874227 || Val it_count: 1107 || Current Learning Rate: 0.0001 || Time: 02:01:57.58
Epoch :: 25 || Loss: 0.39316371 || it_count: 8344 || Val Loss: 0.42872888 || Val it_count: 1107 || Current Learning Rate: 0.0001 || Time: 02:07:1.47
Epoch :: 26 || Loss: 0.39053324 || it_count: 8344 || Val Loss: 0.42940669 || Val it_count: 1107 || Current Learning Rate: 0.0001 || Time: 02:12:9.18
Epoch :: 27 || Loss: 0.38841322 || it_count: 8344 || Val Loss: 0.43028679 || Val it_count: 1107 || Current Learning Rate: 0.0001 || Time: 02:17:13.48
Epoch :: 28 || Loss: 0.38656476 || it_count: 8344 || Val Loss: 0.43137088 || Val it_count: 1107 || Current Learning Rate: 0.0001 || Time: 02:22:25.05
Epoch :: 29 || Loss: 0.38483991 || it_count: 8344 || Val Loss: 0.43247007 || Val it_count: 1107 || Current Learning Rate: 0.0001 || Time: 02:27:28.00
Epoch 00014: reducing learning rate of group 0 to 1.0000e-05.
Epoch :: 30 || Loss: 0.38325739 || it_count: 8344 || Val Loss: 0.43355188 || Val it_count: 1107 || Current Learning Rate: 1e-05 || Time: 02:32:33.03
Epoch :: 31 || Loss: 0.39281333 || it_count: 8344 || Val Loss: 0.42282389 || Val it_count: 1107 || Current Learning Rate: 1e-05 || Time: 02:37:30.99
Epoch :: 32 || Loss: 0.38955688 || it_count: 8344 || Val Loss: 0.42238733 || Val it_count: 1107 || Current Learning Rate: 1e-05 || Time: 02:42:31.67
Epoch :: 33 || Loss: 0.38882457 || it_count: 8344 || Val Loss: 0.42230184 || Val it_count: 1107 || Current Learning Rate: 1e-05 || Time: 02:47:33.28
Epoch :: 34 || Loss: 0.38840041 || it_count: 8344 || Val Loss: 0.42227533 || Val it_count: 1107 || Current Learning Rate: 1e-05 || Time: 02:52:31.23
Epoch :: 35 || Loss: 0.38805107 || it_count: 8344 || Val Loss: 0.42224969 || Val it_count: 1107 || Current Learning Rate: 1e-05 || Time: 02:57:33.87
Epoch :: 36 || Loss: 0.38773999 || it_count: 8344 || Val Loss: 0.42223936 || Val it_count: 1107 || Current Learning Rate: 1e-05 || Time: 03:02:33.62
Epoch :: 37 || Loss: 0.38744645 || it_count: 8344 || Val Loss: 0.42225960 || Val it_count: 1107 || Current Learning Rate: 1e-05 || Time: 03:07:33.43
Epoch :: 38 || Loss: 0.38716450 || it_count: 8344 || Val Loss: 0.42228018 || Val it_count: 1107 || Current Learning Rate: 1e-05 || Time: 03:12:40.73
Epoch :: 39 || Loss: 0.38689592 || it_count: 8344 || Val Loss: 0.42233698 || Val it_count: 1107 || Current Learning Rate: 1e-05 || Time: 03:17:39.00
Epoch :: 40 || Loss: 0.38663552 || it_count: 8344 || Val Loss: 0.42237614 || Val it_count: 1107 || Current Learning Rate: 1e-05 || Time: 03:22:38.97
Epoch 00025: reducing learning rate of group 0 to 1.0000e-06.
Epoch :: 41 || Loss: 0.38637881 || it_count: 8344 || Val Loss: 0.42241449 || Val it_count: 1107 || Current Learning Rate: 1.0000000000000002e-06 || Time: 03:27:47.56
Epoch :: 42 || Loss: 0.38685288 || it_count: 8344 || Val Loss: 0.42285273 || Val it_count: 1107 || Current Learning Rate: 1.0000000000000002e-06 || Time: 03:32:47.55
Epoch :: 43 || Loss: 0.38670479 || it_count: 8344 || Val Loss: 0.42296443 || Val it_count: 1107 || Current Learning Rate: 1.0000000000000002e-06 || Time: 03:37:48.72
Epoch :: 44 || Loss: 0.38662765 || it_count: 8344 || Val Loss: 0.42298785 || Val it_count: 1107 || Current Learning Rate: 1.0000000000000002e-06 || Time: 03:42:53.85
Epoch :: 45 || Loss: 0.38657253 || it_count: 8344 || Val Loss: 0.42299083 || Val it_count: 1107 || Current Learning Rate: 1.0000000000000002e-06 || Time: 03:47:55.52
Epoch :: 46 || Loss: 0.38652725 || it_count: 8344 || Val Loss: 0.42299621 || Val it_count: 1107 || Current Learning Rate: 1.0000000000000002e-06 || Time: 03:53:2.25
Epoch 00031: reducing learning rate of group 0 to 1.0000e-07.
Early stopping triggered due to learning rate below threshold.
Done Total time: 03:58:9.18
best_loss: 0.4222393569931403

--------------------Testing--------------------

total_samples :: test_dataset = 139200, test_dataloader = 139200
Epoch ::  1 || Loss: 0.24489747 || it_count: 544 || Time: 00:00:15.51
MAE:  0.25779593
MSE:  0.24489672
RMSE:  0.4497539

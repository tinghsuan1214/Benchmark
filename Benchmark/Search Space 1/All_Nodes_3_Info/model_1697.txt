--------------------Training--------------------
arch_str :: |lstm_1~0|+|none~0|lstm_2~1|[relu->linear->dropout->linear]
model :: 3N
InferCell(
  info :: nodes=3, inC=1, outC=64, [1<-(I0-L0) | 2<-(I0-L1,I1-L2)], genotype_str: lstm_1~0|none~0|lstm_2~1
  linear_layers: [relu->linear->dropout->linear]
  (layers): ModuleList(
    (0): LSTM(
      (lstm): LSTM(1, 64, batch_first=True)
    )
    (1): Zero(C_in=1, C_out=64, stride=1)
    (2): LSTM(
      (lstm): LSTM(64, 64, num_layers=2, batch_first=True)
    )
  )
  (linear_layers): ModuleList(
    (0): ReLU()
    (1): Linear(in_features=3072, out_features=1536, bias=True)
    (2): Dropout(p=0.1, inplace=False)
    (3): Linear(in_features=1536, out_features=1, bias=True)
  )
)
tr_params :: epochs = 100, patience = 20, batch_size = 256, window_size = 48, data_size = 100
Model FLOPs: 8.812M, Model Params: 4.805M
learning rate scheduling :: (optimizer, mode='min', factor=0.1, patience=5, verbose=True)
total_samples :: train_dataset = 2136000, train_dataloader = 2136000
total_samples :: valid_dataset = 283200, valid_dataloader = 283200
Epoch ::  1 || Loss: 0.42499928 || it_count: 8344 || Val Loss: 0.45895827 || Val it_count: 1107 || Current Learning Rate: 0.001 || Time: 00:07:55.44
Epoch ::  2 || Loss: 0.41809774 || it_count: 8344 || Val Loss: 0.45708363 || Val it_count: 1107 || Current Learning Rate: 0.001 || Time: 00:15:47.98
Epoch ::  3 || Loss: 0.41748102 || it_count: 8344 || Val Loss: 0.45144729 || Val it_count: 1107 || Current Learning Rate: 0.001 || Time: 00:23:41.69
Epoch ::  4 || Loss: 0.41760293 || it_count: 8344 || Val Loss: 0.45053546 || Val it_count: 1107 || Current Learning Rate: 0.001 || Time: 00:31:36.67
Epoch ::  5 || Loss: 0.41683766 || it_count: 8344 || Val Loss: 0.45033723 || Val it_count: 1107 || Current Learning Rate: 0.001 || Time: 00:39:33.36
Epoch ::  6 || Loss: 0.41636817 || it_count: 8344 || Val Loss: 0.45092287 || Val it_count: 1107 || Current Learning Rate: 0.001 || Time: 00:47:32.14
Epoch ::  7 || Loss: 0.41656720 || it_count: 8344 || Val Loss: 0.45139929 || Val it_count: 1107 || Current Learning Rate: 0.001 || Time: 00:55:30.38
Epoch ::  8 || Loss: 0.41622078 || it_count: 8344 || Val Loss: 0.45159688 || Val it_count: 1107 || Current Learning Rate: 0.001 || Time: 01:03:28.20
Epoch ::  9 || Loss: 0.41563747 || it_count: 8344 || Val Loss: 0.45274210 || Val it_count: 1107 || Current Learning Rate: 0.001 || Time: 01:11:26.39
Epoch :: 10 || Loss: 0.41528382 || it_count: 8344 || Val Loss: 0.45219338 || Val it_count: 1107 || Current Learning Rate: 0.001 || Time: 01:19:24.96
Epoch :: 11 || Loss: 0.41537438 || it_count: 8344 || Val Loss: 0.45246518 || Val it_count: 1107 || Current Learning Rate: 0.001 || Time: 01:27:23.54
Epoch :: 12 || Loss: 0.41550953 || it_count: 8344 || Val Loss: 0.45116758 || Val it_count: 1107 || Current Learning Rate: 0.001 || Time: 01:35:22.94
Epoch :: 13 || Loss: 0.41510771 || it_count: 8344 || Val Loss: 0.45087954 || Val it_count: 1107 || Current Learning Rate: 0.001 || Time: 01:43:21.19
Epoch :: 14 || Loss: 0.41494238 || it_count: 8344 || Val Loss: 0.45114399 || Val it_count: 1107 || Current Learning Rate: 0.001 || Time: 01:51:18.66
Epoch :: 15 || Loss: 0.41456377 || it_count: 8344 || Val Loss: 0.45353573 || Val it_count: 1107 || Current Learning Rate: 0.001 || Time: 01:59:17.41
Epoch :: 16 || Loss: 0.41441052 || it_count: 8344 || Val Loss: 0.45364536 || Val it_count: 1107 || Current Learning Rate: 0.001 || Time: 02:07:17.58
Epoch :: 17 || Loss: 0.41274256 || it_count: 8344 || Val Loss: 0.45232374 || Val it_count: 1107 || Current Learning Rate: 0.001 || Time: 02:15:15.53
Epoch :: 18 || Loss: 0.41214280 || it_count: 8344 || Val Loss: 0.45190339 || Val it_count: 1107 || Current Learning Rate: 0.001 || Time: 02:23:14.49
Epoch :: 19 || Loss: 0.41178753 || it_count: 8344 || Val Loss: 0.45194410 || Val it_count: 1107 || Current Learning Rate: 0.001 || Time: 02:31:13.98
Epoch :: 20 || Loss: 0.41178793 || it_count: 8344 || Val Loss: 0.45170712 || Val it_count: 1107 || Current Learning Rate: 0.001 || Time: 02:39:13.48
Epoch :: 21 || Loss: 0.41113883 || it_count: 8344 || Val Loss: 0.45183856 || Val it_count: 1107 || Current Learning Rate: 0.001 || Time: 02:47:13.49
Epoch :: 22 || Loss: 0.41060707 || it_count: 8344 || Val Loss: 0.45054580 || Val it_count: 1107 || Current Learning Rate: 0.001 || Time: 02:55:13.63
Epoch :: 23 || Loss: 0.41038741 || it_count: 8344 || Val Loss: 0.45165928 || Val it_count: 1107 || Current Learning Rate: 0.001 || Time: 03:03:11.06
Epoch :: 24 || Loss: 0.41391752 || it_count: 8344 || Val Loss: 0.45432539 || Val it_count: 1107 || Current Learning Rate: 0.001 || Time: 03:11:10.34
Epoch :: 25 || Loss: 0.41145700 || it_count: 8344 || Val Loss: 0.45224747 || Val it_count: 1107 || Current Learning Rate: 0.001 || Time: 03:19:8.04
Early stopping triggered due to patience exceeded.
Done Total time: 03:19:8.04
best_loss: 0.4503372345725087

--------------------Testing--------------------

total_samples :: test_dataset = 139200, test_dataloader = 139200
Epoch ::  1 || Loss: 0.33694689 || it_count: 544 || Time: 00:00:22.53
MAE:  0.2882554
MSE:  0.3370169
RMSE:  0.48760623

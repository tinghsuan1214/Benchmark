--------------------Training--------------------
arch_str :: |lstm_1~0|+|lstm_2~0|lstm_3~1|[relu->linear->dropout->linear]
model :: 3N
InferCell(
  info :: nodes=3, inC=1, outC=64, [1<-(I0-L0) | 2<-(I0-L1,I1-L2)], genotype_str: lstm_1~0|lstm_2~0|lstm_3~1
  linear_layers: [relu->linear->dropout->linear]
  (layers): ModuleList(
    (0): LSTM(
      (lstm): LSTM(1, 64, batch_first=True)
    )
    (1): LSTM(
      (lstm): LSTM(1, 64, num_layers=2, batch_first=True)
    )
    (2): LSTM(
      (lstm): LSTM(64, 64, num_layers=3, batch_first=True)
    )
  )
  (linear_layers): ModuleList(
    (0): ReLU()
    (1): Linear(in_features=3072, out_features=1536, bias=True)
    (2): Dropout(p=0.1, inplace=False)
    (3): Linear(in_features=1536, out_features=1, bias=True)
  )
)
tr_params :: epochs = 100, patience = 20, batch_size = 256, window_size = 48, data_size = 100
Model FLOPs: 12.904M, Model Params: 4.889M
learning rate scheduling :: (optimizer, mode='min', factor=0.1, patience=5, verbose=True)
total_samples :: train_dataset = 2136000, train_dataloader = 2136000
total_samples :: valid_dataset = 283200, valid_dataloader = 283200
Epoch ::  1 || Loss: 0.42428475 || it_count: 8344 || Val Loss: 0.45673663 || Val it_count: 1107 || Current Learning Rate: 0.001 || Time: 00:11:2.26
Epoch ::  2 || Loss: 0.41796554 || it_count: 8344 || Val Loss: 0.45234263 || Val it_count: 1107 || Current Learning Rate: 0.001 || Time: 00:22:10.05
Epoch ::  3 || Loss: 0.41720649 || it_count: 8344 || Val Loss: 0.45212419 || Val it_count: 1107 || Current Learning Rate: 0.001 || Time: 00:33:23.58
Epoch ::  4 || Loss: 0.41710692 || it_count: 8344 || Val Loss: 0.45244900 || Val it_count: 1107 || Current Learning Rate: 0.001 || Time: 00:44:39.57
Epoch ::  5 || Loss: 0.42307392 || it_count: 8344 || Val Loss: 0.45225729 || Val it_count: 1107 || Current Learning Rate: 0.001 || Time: 00:55:56.31
Epoch ::  6 || Loss: 0.41624458 || it_count: 8344 || Val Loss: 0.44993689 || Val it_count: 1107 || Current Learning Rate: 0.001 || Time: 01:07:13.26
Epoch ::  7 || Loss: 0.41628899 || it_count: 8344 || Val Loss: 0.45084624 || Val it_count: 1107 || Current Learning Rate: 0.001 || Time: 01:18:32.42
Epoch ::  8 || Loss: 0.41580968 || it_count: 8344 || Val Loss: 0.44954992 || Val it_count: 1107 || Current Learning Rate: 0.001 || Time: 01:29:51.41
Epoch ::  9 || Loss: 0.41524342 || it_count: 8344 || Val Loss: 0.44941755 || Val it_count: 1107 || Current Learning Rate: 0.001 || Time: 01:41:12.37
Epoch :: 10 || Loss: 0.41499909 || it_count: 8344 || Val Loss: 0.44963792 || Val it_count: 1107 || Current Learning Rate: 0.001 || Time: 01:52:33.07
Epoch :: 11 || Loss: 0.41468458 || it_count: 8344 || Val Loss: 0.44959944 || Val it_count: 1107 || Current Learning Rate: 0.001 || Time: 02:03:55.20
Epoch :: 12 || Loss: 0.41439225 || it_count: 8344 || Val Loss: 0.44915063 || Val it_count: 1107 || Current Learning Rate: 0.001 || Time: 02:15:16.85
Epoch :: 13 || Loss: 0.41441957 || it_count: 8344 || Val Loss: 0.44882236 || Val it_count: 1107 || Current Learning Rate: 0.001 || Time: 02:26:40.26
Epoch :: 14 || Loss: 0.41414193 || it_count: 8344 || Val Loss: 0.44878339 || Val it_count: 1107 || Current Learning Rate: 0.001 || Time: 02:38:3.06
Epoch :: 15 || Loss: 0.41386053 || it_count: 8344 || Val Loss: 0.44879755 || Val it_count: 1107 || Current Learning Rate: 0.001 || Time: 02:49:25.95
Epoch :: 16 || Loss: 0.41437057 || it_count: 8344 || Val Loss: 0.44815091 || Val it_count: 1107 || Current Learning Rate: 0.001 || Time: 03:00:47.32
Epoch :: 17 || Loss: 0.41375676 || it_count: 8344 || Val Loss: 0.44899512 || Val it_count: 1107 || Current Learning Rate: 0.001 || Time: 03:12:9.23
Epoch :: 18 || Loss: 0.41384716 || it_count: 8344 || Val Loss: 0.44792119 || Val it_count: 1107 || Current Learning Rate: 0.001 || Time: 03:23:32.00
Epoch :: 19 || Loss: 0.41266340 || it_count: 8344 || Val Loss: 0.44742705 || Val it_count: 1107 || Current Learning Rate: 0.001 || Time: 03:34:56.56
Epoch :: 20 || Loss: 0.41234194 || it_count: 8344 || Val Loss: 0.44852898 || Val it_count: 1107 || Current Learning Rate: 0.001 || Time: 03:46:19.70
Epoch :: 21 || Loss: 0.41209391 || it_count: 8344 || Val Loss: 0.44840011 || Val it_count: 1107 || Current Learning Rate: 0.001 || Time: 03:57:43.74
Epoch :: 22 || Loss: 0.41209876 || it_count: 8344 || Val Loss: 0.44716971 || Val it_count: 1107 || Current Learning Rate: 0.001 || Time: 04:09:6.81
Epoch :: 23 || Loss: 0.41178037 || it_count: 8344 || Val Loss: 0.44773880 || Val it_count: 1107 || Current Learning Rate: 0.001 || Time: 04:20:30.80
Epoch :: 24 || Loss: 0.41181924 || it_count: 8344 || Val Loss: 0.44750653 || Val it_count: 1107 || Current Learning Rate: 0.001 || Time: 04:31:54.05
Epoch :: 25 || Loss: 0.41139304 || it_count: 8344 || Val Loss: 0.44683235 || Val it_count: 1107 || Current Learning Rate: 0.001 || Time: 04:43:17.77
Epoch :: 26 || Loss: 0.41108470 || it_count: 8344 || Val Loss: 0.44704170 || Val it_count: 1107 || Current Learning Rate: 0.001 || Time: 04:54:40.74
Epoch :: 27 || Loss: 0.41087224 || it_count: 8344 || Val Loss: 0.44750556 || Val it_count: 1107 || Current Learning Rate: 0.001 || Time: 05:06:3.93
Epoch :: 28 || Loss: 0.41115073 || it_count: 8344 || Val Loss: 0.44681591 || Val it_count: 1107 || Current Learning Rate: 0.001 || Time: 05:17:26.76
Epoch :: 29 || Loss: 0.41162140 || it_count: 8344 || Val Loss: 0.44965080 || Val it_count: 1107 || Current Learning Rate: 0.001 || Time: 05:28:50.28
Epoch :: 30 || Loss: 0.41078972 || it_count: 8344 || Val Loss: 0.44912106 || Val it_count: 1107 || Current Learning Rate: 0.001 || Time: 05:40:12.70
Epoch 00015: reducing learning rate of group 0 to 1.0000e-04.
Epoch :: 31 || Loss: 0.41044048 || it_count: 8344 || Val Loss: 0.45045862 || Val it_count: 1107 || Current Learning Rate: 0.0001 || Time: 05:51:35.99
Epoch :: 32 || Loss: 0.41683614 || it_count: 8344 || Val Loss: 0.43158752 || Val it_count: 1107 || Current Learning Rate: 0.0001 || Time: 06:02:58.54
Epoch :: 33 || Loss: 0.41308047 || it_count: 8344 || Val Loss: 0.43001576 || Val it_count: 1107 || Current Learning Rate: 0.0001 || Time: 06:14:22.52
Epoch :: 34 || Loss: 0.41213180 || it_count: 8344 || Val Loss: 0.42927315 || Val it_count: 1107 || Current Learning Rate: 0.0001 || Time: 06:25:45.51
Epoch :: 35 || Loss: 0.41150689 || it_count: 8344 || Val Loss: 0.42866039 || Val it_count: 1107 || Current Learning Rate: 0.0001 || Time: 06:37:9.30
Epoch :: 36 || Loss: 0.41110351 || it_count: 8344 || Val Loss: 0.42811422 || Val it_count: 1107 || Current Learning Rate: 0.0001 || Time: 06:48:32.26
Epoch :: 37 || Loss: 0.41081580 || it_count: 8344 || Val Loss: 0.42773598 || Val it_count: 1107 || Current Learning Rate: 0.0001 || Time: 06:59:55.58
Epoch :: 38 || Loss: 0.41061515 || it_count: 8344 || Val Loss: 0.42677961 || Val it_count: 1107 || Current Learning Rate: 0.0001 || Time: 07:11:17.20
Epoch :: 39 || Loss: 0.41042062 || it_count: 8344 || Val Loss: 0.42682963 || Val it_count: 1107 || Current Learning Rate: 0.0001 || Time: 07:22:39.70
Epoch :: 40 || Loss: 0.41019494 || it_count: 8344 || Val Loss: 0.42601859 || Val it_count: 1107 || Current Learning Rate: 0.0001 || Time: 07:34:1.25
Epoch :: 41 || Loss: 0.41000933 || it_count: 8344 || Val Loss: 0.42616838 || Val it_count: 1107 || Current Learning Rate: 0.0001 || Time: 07:45:24.04
Epoch :: 42 || Loss: 0.40985186 || it_count: 8344 || Val Loss: 0.42616201 || Val it_count: 1107 || Current Learning Rate: 0.0001 || Time: 07:56:45.61
Epoch :: 43 || Loss: 0.40972294 || it_count: 8344 || Val Loss: 0.42624599 || Val it_count: 1107 || Current Learning Rate: 0.0001 || Time: 08:08:8.10
Epoch :: 44 || Loss: 0.40966784 || it_count: 8344 || Val Loss: 0.42551898 || Val it_count: 1107 || Current Learning Rate: 0.0001 || Time: 08:19:29.99
Epoch :: 45 || Loss: 0.40945770 || it_count: 8344 || Val Loss: 0.42586977 || Val it_count: 1107 || Current Learning Rate: 0.0001 || Time: 08:30:52.54
Epoch :: 46 || Loss: 0.40934900 || it_count: 8344 || Val Loss: 0.42564343 || Val it_count: 1107 || Current Learning Rate: 0.0001 || Time: 08:42:13.63
Epoch :: 47 || Loss: 0.40927088 || it_count: 8344 || Val Loss: 0.42548935 || Val it_count: 1107 || Current Learning Rate: 0.0001 || Time: 08:53:36.37
Epoch :: 48 || Loss: 0.40906916 || it_count: 8344 || Val Loss: 0.42604563 || Val it_count: 1107 || Current Learning Rate: 0.0001 || Time: 09:04:57.99
Epoch :: 49 || Loss: 0.40898419 || it_count: 8344 || Val Loss: 0.42616956 || Val it_count: 1107 || Current Learning Rate: 0.0001 || Time: 09:16:19.93
Epoch 00034: reducing learning rate of group 0 to 1.0000e-05.
Epoch :: 50 || Loss: 0.40895028 || it_count: 8344 || Val Loss: 0.42612027 || Val it_count: 1107 || Current Learning Rate: 1e-05 || Time: 09:27:41.04
Epoch :: 51 || Loss: 0.41280177 || it_count: 8344 || Val Loss: 0.41343439 || Val it_count: 1107 || Current Learning Rate: 1e-05 || Time: 09:39:3.10
Epoch :: 52 || Loss: 0.41017397 || it_count: 8344 || Val Loss: 0.41319305 || Val it_count: 1107 || Current Learning Rate: 1e-05 || Time: 09:50:24.92
Epoch :: 53 || Loss: 0.41001036 || it_count: 8344 || Val Loss: 0.41313208 || Val it_count: 1107 || Current Learning Rate: 1e-05 || Time: 10:01:47.82
Epoch :: 54 || Loss: 0.40995268 || it_count: 8344 || Val Loss: 0.41306451 || Val it_count: 1107 || Current Learning Rate: 1e-05 || Time: 10:13:9.74
Epoch :: 55 || Loss: 0.40989144 || it_count: 8344 || Val Loss: 0.41304960 || Val it_count: 1107 || Current Learning Rate: 1e-05 || Time: 10:24:32.67
Epoch :: 56 || Loss: 0.40980373 || it_count: 8344 || Val Loss: 0.41302491 || Val it_count: 1107 || Current Learning Rate: 1e-05 || Time: 10:35:54.91
Epoch :: 57 || Loss: 0.40975892 || it_count: 8344 || Val Loss: 0.41299754 || Val it_count: 1107 || Current Learning Rate: 1e-05 || Time: 10:47:18.03
Epoch :: 58 || Loss: 0.40973262 || it_count: 8344 || Val Loss: 0.41299407 || Val it_count: 1107 || Current Learning Rate: 1e-05 || Time: 10:58:39.91
Epoch :: 59 || Loss: 0.40968284 || it_count: 8344 || Val Loss: 0.41297630 || Val it_count: 1107 || Current Learning Rate: 1e-05 || Time: 11:10:3.10
Epoch :: 60 || Loss: 0.40963979 || it_count: 8344 || Val Loss: 0.41296106 || Val it_count: 1107 || Current Learning Rate: 1e-05 || Time: 11:21:25.04
Epoch :: 61 || Loss: 0.40962292 || it_count: 8344 || Val Loss: 0.41295914 || Val it_count: 1107 || Current Learning Rate: 1e-05 || Time: 11:32:47.90
Epoch :: 62 || Loss: 0.40957068 || it_count: 8344 || Val Loss: 0.41294549 || Val it_count: 1107 || Current Learning Rate: 1e-05 || Time: 11:44:9.87
Epoch :: 63 || Loss: 0.40951581 || it_count: 8344 || Val Loss: 0.41293528 || Val it_count: 1107 || Current Learning Rate: 1e-05 || Time: 11:55:32.84
Epoch :: 64 || Loss: 0.40949332 || it_count: 8344 || Val Loss: 0.41291042 || Val it_count: 1107 || Current Learning Rate: 1e-05 || Time: 12:06:54.71
Epoch :: 65 || Loss: 0.40945877 || it_count: 8344 || Val Loss: 0.41288552 || Val it_count: 1107 || Current Learning Rate: 1e-05 || Time: 12:18:17.67
Epoch :: 66 || Loss: 0.40946460 || it_count: 8344 || Val Loss: 0.41290518 || Val it_count: 1107 || Current Learning Rate: 1e-05 || Time: 12:29:39.40
Epoch :: 67 || Loss: 0.40939449 || it_count: 8344 || Val Loss: 0.41290374 || Val it_count: 1107 || Current Learning Rate: 1e-05 || Time: 12:41:2.45
Epoch :: 68 || Loss: 0.40936776 || it_count: 8344 || Val Loss: 0.41288059 || Val it_count: 1107 || Current Learning Rate: 1e-05 || Time: 12:52:24.23
Epoch :: 69 || Loss: 0.40939421 || it_count: 8344 || Val Loss: 0.41288258 || Val it_count: 1107 || Current Learning Rate: 1e-05 || Time: 13:03:47.55
Epoch :: 70 || Loss: 0.40935999 || it_count: 8344 || Val Loss: 0.41288688 || Val it_count: 1107 || Current Learning Rate: 1e-05 || Time: 13:15:9.33
Epoch 00055: reducing learning rate of group 0 to 1.0000e-06.
Epoch :: 71 || Loss: 0.40928343 || it_count: 8344 || Val Loss: 0.41290011 || Val it_count: 1107 || Current Learning Rate: 1.0000000000000002e-06 || Time: 13:26:32.00
Epoch :: 72 || Loss: 0.40965114 || it_count: 8344 || Val Loss: 0.41224748 || Val it_count: 1107 || Current Learning Rate: 1.0000000000000002e-06 || Time: 13:37:53.84
Epoch :: 73 || Loss: 0.40953767 || it_count: 8344 || Val Loss: 0.41219743 || Val it_count: 1107 || Current Learning Rate: 1.0000000000000002e-06 || Time: 13:49:16.66
Epoch :: 74 || Loss: 0.40946926 || it_count: 8344 || Val Loss: 0.41218413 || Val it_count: 1107 || Current Learning Rate: 1.0000000000000002e-06 || Time: 14:00:38.77
Epoch :: 75 || Loss: 0.40945864 || it_count: 8344 || Val Loss: 0.41217309 || Val it_count: 1107 || Current Learning Rate: 1.0000000000000002e-06 || Time: 14:12:1.42
Epoch :: 76 || Loss: 0.40942486 || it_count: 8344 || Val Loss: 0.41216706 || Val it_count: 1107 || Current Learning Rate: 1.0000000000000002e-06 || Time: 14:23:23.59
Epoch :: 77 || Loss: 0.40942974 || it_count: 8344 || Val Loss: 0.41215886 || Val it_count: 1107 || Current Learning Rate: 1.0000000000000002e-06 || Time: 14:34:46.58
Epoch :: 78 || Loss: 0.40941283 || it_count: 8344 || Val Loss: 0.41215713 || Val it_count: 1107 || Current Learning Rate: 1.0000000000000002e-06 || Time: 14:46:8.62
Epoch :: 79 || Loss: 0.40943664 || it_count: 8344 || Val Loss: 0.41215156 || Val it_count: 1107 || Current Learning Rate: 1.0000000000000002e-06 || Time: 14:57:32.64
Epoch :: 80 || Loss: 0.40941996 || it_count: 8344 || Val Loss: 0.41214923 || Val it_count: 1107 || Current Learning Rate: 1.0000000000000002e-06 || Time: 15:08:55.17
Epoch :: 81 || Loss: 0.40944582 || it_count: 8344 || Val Loss: 0.41214480 || Val it_count: 1107 || Current Learning Rate: 1.0000000000000002e-06 || Time: 15:20:18.92
Epoch :: 82 || Loss: 0.40942132 || it_count: 8344 || Val Loss: 0.41214360 || Val it_count: 1107 || Current Learning Rate: 1.0000000000000002e-06 || Time: 15:31:41.94
Epoch :: 83 || Loss: 0.40937220 || it_count: 8344 || Val Loss: 0.41214530 || Val it_count: 1107 || Current Learning Rate: 1.0000000000000002e-06 || Time: 15:43:6.80
Epoch :: 84 || Loss: 0.40934508 || it_count: 8344 || Val Loss: 0.41214129 || Val it_count: 1107 || Current Learning Rate: 1.0000000000000002e-06 || Time: 15:54:31.39
Epoch 00069: reducing learning rate of group 0 to 1.0000e-07.
Early stopping triggered due to learning rate below threshold.
Done Total time: 16:05:57.01
best_loss: 0.4121412869033772

--------------------Testing--------------------

total_samples :: test_dataset = 139200, test_dataloader = 139200
Epoch ::  1 || Loss: 0.23614995 || it_count: 544 || Time: 00:00:27.17
MAE:  0.25344506
MSE:  0.23617056
RMSE:  0.44193706

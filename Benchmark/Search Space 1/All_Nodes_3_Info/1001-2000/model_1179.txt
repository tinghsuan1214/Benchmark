--------------------Training--------------------
arch_str :: |lstm_3~0|+|none~0|lstm_1~1|[dropout->linear->dropout->linear]
model :: 3J
InferCell(
  info :: nodes=3, inC=1, outC=64, [1<-(I0-L0) | 2<-(I0-L1,I1-L2)], genotype_str: lstm_3~0|none~0|lstm_1~1
  linear_layers: [dropout->linear->dropout->linear]
  (layers): ModuleList(
    (0): LSTM(
      (lstm): LSTM(1, 64, num_layers=3, batch_first=True)
    )
    (1): Zero(C_in=1, C_out=64, stride=1)
    (2): LSTM(
      (lstm): LSTM(64, 64, batch_first=True)
    )
  )
  (linear_layers): ModuleList(
    (0): Dropout(p=0.1, inplace=False)
    (1): Linear(in_features=3072, out_features=1536, bias=True)
    (2): Dropout(p=0.1, inplace=False)
    (3): Linear(in_features=1536, out_features=1, bias=True)
  )
)
tr_params :: epochs = 100, patience = 20, batch_size = 256, window_size = 48, data_size = 100
Model FLOPs: 10.434M, Model Params: 4.839M
learning rate scheduling :: (optimizer, mode='min', factor=0.1, patience=5, verbose=True)
total_samples :: train_dataset = 2136000, train_dataloader = 2136000
total_samples :: valid_dataset = 283200, valid_dataloader = 283200
Epoch ::  1 || Loss: 0.43184495 || it_count: 8344 || Val Loss: 0.45675895 || Val it_count: 1107 || Current Learning Rate: 0.001 || Time: 00:04:18.45
Epoch ::  2 || Loss: 0.41956567 || it_count: 8344 || Val Loss: 0.45242814 || Val it_count: 1107 || Current Learning Rate: 0.001 || Time: 00:08:34.70
Epoch ::  3 || Loss: 0.41924171 || it_count: 8344 || Val Loss: 0.45732504 || Val it_count: 1107 || Current Learning Rate: 0.001 || Time: 00:12:45.96
Epoch ::  4 || Loss: 0.41890195 || it_count: 8344 || Val Loss: 0.45760260 || Val it_count: 1107 || Current Learning Rate: 0.001 || Time: 00:17:1.81
Epoch ::  5 || Loss: 0.41815342 || it_count: 8344 || Val Loss: 0.45662033 || Val it_count: 1107 || Current Learning Rate: 0.001 || Time: 00:21:14.41
Epoch ::  6 || Loss: 0.41766840 || it_count: 8344 || Val Loss: 0.45604037 || Val it_count: 1107 || Current Learning Rate: 0.001 || Time: 00:25:27.36
Epoch ::  7 || Loss: 0.41711430 || it_count: 8344 || Val Loss: 0.45486599 || Val it_count: 1107 || Current Learning Rate: 0.001 || Time: 00:29:41.14
Epoch ::  8 || Loss: 0.41670336 || it_count: 8344 || Val Loss: 0.45404619 || Val it_count: 1107 || Current Learning Rate: 0.001 || Time: 00:33:54.79
Epoch ::  9 || Loss: 0.41630818 || it_count: 8344 || Val Loss: 0.45268074 || Val it_count: 1107 || Current Learning Rate: 0.001 || Time: 00:38:8.60
Epoch :: 10 || Loss: 0.41623855 || it_count: 8344 || Val Loss: 0.45320899 || Val it_count: 1107 || Current Learning Rate: 0.001 || Time: 00:42:22.18
Epoch :: 11 || Loss: 0.41592488 || it_count: 8344 || Val Loss: 0.45335877 || Val it_count: 1107 || Current Learning Rate: 0.001 || Time: 00:46:34.29
Epoch :: 12 || Loss: 0.41582660 || it_count: 8344 || Val Loss: 0.45339374 || Val it_count: 1107 || Current Learning Rate: 0.001 || Time: 00:50:46.36
Epoch :: 13 || Loss: 0.41575968 || it_count: 8344 || Val Loss: 0.45361996 || Val it_count: 1107 || Current Learning Rate: 0.001 || Time: 00:54:56.17
Epoch :: 14 || Loss: 0.41536082 || it_count: 8344 || Val Loss: 0.45289014 || Val it_count: 1107 || Current Learning Rate: 0.001 || Time: 00:59:5.69
Epoch :: 15 || Loss: 0.41446027 || it_count: 8344 || Val Loss: 0.45614534 || Val it_count: 1107 || Current Learning Rate: 0.001 || Time: 01:03:16.75
Epoch :: 16 || Loss: 0.41388109 || it_count: 8344 || Val Loss: 0.45450134 || Val it_count: 1107 || Current Learning Rate: 0.001 || Time: 01:07:27.10
Epoch :: 17 || Loss: 0.41367812 || it_count: 8344 || Val Loss: 0.45414759 || Val it_count: 1107 || Current Learning Rate: 0.001 || Time: 01:11:37.65
Epoch :: 18 || Loss: 0.41384844 || it_count: 8344 || Val Loss: 0.45526064 || Val it_count: 1107 || Current Learning Rate: 0.001 || Time: 01:15:49.40
Epoch :: 19 || Loss: 0.41344889 || it_count: 8344 || Val Loss: 0.45343478 || Val it_count: 1107 || Current Learning Rate: 0.001 || Time: 01:20:0.61
Epoch :: 20 || Loss: 0.41345703 || it_count: 8344 || Val Loss: 0.45254753 || Val it_count: 1107 || Current Learning Rate: 0.001 || Time: 01:24:10.63
Epoch :: 21 || Loss: 0.41342125 || it_count: 8344 || Val Loss: 0.45234770 || Val it_count: 1107 || Current Learning Rate: 0.001 || Time: 01:28:21.23
Epoch :: 22 || Loss: 0.41307930 || it_count: 8344 || Val Loss: 0.45176624 || Val it_count: 1107 || Current Learning Rate: 0.001 || Time: 01:32:32.64
Epoch :: 23 || Loss: 0.41396648 || it_count: 8344 || Val Loss: 0.45244593 || Val it_count: 1107 || Current Learning Rate: 0.001 || Time: 01:36:44.38
Epoch :: 24 || Loss: 0.41330821 || it_count: 8344 || Val Loss: 0.45030924 || Val it_count: 1107 || Current Learning Rate: 0.001 || Time: 01:40:55.99
Epoch :: 25 || Loss: 0.41278612 || it_count: 8344 || Val Loss: 0.44783230 || Val it_count: 1107 || Current Learning Rate: 0.001 || Time: 01:45:5.81
Epoch :: 26 || Loss: 0.41218272 || it_count: 8344 || Val Loss: 0.44837270 || Val it_count: 1107 || Current Learning Rate: 0.001 || Time: 01:49:17.81
Epoch :: 27 || Loss: 0.41160155 || it_count: 8344 || Val Loss: 0.44882645 || Val it_count: 1107 || Current Learning Rate: 0.001 || Time: 01:53:29.08
Epoch :: 28 || Loss: 0.41138083 || it_count: 8344 || Val Loss: 0.44848552 || Val it_count: 1107 || Current Learning Rate: 0.001 || Time: 01:57:41.94
Epoch :: 29 || Loss: 0.41205814 || it_count: 8344 || Val Loss: 0.44874751 || Val it_count: 1107 || Current Learning Rate: 0.001 || Time: 02:01:52.91
Epoch :: 30 || Loss: 0.41056024 || it_count: 8344 || Val Loss: 0.44829898 || Val it_count: 1107 || Current Learning Rate: 0.001 || Time: 02:06:3.94
Epoch :: 31 || Loss: 0.41069668 || it_count: 8344 || Val Loss: 0.44748029 || Val it_count: 1107 || Current Learning Rate: 0.001 || Time: 02:10:15.98
Epoch :: 32 || Loss: 0.40996853 || it_count: 8344 || Val Loss: 0.44863901 || Val it_count: 1107 || Current Learning Rate: 0.001 || Time: 02:14:28.50
Epoch :: 33 || Loss: 0.40943526 || it_count: 8344 || Val Loss: 0.44855364 || Val it_count: 1107 || Current Learning Rate: 0.001 || Time: 02:18:40.57
Epoch :: 34 || Loss: 0.40942306 || it_count: 8344 || Val Loss: 0.44874193 || Val it_count: 1107 || Current Learning Rate: 0.001 || Time: 02:22:54.27
Epoch :: 35 || Loss: 0.40924771 || it_count: 8344 || Val Loss: 0.45042553 || Val it_count: 1107 || Current Learning Rate: 0.001 || Time: 02:27:8.04
Epoch :: 36 || Loss: 0.40935195 || it_count: 8344 || Val Loss: 0.44899250 || Val it_count: 1107 || Current Learning Rate: 0.001 || Time: 02:31:19.03
Epoch :: 37 || Loss: 0.40830369 || it_count: 8344 || Val Loss: 0.44937621 || Val it_count: 1107 || Current Learning Rate: 0.0001 || Time: 02:35:31.41
Epoch :: 38 || Loss: 0.41589320 || it_count: 8344 || Val Loss: 0.43083394 || Val it_count: 1107 || Current Learning Rate: 0.0001 || Time: 02:39:43.32
Epoch :: 39 || Loss: 0.41173221 || it_count: 8344 || Val Loss: 0.42912377 || Val it_count: 1107 || Current Learning Rate: 0.0001 || Time: 02:43:53.07
Epoch :: 40 || Loss: 0.41059327 || it_count: 8344 || Val Loss: 0.42805484 || Val it_count: 1107 || Current Learning Rate: 0.0001 || Time: 02:48:4.36
Epoch :: 41 || Loss: 0.40989815 || it_count: 8344 || Val Loss: 0.42743464 || Val it_count: 1107 || Current Learning Rate: 0.0001 || Time: 02:52:13.06
Epoch :: 42 || Loss: 0.40940640 || it_count: 8344 || Val Loss: 0.42780937 || Val it_count: 1107 || Current Learning Rate: 0.0001 || Time: 02:56:25.07
Epoch :: 43 || Loss: 0.40901598 || it_count: 8344 || Val Loss: 0.42752768 || Val it_count: 1107 || Current Learning Rate: 0.0001 || Time: 03:00:36.43
Epoch :: 44 || Loss: 0.40868018 || it_count: 8344 || Val Loss: 0.42780224 || Val it_count: 1107 || Current Learning Rate: 0.0001 || Time: 03:04:49.32
Epoch :: 45 || Loss: 0.40843318 || it_count: 8344 || Val Loss: 0.42793037 || Val it_count: 1107 || Current Learning Rate: 0.0001 || Time: 03:09:1.65
Epoch :: 46 || Loss: 0.40820027 || it_count: 8344 || Val Loss: 0.42735024 || Val it_count: 1107 || Current Learning Rate: 0.0001 || Time: 03:13:13.99
Epoch :: 47 || Loss: 0.40781076 || it_count: 8344 || Val Loss: 0.42790960 || Val it_count: 1107 || Current Learning Rate: 0.0001 || Time: 03:17:27.63
Epoch :: 48 || Loss: 0.40774460 || it_count: 8344 || Val Loss: 0.42759267 || Val it_count: 1107 || Current Learning Rate: 0.0001 || Time: 03:21:38.42
Epoch :: 49 || Loss: 0.40739451 || it_count: 8344 || Val Loss: 0.42729224 || Val it_count: 1107 || Current Learning Rate: 0.0001 || Time: 03:25:52.33
Epoch :: 50 || Loss: 0.40715834 || it_count: 8344 || Val Loss: 0.42765385 || Val it_count: 1107 || Current Learning Rate: 0.0001 || Time: 03:30:5.23
Epoch :: 51 || Loss: 0.40706407 || it_count: 8344 || Val Loss: 0.42755821 || Val it_count: 1107 || Current Learning Rate: 0.0001 || Time: 03:34:18.12
Epoch :: 52 || Loss: 0.40674647 || it_count: 8344 || Val Loss: 0.42747454 || Val it_count: 1107 || Current Learning Rate: 0.0001 || Time: 03:38:31.24
Epoch :: 53 || Loss: 0.40665217 || it_count: 8344 || Val Loss: 0.42750121 || Val it_count: 1107 || Current Learning Rate: 0.0001 || Time: 03:42:44.53
Epoch :: 54 || Loss: 0.40653463 || it_count: 8344 || Val Loss: 0.42739936 || Val it_count: 1107 || Current Learning Rate: 0.0001 || Time: 03:46:54.82
Epoch :: 55 || Loss: 0.40631269 || it_count: 8344 || Val Loss: 0.42738965 || Val it_count: 1107 || Current Learning Rate: 1e-05 || Time: 03:51:7.27
Epoch :: 56 || Loss: 0.41030910 || it_count: 8344 || Val Loss: 0.41353700 || Val it_count: 1107 || Current Learning Rate: 1e-05 || Time: 03:55:19.79
Epoch :: 57 || Loss: 0.40812126 || it_count: 8344 || Val Loss: 0.41335784 || Val it_count: 1107 || Current Learning Rate: 1e-05 || Time: 03:59:32.66
Epoch :: 58 || Loss: 0.40781854 || it_count: 8344 || Val Loss: 0.41318493 || Val it_count: 1107 || Current Learning Rate: 1e-05 || Time: 04:03:47.94
Epoch :: 59 || Loss: 0.40764427 || it_count: 8344 || Val Loss: 0.41312373 || Val it_count: 1107 || Current Learning Rate: 1e-05 || Time: 04:07:59.80
Epoch :: 60 || Loss: 0.40759262 || it_count: 8344 || Val Loss: 0.41307034 || Val it_count: 1107 || Current Learning Rate: 1e-05 || Time: 04:12:13.23
Epoch :: 61 || Loss: 0.40743596 || it_count: 8344 || Val Loss: 0.41301174 || Val it_count: 1107 || Current Learning Rate: 1e-05 || Time: 04:16:24.42
Epoch :: 62 || Loss: 0.40736644 || it_count: 8344 || Val Loss: 0.41305622 || Val it_count: 1107 || Current Learning Rate: 1e-05 || Time: 04:20:37.24
Epoch :: 63 || Loss: 0.40729285 || it_count: 8344 || Val Loss: 0.41307200 || Val it_count: 1107 || Current Learning Rate: 1e-05 || Time: 04:24:50.78
Epoch :: 64 || Loss: 0.40721371 || it_count: 8344 || Val Loss: 0.41307087 || Val it_count: 1107 || Current Learning Rate: 1e-05 || Time: 04:29:4.65
Epoch :: 65 || Loss: 0.40713444 || it_count: 8344 || Val Loss: 0.41302561 || Val it_count: 1107 || Current Learning Rate: 1e-05 || Time: 04:33:17.91
Epoch :: 66 || Loss: 0.40707157 || it_count: 8344 || Val Loss: 0.41301915 || Val it_count: 1107 || Current Learning Rate: 1e-05 || Time: 04:37:29.80
Epoch :: 67 || Loss: 0.40707487 || it_count: 8344 || Val Loss: 0.41300162 || Val it_count: 1107 || Current Learning Rate: 1.0000000000000002e-06 || Time: 04:41:39.89
Epoch :: 68 || Loss: 0.40751263 || it_count: 8344 || Val Loss: 0.41188581 || Val it_count: 1107 || Current Learning Rate: 1.0000000000000002e-06 || Time: 04:45:51.87
Epoch :: 69 || Loss: 0.40730290 || it_count: 8344 || Val Loss: 0.41178576 || Val it_count: 1107 || Current Learning Rate: 1.0000000000000002e-06 || Time: 04:50:3.80
Epoch :: 70 || Loss: 0.40727959 || it_count: 8344 || Val Loss: 0.41174650 || Val it_count: 1107 || Current Learning Rate: 1.0000000000000002e-06 || Time: 04:54:16.11
Epoch :: 71 || Loss: 0.40716205 || it_count: 8344 || Val Loss: 0.41172170 || Val it_count: 1107 || Current Learning Rate: 1.0000000000000002e-06 || Time: 04:58:30.50
Epoch :: 72 || Loss: 0.40718049 || it_count: 8344 || Val Loss: 0.41170696 || Val it_count: 1107 || Current Learning Rate: 1.0000000000000002e-06 || Time: 05:02:41.83
Epoch :: 73 || Loss: 0.40715901 || it_count: 8344 || Val Loss: 0.41170092 || Val it_count: 1107 || Current Learning Rate: 1.0000000000000002e-06 || Time: 05:06:55.03
Epoch :: 74 || Loss: 0.40710936 || it_count: 8344 || Val Loss: 0.41168636 || Val it_count: 1107 || Current Learning Rate: 1.0000000000000002e-06 || Time: 05:11:7.55
Epoch :: 75 || Loss: 0.40712770 || it_count: 8344 || Val Loss: 0.41167943 || Val it_count: 1107 || Current Learning Rate: 1.0000000000000002e-06 || Time: 05:15:18.48
Epoch :: 76 || Loss: 0.40715881 || it_count: 8344 || Val Loss: 0.41167062 || Val it_count: 1107 || Current Learning Rate: 1.0000000000000002e-06 || Time: 05:19:32.31
Epoch :: 77 || Loss: 0.40710087 || it_count: 8344 || Val Loss: 0.41166828 || Val it_count: 1107 || Current Learning Rate: 1.0000000000000002e-06 || Time: 05:23:46.54
Epoch :: 78 || Loss: 0.40712034 || it_count: 8344 || Val Loss: 0.41166234 || Val it_count: 1107 || Current Learning Rate: 1.0000000000000002e-06 || Time: 05:27:57.85
Epoch :: 79 || Loss: 0.40715217 || it_count: 8344 || Val Loss: 0.41166060 || Val it_count: 1107 || Current Learning Rate: 1.0000000000000002e-06 || Time: 05:32:12.40
Epoch :: 80 || Loss: 0.40704295 || it_count: 8344 || Val Loss: 0.41164874 || Val it_count: 1107 || Current Learning Rate: 1.0000000000000002e-06 || Time: 05:36:26.10
Early stopping triggered due to learning rate below threshold.
Done Total time: 05:40:41.21
best_loss: 0.41164873525893686

--------------------Testing--------------------

total_samples :: test_dataset = 139200, test_dataloader = 139200
Epoch ::  1 || Loss: 0.23523662 || it_count: 544 || Time: 00:00:13.22
MAE:  0.25249293
MSE:  0.23526019
RMSE:  0.44119573

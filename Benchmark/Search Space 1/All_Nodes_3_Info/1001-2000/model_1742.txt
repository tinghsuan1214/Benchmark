--------------------Training--------------------
arch_str :: |skip_connect~0|+|none~0|lstm_1~1|[relu->linear->dropout->linear]
model :: 3N
InferCell(
  info :: nodes=3, inC=1, outC=64, [1<-(I0-L0) | 2<-(I0-L1,I1-L2)], genotype_str: skip_connect~0|none~0|lstm_1~1
  linear_layers: [relu->linear->dropout->linear]
  (layers): ModuleList(
    (0): FactorizedReduce(
      C_in=1, C_out=64, stride=1
      (relu): ReLU()
      (conv): Conv1d(1, 64, kernel_size=(1,), stride=(1,), bias=False)
      (bn): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (1): Zero(C_in=1, C_out=64, stride=1)
    (2): LSTM(
      (lstm): LSTM(64, 64, batch_first=True)
    )
  )
  (linear_layers): ModuleList(
    (0): ReLU()
    (1): Linear(in_features=3072, out_features=1536, bias=True)
    (2): Dropout(p=0.1, inplace=False)
    (3): Linear(in_features=1536, out_features=1, bias=True)
  )
)
tr_params :: epochs = 100, patience = 20, batch_size = 256, window_size = 48, data_size = 100
Model FLOPs: 6.358M, Model Params: 4.755M
learning rate scheduling :: (optimizer, mode='min', factor=0.1, patience=5, verbose=True)
total_samples :: train_dataset = 2136000, train_dataloader = 2136000
total_samples :: valid_dataset = 283200, valid_dataloader = 283200
Epoch ::  1 || Loss: 0.46060270 || it_count: 8344 || Val Loss: 0.50946662 || Val it_count: 1107 || Current Learning Rate: 0.001 || Time: 00:06:0.95
Epoch ::  2 || Loss: 0.45525687 || it_count: 8344 || Val Loss: 0.49350450 || Val it_count: 1107 || Current Learning Rate: 0.001 || Time: 00:11:56.57
Epoch ::  3 || Loss: 0.44417363 || it_count: 8344 || Val Loss: 0.50320875 || Val it_count: 1107 || Current Learning Rate: 0.001 || Time: 00:17:49.10
Epoch ::  4 || Loss: 0.44171372 || it_count: 8344 || Val Loss: 0.50225850 || Val it_count: 1107 || Current Learning Rate: 0.001 || Time: 00:23:42.27
Epoch ::  5 || Loss: 0.44683820 || it_count: 8344 || Val Loss: 0.50534746 || Val it_count: 1107 || Current Learning Rate: 0.001 || Time: 00:29:37.03
Epoch ::  6 || Loss: 0.44502788 || it_count: 8344 || Val Loss: 0.50571488 || Val it_count: 1107 || Current Learning Rate: 0.001 || Time: 00:35:29.62
Epoch ::  7 || Loss: 0.45233046 || it_count: 8344 || Val Loss: 0.49990351 || Val it_count: 1107 || Current Learning Rate: 0.001 || Time: 00:41:24.37
Epoch ::  8 || Loss: 0.44895176 || it_count: 8344 || Val Loss: 0.50762512 || Val it_count: 1107 || Current Learning Rate: 0.001 || Time: 00:47:18.52
Epoch ::  9 || Loss: 0.44543717 || it_count: 8344 || Val Loss: 0.50592631 || Val it_count: 1107 || Current Learning Rate: 0.001 || Time: 00:53:13.26
Epoch :: 10 || Loss: 0.44822609 || it_count: 8344 || Val Loss: 0.49944640 || Val it_count: 1107 || Current Learning Rate: 0.001 || Time: 00:59:7.65
Epoch :: 11 || Loss: 0.44770429 || it_count: 8344 || Val Loss: 0.50367206 || Val it_count: 1107 || Current Learning Rate: 0.001 || Time: 01:05:1.77
Epoch :: 12 || Loss: 0.44453895 || it_count: 8344 || Val Loss: 0.50499204 || Val it_count: 1107 || Current Learning Rate: 0.001 || Time: 01:10:57.09
Epoch :: 13 || Loss: 0.44521837 || it_count: 8344 || Val Loss: 0.50411195 || Val it_count: 1107 || Current Learning Rate: 0.001 || Time: 01:16:51.60
Epoch :: 14 || Loss: 0.44411511 || it_count: 8344 || Val Loss: 0.50207694 || Val it_count: 1107 || Current Learning Rate: 0.001 || Time: 01:22:44.28
Epoch :: 15 || Loss: 0.44788469 || it_count: 8344 || Val Loss: 0.49662389 || Val it_count: 1107 || Current Learning Rate: 0.001 || Time: 01:28:36.97
Epoch :: 16 || Loss: 0.45389297 || it_count: 8344 || Val Loss: 0.49721334 || Val it_count: 1107 || Current Learning Rate: 0.001 || Time: 01:34:30.30
Epoch :: 17 || Loss: 0.44920158 || it_count: 8344 || Val Loss: 0.49222560 || Val it_count: 1107 || Current Learning Rate: 0.001 || Time: 01:40:21.64
Epoch :: 18 || Loss: 0.45097549 || it_count: 8344 || Val Loss: 0.51954212 || Val it_count: 1107 || Current Learning Rate: 0.001 || Time: 01:46:14.18
Epoch :: 19 || Loss: 0.44849369 || it_count: 8344 || Val Loss: 0.51235712 || Val it_count: 1107 || Current Learning Rate: 0.001 || Time: 01:52:6.84
Epoch :: 20 || Loss: 0.44629401 || it_count: 8344 || Val Loss: 0.50505927 || Val it_count: 1107 || Current Learning Rate: 0.001 || Time: 01:58:1.93
Epoch :: 21 || Loss: 0.44465072 || it_count: 8344 || Val Loss: 0.51169445 || Val it_count: 1107 || Current Learning Rate: 0.001 || Time: 02:03:55.13
Epoch :: 22 || Loss: 0.44370083 || it_count: 8344 || Val Loss: 0.50783037 || Val it_count: 1107 || Current Learning Rate: 0.001 || Time: 02:09:46.79
Epoch 00007: reducing learning rate of group 0 to 1.0000e-04.
Epoch :: 23 || Loss: 0.44290744 || it_count: 8344 || Val Loss: 0.50450449 || Val it_count: 1107 || Current Learning Rate: 0.0001 || Time: 02:15:41.65
Epoch :: 24 || Loss: 0.44631581 || it_count: 8344 || Val Loss: 0.49224620 || Val it_count: 1107 || Current Learning Rate: 0.0001 || Time: 02:21:34.76
Epoch :: 25 || Loss: 0.43891516 || it_count: 8344 || Val Loss: 0.49134969 || Val it_count: 1107 || Current Learning Rate: 0.0001 || Time: 02:27:28.49
Epoch :: 26 || Loss: 0.43674027 || it_count: 8344 || Val Loss: 0.48981050 || Val it_count: 1107 || Current Learning Rate: 0.0001 || Time: 02:33:22.10
Epoch :: 27 || Loss: 0.43558473 || it_count: 8344 || Val Loss: 0.48945895 || Val it_count: 1107 || Current Learning Rate: 0.0001 || Time: 02:39:15.25
Epoch :: 28 || Loss: 0.43440706 || it_count: 8344 || Val Loss: 0.48889122 || Val it_count: 1107 || Current Learning Rate: 0.0001 || Time: 02:45:7.93
Epoch :: 29 || Loss: 0.43324014 || it_count: 8344 || Val Loss: 0.48956821 || Val it_count: 1107 || Current Learning Rate: 0.0001 || Time: 02:51:2.02
Epoch :: 30 || Loss: 0.43221949 || it_count: 8344 || Val Loss: 0.48866775 || Val it_count: 1107 || Current Learning Rate: 0.0001 || Time: 02:56:56.21
Epoch :: 31 || Loss: 0.43121496 || it_count: 8344 || Val Loss: 0.48768203 || Val it_count: 1107 || Current Learning Rate: 0.0001 || Time: 03:02:50.03
Epoch :: 32 || Loss: 0.43047566 || it_count: 8344 || Val Loss: 0.48609221 || Val it_count: 1107 || Current Learning Rate: 0.0001 || Time: 03:08:43.18
Epoch :: 33 || Loss: 0.42980125 || it_count: 8344 || Val Loss: 0.48489449 || Val it_count: 1107 || Current Learning Rate: 0.0001 || Time: 03:14:36.75
Epoch :: 34 || Loss: 0.42928649 || it_count: 8344 || Val Loss: 0.48322385 || Val it_count: 1107 || Current Learning Rate: 0.0001 || Time: 03:20:31.10
Epoch :: 35 || Loss: 0.42882921 || it_count: 8344 || Val Loss: 0.48407897 || Val it_count: 1107 || Current Learning Rate: 0.0001 || Time: 03:26:25.27
Epoch :: 36 || Loss: 0.42842714 || it_count: 8344 || Val Loss: 0.48374606 || Val it_count: 1107 || Current Learning Rate: 0.0001 || Time: 03:32:18.07
Epoch :: 37 || Loss: 0.42797330 || it_count: 8344 || Val Loss: 0.48539007 || Val it_count: 1107 || Current Learning Rate: 0.0001 || Time: 03:38:11.55
Epoch :: 38 || Loss: 0.42771170 || it_count: 8344 || Val Loss: 0.48263463 || Val it_count: 1107 || Current Learning Rate: 0.0001 || Time: 03:44:4.87
Epoch :: 39 || Loss: 0.42755531 || it_count: 8344 || Val Loss: 0.48554985 || Val it_count: 1107 || Current Learning Rate: 0.0001 || Time: 03:49:59.74
Epoch :: 40 || Loss: 0.42723383 || it_count: 8344 || Val Loss: 0.48568952 || Val it_count: 1107 || Current Learning Rate: 0.0001 || Time: 03:55:54.21
Epoch :: 41 || Loss: 0.42680676 || it_count: 8344 || Val Loss: 0.48603214 || Val it_count: 1107 || Current Learning Rate: 0.0001 || Time: 04:01:48.97
Epoch :: 42 || Loss: 0.42654240 || it_count: 8344 || Val Loss: 0.48445189 || Val it_count: 1107 || Current Learning Rate: 0.0001 || Time: 04:07:41.79
Epoch :: 43 || Loss: 0.42633355 || it_count: 8344 || Val Loss: 0.48701333 || Val it_count: 1107 || Current Learning Rate: 0.0001 || Time: 04:13:36.63
Epoch 00028: reducing learning rate of group 0 to 1.0000e-05.
Epoch :: 44 || Loss: 0.42598595 || it_count: 8344 || Val Loss: 0.48574669 || Val it_count: 1107 || Current Learning Rate: 1e-05 || Time: 04:19:30.02
Epoch :: 45 || Loss: 0.43578860 || it_count: 8344 || Val Loss: 0.47312138 || Val it_count: 1107 || Current Learning Rate: 1e-05 || Time: 04:25:24.26
Epoch :: 46 || Loss: 0.43134553 || it_count: 8344 || Val Loss: 0.47288731 || Val it_count: 1107 || Current Learning Rate: 1e-05 || Time: 04:31:18.95
Epoch :: 47 || Loss: 0.42968889 || it_count: 8344 || Val Loss: 0.47323753 || Val it_count: 1107 || Current Learning Rate: 1e-05 || Time: 04:37:12.76
Epoch :: 48 || Loss: 0.42868057 || it_count: 8344 || Val Loss: 0.47370551 || Val it_count: 1107 || Current Learning Rate: 1e-05 || Time: 04:43:5.59
Epoch :: 49 || Loss: 0.42800735 || it_count: 8344 || Val Loss: 0.47447110 || Val it_count: 1107 || Current Learning Rate: 1e-05 || Time: 04:49:0.07
Epoch :: 50 || Loss: 0.42736309 || it_count: 8344 || Val Loss: 0.47528751 || Val it_count: 1107 || Current Learning Rate: 1e-05 || Time: 04:54:52.64
Epoch :: 51 || Loss: 0.42692834 || it_count: 8344 || Val Loss: 0.47604901 || Val it_count: 1107 || Current Learning Rate: 1e-05 || Time: 05:00:45.47
Epoch 00036: reducing learning rate of group 0 to 1.0000e-06.
Epoch :: 52 || Loss: 0.42649077 || it_count: 8344 || Val Loss: 0.47659077 || Val it_count: 1107 || Current Learning Rate: 1.0000000000000002e-06 || Time: 05:06:40.74
Epoch :: 53 || Loss: 0.42993110 || it_count: 8344 || Val Loss: 0.47709647 || Val it_count: 1107 || Current Learning Rate: 1.0000000000000002e-06 || Time: 05:12:34.45
Epoch :: 54 || Loss: 0.42928154 || it_count: 8344 || Val Loss: 0.47708866 || Val it_count: 1107 || Current Learning Rate: 1.0000000000000002e-06 || Time: 05:18:29.80
Epoch :: 55 || Loss: 0.42895492 || it_count: 8344 || Val Loss: 0.47698450 || Val it_count: 1107 || Current Learning Rate: 1.0000000000000002e-06 || Time: 05:24:23.78
Epoch :: 56 || Loss: 0.42869469 || it_count: 8344 || Val Loss: 0.47690204 || Val it_count: 1107 || Current Learning Rate: 1.0000000000000002e-06 || Time: 05:30:17.82
Epoch :: 57 || Loss: 0.42847363 || it_count: 8344 || Val Loss: 0.47683036 || Val it_count: 1107 || Current Learning Rate: 1.0000000000000002e-06 || Time: 05:36:12.85
Epoch 00042: reducing learning rate of group 0 to 1.0000e-07.
Early stopping triggered due to learning rate below threshold.
Done Total time: 05:42:7.73
best_loss: 0.47288730530559137

--------------------Testing--------------------

total_samples :: test_dataset = 139200, test_dataloader = 139200
Epoch ::  1 || Loss: 0.53455896 || it_count: 544 || Time: 00:00:19.36
MAE:  0.33332512
MSE:  0.53471184
RMSE:  0.5323272

--------------------Training--------------------
arch_str :: |lstm_1~0|+|lstm_3~0|none~1|[relu->linear->dropout->linear]
model :: 3N
InferCell(
  info :: nodes=3, inC=1, outC=64, [1<-(I0-L0) | 2<-(I0-L1,I1-L2)], genotype_str: lstm_1~0|lstm_3~0|none~1
  linear_layers: [relu->linear->dropout->linear]
  (layers): ModuleList(
    (0): LSTM(
      (lstm): LSTM(1, 64, batch_first=True)
    )
    (1): LSTM(
      (lstm): LSTM(1, 64, num_layers=3, batch_first=True)
    )
    (2): Zero(C_in=64, C_out=64, stride=1)
  )
  (linear_layers): ModuleList(
    (0): ReLU()
    (1): Linear(in_features=3072, out_features=1536, bias=True)
    (2): Dropout(p=0.1, inplace=False)
    (3): Linear(in_features=1536, out_features=1, bias=True)
  )
)
tr_params :: epochs = 100, patience = 20, batch_size = 256, window_size = 48, data_size = 100
Model FLOPs: 9.660M, Model Params: 4.823M
learning rate scheduling :: (optimizer, mode='min', factor=0.1, patience=5, verbose=True)
total_samples :: train_dataset = 2136000, train_dataloader = 2136000
total_samples :: valid_dataset = 283200, valid_dataloader = 283200
Epoch ::  1 || Loss: 0.42663476 || it_count: 8344 || Val Loss: 0.45791145 || Val it_count: 1107 || Current Learning Rate: 0.001 || Time: 00:08:25.37
Epoch ::  2 || Loss: 0.41822557 || it_count: 8344 || Val Loss: 0.45562014 || Val it_count: 1107 || Current Learning Rate: 0.001 || Time: 00:16:48.41
Epoch ::  3 || Loss: 0.41782452 || it_count: 8344 || Val Loss: 0.45367576 || Val it_count: 1107 || Current Learning Rate: 0.001 || Time: 00:25:9.54
Epoch ::  4 || Loss: 0.41750378 || it_count: 8344 || Val Loss: 0.45091042 || Val it_count: 1107 || Current Learning Rate: 0.001 || Time: 00:33:34.23
Epoch ::  5 || Loss: 0.41744415 || it_count: 8344 || Val Loss: 0.45235505 || Val it_count: 1107 || Current Learning Rate: 0.001 || Time: 00:41:59.83
Epoch ::  6 || Loss: 0.41722313 || it_count: 8344 || Val Loss: 0.45194450 || Val it_count: 1107 || Current Learning Rate: 0.001 || Time: 00:50:27.42
Epoch ::  7 || Loss: 0.41704231 || it_count: 8344 || Val Loss: 0.45291038 || Val it_count: 1107 || Current Learning Rate: 0.001 || Time: 00:58:54.45
Epoch ::  8 || Loss: 0.41678911 || it_count: 8344 || Val Loss: 0.45234930 || Val it_count: 1107 || Current Learning Rate: 0.001 || Time: 01:07:22.41
Epoch ::  9 || Loss: 0.41679625 || it_count: 8344 || Val Loss: 0.45136628 || Val it_count: 1107 || Current Learning Rate: 0.001 || Time: 01:15:49.52
Epoch :: 10 || Loss: 0.41649752 || it_count: 8344 || Val Loss: 0.45116161 || Val it_count: 1107 || Current Learning Rate: 0.001 || Time: 01:24:17.57
Epoch :: 11 || Loss: 0.41590391 || it_count: 8344 || Val Loss: 0.45163246 || Val it_count: 1107 || Current Learning Rate: 0.001 || Time: 01:32:45.37
Epoch :: 12 || Loss: 0.41571860 || it_count: 8344 || Val Loss: 0.45058855 || Val it_count: 1107 || Current Learning Rate: 0.001 || Time: 01:41:13.58
Epoch :: 13 || Loss: 0.41551988 || it_count: 8344 || Val Loss: 0.45063885 || Val it_count: 1107 || Current Learning Rate: 0.001 || Time: 01:49:41.06
Epoch :: 14 || Loss: 0.41531905 || it_count: 8344 || Val Loss: 0.45151394 || Val it_count: 1107 || Current Learning Rate: 0.001 || Time: 01:58:8.89
Epoch :: 15 || Loss: 0.41501052 || it_count: 8344 || Val Loss: 0.44954765 || Val it_count: 1107 || Current Learning Rate: 0.001 || Time: 02:06:36.73
Epoch :: 16 || Loss: 0.41499952 || it_count: 8344 || Val Loss: 0.44950676 || Val it_count: 1107 || Current Learning Rate: 0.001 || Time: 02:15:5.63
Epoch :: 17 || Loss: 0.41445090 || it_count: 8344 || Val Loss: 0.45046908 || Val it_count: 1107 || Current Learning Rate: 0.001 || Time: 02:23:34.69
Epoch :: 18 || Loss: 0.41428337 || it_count: 8344 || Val Loss: 0.45034263 || Val it_count: 1107 || Current Learning Rate: 0.001 || Time: 02:32:1.09
Epoch :: 19 || Loss: 0.41423010 || it_count: 8344 || Val Loss: 0.45103071 || Val it_count: 1107 || Current Learning Rate: 0.001 || Time: 02:40:27.87
Epoch :: 20 || Loss: 0.41405781 || it_count: 8344 || Val Loss: 0.45207260 || Val it_count: 1107 || Current Learning Rate: 0.001 || Time: 02:48:56.61
Epoch :: 21 || Loss: 0.41343457 || it_count: 8344 || Val Loss: 0.45094697 || Val it_count: 1107 || Current Learning Rate: 0.001 || Time: 02:57:23.90
Epoch :: 22 || Loss: 0.41282220 || it_count: 8344 || Val Loss: 0.45063730 || Val it_count: 1107 || Current Learning Rate: 0.001 || Time: 03:05:52.84
Epoch :: 23 || Loss: 0.41223658 || it_count: 8344 || Val Loss: 0.45021514 || Val it_count: 1107 || Current Learning Rate: 0.001 || Time: 03:14:22.61
Epoch :: 24 || Loss: 0.41159809 || it_count: 8344 || Val Loss: 0.44970210 || Val it_count: 1107 || Current Learning Rate: 0.001 || Time: 03:22:51.42
Epoch :: 25 || Loss: 0.41101097 || it_count: 8344 || Val Loss: 0.45009762 || Val it_count: 1107 || Current Learning Rate: 0.001 || Time: 03:31:20.75
Epoch :: 26 || Loss: 0.41004508 || it_count: 8344 || Val Loss: 0.44761630 || Val it_count: 1107 || Current Learning Rate: 0.001 || Time: 03:39:49.68
Epoch :: 27 || Loss: 0.40931232 || it_count: 8344 || Val Loss: 0.44900487 || Val it_count: 1107 || Current Learning Rate: 0.001 || Time: 03:48:17.65
Epoch :: 28 || Loss: 0.40907407 || it_count: 8344 || Val Loss: 0.44908526 || Val it_count: 1107 || Current Learning Rate: 0.001 || Time: 03:56:45.51
Epoch :: 29 || Loss: 0.40856503 || it_count: 8344 || Val Loss: 0.44940719 || Val it_count: 1107 || Current Learning Rate: 0.001 || Time: 04:05:14.78
Epoch :: 30 || Loss: 0.40825016 || it_count: 8344 || Val Loss: 0.44877193 || Val it_count: 1107 || Current Learning Rate: 0.001 || Time: 04:13:42.77
Epoch :: 31 || Loss: 0.40772745 || it_count: 8344 || Val Loss: 0.44861749 || Val it_count: 1107 || Current Learning Rate: 0.001 || Time: 04:22:10.65
Epoch 00016: reducing learning rate of group 0 to 1.0000e-04.
Epoch :: 32 || Loss: 0.40768543 || it_count: 8344 || Val Loss: 0.45014839 || Val it_count: 1107 || Current Learning Rate: 0.0001 || Time: 04:30:37.76
Epoch :: 33 || Loss: 0.41299764 || it_count: 8344 || Val Loss: 0.42973183 || Val it_count: 1107 || Current Learning Rate: 0.0001 || Time: 04:39:5.09
Epoch :: 34 || Loss: 0.41026963 || it_count: 8344 || Val Loss: 0.42830029 || Val it_count: 1107 || Current Learning Rate: 0.0001 || Time: 04:47:32.28
Epoch :: 35 || Loss: 0.40928903 || it_count: 8344 || Val Loss: 0.42769880 || Val it_count: 1107 || Current Learning Rate: 0.0001 || Time: 04:56:0.00
Epoch :: 36 || Loss: 0.40871540 || it_count: 8344 || Val Loss: 0.42799587 || Val it_count: 1107 || Current Learning Rate: 0.0001 || Time: 05:04:27.29
Epoch :: 37 || Loss: 0.40838623 || it_count: 8344 || Val Loss: 0.42785799 || Val it_count: 1107 || Current Learning Rate: 0.0001 || Time: 05:12:55.11
Epoch :: 38 || Loss: 0.40802267 || it_count: 8344 || Val Loss: 0.42783393 || Val it_count: 1107 || Current Learning Rate: 0.0001 || Time: 05:21:23.05
Epoch :: 39 || Loss: 0.40766806 || it_count: 8344 || Val Loss: 0.42789930 || Val it_count: 1107 || Current Learning Rate: 0.0001 || Time: 05:29:51.41
Epoch :: 40 || Loss: 0.40746562 || it_count: 8344 || Val Loss: 0.42801420 || Val it_count: 1107 || Current Learning Rate: 0.0001 || Time: 05:38:18.75
Epoch 00025: reducing learning rate of group 0 to 1.0000e-05.
Epoch :: 41 || Loss: 0.40713834 || it_count: 8344 || Val Loss: 0.42777068 || Val it_count: 1107 || Current Learning Rate: 1e-05 || Time: 05:46:46.31
Epoch :: 42 || Loss: 0.41095596 || it_count: 8344 || Val Loss: 0.41367550 || Val it_count: 1107 || Current Learning Rate: 1e-05 || Time: 05:55:14.38
Epoch :: 43 || Loss: 0.40878233 || it_count: 8344 || Val Loss: 0.41296132 || Val it_count: 1107 || Current Learning Rate: 1e-05 || Time: 06:03:41.12
Epoch :: 44 || Loss: 0.40840181 || it_count: 8344 || Val Loss: 0.41266892 || Val it_count: 1107 || Current Learning Rate: 1e-05 || Time: 06:12:9.59
Epoch :: 45 || Loss: 0.40822861 || it_count: 8344 || Val Loss: 0.41255722 || Val it_count: 1107 || Current Learning Rate: 1e-05 || Time: 06:20:36.59
Epoch :: 46 || Loss: 0.40811732 || it_count: 8344 || Val Loss: 0.41247278 || Val it_count: 1107 || Current Learning Rate: 1e-05 || Time: 06:29:3.30
Epoch :: 47 || Loss: 0.40801806 || it_count: 8344 || Val Loss: 0.41243782 || Val it_count: 1107 || Current Learning Rate: 1e-05 || Time: 06:37:30.47
Epoch :: 48 || Loss: 0.40796022 || it_count: 8344 || Val Loss: 0.41238707 || Val it_count: 1107 || Current Learning Rate: 1e-05 || Time: 06:45:58.12
Epoch :: 49 || Loss: 0.40789649 || it_count: 8344 || Val Loss: 0.41235606 || Val it_count: 1107 || Current Learning Rate: 1e-05 || Time: 06:54:25.84
Epoch :: 50 || Loss: 0.40781671 || it_count: 8344 || Val Loss: 0.41231449 || Val it_count: 1107 || Current Learning Rate: 1e-05 || Time: 07:02:53.48
Epoch :: 51 || Loss: 0.40776142 || it_count: 8344 || Val Loss: 0.41229808 || Val it_count: 1107 || Current Learning Rate: 1e-05 || Time: 07:11:21.77
Epoch :: 52 || Loss: 0.40768205 || it_count: 8344 || Val Loss: 0.41227714 || Val it_count: 1107 || Current Learning Rate: 1e-05 || Time: 07:19:49.48
Epoch :: 53 || Loss: 0.40761272 || it_count: 8344 || Val Loss: 0.41226992 || Val it_count: 1107 || Current Learning Rate: 1e-05 || Time: 07:28:16.95
Epoch :: 54 || Loss: 0.40756222 || it_count: 8344 || Val Loss: 0.41224734 || Val it_count: 1107 || Current Learning Rate: 1e-05 || Time: 07:36:43.86
Epoch :: 55 || Loss: 0.40753698 || it_count: 8344 || Val Loss: 0.41221267 || Val it_count: 1107 || Current Learning Rate: 1e-05 || Time: 07:45:11.77
Epoch :: 56 || Loss: 0.40753087 || it_count: 8344 || Val Loss: 0.41222951 || Val it_count: 1107 || Current Learning Rate: 1e-05 || Time: 07:53:39.01
Epoch :: 57 || Loss: 0.40743728 || it_count: 8344 || Val Loss: 0.41218715 || Val it_count: 1107 || Current Learning Rate: 1e-05 || Time: 08:02:6.82
Epoch :: 58 || Loss: 0.40743261 || it_count: 8344 || Val Loss: 0.41219434 || Val it_count: 1107 || Current Learning Rate: 1e-05 || Time: 08:10:33.69
Epoch :: 59 || Loss: 0.40739107 || it_count: 8344 || Val Loss: 0.41218991 || Val it_count: 1107 || Current Learning Rate: 1e-05 || Time: 08:19:1.45
Epoch :: 60 || Loss: 0.40735457 || it_count: 8344 || Val Loss: 0.41218205 || Val it_count: 1107 || Current Learning Rate: 1e-05 || Time: 08:27:29.52
Epoch 00045: reducing learning rate of group 0 to 1.0000e-06.
Epoch :: 61 || Loss: 0.40723644 || it_count: 8344 || Val Loss: 0.41218167 || Val it_count: 1107 || Current Learning Rate: 1.0000000000000002e-06 || Time: 08:35:57.78
Epoch :: 62 || Loss: 0.40761202 || it_count: 8344 || Val Loss: 0.41128520 || Val it_count: 1107 || Current Learning Rate: 1.0000000000000002e-06 || Time: 08:44:25.02
Epoch :: 63 || Loss: 0.40746092 || it_count: 8344 || Val Loss: 0.41120211 || Val it_count: 1107 || Current Learning Rate: 1.0000000000000002e-06 || Time: 08:52:52.48
Epoch :: 64 || Loss: 0.40738243 || it_count: 8344 || Val Loss: 0.41116395 || Val it_count: 1107 || Current Learning Rate: 1.0000000000000002e-06 || Time: 09:01:21.55
Epoch :: 65 || Loss: 0.40739980 || it_count: 8344 || Val Loss: 0.41113298 || Val it_count: 1107 || Current Learning Rate: 1.0000000000000002e-06 || Time: 09:09:49.24
Epoch :: 66 || Loss: 0.40738137 || it_count: 8344 || Val Loss: 0.41111452 || Val it_count: 1107 || Current Learning Rate: 1.0000000000000002e-06 || Time: 09:18:17.03
Epoch :: 67 || Loss: 0.40731517 || it_count: 8344 || Val Loss: 0.41109742 || Val it_count: 1107 || Current Learning Rate: 1.0000000000000002e-06 || Time: 09:26:45.27
Epoch :: 68 || Loss: 0.40736636 || it_count: 8344 || Val Loss: 0.41108246 || Val it_count: 1107 || Current Learning Rate: 1.0000000000000002e-06 || Time: 09:35:12.24
Epoch :: 69 || Loss: 0.40734153 || it_count: 8344 || Val Loss: 0.41107444 || Val it_count: 1107 || Current Learning Rate: 1.0000000000000002e-06 || Time: 09:43:39.44
Epoch :: 70 || Loss: 0.40730306 || it_count: 8344 || Val Loss: 0.41106492 || Val it_count: 1107 || Current Learning Rate: 1.0000000000000002e-06 || Time: 09:52:6.95
Epoch :: 71 || Loss: 0.40728309 || it_count: 8344 || Val Loss: 0.41105453 || Val it_count: 1107 || Current Learning Rate: 1.0000000000000002e-06 || Time: 10:00:34.99
Epoch :: 72 || Loss: 0.40732660 || it_count: 8344 || Val Loss: 0.41104733 || Val it_count: 1107 || Current Learning Rate: 1.0000000000000002e-06 || Time: 10:09:2.91
Epoch :: 73 || Loss: 0.40731385 || it_count: 8344 || Val Loss: 0.41104063 || Val it_count: 1107 || Current Learning Rate: 1.0000000000000002e-06 || Time: 10:17:30.88
Epoch :: 74 || Loss: 0.40731688 || it_count: 8344 || Val Loss: 0.41103707 || Val it_count: 1107 || Current Learning Rate: 1.0000000000000002e-06 || Time: 10:25:57.77
Epoch :: 75 || Loss: 0.40728166 || it_count: 8344 || Val Loss: 0.41102408 || Val it_count: 1107 || Current Learning Rate: 1.0000000000000002e-06 || Time: 10:34:24.64
Epoch :: 76 || Loss: 0.40730226 || it_count: 8344 || Val Loss: 0.41101951 || Val it_count: 1107 || Current Learning Rate: 1.0000000000000002e-06 || Time: 10:42:52.14
Epoch :: 77 || Loss: 0.40730293 || it_count: 8344 || Val Loss: 0.41101763 || Val it_count: 1107 || Current Learning Rate: 1.0000000000000002e-06 || Time: 10:51:21.36
Epoch :: 78 || Loss: 0.40730001 || it_count: 8344 || Val Loss: 0.41101040 || Val it_count: 1107 || Current Learning Rate: 1.0000000000000002e-06 || Time: 10:59:49.22
Epoch 00063: reducing learning rate of group 0 to 1.0000e-07.
Early stopping triggered due to learning rate below threshold.
Done Total time: 11:08:17.46
best_loss: 0.41101039511951437

--------------------Testing--------------------

total_samples :: test_dataset = 139200, test_dataloader = 139200
Epoch ::  1 || Loss: 0.23482234 || it_count: 544 || Time: 00:00:22.85
MAE:  0.25205323
MSE:  0.23483932
RMSE:  0.4406741

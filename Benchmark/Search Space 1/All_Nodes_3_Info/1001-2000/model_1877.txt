--------------------Training--------------------
arch_str :: |lstm_2~0|+|lstm_1~0|lstm_3~1|[relu->linear->relu->dropout->linear]
model :: 3P
InferCell(
  info :: nodes=3, inC=1, outC=64, [1<-(I0-L0) | 2<-(I0-L1,I1-L2)], genotype_str: lstm_2~0|lstm_1~0|lstm_3~1
  linear_layers: [relu->linear->relu->dropout->linear]
  (layers): ModuleList(
    (0): LSTM(
      (lstm): LSTM(1, 64, num_layers=2, batch_first=True)
    )
    (1): LSTM(
      (lstm): LSTM(1, 64, batch_first=True)
    )
    (2): LSTM(
      (lstm): LSTM(64, 64, num_layers=3, batch_first=True)
    )
  )
  (linear_layers): ModuleList(
    (0): ReLU()
    (1): Linear(in_features=3072, out_features=1536, bias=True)
    (2): ReLU()
    (3): Dropout(p=0.1, inplace=False)
    (4): Linear(in_features=1536, out_features=1, bias=True)
  )
)
tr_params :: epochs = 100, patience = 20, batch_size = 256, window_size = 48, data_size = 100
Model FLOPs: 12.904M, Model Params: 4.889M
learning rate scheduling :: (optimizer, mode='min', factor=0.1, patience=5, verbose=True)
total_samples :: train_dataset = 2136000, train_dataloader = 2136000
total_samples :: valid_dataset = 283200, valid_dataloader = 283200
Epoch ::  1 || Loss: 0.41798879 || it_count: 8344 || Val Loss: 0.44933571 || Val it_count: 1107 || Current Learning Rate: 0.001 || Time: 00:15:55.97
Epoch ::  2 || Loss: 0.41670890 || it_count: 8344 || Val Loss: 0.44612364 || Val it_count: 1107 || Current Learning Rate: 0.001 || Time: 00:32:8.89
Epoch ::  3 || Loss: 0.41589080 || it_count: 8344 || Val Loss: 0.44493811 || Val it_count: 1107 || Current Learning Rate: 0.001 || Time: 00:48:26.52
Epoch ::  4 || Loss: 0.41404595 || it_count: 8344 || Val Loss: 0.44456512 || Val it_count: 1107 || Current Learning Rate: 0.001 || Time: 01:04:39.35
Epoch ::  5 || Loss: 0.41276115 || it_count: 8344 || Val Loss: 0.44431136 || Val it_count: 1107 || Current Learning Rate: 0.001 || Time: 01:20:53.64
Epoch ::  6 || Loss: 0.41116088 || it_count: 8344 || Val Loss: 0.44557675 || Val it_count: 1107 || Current Learning Rate: 0.001 || Time: 01:37:7.33
Epoch ::  7 || Loss: 0.41027156 || it_count: 8344 || Val Loss: 0.44330748 || Val it_count: 1107 || Current Learning Rate: 0.001 || Time: 01:53:25.49
Epoch ::  8 || Loss: 0.40955323 || it_count: 8344 || Val Loss: 0.44411119 || Val it_count: 1107 || Current Learning Rate: 0.001 || Time: 02:09:38.97
Epoch ::  9 || Loss: 0.40917716 || it_count: 8344 || Val Loss: 0.44399187 || Val it_count: 1107 || Current Learning Rate: 0.001 || Time: 02:25:54.50
Epoch :: 10 || Loss: 0.40817445 || it_count: 8344 || Val Loss: 0.44396209 || Val it_count: 1107 || Current Learning Rate: 0.001 || Time: 02:42:8.92
Epoch :: 11 || Loss: 0.40745981 || it_count: 8344 || Val Loss: 0.44302272 || Val it_count: 1107 || Current Learning Rate: 0.001 || Time: 02:58:27.76
Epoch :: 12 || Loss: 0.40657321 || it_count: 8344 || Val Loss: 0.44324058 || Val it_count: 1107 || Current Learning Rate: 0.001 || Time: 03:14:42.30
Epoch :: 13 || Loss: 0.40607937 || it_count: 8344 || Val Loss: 0.44176325 || Val it_count: 1107 || Current Learning Rate: 0.001 || Time: 03:30:57.62
Epoch :: 14 || Loss: 0.40545783 || it_count: 8344 || Val Loss: 0.44258160 || Val it_count: 1107 || Current Learning Rate: 0.001 || Time: 03:47:13.29
Epoch :: 15 || Loss: 0.40455893 || it_count: 8344 || Val Loss: 0.44285305 || Val it_count: 1107 || Current Learning Rate: 0.001 || Time: 04:03:31.92
Epoch :: 16 || Loss: 0.40378830 || it_count: 8344 || Val Loss: 0.44291883 || Val it_count: 1107 || Current Learning Rate: 0.001 || Time: 04:19:45.81
Epoch :: 17 || Loss: 0.40293532 || it_count: 8344 || Val Loss: 0.44258559 || Val it_count: 1107 || Current Learning Rate: 0.001 || Time: 04:36:2.41
Epoch :: 18 || Loss: 0.40185124 || it_count: 8344 || Val Loss: 0.44269965 || Val it_count: 1107 || Current Learning Rate: 0.001 || Time: 04:52:17.86
Epoch :: 19 || Loss: 0.40125759 || it_count: 8344 || Val Loss: 0.44423848 || Val it_count: 1107 || Current Learning Rate: 0.001 || Time: 05:08:36.92
Epoch :: 20 || Loss: 0.40008576 || it_count: 8344 || Val Loss: 0.44395466 || Val it_count: 1107 || Current Learning Rate: 0.001 || Time: 05:24:51.08
Epoch :: 21 || Loss: 0.39902081 || it_count: 8344 || Val Loss: 0.44320051 || Val it_count: 1107 || Current Learning Rate: 0.001 || Time: 05:41:7.03
Epoch :: 22 || Loss: 0.39781930 || it_count: 8344 || Val Loss: 0.44614519 || Val it_count: 1107 || Current Learning Rate: 0.001 || Time: 05:57:22.49
Epoch 00007: reducing learning rate of group 0 to 1.0000e-04.
Epoch :: 23 || Loss: 0.39706489 || it_count: 8344 || Val Loss: 0.44542028 || Val it_count: 1107 || Current Learning Rate: 0.0001 || Time: 06:13:41.58
Epoch :: 24 || Loss: 0.40724082 || it_count: 8344 || Val Loss: 0.42178198 || Val it_count: 1107 || Current Learning Rate: 0.0001 || Time: 06:29:56.17
Epoch :: 25 || Loss: 0.40317415 || it_count: 8344 || Val Loss: 0.42123871 || Val it_count: 1107 || Current Learning Rate: 0.0001 || Time: 06:46:13.60
Epoch :: 26 || Loss: 0.40160059 || it_count: 8344 || Val Loss: 0.42142553 || Val it_count: 1107 || Current Learning Rate: 0.0001 || Time: 07:02:28.84
Epoch :: 27 || Loss: 0.40031757 || it_count: 8344 || Val Loss: 0.42159091 || Val it_count: 1107 || Current Learning Rate: 0.0001 || Time: 07:18:48.43
Epoch :: 28 || Loss: 0.39945943 || it_count: 8344 || Val Loss: 0.42195371 || Val it_count: 1107 || Current Learning Rate: 0.0001 || Time: 07:35:2.99
Epoch :: 29 || Loss: 0.39852049 || it_count: 8344 || Val Loss: 0.42266536 || Val it_count: 1107 || Current Learning Rate: 0.0001 || Time: 07:51:19.11
Epoch :: 30 || Loss: 0.39770098 || it_count: 8344 || Val Loss: 0.42285938 || Val it_count: 1107 || Current Learning Rate: 0.0001 || Time: 08:07:34.03
Epoch 00015: reducing learning rate of group 0 to 1.0000e-05.
Epoch :: 31 || Loss: 0.39700336 || it_count: 8344 || Val Loss: 0.42326129 || Val it_count: 1107 || Current Learning Rate: 1e-05 || Time: 08:23:52.95
Epoch :: 32 || Loss: 0.40403767 || it_count: 8344 || Val Loss: 0.41713005 || Val it_count: 1107 || Current Learning Rate: 1e-05 || Time: 08:40:7.50
Epoch :: 33 || Loss: 0.40181823 || it_count: 8344 || Val Loss: 0.41682150 || Val it_count: 1107 || Current Learning Rate: 1e-05 || Time: 08:56:22.93
Epoch :: 34 || Loss: 0.40127228 || it_count: 8344 || Val Loss: 0.41667012 || Val it_count: 1107 || Current Learning Rate: 1e-05 || Time: 09:12:34.94
Epoch :: 35 || Loss: 0.40096300 || it_count: 8344 || Val Loss: 0.41652103 || Val it_count: 1107 || Current Learning Rate: 1e-05 || Time: 09:28:51.88
Epoch :: 36 || Loss: 0.40068271 || it_count: 8344 || Val Loss: 0.41647339 || Val it_count: 1107 || Current Learning Rate: 1e-05 || Time: 09:45:3.47
Epoch :: 37 || Loss: 0.40053291 || it_count: 8344 || Val Loss: 0.41637182 || Val it_count: 1107 || Current Learning Rate: 1e-05 || Time: 10:01:16.89
Epoch :: 38 || Loss: 0.40043947 || it_count: 8344 || Val Loss: 0.41633994 || Val it_count: 1107 || Current Learning Rate: 1e-05 || Time: 10:17:29.50
Epoch :: 39 || Loss: 0.40022004 || it_count: 8344 || Val Loss: 0.41635839 || Val it_count: 1107 || Current Learning Rate: 1e-05 || Time: 10:33:47.58
Epoch :: 40 || Loss: 0.40014059 || it_count: 8344 || Val Loss: 0.41632863 || Val it_count: 1107 || Current Learning Rate: 1e-05 || Time: 10:50:1.91
Epoch :: 41 || Loss: 0.39999998 || it_count: 8344 || Val Loss: 0.41630720 || Val it_count: 1107 || Current Learning Rate: 1e-05 || Time: 11:06:18.12
Epoch :: 42 || Loss: 0.39997940 || it_count: 8344 || Val Loss: 0.41624444 || Val it_count: 1107 || Current Learning Rate: 1e-05 || Time: 11:22:33.17
Epoch :: 43 || Loss: 0.39992465 || it_count: 8344 || Val Loss: 0.41628967 || Val it_count: 1107 || Current Learning Rate: 1e-05 || Time: 11:38:52.47
Epoch :: 44 || Loss: 0.39961453 || it_count: 8344 || Val Loss: 0.41628435 || Val it_count: 1107 || Current Learning Rate: 1e-05 || Time: 11:55:6.77
Epoch :: 45 || Loss: 0.39968112 || it_count: 8344 || Val Loss: 0.41627444 || Val it_count: 1107 || Current Learning Rate: 1e-05 || Time: 12:11:22.61
Epoch :: 46 || Loss: 0.39944106 || it_count: 8344 || Val Loss: 0.41628883 || Val it_count: 1107 || Current Learning Rate: 1e-05 || Time: 12:27:37.81
Epoch :: 47 || Loss: 0.39955140 || it_count: 8344 || Val Loss: 0.41629002 || Val it_count: 1107 || Current Learning Rate: 1e-05 || Time: 12:43:56.94
Epoch 00032: reducing learning rate of group 0 to 1.0000e-06.
Epoch :: 48 || Loss: 0.39934337 || it_count: 8344 || Val Loss: 0.41631330 || Val it_count: 1107 || Current Learning Rate: 1.0000000000000002e-06 || Time: 13:00:11.07
Epoch :: 49 || Loss: 0.39995455 || it_count: 8344 || Val Loss: 0.41573030 || Val it_count: 1107 || Current Learning Rate: 1.0000000000000002e-06 || Time: 13:16:28.08
Epoch :: 50 || Loss: 0.39976874 || it_count: 8344 || Val Loss: 0.41568035 || Val it_count: 1107 || Current Learning Rate: 1.0000000000000002e-06 || Time: 13:32:43.29
Epoch :: 51 || Loss: 0.39964425 || it_count: 8344 || Val Loss: 0.41564722 || Val it_count: 1107 || Current Learning Rate: 1.0000000000000002e-06 || Time: 13:49:2.38
Epoch :: 52 || Loss: 0.39966337 || it_count: 8344 || Val Loss: 0.41562818 || Val it_count: 1107 || Current Learning Rate: 1.0000000000000002e-06 || Time: 14:05:16.97
Epoch :: 53 || Loss: 0.39966487 || it_count: 8344 || Val Loss: 0.41562039 || Val it_count: 1107 || Current Learning Rate: 1.0000000000000002e-06 || Time: 14:21:33.27
Epoch :: 54 || Loss: 0.39969336 || it_count: 8344 || Val Loss: 0.41561133 || Val it_count: 1107 || Current Learning Rate: 1.0000000000000002e-06 || Time: 14:37:48.39
Epoch :: 55 || Loss: 0.39954960 || it_count: 8344 || Val Loss: 0.41560288 || Val it_count: 1107 || Current Learning Rate: 1.0000000000000002e-06 || Time: 14:54:7.55
Epoch :: 56 || Loss: 0.39961423 || it_count: 8344 || Val Loss: 0.41558910 || Val it_count: 1107 || Current Learning Rate: 1.0000000000000002e-06 || Time: 15:10:22.86
Epoch :: 57 || Loss: 0.39958898 || it_count: 8344 || Val Loss: 0.41558787 || Val it_count: 1107 || Current Learning Rate: 1.0000000000000002e-06 || Time: 15:26:39.89
Epoch :: 58 || Loss: 0.39959505 || it_count: 8344 || Val Loss: 0.41557905 || Val it_count: 1107 || Current Learning Rate: 1.0000000000000002e-06 || Time: 15:42:55.39
Epoch :: 59 || Loss: 0.39953338 || it_count: 8344 || Val Loss: 0.41558185 || Val it_count: 1107 || Current Learning Rate: 1.0000000000000002e-06 || Time: 15:59:14.01
Epoch :: 60 || Loss: 0.39953259 || it_count: 8344 || Val Loss: 0.41557208 || Val it_count: 1107 || Current Learning Rate: 1.0000000000000002e-06 || Time: 16:15:28.70
Epoch :: 61 || Loss: 0.39950633 || it_count: 8344 || Val Loss: 0.41556726 || Val it_count: 1107 || Current Learning Rate: 1.0000000000000002e-06 || Time: 16:31:44.72
Epoch :: 62 || Loss: 0.39956101 || it_count: 8344 || Val Loss: 0.41556186 || Val it_count: 1107 || Current Learning Rate: 1.0000000000000002e-06 || Time: 16:47:59.74
Epoch :: 63 || Loss: 0.39951139 || it_count: 8344 || Val Loss: 0.41555140 || Val it_count: 1107 || Current Learning Rate: 1.0000000000000002e-06 || Time: 17:04:18.97
Epoch 00048: reducing learning rate of group 0 to 1.0000e-07.
Early stopping triggered due to learning rate below threshold.
Done Total time: 17:20:34.36
best_loss: 0.4155514002068672

--------------------Testing--------------------

total_samples :: test_dataset = 139200, test_dataloader = 139200
Epoch ::  1 || Loss: 0.24166977 || it_count: 544 || Time: 00:00:30.43
MAE:  0.25413412
MSE:  0.24169074
RMSE:  0.4460598

--------------------Training--------------------
arch_str :: |skip_connect~0|+|lstm_1~0|lstm_2~1|[dropout->linear->dropout->linear]
model :: 3J
InferCell(
  info :: nodes=3, inC=1, outC=64, [1<-(I0-L0) | 2<-(I0-L1,I1-L2)], genotype_str: skip_connect~0|lstm_1~0|lstm_2~1
  linear_layers: [dropout->linear->dropout->linear]
  (layers): ModuleList(
    (0): FactorizedReduce(
      C_in=1, C_out=64, stride=1
      (relu): ReLU()
      (conv): Conv1d(1, 64, kernel_size=(1,), stride=(1,), bias=False)
      (bn): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (1): LSTM(
      (lstm): LSTM(1, 64, batch_first=True)
    )
    (2): LSTM(
      (lstm): LSTM(64, 64, num_layers=2, batch_first=True)
    )
  )
  (linear_layers): ModuleList(
    (0): Dropout(p=0.1, inplace=False)
    (1): Linear(in_features=3072, out_features=1536, bias=True)
    (2): Dropout(p=0.1, inplace=False)
    (3): Linear(in_features=1536, out_features=1, bias=True)
  )
)
tr_params :: epochs = 100, patience = 20, batch_size = 256, window_size = 48, data_size = 100
Model FLOPs: 8.827M, Model Params: 4.806M
learning rate scheduling :: (optimizer, mode='min', factor=0.1, patience=5, verbose=True)
total_samples :: train_dataset = 2136000, train_dataloader = 2136000
total_samples :: valid_dataset = 283200, valid_dataloader = 283200
Epoch ::  1 || Loss: 0.42033574 || it_count: 8344 || Val Loss: 0.46103512 || Val it_count: 1107 || Current Learning Rate: 0.001 || Time: 00:04:14.88
Epoch ::  2 || Loss: 0.41464660 || it_count: 8344 || Val Loss: 0.45091128 || Val it_count: 1107 || Current Learning Rate: 0.001 || Time: 00:08:24.62
Epoch ::  3 || Loss: 0.41412320 || it_count: 8344 || Val Loss: 0.45466513 || Val it_count: 1107 || Current Learning Rate: 0.001 || Time: 00:12:30.80
Epoch ::  4 || Loss: 0.41220415 || it_count: 8344 || Val Loss: 0.45672885 || Val it_count: 1107 || Current Learning Rate: 0.001 || Time: 00:16:39.19
Epoch ::  5 || Loss: 0.41161889 || it_count: 8344 || Val Loss: 0.45346634 || Val it_count: 1107 || Current Learning Rate: 0.001 || Time: 00:20:56.30
Epoch ::  6 || Loss: 0.41044896 || it_count: 8344 || Val Loss: 0.45379671 || Val it_count: 1107 || Current Learning Rate: 0.001 || Time: 00:25:3.10
Epoch ::  7 || Loss: 0.40970284 || it_count: 8344 || Val Loss: 0.45327385 || Val it_count: 1107 || Current Learning Rate: 0.001 || Time: 00:29:11.03
Epoch ::  8 || Loss: 0.41007812 || it_count: 8344 || Val Loss: 0.45670013 || Val it_count: 1107 || Current Learning Rate: 0.001 || Time: 00:33:22.50
Epoch ::  9 || Loss: 0.41045673 || it_count: 8344 || Val Loss: 0.45536451 || Val it_count: 1107 || Current Learning Rate: 0.001 || Time: 00:37:31.02
Epoch :: 10 || Loss: 0.41248100 || it_count: 8344 || Val Loss: 0.45259703 || Val it_count: 1107 || Current Learning Rate: 0.001 || Time: 00:41:47.74
Epoch :: 11 || Loss: 0.41271119 || it_count: 8344 || Val Loss: 0.45499533 || Val it_count: 1107 || Current Learning Rate: 0.001 || Time: 00:45:56.11
Epoch :: 12 || Loss: 0.41071073 || it_count: 8344 || Val Loss: 0.45334823 || Val it_count: 1107 || Current Learning Rate: 0.001 || Time: 00:50:9.13
Epoch :: 13 || Loss: 0.41041201 || it_count: 8344 || Val Loss: 0.45175307 || Val it_count: 1107 || Current Learning Rate: 0.001 || Time: 00:54:17.31
Epoch :: 14 || Loss: 0.40980790 || it_count: 8344 || Val Loss: 0.45272462 || Val it_count: 1107 || Current Learning Rate: 0.001 || Time: 00:58:24.07
Epoch :: 15 || Loss: 0.41023242 || it_count: 8344 || Val Loss: 0.45435103 || Val it_count: 1107 || Current Learning Rate: 0.001 || Time: 01:02:33.66
Epoch :: 16 || Loss: 0.41217014 || it_count: 8344 || Val Loss: 0.45554513 || Val it_count: 1107 || Current Learning Rate: 0.001 || Time: 01:06:40.95
Epoch :: 17 || Loss: 0.41312936 || it_count: 8344 || Val Loss: 0.45538023 || Val it_count: 1107 || Current Learning Rate: 0.001 || Time: 01:10:47.22
Epoch :: 18 || Loss: 0.41308203 || it_count: 8344 || Val Loss: 0.45491536 || Val it_count: 1107 || Current Learning Rate: 0.001 || Time: 01:14:50.62
Epoch :: 19 || Loss: 0.40997005 || it_count: 8344 || Val Loss: 0.45573517 || Val it_count: 1107 || Current Learning Rate: 0.001 || Time: 01:18:56.38
Epoch :: 20 || Loss: 0.40999464 || it_count: 8344 || Val Loss: 0.44991991 || Val it_count: 1107 || Current Learning Rate: 0.001 || Time: 01:23:1.47
Epoch :: 21 || Loss: 0.41005741 || it_count: 8344 || Val Loss: 0.45444804 || Val it_count: 1107 || Current Learning Rate: 0.001 || Time: 01:27:8.52
Epoch :: 22 || Loss: 0.40916370 || it_count: 8344 || Val Loss: 0.45533539 || Val it_count: 1107 || Current Learning Rate: 0.001 || Time: 01:31:13.26
Epoch :: 23 || Loss: 0.40843067 || it_count: 8344 || Val Loss: 0.45781187 || Val it_count: 1107 || Current Learning Rate: 0.001 || Time: 01:35:17.17
Epoch :: 24 || Loss: 0.40850682 || it_count: 8344 || Val Loss: 0.45557045 || Val it_count: 1107 || Current Learning Rate: 0.001 || Time: 01:39:24.18
Epoch :: 25 || Loss: 0.40812184 || it_count: 8344 || Val Loss: 0.45774538 || Val it_count: 1107 || Current Learning Rate: 0.001 || Time: 01:43:32.72
Epoch :: 26 || Loss: 0.40770257 || it_count: 8344 || Val Loss: 0.45903921 || Val it_count: 1107 || Current Learning Rate: 0.0001 || Time: 01:47:39.91
Epoch :: 27 || Loss: 0.41265932 || it_count: 8344 || Val Loss: 0.44705214 || Val it_count: 1107 || Current Learning Rate: 0.0001 || Time: 01:51:43.67
Epoch :: 28 || Loss: 0.40981114 || it_count: 8344 || Val Loss: 0.44490169 || Val it_count: 1107 || Current Learning Rate: 0.0001 || Time: 01:55:47.78
Epoch :: 29 || Loss: 0.40901546 || it_count: 8344 || Val Loss: 0.44461328 || Val it_count: 1107 || Current Learning Rate: 0.0001 || Time: 01:59:54.43
Epoch :: 30 || Loss: 0.40854625 || it_count: 8344 || Val Loss: 0.44391069 || Val it_count: 1107 || Current Learning Rate: 0.0001 || Time: 02:03:59.61
Epoch :: 31 || Loss: 0.40811173 || it_count: 8344 || Val Loss: 0.44340911 || Val it_count: 1107 || Current Learning Rate: 0.0001 || Time: 02:08:7.89
Epoch :: 32 || Loss: 0.40780479 || it_count: 8344 || Val Loss: 0.44364088 || Val it_count: 1107 || Current Learning Rate: 0.0001 || Time: 02:12:17.17
Epoch :: 33 || Loss: 0.40745088 || it_count: 8344 || Val Loss: 0.44393452 || Val it_count: 1107 || Current Learning Rate: 0.0001 || Time: 02:16:24.43
Epoch :: 34 || Loss: 0.40733296 || it_count: 8344 || Val Loss: 0.44431519 || Val it_count: 1107 || Current Learning Rate: 0.0001 || Time: 02:20:28.59
Epoch :: 35 || Loss: 0.40713516 || it_count: 8344 || Val Loss: 0.44491599 || Val it_count: 1107 || Current Learning Rate: 0.0001 || Time: 02:24:32.56
Epoch :: 36 || Loss: 0.40695313 || it_count: 8344 || Val Loss: 0.44563053 || Val it_count: 1107 || Current Learning Rate: 0.0001 || Time: 02:28:37.54
Epoch :: 37 || Loss: 0.40669334 || it_count: 8344 || Val Loss: 0.44562919 || Val it_count: 1107 || Current Learning Rate: 1e-05 || Time: 02:32:44.54
Epoch :: 38 || Loss: 0.40990782 || it_count: 8344 || Val Loss: 0.44103857 || Val it_count: 1107 || Current Learning Rate: 1e-05 || Time: 02:36:50.50
Epoch :: 39 || Loss: 0.40869629 || it_count: 8344 || Val Loss: 0.44069612 || Val it_count: 1107 || Current Learning Rate: 1e-05 || Time: 02:40:56.52
Epoch :: 40 || Loss: 0.40833385 || it_count: 8344 || Val Loss: 0.44074942 || Val it_count: 1107 || Current Learning Rate: 1e-05 || Time: 02:45:1.35
Epoch :: 41 || Loss: 0.40803343 || it_count: 8344 || Val Loss: 0.44065772 || Val it_count: 1107 || Current Learning Rate: 1e-05 || Time: 02:49:6.55
Epoch :: 42 || Loss: 0.40794759 || it_count: 8344 || Val Loss: 0.44076410 || Val it_count: 1107 || Current Learning Rate: 1e-05 || Time: 02:53:16.53
Epoch :: 43 || Loss: 0.40780182 || it_count: 8344 || Val Loss: 0.44065399 || Val it_count: 1107 || Current Learning Rate: 1e-05 || Time: 02:57:20.38
Epoch :: 44 || Loss: 0.40766089 || it_count: 8344 || Val Loss: 0.44069639 || Val it_count: 1107 || Current Learning Rate: 1e-05 || Time: 03:01:27.84
Epoch :: 45 || Loss: 0.40753571 || it_count: 8344 || Val Loss: 0.44073312 || Val it_count: 1107 || Current Learning Rate: 1.0000000000000002e-06 || Time: 03:05:37.04
Epoch :: 46 || Loss: 0.40807942 || it_count: 8344 || Val Loss: 0.44011843 || Val it_count: 1107 || Current Learning Rate: 1.0000000000000002e-06 || Time: 03:09:43.38
Epoch :: 47 || Loss: 0.40785813 || it_count: 8344 || Val Loss: 0.43951638 || Val it_count: 1107 || Current Learning Rate: 1.0000000000000002e-06 || Time: 03:13:49.89
Epoch :: 48 || Loss: 0.40780777 || it_count: 8344 || Val Loss: 0.43914289 || Val it_count: 1107 || Current Learning Rate: 1.0000000000000002e-06 || Time: 03:17:55.25
Epoch :: 49 || Loss: 0.40776114 || it_count: 8344 || Val Loss: 0.43897800 || Val it_count: 1107 || Current Learning Rate: 1.0000000000000002e-06 || Time: 03:22:1.61
Epoch :: 50 || Loss: 0.40782423 || it_count: 8344 || Val Loss: 0.43888408 || Val it_count: 1107 || Current Learning Rate: 1.0000000000000002e-06 || Time: 03:26:7.68
Epoch :: 51 || Loss: 0.40775081 || it_count: 8344 || Val Loss: 0.43880067 || Val it_count: 1107 || Current Learning Rate: 1.0000000000000002e-06 || Time: 03:30:14.56
Epoch :: 52 || Loss: 0.40772053 || it_count: 8344 || Val Loss: 0.43873674 || Val it_count: 1107 || Current Learning Rate: 1.0000000000000002e-06 || Time: 03:34:21.42
Epoch :: 53 || Loss: 0.40770028 || it_count: 8344 || Val Loss: 0.43871753 || Val it_count: 1107 || Current Learning Rate: 1.0000000000000002e-06 || Time: 03:38:26.51
Epoch :: 54 || Loss: 0.40769926 || it_count: 8344 || Val Loss: 0.43871206 || Val it_count: 1107 || Current Learning Rate: 1.0000000000000002e-06 || Time: 03:42:33.25
Epoch :: 55 || Loss: 0.40773625 || it_count: 8344 || Val Loss: 0.43871525 || Val it_count: 1107 || Current Learning Rate: 1.0000000000000002e-06 || Time: 03:46:39.09
Epoch :: 56 || Loss: 0.40770651 || it_count: 8344 || Val Loss: 0.43871738 || Val it_count: 1107 || Current Learning Rate: 1.0000000000000002e-06 || Time: 03:50:51.61
Epoch :: 57 || Loss: 0.40767197 || it_count: 8344 || Val Loss: 0.43872412 || Val it_count: 1107 || Current Learning Rate: 1.0000000000000002e-06 || Time: 03:54:59.96
Early stopping triggered due to learning rate below threshold.
Done Total time: 03:59:7.02
best_loss: 0.43871205945848823

--------------------Testing--------------------

total_samples :: test_dataset = 139200, test_dataloader = 139200
Epoch ::  1 || Loss: 0.30485407 || it_count: 544 || Time: 00:00:12.91
MAE:  0.27875736
MSE:  0.30490413
RMSE:  0.47556713

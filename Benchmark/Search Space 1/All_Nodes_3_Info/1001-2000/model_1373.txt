--------------------Training--------------------
arch_str :: |lstm_2~0|+|none~0|lstm_1~1|[dropout->linear->relu->linear]
model :: 3K
InferCell(
  info :: nodes=3, inC=1, outC=64, [1<-(I0-L0) | 2<-(I0-L1,I1-L2)], genotype_str: lstm_2~0|none~0|lstm_1~1
  linear_layers: [dropout->linear->relu->linear]
  (layers): ModuleList(
    (0): LSTM(
      (lstm): LSTM(1, 64, num_layers=2, batch_first=True)
    )
    (1): Zero(C_in=1, C_out=64, stride=1)
    (2): LSTM(
      (lstm): LSTM(64, 64, batch_first=True)
    )
  )
  (linear_layers): ModuleList(
    (0): Dropout(p=0.1, inplace=False)
    (1): Linear(in_features=3072, out_features=1536, bias=True)
    (2): ReLU()
    (3): Linear(in_features=1536, out_features=1, bias=True)
  )
)
tr_params :: epochs = 100, patience = 20, batch_size = 256, window_size = 48, data_size = 100
Model FLOPs: 8.812M, Model Params: 4.805M
learning rate scheduling :: (optimizer, mode='min', factor=0.1, patience=5, verbose=True)
total_samples :: train_dataset = 2136000, train_dataloader = 2136000
total_samples :: valid_dataset = 283200, valid_dataloader = 283200
Epoch ::  1 || Loss: 0.42105586 || it_count: 8344 || Val Loss: 0.45438507 || Val it_count: 1107 || Current Learning Rate: 0.001 || Time: 00:04:11.42
Epoch ::  2 || Loss: 0.41510974 || it_count: 8344 || Val Loss: 0.45162410 || Val it_count: 1107 || Current Learning Rate: 0.001 || Time: 00:08:19.15
Epoch ::  3 || Loss: 0.41415253 || it_count: 8344 || Val Loss: 0.45282862 || Val it_count: 1107 || Current Learning Rate: 0.001 || Time: 00:12:27.16
Epoch ::  4 || Loss: 0.41287408 || it_count: 8344 || Val Loss: 0.45271437 || Val it_count: 1107 || Current Learning Rate: 0.001 || Time: 00:16:33.14
Epoch ::  5 || Loss: 0.41173221 || it_count: 8344 || Val Loss: 0.45358629 || Val it_count: 1107 || Current Learning Rate: 0.001 || Time: 00:20:39.55
Epoch ::  6 || Loss: 0.41065715 || it_count: 8344 || Val Loss: 0.45153553 || Val it_count: 1107 || Current Learning Rate: 0.001 || Time: 00:24:46.82
Epoch ::  7 || Loss: 0.40995904 || it_count: 8344 || Val Loss: 0.45268716 || Val it_count: 1107 || Current Learning Rate: 0.001 || Time: 00:28:51.14
Epoch ::  8 || Loss: 0.40901609 || it_count: 8344 || Val Loss: 0.45336172 || Val it_count: 1107 || Current Learning Rate: 0.001 || Time: 00:32:58.20
Epoch ::  9 || Loss: 0.40840869 || it_count: 8344 || Val Loss: 0.45381365 || Val it_count: 1107 || Current Learning Rate: 0.001 || Time: 00:37:5.84
Epoch :: 10 || Loss: 0.40758976 || it_count: 8344 || Val Loss: 0.45383450 || Val it_count: 1107 || Current Learning Rate: 0.001 || Time: 00:41:12.21
Epoch :: 11 || Loss: 0.40653905 || it_count: 8344 || Val Loss: 0.45287239 || Val it_count: 1107 || Current Learning Rate: 0.001 || Time: 00:45:17.59
Epoch :: 12 || Loss: 0.40539318 || it_count: 8344 || Val Loss: 0.45320467 || Val it_count: 1107 || Current Learning Rate: 0.001 || Time: 00:49:24.13
Epoch :: 13 || Loss: 0.40430951 || it_count: 8344 || Val Loss: 0.45148807 || Val it_count: 1107 || Current Learning Rate: 0.001 || Time: 00:53:30.72
Epoch :: 14 || Loss: 0.40287793 || it_count: 8344 || Val Loss: 0.45153721 || Val it_count: 1107 || Current Learning Rate: 0.001 || Time: 00:57:37.57
Epoch :: 15 || Loss: 0.40156136 || it_count: 8344 || Val Loss: 0.45160473 || Val it_count: 1107 || Current Learning Rate: 0.001 || Time: 01:01:43.24
Epoch :: 16 || Loss: 0.39996916 || it_count: 8344 || Val Loss: 0.45178086 || Val it_count: 1107 || Current Learning Rate: 0.001 || Time: 01:05:50.19
Epoch :: 17 || Loss: 0.39808862 || it_count: 8344 || Val Loss: 0.45316716 || Val it_count: 1107 || Current Learning Rate: 0.001 || Time: 01:09:56.56
Epoch :: 18 || Loss: 0.39627265 || it_count: 8344 || Val Loss: 0.45120551 || Val it_count: 1107 || Current Learning Rate: 0.001 || Time: 01:14:2.79
Epoch :: 19 || Loss: 0.39400527 || it_count: 8344 || Val Loss: 0.45296928 || Val it_count: 1107 || Current Learning Rate: 0.001 || Time: 01:18:8.87
Epoch :: 20 || Loss: 0.39164750 || it_count: 8344 || Val Loss: 0.45084459 || Val it_count: 1107 || Current Learning Rate: 0.001 || Time: 01:22:16.24
Epoch :: 21 || Loss: 0.38919654 || it_count: 8344 || Val Loss: 0.45311326 || Val it_count: 1107 || Current Learning Rate: 0.001 || Time: 01:26:22.73
Epoch :: 22 || Loss: 0.38647407 || it_count: 8344 || Val Loss: 0.45843883 || Val it_count: 1107 || Current Learning Rate: 0.001 || Time: 01:30:29.20
Epoch :: 23 || Loss: 0.38394168 || it_count: 8344 || Val Loss: 0.46312079 || Val it_count: 1107 || Current Learning Rate: 0.001 || Time: 01:34:36.48
Epoch :: 24 || Loss: 0.38090788 || it_count: 8344 || Val Loss: 0.46188848 || Val it_count: 1107 || Current Learning Rate: 0.001 || Time: 01:38:44.33
Epoch :: 25 || Loss: 0.37810360 || it_count: 8344 || Val Loss: 0.47010665 || Val it_count: 1107 || Current Learning Rate: 0.001 || Time: 01:42:50.65
Epoch :: 26 || Loss: 0.37538583 || it_count: 8344 || Val Loss: 0.46790650 || Val it_count: 1107 || Current Learning Rate: 0.0001 || Time: 01:46:57.75
Epoch :: 27 || Loss: 0.38842836 || it_count: 8344 || Val Loss: 0.43745276 || Val it_count: 1107 || Current Learning Rate: 0.0001 || Time: 01:51:5.86
Epoch :: 28 || Loss: 0.38154905 || it_count: 8344 || Val Loss: 0.43662848 || Val it_count: 1107 || Current Learning Rate: 0.0001 || Time: 01:55:15.66
Epoch :: 29 || Loss: 0.37849491 || it_count: 8344 || Val Loss: 0.43681970 || Val it_count: 1107 || Current Learning Rate: 0.0001 || Time: 01:59:27.63
Epoch :: 30 || Loss: 0.37573718 || it_count: 8344 || Val Loss: 0.43747111 || Val it_count: 1107 || Current Learning Rate: 0.0001 || Time: 02:03:35.37
Epoch :: 31 || Loss: 0.37364116 || it_count: 8344 || Val Loss: 0.43850500 || Val it_count: 1107 || Current Learning Rate: 0.0001 || Time: 02:07:40.52
Epoch :: 32 || Loss: 0.37146469 || it_count: 8344 || Val Loss: 0.43827020 || Val it_count: 1107 || Current Learning Rate: 0.0001 || Time: 02:11:48.97
Epoch :: 33 || Loss: 0.36948289 || it_count: 8344 || Val Loss: 0.44000231 || Val it_count: 1107 || Current Learning Rate: 0.0001 || Time: 02:15:55.74
Epoch :: 34 || Loss: 0.36759750 || it_count: 8344 || Val Loss: 0.44008610 || Val it_count: 1107 || Current Learning Rate: 1e-05 || Time: 02:20:3.64
Epoch :: 35 || Loss: 0.38166709 || it_count: 8344 || Val Loss: 0.43130229 || Val it_count: 1107 || Current Learning Rate: 1e-05 || Time: 02:24:13.49
Epoch :: 36 || Loss: 0.37732925 || it_count: 8344 || Val Loss: 0.43049725 || Val it_count: 1107 || Current Learning Rate: 1e-05 || Time: 02:28:19.69
Epoch :: 37 || Loss: 0.37643918 || it_count: 8344 || Val Loss: 0.43014126 || Val it_count: 1107 || Current Learning Rate: 1e-05 || Time: 02:32:26.53
Epoch :: 38 || Loss: 0.37588667 || it_count: 8344 || Val Loss: 0.42998011 || Val it_count: 1107 || Current Learning Rate: 1e-05 || Time: 02:36:37.67
Epoch :: 39 || Loss: 0.37549290 || it_count: 8344 || Val Loss: 0.42989409 || Val it_count: 1107 || Current Learning Rate: 1e-05 || Time: 02:40:46.77
Epoch :: 40 || Loss: 0.37505356 || it_count: 8344 || Val Loss: 0.42992428 || Val it_count: 1107 || Current Learning Rate: 1e-05 || Time: 02:44:53.66
Epoch :: 41 || Loss: 0.37463491 || it_count: 8344 || Val Loss: 0.42992340 || Val it_count: 1107 || Current Learning Rate: 1e-05 || Time: 02:49:1.49
Epoch :: 42 || Loss: 0.37450415 || it_count: 8344 || Val Loss: 0.42980193 || Val it_count: 1107 || Current Learning Rate: 1e-05 || Time: 02:53:8.22
Epoch :: 43 || Loss: 0.37414265 || it_count: 8344 || Val Loss: 0.42966440 || Val it_count: 1107 || Current Learning Rate: 1e-05 || Time: 02:57:17.59
Epoch :: 44 || Loss: 0.37375961 || it_count: 8344 || Val Loss: 0.43023699 || Val it_count: 1107 || Current Learning Rate: 1e-05 || Time: 03:01:24.71
Epoch :: 45 || Loss: 0.37345186 || it_count: 8344 || Val Loss: 0.43009919 || Val it_count: 1107 || Current Learning Rate: 1e-05 || Time: 03:05:32.01
Epoch :: 46 || Loss: 0.37319934 || it_count: 8344 || Val Loss: 0.43020127 || Val it_count: 1107 || Current Learning Rate: 1e-05 || Time: 03:09:37.31
Epoch :: 47 || Loss: 0.37312875 || it_count: 8344 || Val Loss: 0.43031381 || Val it_count: 1107 || Current Learning Rate: 1e-05 || Time: 03:13:43.05
Epoch :: 48 || Loss: 0.37274742 || it_count: 8344 || Val Loss: 0.43010276 || Val it_count: 1107 || Current Learning Rate: 1e-05 || Time: 03:17:50.54
Epoch :: 49 || Loss: 0.37244786 || it_count: 8344 || Val Loss: 0.43038463 || Val it_count: 1107 || Current Learning Rate: 1.0000000000000002e-06 || Time: 03:22:1.25
Epoch :: 50 || Loss: 0.37386400 || it_count: 8344 || Val Loss: 0.43049699 || Val it_count: 1107 || Current Learning Rate: 1.0000000000000002e-06 || Time: 03:26:11.60
Epoch :: 51 || Loss: 0.37350275 || it_count: 8344 || Val Loss: 0.43050009 || Val it_count: 1107 || Current Learning Rate: 1.0000000000000002e-06 || Time: 03:30:19.11
Epoch :: 52 || Loss: 0.37320505 || it_count: 8344 || Val Loss: 0.43043488 || Val it_count: 1107 || Current Learning Rate: 1.0000000000000002e-06 || Time: 03:34:27.12
Epoch :: 53 || Loss: 0.37297875 || it_count: 8344 || Val Loss: 0.43043501 || Val it_count: 1107 || Current Learning Rate: 1.0000000000000002e-06 || Time: 03:38:36.07
Epoch :: 54 || Loss: 0.37289245 || it_count: 8344 || Val Loss: 0.43039093 || Val it_count: 1107 || Current Learning Rate: 1.0000000000000002e-06 || Time: 03:42:43.29
Early stopping triggered due to learning rate below threshold.
Done Total time: 03:46:55.26
best_loss: 0.42966440283714297

--------------------Testing--------------------

total_samples :: test_dataset = 139200, test_dataloader = 139200
Epoch ::  1 || Loss: 0.25660881 || it_count: 544 || Time: 00:00:13.25
MAE:  0.26224297
MSE:  0.25660455
RMSE:  0.4587828

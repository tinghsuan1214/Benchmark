--------------------Training--------------------
arch_str :: |lstm_3~0|+|lstm_3~0|lstm_1~1|[relu->linear->linear]
model :: 3M
InferCell(
  info :: nodes=3, inC=1, outC=64, [1<-(I0-L0) | 2<-(I0-L1,I1-L2)], genotype_str: lstm_3~0|lstm_3~0|lstm_1~1
  linear_layers: [relu->linear->linear]
  (layers): ModuleList(
    (0-1): 2 x LSTM(
      (lstm): LSTM(1, 64, num_layers=3, batch_first=True)
    )
    (2): LSTM(
      (lstm): LSTM(64, 64, batch_first=True)
    )
  )
  (linear_layers): ModuleList(
    (0): ReLU()
    (1): Linear(in_features=3072, out_features=1536, bias=True)
    (2): Linear(in_features=1536, out_features=1, bias=True)
  )
)
tr_params :: epochs = 100, patience = 20, batch_size = 256, window_size = 48, data_size = 100
Model FLOPs: 14.526M, Model Params: 4.922M
learning rate scheduling :: (optimizer, mode='min', factor=0.1, patience=5, verbose=True)
total_samples :: train_dataset = 2136000, train_dataloader = 2136000
total_samples :: valid_dataset = 283200, valid_dataloader = 283200
Epoch ::  1 || Loss: 0.42564053 || it_count: 8344 || Val Loss: 0.45578804 || Val it_count: 1107 || Current Learning Rate: 0.001 || Time: 00:12:56.83
Epoch ::  2 || Loss: 0.41788922 || it_count: 8344 || Val Loss: 0.45237455 || Val it_count: 1107 || Current Learning Rate: 0.001 || Time: 00:25:56.74
Epoch ::  3 || Loss: 0.41719790 || it_count: 8344 || Val Loss: 0.45344182 || Val it_count: 1107 || Current Learning Rate: 0.001 || Time: 00:38:55.69
Epoch ::  4 || Loss: 0.41718670 || it_count: 8344 || Val Loss: 0.45207839 || Val it_count: 1107 || Current Learning Rate: 0.001 || Time: 00:52:6.94
Epoch ::  5 || Loss: 0.41660670 || it_count: 8344 || Val Loss: 0.45241148 || Val it_count: 1107 || Current Learning Rate: 0.001 || Time: 01:05:26.11
Epoch ::  6 || Loss: 0.41619949 || it_count: 8344 || Val Loss: 0.45261983 || Val it_count: 1107 || Current Learning Rate: 0.001 || Time: 01:18:41.80
Epoch ::  7 || Loss: 0.41641532 || it_count: 8344 || Val Loss: 0.45246206 || Val it_count: 1107 || Current Learning Rate: 0.001 || Time: 01:31:55.85
Epoch ::  8 || Loss: 0.41596778 || it_count: 8344 || Val Loss: 0.45302425 || Val it_count: 1107 || Current Learning Rate: 0.001 || Time: 01:45:2.87
Epoch ::  9 || Loss: 0.41569139 || it_count: 8344 || Val Loss: 0.45426089 || Val it_count: 1107 || Current Learning Rate: 0.001 || Time: 01:58:14.15
Epoch :: 10 || Loss: 0.41586129 || it_count: 8344 || Val Loss: 0.45187141 || Val it_count: 1107 || Current Learning Rate: 0.001 || Time: 02:11:27.57
Epoch :: 11 || Loss: 0.41520539 || it_count: 8344 || Val Loss: 0.45495545 || Val it_count: 1107 || Current Learning Rate: 0.001 || Time: 02:24:47.08
Epoch :: 12 || Loss: 0.41483398 || it_count: 8344 || Val Loss: 0.45443497 || Val it_count: 1107 || Current Learning Rate: 0.001 || Time: 02:38:8.41
Epoch :: 13 || Loss: 0.41470239 || it_count: 8344 || Val Loss: 0.45453484 || Val it_count: 1107 || Current Learning Rate: 0.001 || Time: 02:51:29.04
Epoch :: 14 || Loss: 0.41466464 || it_count: 8344 || Val Loss: 0.45325039 || Val it_count: 1107 || Current Learning Rate: 0.001 || Time: 03:04:54.39
Epoch :: 15 || Loss: 0.41426840 || it_count: 8344 || Val Loss: 0.45433017 || Val it_count: 1107 || Current Learning Rate: 0.001 || Time: 03:18:17.89
Epoch :: 16 || Loss: 0.41417322 || it_count: 8344 || Val Loss: 0.45503886 || Val it_count: 1107 || Current Learning Rate: 0.001 || Time: 03:31:46.78
Epoch :: 17 || Loss: 0.41375282 || it_count: 8344 || Val Loss: 0.45272181 || Val it_count: 1107 || Current Learning Rate: 0.001 || Time: 03:45:10.73
Epoch :: 18 || Loss: 0.41328978 || it_count: 8344 || Val Loss: 0.45205617 || Val it_count: 1107 || Current Learning Rate: 0.001 || Time: 03:58:36.39
Epoch :: 19 || Loss: 0.41294372 || it_count: 8344 || Val Loss: 0.45019222 || Val it_count: 1107 || Current Learning Rate: 0.001 || Time: 04:12:5.05
Epoch :: 20 || Loss: 0.41242682 || it_count: 8344 || Val Loss: 0.45199568 || Val it_count: 1107 || Current Learning Rate: 0.001 || Time: 04:25:31.06
Epoch :: 21 || Loss: 0.41221067 || it_count: 8344 || Val Loss: 0.45238837 || Val it_count: 1107 || Current Learning Rate: 0.001 || Time: 04:38:58.92
Epoch :: 22 || Loss: 0.41150367 || it_count: 8344 || Val Loss: 0.45165232 || Val it_count: 1107 || Current Learning Rate: 0.001 || Time: 04:52:25.61
Epoch :: 23 || Loss: 0.41093285 || it_count: 8344 || Val Loss: 0.45220639 || Val it_count: 1107 || Current Learning Rate: 0.001 || Time: 05:05:50.87
Epoch :: 24 || Loss: 0.41061966 || it_count: 8344 || Val Loss: 0.45028755 || Val it_count: 1107 || Current Learning Rate: 0.001 || Time: 05:19:22.29
Epoch :: 25 || Loss: 0.41031056 || it_count: 8344 || Val Loss: 0.44933630 || Val it_count: 1107 || Current Learning Rate: 0.001 || Time: 05:32:48.77
Epoch :: 26 || Loss: 0.40991600 || it_count: 8344 || Val Loss: 0.44809973 || Val it_count: 1107 || Current Learning Rate: 0.001 || Time: 05:46:14.29
Epoch :: 27 || Loss: 0.40964527 || it_count: 8344 || Val Loss: 0.44707307 || Val it_count: 1107 || Current Learning Rate: 0.001 || Time: 05:59:41.57
Epoch :: 28 || Loss: 0.40928657 || it_count: 8344 || Val Loss: 0.44664119 || Val it_count: 1107 || Current Learning Rate: 0.001 || Time: 06:13:10.74
Epoch :: 29 || Loss: 0.40885023 || it_count: 8344 || Val Loss: 0.44699108 || Val it_count: 1107 || Current Learning Rate: 0.001 || Time: 06:26:36.60
Epoch :: 30 || Loss: 0.40890020 || it_count: 8344 || Val Loss: 0.44811801 || Val it_count: 1107 || Current Learning Rate: 0.001 || Time: 06:40:1.57
Epoch :: 31 || Loss: 0.40862001 || it_count: 8344 || Val Loss: 0.44493511 || Val it_count: 1107 || Current Learning Rate: 0.001 || Time: 06:53:26.62
Epoch :: 32 || Loss: 0.40838810 || it_count: 8344 || Val Loss: 0.44812393 || Val it_count: 1107 || Current Learning Rate: 0.001 || Time: 07:06:54.63
Epoch :: 33 || Loss: 0.40831194 || it_count: 8344 || Val Loss: 0.44739306 || Val it_count: 1107 || Current Learning Rate: 0.001 || Time: 07:20:23.62
Epoch :: 34 || Loss: 0.40882408 || it_count: 8344 || Val Loss: 0.45316393 || Val it_count: 1107 || Current Learning Rate: 0.001 || Time: 07:33:58.35
Epoch :: 35 || Loss: 0.40837263 || it_count: 8344 || Val Loss: 0.44484165 || Val it_count: 1107 || Current Learning Rate: 0.001 || Time: 07:47:31.09
Epoch :: 36 || Loss: 0.40759730 || it_count: 8344 || Val Loss: 0.44463912 || Val it_count: 1107 || Current Learning Rate: 0.001 || Time: 08:01:2.63
Epoch :: 37 || Loss: 0.40842091 || it_count: 8344 || Val Loss: 0.44360517 || Val it_count: 1107 || Current Learning Rate: 0.001 || Time: 08:14:32.60
Epoch :: 38 || Loss: 0.40761826 || it_count: 8344 || Val Loss: 0.44584157 || Val it_count: 1107 || Current Learning Rate: 0.001 || Time: 08:28:4.24
Epoch :: 39 || Loss: 0.40698138 || it_count: 8344 || Val Loss: 0.44617798 || Val it_count: 1107 || Current Learning Rate: 0.001 || Time: 08:41:40.94
Epoch :: 40 || Loss: 0.40671119 || it_count: 8344 || Val Loss: 0.44640890 || Val it_count: 1107 || Current Learning Rate: 0.001 || Time: 08:55:15.32
Epoch :: 41 || Loss: 0.40644167 || it_count: 8344 || Val Loss: 0.44469073 || Val it_count: 1107 || Current Learning Rate: 0.001 || Time: 09:08:50.14
Epoch :: 42 || Loss: 0.40623853 || it_count: 8344 || Val Loss: 0.44617314 || Val it_count: 1107 || Current Learning Rate: 0.001 || Time: 09:22:27.39
Epoch 00027: reducing learning rate of group 0 to 1.0000e-04.
Epoch :: 43 || Loss: 0.40599332 || it_count: 8344 || Val Loss: 0.44522284 || Val it_count: 1107 || Current Learning Rate: 0.0001 || Time: 09:36:3.24
Epoch :: 44 || Loss: 0.41197595 || it_count: 8344 || Val Loss: 0.43357039 || Val it_count: 1107 || Current Learning Rate: 0.0001 || Time: 09:49:33.98
Epoch :: 45 || Loss: 0.40972839 || it_count: 8344 || Val Loss: 0.43252390 || Val it_count: 1107 || Current Learning Rate: 0.0001 || Time: 10:03:4.14
Epoch :: 46 || Loss: 0.40873964 || it_count: 8344 || Val Loss: 0.43168620 || Val it_count: 1107 || Current Learning Rate: 0.0001 || Time: 10:16:37.57
Epoch :: 47 || Loss: 0.40808064 || it_count: 8344 || Val Loss: 0.43164064 || Val it_count: 1107 || Current Learning Rate: 0.0001 || Time: 10:30:11.12
Epoch :: 48 || Loss: 0.40754369 || it_count: 8344 || Val Loss: 0.43040904 || Val it_count: 1107 || Current Learning Rate: 0.0001 || Time: 10:43:51.43
Epoch :: 49 || Loss: 0.40707725 || it_count: 8344 || Val Loss: 0.43001604 || Val it_count: 1107 || Current Learning Rate: 0.0001 || Time: 10:57:40.69
Epoch :: 50 || Loss: 0.40666390 || it_count: 8344 || Val Loss: 0.42960807 || Val it_count: 1107 || Current Learning Rate: 0.0001 || Time: 11:11:33.73
Epoch :: 51 || Loss: 0.40627506 || it_count: 8344 || Val Loss: 0.42941231 || Val it_count: 1107 || Current Learning Rate: 0.0001 || Time: 11:25:33.29
Epoch :: 52 || Loss: 0.40593906 || it_count: 8344 || Val Loss: 0.42907253 || Val it_count: 1107 || Current Learning Rate: 0.0001 || Time: 11:39:31.05
Epoch :: 53 || Loss: 0.40562362 || it_count: 8344 || Val Loss: 0.42850296 || Val it_count: 1107 || Current Learning Rate: 0.0001 || Time: 11:53:20.42
Epoch :: 54 || Loss: 0.40523480 || it_count: 8344 || Val Loss: 0.42770121 || Val it_count: 1107 || Current Learning Rate: 0.0001 || Time: 12:07:1.75
Epoch :: 55 || Loss: 0.40488312 || it_count: 8344 || Val Loss: 0.42745784 || Val it_count: 1107 || Current Learning Rate: 0.0001 || Time: 12:20:37.55
Epoch :: 56 || Loss: 0.40455545 || it_count: 8344 || Val Loss: 0.42717392 || Val it_count: 1107 || Current Learning Rate: 0.0001 || Time: 12:34:10.05
Epoch :: 57 || Loss: 0.40434564 || it_count: 8344 || Val Loss: 0.42679989 || Val it_count: 1107 || Current Learning Rate: 0.0001 || Time: 12:47:37.23
Epoch :: 58 || Loss: 0.40404674 || it_count: 8344 || Val Loss: 0.42694894 || Val it_count: 1107 || Current Learning Rate: 0.0001 || Time: 13:00:57.56
Epoch :: 59 || Loss: 0.40402330 || it_count: 8344 || Val Loss: 0.42648043 || Val it_count: 1107 || Current Learning Rate: 0.0001 || Time: 13:14:20.08
Epoch :: 60 || Loss: 0.40353536 || it_count: 8344 || Val Loss: 0.42667306 || Val it_count: 1107 || Current Learning Rate: 0.0001 || Time: 13:27:42.54
Epoch :: 61 || Loss: 0.40335765 || it_count: 8344 || Val Loss: 0.42659313 || Val it_count: 1107 || Current Learning Rate: 0.0001 || Time: 13:41:3.31
Epoch :: 62 || Loss: 0.40308908 || it_count: 8344 || Val Loss: 0.42667789 || Val it_count: 1107 || Current Learning Rate: 0.0001 || Time: 13:54:33.84
Epoch :: 63 || Loss: 0.40287958 || it_count: 8344 || Val Loss: 0.42675351 || Val it_count: 1107 || Current Learning Rate: 0.0001 || Time: 14:07:49.30
Epoch :: 64 || Loss: 0.40263630 || it_count: 8344 || Val Loss: 0.42700388 || Val it_count: 1107 || Current Learning Rate: 0.0001 || Time: 14:21:5.37
Epoch 00049: reducing learning rate of group 0 to 1.0000e-05.
Epoch :: 65 || Loss: 0.40262468 || it_count: 8344 || Val Loss: 0.42773506 || Val it_count: 1107 || Current Learning Rate: 1e-05 || Time: 14:34:23.48
Epoch :: 66 || Loss: 0.40788809 || it_count: 8344 || Val Loss: 0.41319792 || Val it_count: 1107 || Current Learning Rate: 1e-05 || Time: 14:47:31.89
Epoch :: 67 || Loss: 0.40616066 || it_count: 8344 || Val Loss: 0.41316243 || Val it_count: 1107 || Current Learning Rate: 1e-05 || Time: 15:00:42.89
Epoch :: 68 || Loss: 0.40585180 || it_count: 8344 || Val Loss: 0.41312386 || Val it_count: 1107 || Current Learning Rate: 1e-05 || Time: 15:13:59.54
Epoch :: 69 || Loss: 0.40574711 || it_count: 8344 || Val Loss: 0.41305212 || Val it_count: 1107 || Current Learning Rate: 1e-05 || Time: 15:27:15.93
Epoch :: 70 || Loss: 0.40555152 || it_count: 8344 || Val Loss: 0.41304836 || Val it_count: 1107 || Current Learning Rate: 1e-05 || Time: 15:40:31.44
Epoch :: 71 || Loss: 0.40542307 || it_count: 8344 || Val Loss: 0.41304042 || Val it_count: 1107 || Current Learning Rate: 1e-05 || Time: 15:53:43.85
Epoch :: 72 || Loss: 0.40532322 || it_count: 8344 || Val Loss: 0.41304289 || Val it_count: 1107 || Current Learning Rate: 1e-05 || Time: 16:07:4.12
Epoch :: 73 || Loss: 0.40523907 || it_count: 8344 || Val Loss: 0.41304247 || Val it_count: 1107 || Current Learning Rate: 1e-05 || Time: 16:20:12.47
Epoch :: 74 || Loss: 0.40517955 || it_count: 8344 || Val Loss: 0.41304755 || Val it_count: 1107 || Current Learning Rate: 1e-05 || Time: 16:33:18.68
Epoch 00059: reducing learning rate of group 0 to 1.0000e-06.
Epoch :: 75 || Loss: 0.40509179 || it_count: 8344 || Val Loss: 0.41305369 || Val it_count: 1107 || Current Learning Rate: 1.0000000000000002e-06 || Time: 16:46:23.09
Epoch :: 76 || Loss: 0.40581458 || it_count: 8344 || Val Loss: 0.41164971 || Val it_count: 1107 || Current Learning Rate: 1.0000000000000002e-06 || Time: 16:59:28.67
Epoch :: 77 || Loss: 0.40548917 || it_count: 8344 || Val Loss: 0.41144237 || Val it_count: 1107 || Current Learning Rate: 1.0000000000000002e-06 || Time: 17:12:36.38
Epoch :: 78 || Loss: 0.40539615 || it_count: 8344 || Val Loss: 0.41137454 || Val it_count: 1107 || Current Learning Rate: 1.0000000000000002e-06 || Time: 17:25:40.51
Epoch :: 79 || Loss: 0.40534524 || it_count: 8344 || Val Loss: 0.41133729 || Val it_count: 1107 || Current Learning Rate: 1.0000000000000002e-06 || Time: 17:38:46.09
Epoch :: 80 || Loss: 0.40531105 || it_count: 8344 || Val Loss: 0.41131087 || Val it_count: 1107 || Current Learning Rate: 1.0000000000000002e-06 || Time: 17:51:52.27
Epoch :: 81 || Loss: 0.40528538 || it_count: 8344 || Val Loss: 0.41128965 || Val it_count: 1107 || Current Learning Rate: 1.0000000000000002e-06 || Time: 18:05:1.39
Epoch :: 82 || Loss: 0.40526493 || it_count: 8344 || Val Loss: 0.41127150 || Val it_count: 1107 || Current Learning Rate: 1.0000000000000002e-06 || Time: 18:18:6.32
Epoch :: 83 || Loss: 0.40524756 || it_count: 8344 || Val Loss: 0.41125716 || Val it_count: 1107 || Current Learning Rate: 1.0000000000000002e-06 || Time: 18:31:12.21
Epoch :: 84 || Loss: 0.40523253 || it_count: 8344 || Val Loss: 0.41124541 || Val it_count: 1107 || Current Learning Rate: 1.0000000000000002e-06 || Time: 18:44:24.48
Epoch :: 85 || Loss: 0.40521873 || it_count: 8344 || Val Loss: 0.41123510 || Val it_count: 1107 || Current Learning Rate: 1.0000000000000002e-06 || Time: 18:57:34.86
Epoch :: 86 || Loss: 0.40520629 || it_count: 8344 || Val Loss: 0.41122595 || Val it_count: 1107 || Current Learning Rate: 1.0000000000000002e-06 || Time: 19:10:46.52
Epoch :: 87 || Loss: 0.40519476 || it_count: 8344 || Val Loss: 0.41121796 || Val it_count: 1107 || Current Learning Rate: 1.0000000000000002e-06 || Time: 19:23:56.47
Epoch :: 88 || Loss: 0.40518382 || it_count: 8344 || Val Loss: 0.41121127 || Val it_count: 1107 || Current Learning Rate: 1.0000000000000002e-06 || Time: 19:37:6.80
Epoch :: 89 || Loss: 0.40517355 || it_count: 8344 || Val Loss: 0.41120493 || Val it_count: 1107 || Current Learning Rate: 1.0000000000000002e-06 || Time: 19:50:15.74
Epoch :: 90 || Loss: 0.40516373 || it_count: 8344 || Val Loss: 0.41119913 || Val it_count: 1107 || Current Learning Rate: 1.0000000000000002e-06 || Time: 20:03:24.61
Epoch :: 91 || Loss: 0.40515419 || it_count: 8344 || Val Loss: 0.41119402 || Val it_count: 1107 || Current Learning Rate: 1.0000000000000002e-06 || Time: 20:16:40.05
Epoch :: 92 || Loss: 0.40514516 || it_count: 8344 || Val Loss: 0.41119044 || Val it_count: 1107 || Current Learning Rate: 1.0000000000000002e-06 || Time: 20:30:2.63
Epoch :: 93 || Loss: 0.40513641 || it_count: 8344 || Val Loss: 0.41118694 || Val it_count: 1107 || Current Learning Rate: 1.0000000000000002e-06 || Time: 20:43:19.28
Epoch 00078: reducing learning rate of group 0 to 1.0000e-07.
Early stopping triggered due to learning rate below threshold.
Done Total time: 20:56:50.26
best_loss: 0.41118694278121143

--------------------Testing--------------------

total_samples :: test_dataset = 139200, test_dataloader = 139200
Epoch ::  1 || Loss: 0.23705335 || it_count: 544 || Time: 00:00:28.73
MAE:  0.252147
MSE:  0.23707323
RMSE:  0.44205695

--------------------Training--------------------
arch_str :: |none~0|+|lstm_2~0|lstm_1~1|[relu->linear->linear]
model :: 3M
InferCell(
  info :: nodes=3, inC=1, outC=64, [1<-(I0-L0) | 2<-(I0-L1,I1-L2)], genotype_str: none~0|lstm_2~0|lstm_1~1
  linear_layers: [relu->linear->linear]
  (layers): ModuleList(
    (0): Zero(C_in=1, C_out=64, stride=1)
    (1): LSTM(
      (lstm): LSTM(1, 64, num_layers=2, batch_first=True)
    )
    (2): LSTM(
      (lstm): LSTM(64, 64, batch_first=True)
    )
  )
  (linear_layers): ModuleList(
    (0): ReLU()
    (1): Linear(in_features=3072, out_features=1536, bias=True)
    (2): Linear(in_features=1536, out_features=1, bias=True)
  )
)
tr_params :: epochs = 100, patience = 20, batch_size = 256, window_size = 48, data_size = 100
Model FLOPs: 8.812M, Model Params: 4.805M
learning rate scheduling :: (optimizer, mode='min', factor=0.1, patience=5, verbose=True)
total_samples :: train_dataset = 2136000, train_dataloader = 2136000
total_samples :: valid_dataset = 283200, valid_dataloader = 283200
Epoch ::  1 || Loss: 0.42358193 || it_count: 8344 || Val Loss: 0.45762286 || Val it_count: 1107 || Current Learning Rate: 0.001 || Time: 00:08:22.35
Epoch ::  2 || Loss: 0.41792348 || it_count: 8344 || Val Loss: 0.45266814 || Val it_count: 1107 || Current Learning Rate: 0.001 || Time: 00:16:49.20
Epoch ::  3 || Loss: 0.41669622 || it_count: 8344 || Val Loss: 0.45222531 || Val it_count: 1107 || Current Learning Rate: 0.001 || Time: 00:25:19.37
Epoch ::  4 || Loss: 0.41609779 || it_count: 8344 || Val Loss: 0.45061003 || Val it_count: 1107 || Current Learning Rate: 0.001 || Time: 00:33:53.76
Epoch ::  5 || Loss: 0.41563105 || it_count: 8344 || Val Loss: 0.45195972 || Val it_count: 1107 || Current Learning Rate: 0.001 || Time: 00:42:28.89
Epoch ::  6 || Loss: 0.41520513 || it_count: 8344 || Val Loss: 0.45121746 || Val it_count: 1107 || Current Learning Rate: 0.001 || Time: 00:51:4.70
Epoch ::  7 || Loss: 0.41485685 || it_count: 8344 || Val Loss: 0.45231847 || Val it_count: 1107 || Current Learning Rate: 0.001 || Time: 00:59:41.35
Epoch ::  8 || Loss: 0.41490572 || it_count: 8344 || Val Loss: 0.45310413 || Val it_count: 1107 || Current Learning Rate: 0.001 || Time: 01:08:18.19
Epoch ::  9 || Loss: 0.41451731 || it_count: 8344 || Val Loss: 0.45385378 || Val it_count: 1107 || Current Learning Rate: 0.001 || Time: 01:16:55.29
Epoch :: 10 || Loss: 0.41442561 || it_count: 8344 || Val Loss: 0.45251583 || Val it_count: 1107 || Current Learning Rate: 0.001 || Time: 01:25:32.75
Epoch :: 11 || Loss: 0.41424744 || it_count: 8344 || Val Loss: 0.45244167 || Val it_count: 1107 || Current Learning Rate: 0.001 || Time: 01:34:11.00
Epoch :: 12 || Loss: 0.41453490 || it_count: 8344 || Val Loss: 0.45199068 || Val it_count: 1107 || Current Learning Rate: 0.001 || Time: 01:42:51.95
Epoch :: 13 || Loss: 0.41399185 || it_count: 8344 || Val Loss: 0.45158833 || Val it_count: 1107 || Current Learning Rate: 0.001 || Time: 01:51:32.57
Epoch :: 14 || Loss: 0.41415030 || it_count: 8344 || Val Loss: 0.45080897 || Val it_count: 1107 || Current Learning Rate: 0.001 || Time: 02:00:12.44
Epoch :: 15 || Loss: 0.41386020 || it_count: 8344 || Val Loss: 0.45112188 || Val it_count: 1107 || Current Learning Rate: 0.001 || Time: 02:08:54.62
Epoch :: 16 || Loss: 0.41354277 || it_count: 8344 || Val Loss: 0.45137551 || Val it_count: 1107 || Current Learning Rate: 0.001 || Time: 02:17:37.07
Epoch :: 17 || Loss: 0.41319057 || it_count: 8344 || Val Loss: 0.45032492 || Val it_count: 1107 || Current Learning Rate: 0.001 || Time: 02:26:19.23
Epoch :: 18 || Loss: 0.41279641 || it_count: 8344 || Val Loss: 0.45015034 || Val it_count: 1107 || Current Learning Rate: 0.001 || Time: 02:35:1.63
Epoch :: 19 || Loss: 0.41285620 || it_count: 8344 || Val Loss: 0.44943974 || Val it_count: 1107 || Current Learning Rate: 0.001 || Time: 02:43:44.88
Epoch :: 20 || Loss: 0.41273892 || it_count: 8344 || Val Loss: 0.44921607 || Val it_count: 1107 || Current Learning Rate: 0.001 || Time: 02:52:31.11
Epoch :: 21 || Loss: 0.41171620 || it_count: 8344 || Val Loss: 0.45051134 || Val it_count: 1107 || Current Learning Rate: 0.001 || Time: 03:01:17.77
Epoch :: 22 || Loss: 0.41116116 || it_count: 8344 || Val Loss: 0.44919088 || Val it_count: 1107 || Current Learning Rate: 0.001 || Time: 03:10:4.31
Epoch :: 23 || Loss: 0.41072671 || it_count: 8344 || Val Loss: 0.44811586 || Val it_count: 1107 || Current Learning Rate: 0.001 || Time: 03:18:53.50
Epoch :: 24 || Loss: 0.41088788 || it_count: 8344 || Val Loss: 0.44629014 || Val it_count: 1107 || Current Learning Rate: 0.001 || Time: 03:27:44.58
Epoch :: 25 || Loss: 0.40971060 || it_count: 8344 || Val Loss: 0.44580856 || Val it_count: 1107 || Current Learning Rate: 0.001 || Time: 03:36:31.82
Epoch :: 26 || Loss: 0.40902076 || it_count: 8344 || Val Loss: 0.44545694 || Val it_count: 1107 || Current Learning Rate: 0.001 || Time: 03:45:21.07
Epoch :: 27 || Loss: 0.40868402 || it_count: 8344 || Val Loss: 0.44504436 || Val it_count: 1107 || Current Learning Rate: 0.001 || Time: 03:54:8.24
Epoch :: 28 || Loss: 0.40812430 || it_count: 8344 || Val Loss: 0.44447561 || Val it_count: 1107 || Current Learning Rate: 0.001 || Time: 04:03:1.23
Epoch :: 29 || Loss: 0.40815394 || it_count: 8344 || Val Loss: 0.44377620 || Val it_count: 1107 || Current Learning Rate: 0.001 || Time: 04:11:50.48
Epoch :: 30 || Loss: 0.40802649 || it_count: 8344 || Val Loss: 0.44313061 || Val it_count: 1107 || Current Learning Rate: 0.001 || Time: 04:20:38.02
Epoch :: 31 || Loss: 0.40771383 || it_count: 8344 || Val Loss: 0.44178875 || Val it_count: 1107 || Current Learning Rate: 0.001 || Time: 04:29:29.94
Epoch :: 32 || Loss: 0.40754711 || it_count: 8344 || Val Loss: 0.44187608 || Val it_count: 1107 || Current Learning Rate: 0.001 || Time: 04:38:20.96
Epoch :: 33 || Loss: 0.40721526 || it_count: 8344 || Val Loss: 0.44238182 || Val it_count: 1107 || Current Learning Rate: 0.001 || Time: 04:47:9.37
Epoch :: 34 || Loss: 0.40650314 || it_count: 8344 || Val Loss: 0.44383257 || Val it_count: 1107 || Current Learning Rate: 0.001 || Time: 04:55:57.81
Epoch :: 35 || Loss: 0.40617758 || it_count: 8344 || Val Loss: 0.44318206 || Val it_count: 1107 || Current Learning Rate: 0.001 || Time: 05:04:45.28
Epoch :: 36 || Loss: 0.40563619 || it_count: 8344 || Val Loss: 0.44349499 || Val it_count: 1107 || Current Learning Rate: 0.001 || Time: 05:13:36.19
Epoch 00021: reducing learning rate of group 0 to 1.0000e-04.
Epoch :: 37 || Loss: 0.40515956 || it_count: 8344 || Val Loss: 0.44447511 || Val it_count: 1107 || Current Learning Rate: 0.0001 || Time: 05:22:19.72
Epoch :: 38 || Loss: 0.41305143 || it_count: 8344 || Val Loss: 0.43421134 || Val it_count: 1107 || Current Learning Rate: 0.0001 || Time: 05:31:6.93
Epoch :: 39 || Loss: 0.41110733 || it_count: 8344 || Val Loss: 0.43242266 || Val it_count: 1107 || Current Learning Rate: 0.0001 || Time: 05:39:54.84
Epoch :: 40 || Loss: 0.41004072 || it_count: 8344 || Val Loss: 0.43095046 || Val it_count: 1107 || Current Learning Rate: 0.0001 || Time: 05:48:41.72
Epoch :: 41 || Loss: 0.40931237 || it_count: 8344 || Val Loss: 0.42935080 || Val it_count: 1107 || Current Learning Rate: 0.0001 || Time: 05:57:28.11
Epoch :: 42 || Loss: 0.40862265 || it_count: 8344 || Val Loss: 0.42824891 || Val it_count: 1107 || Current Learning Rate: 0.0001 || Time: 06:06:15.48
Epoch :: 43 || Loss: 0.40808616 || it_count: 8344 || Val Loss: 0.42752054 || Val it_count: 1107 || Current Learning Rate: 0.0001 || Time: 06:14:59.78
Epoch :: 44 || Loss: 0.40764010 || it_count: 8344 || Val Loss: 0.42710589 || Val it_count: 1107 || Current Learning Rate: 0.0001 || Time: 06:23:47.26
Epoch :: 45 || Loss: 0.40721729 || it_count: 8344 || Val Loss: 0.42671679 || Val it_count: 1107 || Current Learning Rate: 0.0001 || Time: 06:32:30.96
Epoch :: 46 || Loss: 0.40687803 || it_count: 8344 || Val Loss: 0.42656145 || Val it_count: 1107 || Current Learning Rate: 0.0001 || Time: 06:41:14.56
Epoch :: 47 || Loss: 0.40660116 || it_count: 8344 || Val Loss: 0.42628598 || Val it_count: 1107 || Current Learning Rate: 0.0001 || Time: 06:49:58.12
Epoch :: 48 || Loss: 0.40631446 || it_count: 8344 || Val Loss: 0.42607516 || Val it_count: 1107 || Current Learning Rate: 0.0001 || Time: 06:58:50.02
Epoch :: 49 || Loss: 0.40607310 || it_count: 8344 || Val Loss: 0.42611503 || Val it_count: 1107 || Current Learning Rate: 0.0001 || Time: 07:07:35.93
Epoch :: 50 || Loss: 0.40576056 || it_count: 8344 || Val Loss: 0.42612538 || Val it_count: 1107 || Current Learning Rate: 0.0001 || Time: 07:16:19.78
Epoch :: 51 || Loss: 0.40555542 || it_count: 8344 || Val Loss: 0.42608397 || Val it_count: 1107 || Current Learning Rate: 0.0001 || Time: 07:25:4.63
Epoch :: 52 || Loss: 0.40529738 || it_count: 8344 || Val Loss: 0.42618298 || Val it_count: 1107 || Current Learning Rate: 0.0001 || Time: 07:33:49.50
Epoch :: 53 || Loss: 0.40507523 || it_count: 8344 || Val Loss: 0.42634625 || Val it_count: 1107 || Current Learning Rate: 0.0001 || Time: 07:42:31.44
Epoch 00038: reducing learning rate of group 0 to 1.0000e-05.
Epoch :: 54 || Loss: 0.40486620 || it_count: 8344 || Val Loss: 0.42656692 || Val it_count: 1107 || Current Learning Rate: 1e-05 || Time: 07:51:13.35
Epoch :: 55 || Loss: 0.41055781 || it_count: 8344 || Val Loss: 0.41417096 || Val it_count: 1107 || Current Learning Rate: 1e-05 || Time: 07:59:55.02
Epoch :: 56 || Loss: 0.40792709 || it_count: 8344 || Val Loss: 0.41330104 || Val it_count: 1107 || Current Learning Rate: 1e-05 || Time: 08:08:35.40
Epoch :: 57 || Loss: 0.40764889 || it_count: 8344 || Val Loss: 0.41320415 || Val it_count: 1107 || Current Learning Rate: 1e-05 || Time: 08:17:16.04
Epoch :: 58 || Loss: 0.40747310 || it_count: 8344 || Val Loss: 0.41309658 || Val it_count: 1107 || Current Learning Rate: 1e-05 || Time: 08:25:58.19
Epoch :: 59 || Loss: 0.40734589 || it_count: 8344 || Val Loss: 0.41303291 || Val it_count: 1107 || Current Learning Rate: 1e-05 || Time: 08:34:40.10
Epoch :: 60 || Loss: 0.40724211 || it_count: 8344 || Val Loss: 0.41297780 || Val it_count: 1107 || Current Learning Rate: 1e-05 || Time: 08:43:21.18
Epoch :: 61 || Loss: 0.40715129 || it_count: 8344 || Val Loss: 0.41293910 || Val it_count: 1107 || Current Learning Rate: 1e-05 || Time: 08:52:2.00
Epoch :: 62 || Loss: 0.40707933 || it_count: 8344 || Val Loss: 0.41291919 || Val it_count: 1107 || Current Learning Rate: 1e-05 || Time: 09:00:41.77
Epoch :: 63 || Loss: 0.40701345 || it_count: 8344 || Val Loss: 0.41291597 || Val it_count: 1107 || Current Learning Rate: 1e-05 || Time: 09:09:23.13
Epoch :: 64 || Loss: 0.40695544 || it_count: 8344 || Val Loss: 0.41290009 || Val it_count: 1107 || Current Learning Rate: 1e-05 || Time: 09:18:3.10
Epoch :: 65 || Loss: 0.40690017 || it_count: 8344 || Val Loss: 0.41290431 || Val it_count: 1107 || Current Learning Rate: 1e-05 || Time: 09:26:43.57
Epoch :: 66 || Loss: 0.40685073 || it_count: 8344 || Val Loss: 0.41291208 || Val it_count: 1107 || Current Learning Rate: 1e-05 || Time: 09:35:23.74
Epoch :: 67 || Loss: 0.40680325 || it_count: 8344 || Val Loss: 0.41293226 || Val it_count: 1107 || Current Learning Rate: 1e-05 || Time: 09:44:3.56
Epoch 00052: reducing learning rate of group 0 to 1.0000e-06.
Epoch :: 68 || Loss: 0.40675809 || it_count: 8344 || Val Loss: 0.41295310 || Val it_count: 1107 || Current Learning Rate: 1.0000000000000002e-06 || Time: 09:52:44.69
Epoch :: 69 || Loss: 0.40732006 || it_count: 8344 || Val Loss: 0.41189993 || Val it_count: 1107 || Current Learning Rate: 1.0000000000000002e-06 || Time: 10:01:26.46
Epoch :: 70 || Loss: 0.40704389 || it_count: 8344 || Val Loss: 0.41171152 || Val it_count: 1107 || Current Learning Rate: 1.0000000000000002e-06 || Time: 10:10:8.74
Epoch :: 71 || Loss: 0.40697384 || it_count: 8344 || Val Loss: 0.41165720 || Val it_count: 1107 || Current Learning Rate: 1.0000000000000002e-06 || Time: 10:18:52.87
Epoch :: 72 || Loss: 0.40693946 || it_count: 8344 || Val Loss: 0.41163684 || Val it_count: 1107 || Current Learning Rate: 1.0000000000000002e-06 || Time: 10:27:37.31
Epoch :: 73 || Loss: 0.40691607 || it_count: 8344 || Val Loss: 0.41162783 || Val it_count: 1107 || Current Learning Rate: 1.0000000000000002e-06 || Time: 10:36:20.67
Epoch :: 74 || Loss: 0.40689830 || it_count: 8344 || Val Loss: 0.41162196 || Val it_count: 1107 || Current Learning Rate: 1.0000000000000002e-06 || Time: 10:45:2.38
Epoch :: 75 || Loss: 0.40688377 || it_count: 8344 || Val Loss: 0.41161695 || Val it_count: 1107 || Current Learning Rate: 1.0000000000000002e-06 || Time: 10:53:48.95
Epoch :: 76 || Loss: 0.40687119 || it_count: 8344 || Val Loss: 0.41161383 || Val it_count: 1107 || Current Learning Rate: 1.0000000000000002e-06 || Time: 11:02:32.78
Epoch :: 77 || Loss: 0.40686030 || it_count: 8344 || Val Loss: 0.41161055 || Val it_count: 1107 || Current Learning Rate: 1.0000000000000002e-06 || Time: 11:11:14.37
Epoch :: 78 || Loss: 0.40685073 || it_count: 8344 || Val Loss: 0.41160731 || Val it_count: 1107 || Current Learning Rate: 1.0000000000000002e-06 || Time: 11:19:57.45
Epoch :: 79 || Loss: 0.40684169 || it_count: 8344 || Val Loss: 0.41160425 || Val it_count: 1107 || Current Learning Rate: 1.0000000000000002e-06 || Time: 11:28:41.57
Epoch :: 80 || Loss: 0.40683321 || it_count: 8344 || Val Loss: 0.41160160 || Val it_count: 1107 || Current Learning Rate: 1.0000000000000002e-06 || Time: 11:37:27.13
Epoch :: 81 || Loss: 0.40682580 || it_count: 8344 || Val Loss: 0.41159844 || Val it_count: 1107 || Current Learning Rate: 1.0000000000000002e-06 || Time: 11:46:11.21
Epoch 00066: reducing learning rate of group 0 to 1.0000e-07.
Early stopping triggered due to learning rate below threshold.
Done Total time: 11:54:55.74
best_loss: 0.41159844183321054

--------------------Testing--------------------

total_samples :: test_dataset = 139200, test_dataloader = 139200
Epoch ::  1 || Loss: 0.23602308 || it_count: 544 || Time: 00:00:21.93
MAE:  0.25204223
MSE:  0.23604015
RMSE:  0.4411704

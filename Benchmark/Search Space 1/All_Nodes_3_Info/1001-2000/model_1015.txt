--------------------Training--------------------
arch_str :: |lstm_1~0|+|lstm_3~0|lstm_1~1|[dropout->linear->linear]
model :: 3I
InferCell(
  info :: nodes=3, inC=1, outC=64, [1<-(I0-L0) | 2<-(I0-L1,I1-L2)], genotype_str: lstm_1~0|lstm_3~0|lstm_1~1
  linear_layers: [dropout->linear->linear]
  (layers): ModuleList(
    (0): LSTM(
      (lstm): LSTM(1, 64, batch_first=True)
    )
    (1): LSTM(
      (lstm): LSTM(1, 64, num_layers=3, batch_first=True)
    )
    (2): LSTM(
      (lstm): LSTM(64, 64, batch_first=True)
    )
  )
  (linear_layers): ModuleList(
    (0): Dropout(p=0.1, inplace=False)
    (1): Linear(in_features=3072, out_features=1536, bias=True)
    (2): Linear(in_features=1536, out_features=1, bias=True)
  )
)
tr_params :: epochs = 100, patience = 20, batch_size = 256, window_size = 48, data_size = 100
Model FLOPs: 11.282M, Model Params: 4.856M
learning rate scheduling :: (optimizer, mode='min', factor=0.1, patience=5, verbose=True)
total_samples :: train_dataset = 2136000, train_dataloader = 2136000
total_samples :: valid_dataset = 283200, valid_dataloader = 283200
Epoch ::  1 || Loss: 0.42422172 || it_count: 8344 || Val Loss: 0.46012486 || Val it_count: 1107 || Current Learning Rate: 0.001 || Time: 00:04:33.17
Epoch ::  2 || Loss: 0.41749392 || it_count: 8344 || Val Loss: 0.44931476 || Val it_count: 1107 || Current Learning Rate: 0.001 || Time: 00:09:4.88
Epoch ::  3 || Loss: 0.41677789 || it_count: 8344 || Val Loss: 0.44893776 || Val it_count: 1107 || Current Learning Rate: 0.001 || Time: 00:13:38.50
Epoch ::  4 || Loss: 0.41620175 || it_count: 8344 || Val Loss: 0.45014476 || Val it_count: 1107 || Current Learning Rate: 0.001 || Time: 00:18:13.32
Epoch ::  5 || Loss: 0.41598233 || it_count: 8344 || Val Loss: 0.45033403 || Val it_count: 1107 || Current Learning Rate: 0.001 || Time: 00:22:47.01
Epoch ::  6 || Loss: 0.41578949 || it_count: 8344 || Val Loss: 0.44980683 || Val it_count: 1107 || Current Learning Rate: 0.001 || Time: 00:27:19.70
Epoch ::  7 || Loss: 0.41547752 || it_count: 8344 || Val Loss: 0.44833326 || Val it_count: 1107 || Current Learning Rate: 0.001 || Time: 00:31:54.07
Epoch ::  8 || Loss: 0.41513400 || it_count: 8344 || Val Loss: 0.45001723 || Val it_count: 1107 || Current Learning Rate: 0.001 || Time: 00:36:27.71
Epoch ::  9 || Loss: 0.41491520 || it_count: 8344 || Val Loss: 0.45060127 || Val it_count: 1107 || Current Learning Rate: 0.001 || Time: 00:41:2.68
Epoch :: 10 || Loss: 0.41477483 || it_count: 8344 || Val Loss: 0.45043639 || Val it_count: 1107 || Current Learning Rate: 0.001 || Time: 00:45:38.16
Epoch :: 11 || Loss: 0.41466744 || it_count: 8344 || Val Loss: 0.45010921 || Val it_count: 1107 || Current Learning Rate: 0.001 || Time: 00:50:12.67
Epoch :: 12 || Loss: 0.41469650 || it_count: 8344 || Val Loss: 0.44985683 || Val it_count: 1107 || Current Learning Rate: 0.001 || Time: 00:54:46.88
Epoch :: 13 || Loss: 0.41446592 || it_count: 8344 || Val Loss: 0.44910518 || Val it_count: 1107 || Current Learning Rate: 0.001 || Time: 00:59:22.95
Epoch :: 14 || Loss: 0.41430477 || it_count: 8344 || Val Loss: 0.44832863 || Val it_count: 1107 || Current Learning Rate: 0.001 || Time: 01:03:59.74
Epoch :: 15 || Loss: 0.41429443 || it_count: 8344 || Val Loss: 0.44771000 || Val it_count: 1107 || Current Learning Rate: 0.001 || Time: 01:08:36.12
Epoch :: 16 || Loss: 0.41391273 || it_count: 8344 || Val Loss: 0.44664326 || Val it_count: 1107 || Current Learning Rate: 0.001 || Time: 01:13:11.28
Epoch :: 17 || Loss: 0.41376167 || it_count: 8344 || Val Loss: 0.44591031 || Val it_count: 1107 || Current Learning Rate: 0.001 || Time: 01:17:48.69
Epoch :: 18 || Loss: 0.41332713 || it_count: 8344 || Val Loss: 0.44633839 || Val it_count: 1107 || Current Learning Rate: 0.001 || Time: 01:22:27.76
Epoch :: 19 || Loss: 0.41322501 || it_count: 8344 || Val Loss: 0.44724603 || Val it_count: 1107 || Current Learning Rate: 0.001 || Time: 01:27:4.45
Epoch :: 20 || Loss: 0.41323202 || it_count: 8344 || Val Loss: 0.44708897 || Val it_count: 1107 || Current Learning Rate: 0.001 || Time: 01:31:41.87
Epoch :: 21 || Loss: 0.41290810 || it_count: 8344 || Val Loss: 0.44662378 || Val it_count: 1107 || Current Learning Rate: 0.001 || Time: 01:36:20.64
Epoch :: 22 || Loss: 0.41290703 || it_count: 8344 || Val Loss: 0.44664670 || Val it_count: 1107 || Current Learning Rate: 0.001 || Time: 01:40:55.92
Epoch :: 23 || Loss: 0.41271095 || it_count: 8344 || Val Loss: 0.44687036 || Val it_count: 1107 || Current Learning Rate: 0.0001 || Time: 01:45:28.80
Epoch :: 24 || Loss: 0.41983193 || it_count: 8344 || Val Loss: 0.43499053 || Val it_count: 1107 || Current Learning Rate: 0.0001 || Time: 01:50:8.93
Epoch :: 25 || Loss: 0.41767412 || it_count: 8344 || Val Loss: 0.43374003 || Val it_count: 1107 || Current Learning Rate: 0.0001 || Time: 01:54:44.45
Epoch :: 26 || Loss: 0.41702807 || it_count: 8344 || Val Loss: 0.43238542 || Val it_count: 1107 || Current Learning Rate: 0.0001 || Time: 01:59:19.87
Epoch :: 27 || Loss: 0.41643492 || it_count: 8344 || Val Loss: 0.43156660 || Val it_count: 1107 || Current Learning Rate: 0.0001 || Time: 02:03:58.32
Epoch :: 28 || Loss: 0.41586154 || it_count: 8344 || Val Loss: 0.43132109 || Val it_count: 1107 || Current Learning Rate: 0.0001 || Time: 02:08:38.81
Epoch :: 29 || Loss: 0.41544912 || it_count: 8344 || Val Loss: 0.43175689 || Val it_count: 1107 || Current Learning Rate: 0.0001 || Time: 02:13:16.26
Epoch :: 30 || Loss: 0.41525655 || it_count: 8344 || Val Loss: 0.43119032 || Val it_count: 1107 || Current Learning Rate: 0.0001 || Time: 02:17:51.83
Epoch :: 31 || Loss: 0.41496942 || it_count: 8344 || Val Loss: 0.43090129 || Val it_count: 1107 || Current Learning Rate: 0.0001 || Time: 02:22:31.05
Epoch :: 32 || Loss: 0.41476103 || it_count: 8344 || Val Loss: 0.43091929 || Val it_count: 1107 || Current Learning Rate: 0.0001 || Time: 02:27:9.40
Epoch :: 33 || Loss: 0.41453798 || it_count: 8344 || Val Loss: 0.43037540 || Val it_count: 1107 || Current Learning Rate: 0.0001 || Time: 02:31:46.19
Epoch :: 34 || Loss: 0.41426181 || it_count: 8344 || Val Loss: 0.43037720 || Val it_count: 1107 || Current Learning Rate: 0.0001 || Time: 02:36:23.03
Epoch :: 35 || Loss: 0.41403856 || it_count: 8344 || Val Loss: 0.43026227 || Val it_count: 1107 || Current Learning Rate: 0.0001 || Time: 02:40:59.86
Epoch :: 36 || Loss: 0.41367912 || it_count: 8344 || Val Loss: 0.43012034 || Val it_count: 1107 || Current Learning Rate: 0.0001 || Time: 02:45:35.68
Epoch :: 37 || Loss: 0.41330576 || it_count: 8344 || Val Loss: 0.42991415 || Val it_count: 1107 || Current Learning Rate: 0.0001 || Time: 02:50:13.99
Epoch :: 38 || Loss: 0.41291130 || it_count: 8344 || Val Loss: 0.42978735 || Val it_count: 1107 || Current Learning Rate: 0.0001 || Time: 02:54:50.98
Epoch :: 39 || Loss: 0.41268754 || it_count: 8344 || Val Loss: 0.42876049 || Val it_count: 1107 || Current Learning Rate: 0.0001 || Time: 02:59:27.64
Epoch :: 40 || Loss: 0.41236979 || it_count: 8344 || Val Loss: 0.42906729 || Val it_count: 1107 || Current Learning Rate: 0.0001 || Time: 03:04:3.20
Epoch :: 41 || Loss: 0.41211313 || it_count: 8344 || Val Loss: 0.42930727 || Val it_count: 1107 || Current Learning Rate: 0.0001 || Time: 03:08:40.55
Epoch :: 42 || Loss: 0.41192769 || it_count: 8344 || Val Loss: 0.42944444 || Val it_count: 1107 || Current Learning Rate: 0.0001 || Time: 03:13:14.55
Epoch :: 43 || Loss: 0.41172729 || it_count: 8344 || Val Loss: 0.42951059 || Val it_count: 1107 || Current Learning Rate: 0.0001 || Time: 03:17:49.31
Epoch :: 44 || Loss: 0.41151714 || it_count: 8344 || Val Loss: 0.42985917 || Val it_count: 1107 || Current Learning Rate: 0.0001 || Time: 03:22:27.47
Epoch :: 45 || Loss: 0.41136220 || it_count: 8344 || Val Loss: 0.42979124 || Val it_count: 1107 || Current Learning Rate: 1e-05 || Time: 03:27:5.74
Epoch :: 46 || Loss: 0.41508537 || it_count: 8344 || Val Loss: 0.41698265 || Val it_count: 1107 || Current Learning Rate: 1e-05 || Time: 03:31:44.52
Epoch :: 47 || Loss: 0.41301676 || it_count: 8344 || Val Loss: 0.41625041 || Val it_count: 1107 || Current Learning Rate: 1e-05 || Time: 03:36:20.08
Epoch :: 48 || Loss: 0.41278955 || it_count: 8344 || Val Loss: 0.41597680 || Val it_count: 1107 || Current Learning Rate: 1e-05 || Time: 03:40:56.40
Epoch :: 49 || Loss: 0.41270297 || it_count: 8344 || Val Loss: 0.41596395 || Val it_count: 1107 || Current Learning Rate: 1e-05 || Time: 03:45:34.50
Epoch :: 50 || Loss: 0.41261595 || it_count: 8344 || Val Loss: 0.41590997 || Val it_count: 1107 || Current Learning Rate: 1e-05 || Time: 03:50:14.29
Epoch :: 51 || Loss: 0.41257402 || it_count: 8344 || Val Loss: 0.41586145 || Val it_count: 1107 || Current Learning Rate: 1e-05 || Time: 03:54:48.32
Epoch :: 52 || Loss: 0.41252488 || it_count: 8344 || Val Loss: 0.41590606 || Val it_count: 1107 || Current Learning Rate: 1e-05 || Time: 03:59:26.02
Epoch :: 53 || Loss: 0.41242081 || it_count: 8344 || Val Loss: 0.41589611 || Val it_count: 1107 || Current Learning Rate: 1e-05 || Time: 04:04:3.19
Epoch :: 54 || Loss: 0.41241780 || it_count: 8344 || Val Loss: 0.41590631 || Val it_count: 1107 || Current Learning Rate: 1e-05 || Time: 04:08:42.71
Epoch :: 55 || Loss: 0.41233206 || it_count: 8344 || Val Loss: 0.41596445 || Val it_count: 1107 || Current Learning Rate: 1e-05 || Time: 04:13:18.67
Epoch :: 56 || Loss: 0.41232122 || it_count: 8344 || Val Loss: 0.41598284 || Val it_count: 1107 || Current Learning Rate: 1e-05 || Time: 04:17:56.78
Epoch :: 57 || Loss: 0.41230985 || it_count: 8344 || Val Loss: 0.41596111 || Val it_count: 1107 || Current Learning Rate: 1.0000000000000002e-06 || Time: 04:22:32.88
Epoch :: 58 || Loss: 0.41270397 || it_count: 8344 || Val Loss: 0.41499395 || Val it_count: 1107 || Current Learning Rate: 1.0000000000000002e-06 || Time: 04:27:9.60
Epoch :: 59 || Loss: 0.41248934 || it_count: 8344 || Val Loss: 0.41482257 || Val it_count: 1107 || Current Learning Rate: 1.0000000000000002e-06 || Time: 04:31:49.67
Epoch :: 60 || Loss: 0.41245029 || it_count: 8344 || Val Loss: 0.41478841 || Val it_count: 1107 || Current Learning Rate: 1.0000000000000002e-06 || Time: 04:36:28.93
Epoch :: 61 || Loss: 0.41234679 || it_count: 8344 || Val Loss: 0.41477451 || Val it_count: 1107 || Current Learning Rate: 1.0000000000000002e-06 || Time: 04:41:5.69
Epoch :: 62 || Loss: 0.41236937 || it_count: 8344 || Val Loss: 0.41477446 || Val it_count: 1107 || Current Learning Rate: 1.0000000000000002e-06 || Time: 04:45:42.62
Epoch :: 63 || Loss: 0.41238623 || it_count: 8344 || Val Loss: 0.41477251 || Val it_count: 1107 || Current Learning Rate: 1.0000000000000002e-06 || Time: 04:50:20.47
Epoch :: 64 || Loss: 0.41238693 || it_count: 8344 || Val Loss: 0.41476882 || Val it_count: 1107 || Current Learning Rate: 1.0000000000000002e-06 || Time: 04:54:59.31
Epoch :: 65 || Loss: 0.41232417 || it_count: 8344 || Val Loss: 0.41476444 || Val it_count: 1107 || Current Learning Rate: 1.0000000000000002e-06 || Time: 04:59:35.88
Epoch :: 66 || Loss: 0.41236043 || it_count: 8344 || Val Loss: 0.41477574 || Val it_count: 1107 || Current Learning Rate: 1.0000000000000002e-06 || Time: 05:04:14.66
Early stopping triggered due to learning rate below threshold.
Done Total time: 05:08:53.92
best_loss: 0.4147644397849753

--------------------Testing--------------------

total_samples :: test_dataset = 139200, test_dataloader = 139200
Epoch ::  1 || Loss: 0.23808783 || it_count: 544 || Time: 00:00:14.44
MAE:  0.25580332
MSE:  0.23810908
RMSE:  0.44392392

--------------------Training--------------------
arch_str :: |none~0|+|lstm_2~0|lstm_3~1|[dropout->linear->dropout->linear]
model :: 3J
InferCell(
  info :: nodes=3, inC=1, outC=64, [1<-(I0-L0) | 2<-(I0-L1,I1-L2)], genotype_str: none~0|lstm_2~0|lstm_3~1
  linear_layers: [dropout->linear->dropout->linear]
  (layers): ModuleList(
    (0): Zero(C_in=1, C_out=64, stride=1)
    (1): LSTM(
      (lstm): LSTM(1, 64, num_layers=2, batch_first=True)
    )
    (2): LSTM(
      (lstm): LSTM(64, 64, num_layers=3, batch_first=True)
    )
  )
  (linear_layers): ModuleList(
    (0): Dropout(p=0.1, inplace=False)
    (1): Linear(in_features=3072, out_features=1536, bias=True)
    (2): Dropout(p=0.1, inplace=False)
    (3): Linear(in_features=1536, out_features=1, bias=True)
  )
)
tr_params :: epochs = 100, patience = 20, batch_size = 256, window_size = 48, data_size = 100
Model FLOPs: 12.056M, Model Params: 4.872M
learning rate scheduling :: (optimizer, mode='min', factor=0.1, patience=5, verbose=True)
total_samples :: train_dataset = 2136000, train_dataloader = 2136000
total_samples :: valid_dataset = 283200, valid_dataloader = 283200
Epoch ::  1 || Loss: 0.42573311 || it_count: 8344 || Val Loss: 0.46388893 || Val it_count: 1107 || Current Learning Rate: 0.001 || Time: 00:04:42.15
Epoch ::  2 || Loss: 0.41819578 || it_count: 8344 || Val Loss: 0.45105504 || Val it_count: 1107 || Current Learning Rate: 0.001 || Time: 00:09:22.80
Epoch ::  3 || Loss: 0.41774119 || it_count: 8344 || Val Loss: 0.44903230 || Val it_count: 1107 || Current Learning Rate: 0.001 || Time: 00:14:1.66
Epoch ::  4 || Loss: 0.41733173 || it_count: 8344 || Val Loss: 0.44723125 || Val it_count: 1107 || Current Learning Rate: 0.001 || Time: 00:18:43.95
Epoch ::  5 || Loss: 0.41711488 || it_count: 8344 || Val Loss: 0.44806452 || Val it_count: 1107 || Current Learning Rate: 0.001 || Time: 00:23:24.44
Epoch ::  6 || Loss: 0.41689516 || it_count: 8344 || Val Loss: 0.44873373 || Val it_count: 1107 || Current Learning Rate: 0.001 || Time: 00:28:1.60
Epoch ::  7 || Loss: 0.41647877 || it_count: 8344 || Val Loss: 0.44654877 || Val it_count: 1107 || Current Learning Rate: 0.001 || Time: 00:32:37.74
Epoch ::  8 || Loss: 0.41611630 || it_count: 8344 || Val Loss: 0.44760854 || Val it_count: 1107 || Current Learning Rate: 0.001 || Time: 00:37:14.46
Epoch ::  9 || Loss: 0.41590558 || it_count: 8344 || Val Loss: 0.44786435 || Val it_count: 1107 || Current Learning Rate: 0.001 || Time: 00:41:52.15
Epoch :: 10 || Loss: 0.41587261 || it_count: 8344 || Val Loss: 0.44806348 || Val it_count: 1107 || Current Learning Rate: 0.001 || Time: 00:46:30.20
Epoch :: 11 || Loss: 0.41568603 || it_count: 8344 || Val Loss: 0.44736718 || Val it_count: 1107 || Current Learning Rate: 0.001 || Time: 00:51:3.20
Epoch :: 12 || Loss: 0.41545699 || it_count: 8344 || Val Loss: 0.44840357 || Val it_count: 1107 || Current Learning Rate: 0.001 || Time: 00:55:40.31
Epoch :: 13 || Loss: 0.41535549 || it_count: 8344 || Val Loss: 0.44747117 || Val it_count: 1107 || Current Learning Rate: 0.001 || Time: 01:00:16.78
Epoch :: 14 || Loss: 0.41537437 || it_count: 8344 || Val Loss: 0.44758377 || Val it_count: 1107 || Current Learning Rate: 0.001 || Time: 01:04:54.27
Epoch :: 15 || Loss: 0.41514645 || it_count: 8344 || Val Loss: 0.44839058 || Val it_count: 1107 || Current Learning Rate: 0.001 || Time: 01:09:30.55
Epoch :: 16 || Loss: 0.41521899 || it_count: 8344 || Val Loss: 0.44785561 || Val it_count: 1107 || Current Learning Rate: 0.001 || Time: 01:14:5.12
Epoch :: 17 || Loss: 0.41519737 || it_count: 8344 || Val Loss: 0.44812550 || Val it_count: 1107 || Current Learning Rate: 0.001 || Time: 01:18:39.41
Epoch :: 18 || Loss: 0.41518183 || it_count: 8344 || Val Loss: 0.44756493 || Val it_count: 1107 || Current Learning Rate: 0.001 || Time: 01:23:13.30
Epoch :: 19 || Loss: 0.41469234 || it_count: 8344 || Val Loss: 0.44670111 || Val it_count: 1107 || Current Learning Rate: 0.001 || Time: 01:27:49.45
Epoch :: 20 || Loss: 0.41464207 || it_count: 8344 || Val Loss: 0.44676758 || Val it_count: 1107 || Current Learning Rate: 0.001 || Time: 01:32:26.40
Epoch :: 21 || Loss: 0.41479198 || it_count: 8344 || Val Loss: 0.44778454 || Val it_count: 1107 || Current Learning Rate: 0.001 || Time: 01:37:2.55
Epoch :: 22 || Loss: 0.41448134 || it_count: 8344 || Val Loss: 0.44751400 || Val it_count: 1107 || Current Learning Rate: 0.001 || Time: 01:41:37.45
Epoch :: 23 || Loss: 0.41444392 || it_count: 8344 || Val Loss: 0.44824348 || Val it_count: 1107 || Current Learning Rate: 0.001 || Time: 01:46:12.55
Epoch :: 24 || Loss: 0.41447024 || it_count: 8344 || Val Loss: 0.44801851 || Val it_count: 1107 || Current Learning Rate: 0.001 || Time: 01:50:45.85
Epoch :: 25 || Loss: 0.41434810 || it_count: 8344 || Val Loss: 0.44768619 || Val it_count: 1107 || Current Learning Rate: 0.0001 || Time: 01:55:20.34
Epoch :: 26 || Loss: 0.42132485 || it_count: 8344 || Val Loss: 0.43567781 || Val it_count: 1107 || Current Learning Rate: 0.0001 || Time: 01:59:54.12
Epoch :: 27 || Loss: 0.41871441 || it_count: 8344 || Val Loss: 0.43483562 || Val it_count: 1107 || Current Learning Rate: 0.0001 || Time: 02:04:28.37
Epoch :: 28 || Loss: 0.41806751 || it_count: 8344 || Val Loss: 0.43420635 || Val it_count: 1107 || Current Learning Rate: 0.0001 || Time: 02:09:5.07
Epoch :: 29 || Loss: 0.41765407 || it_count: 8344 || Val Loss: 0.43386736 || Val it_count: 1107 || Current Learning Rate: 0.0001 || Time: 02:13:39.65
Epoch :: 30 || Loss: 0.41736612 || it_count: 8344 || Val Loss: 0.43349074 || Val it_count: 1107 || Current Learning Rate: 0.0001 || Time: 02:18:15.21
Epoch :: 31 || Loss: 0.41714334 || it_count: 8344 || Val Loss: 0.43341360 || Val it_count: 1107 || Current Learning Rate: 0.0001 || Time: 02:22:47.10
Epoch :: 32 || Loss: 0.41700004 || it_count: 8344 || Val Loss: 0.43320701 || Val it_count: 1107 || Current Learning Rate: 0.0001 || Time: 02:27:21.65
Epoch :: 33 || Loss: 0.41664963 || it_count: 8344 || Val Loss: 0.43317644 || Val it_count: 1107 || Current Learning Rate: 0.0001 || Time: 02:31:58.80
Epoch :: 34 || Loss: 0.41646546 || it_count: 8344 || Val Loss: 0.43331088 || Val it_count: 1107 || Current Learning Rate: 0.0001 || Time: 02:36:33.56
Epoch :: 35 || Loss: 0.41635015 || it_count: 8344 || Val Loss: 0.43301546 || Val it_count: 1107 || Current Learning Rate: 0.0001 || Time: 02:41:9.02
Epoch :: 36 || Loss: 0.41609818 || it_count: 8344 || Val Loss: 0.43284947 || Val it_count: 1107 || Current Learning Rate: 0.0001 || Time: 02:45:44.71
Epoch :: 37 || Loss: 0.41590026 || it_count: 8344 || Val Loss: 0.43289377 || Val it_count: 1107 || Current Learning Rate: 0.0001 || Time: 02:50:19.06
Epoch :: 38 || Loss: 0.41582556 || it_count: 8344 || Val Loss: 0.43287715 || Val it_count: 1107 || Current Learning Rate: 0.0001 || Time: 02:54:52.99
Epoch :: 39 || Loss: 0.41562370 || it_count: 8344 || Val Loss: 0.43246586 || Val it_count: 1107 || Current Learning Rate: 0.0001 || Time: 02:59:25.84
Epoch :: 40 || Loss: 0.41544837 || it_count: 8344 || Val Loss: 0.43202888 || Val it_count: 1107 || Current Learning Rate: 0.0001 || Time: 03:03:59.74
Epoch :: 41 || Loss: 0.41522684 || it_count: 8344 || Val Loss: 0.43178270 || Val it_count: 1107 || Current Learning Rate: 0.0001 || Time: 03:08:33.52
Epoch :: 42 || Loss: 0.41495130 || it_count: 8344 || Val Loss: 0.43126950 || Val it_count: 1107 || Current Learning Rate: 0.0001 || Time: 03:13:11.69
Epoch :: 43 || Loss: 0.41463327 || it_count: 8344 || Val Loss: 0.43104350 || Val it_count: 1107 || Current Learning Rate: 0.0001 || Time: 03:17:46.88
Epoch :: 44 || Loss: 0.41433585 || it_count: 8344 || Val Loss: 0.43076087 || Val it_count: 1107 || Current Learning Rate: 0.0001 || Time: 03:22:21.57
Epoch :: 45 || Loss: 0.41412842 || it_count: 8344 || Val Loss: 0.43050082 || Val it_count: 1107 || Current Learning Rate: 0.0001 || Time: 03:26:57.66
Epoch :: 46 || Loss: 0.41391631 || it_count: 8344 || Val Loss: 0.43048074 || Val it_count: 1107 || Current Learning Rate: 0.0001 || Time: 03:31:32.79
Epoch :: 47 || Loss: 0.41377013 || it_count: 8344 || Val Loss: 0.43042991 || Val it_count: 1107 || Current Learning Rate: 0.0001 || Time: 03:36:7.33
Epoch :: 48 || Loss: 0.41366766 || it_count: 8344 || Val Loss: 0.43072798 || Val it_count: 1107 || Current Learning Rate: 0.0001 || Time: 03:40:42.07
Epoch :: 49 || Loss: 0.41343833 || it_count: 8344 || Val Loss: 0.43052809 || Val it_count: 1107 || Current Learning Rate: 0.0001 || Time: 03:45:17.17
Epoch :: 50 || Loss: 0.41331192 || it_count: 8344 || Val Loss: 0.43051289 || Val it_count: 1107 || Current Learning Rate: 0.0001 || Time: 03:49:52.04
Epoch :: 51 || Loss: 0.41318074 || it_count: 8344 || Val Loss: 0.43049396 || Val it_count: 1107 || Current Learning Rate: 0.0001 || Time: 03:54:23.24
Epoch :: 52 || Loss: 0.41307752 || it_count: 8344 || Val Loss: 0.43017939 || Val it_count: 1107 || Current Learning Rate: 0.0001 || Time: 03:58:56.26
Epoch :: 53 || Loss: 0.41298632 || it_count: 8344 || Val Loss: 0.43011959 || Val it_count: 1107 || Current Learning Rate: 0.0001 || Time: 04:03:31.60
Epoch :: 54 || Loss: 0.41283210 || it_count: 8344 || Val Loss: 0.43013014 || Val it_count: 1107 || Current Learning Rate: 0.0001 || Time: 04:08:5.71
Epoch :: 55 || Loss: 0.41271821 || it_count: 8344 || Val Loss: 0.43014018 || Val it_count: 1107 || Current Learning Rate: 0.0001 || Time: 04:12:40.96
Epoch :: 56 || Loss: 0.41260359 || it_count: 8344 || Val Loss: 0.42996772 || Val it_count: 1107 || Current Learning Rate: 0.0001 || Time: 04:17:15.26
Epoch :: 57 || Loss: 0.41240925 || it_count: 8344 || Val Loss: 0.43012644 || Val it_count: 1107 || Current Learning Rate: 0.0001 || Time: 04:21:48.15
Epoch :: 58 || Loss: 0.41231045 || it_count: 8344 || Val Loss: 0.43003900 || Val it_count: 1107 || Current Learning Rate: 0.0001 || Time: 04:26:20.99
Epoch :: 59 || Loss: 0.41227477 || it_count: 8344 || Val Loss: 0.42994104 || Val it_count: 1107 || Current Learning Rate: 0.0001 || Time: 04:30:52.40
Epoch :: 60 || Loss: 0.41224128 || it_count: 8344 || Val Loss: 0.43008661 || Val it_count: 1107 || Current Learning Rate: 0.0001 || Time: 04:35:25.39
Epoch :: 61 || Loss: 0.41204534 || it_count: 8344 || Val Loss: 0.43004144 || Val it_count: 1107 || Current Learning Rate: 0.0001 || Time: 04:39:56.67
Epoch :: 62 || Loss: 0.41194896 || it_count: 8344 || Val Loss: 0.43011332 || Val it_count: 1107 || Current Learning Rate: 1e-05 || Time: 04:44:30.19
Epoch :: 63 || Loss: 0.41586143 || it_count: 8344 || Val Loss: 0.41892568 || Val it_count: 1107 || Current Learning Rate: 1e-05 || Time: 04:49:4.03
Epoch :: 64 || Loss: 0.41357008 || it_count: 8344 || Val Loss: 0.41811499 || Val it_count: 1107 || Current Learning Rate: 1e-05 || Time: 04:53:34.63
Epoch :: 65 || Loss: 0.41320881 || it_count: 8344 || Val Loss: 0.41786641 || Val it_count: 1107 || Current Learning Rate: 1e-05 || Time: 04:58:8.38
Epoch :: 66 || Loss: 0.41309385 || it_count: 8344 || Val Loss: 0.41785953 || Val it_count: 1107 || Current Learning Rate: 1e-05 || Time: 05:02:39.91
Epoch :: 67 || Loss: 0.41302594 || it_count: 8344 || Val Loss: 0.41780002 || Val it_count: 1107 || Current Learning Rate: 1e-05 || Time: 05:07:13.75
Epoch :: 68 || Loss: 0.41299211 || it_count: 8344 || Val Loss: 0.41785190 || Val it_count: 1107 || Current Learning Rate: 1e-05 || Time: 05:11:48.38
Epoch :: 69 || Loss: 0.41289224 || it_count: 8344 || Val Loss: 0.41790235 || Val it_count: 1107 || Current Learning Rate: 1e-05 || Time: 05:16:21.54
Epoch :: 70 || Loss: 0.41284755 || it_count: 8344 || Val Loss: 0.41789749 || Val it_count: 1107 || Current Learning Rate: 1e-05 || Time: 05:20:53.31
Epoch :: 71 || Loss: 0.41280328 || it_count: 8344 || Val Loss: 0.41793219 || Val it_count: 1107 || Current Learning Rate: 1e-05 || Time: 05:25:25.56
Epoch :: 72 || Loss: 0.41270776 || it_count: 8344 || Val Loss: 0.41788488 || Val it_count: 1107 || Current Learning Rate: 1e-05 || Time: 05:29:59.45
Epoch :: 73 || Loss: 0.41276293 || it_count: 8344 || Val Loss: 0.41801382 || Val it_count: 1107 || Current Learning Rate: 1.0000000000000002e-06 || Time: 05:34:33.85
Epoch :: 74 || Loss: 0.41308355 || it_count: 8344 || Val Loss: 0.41698092 || Val it_count: 1107 || Current Learning Rate: 1.0000000000000002e-06 || Time: 05:39:8.45
Epoch :: 75 || Loss: 0.41289784 || it_count: 8344 || Val Loss: 0.41690423 || Val it_count: 1107 || Current Learning Rate: 1.0000000000000002e-06 || Time: 05:43:42.67
Epoch :: 76 || Loss: 0.41286343 || it_count: 8344 || Val Loss: 0.41689722 || Val it_count: 1107 || Current Learning Rate: 1.0000000000000002e-06 || Time: 05:48:17.45
Epoch :: 77 || Loss: 0.41282133 || it_count: 8344 || Val Loss: 0.41689009 || Val it_count: 1107 || Current Learning Rate: 1.0000000000000002e-06 || Time: 05:52:50.14
Epoch :: 78 || Loss: 0.41288560 || it_count: 8344 || Val Loss: 0.41690867 || Val it_count: 1107 || Current Learning Rate: 1.0000000000000002e-06 || Time: 05:57:22.66
Epoch :: 79 || Loss: 0.41284279 || it_count: 8344 || Val Loss: 0.41690657 || Val it_count: 1107 || Current Learning Rate: 1.0000000000000002e-06 || Time: 06:01:56.22
Epoch :: 80 || Loss: 0.41279006 || it_count: 8344 || Val Loss: 0.41690692 || Val it_count: 1107 || Current Learning Rate: 1.0000000000000002e-06 || Time: 06:06:27.53
Early stopping triggered due to learning rate below threshold.
Done Total time: 06:10:58.82
best_loss: 0.41689009253325726

--------------------Testing--------------------

total_samples :: test_dataset = 139200, test_dataloader = 139200
Epoch ::  1 || Loss: 0.23826468 || it_count: 544 || Time: 00:00:14.39
MAE:  0.25676745
MSE:  0.23828599
RMSE:  0.44384736

--------------------Training--------------------
arch_str :: |none~0|+|lstm_1~0|skip_connect~1|[dropout->linear->dropout->linear]
model :: 3J
InferCell(
  info :: nodes=3, inC=1, outC=64, [1<-(I0-L0) | 2<-(I0-L1,I1-L2)], genotype_str: none~0|lstm_1~0|skip_connect~1
  linear_layers: [dropout->linear->dropout->linear]
  (layers): ModuleList(
    (0): Zero(C_in=1, C_out=64, stride=1)
    (1): LSTM(
      (lstm): LSTM(1, 64, batch_first=True)
    )
    (2): Identity()
  )
  (linear_layers): ModuleList(
    (0): Dropout(p=0.1, inplace=False)
    (1): Linear(in_features=3072, out_features=1536, bias=True)
    (2): Dropout(p=0.1, inplace=False)
    (3): Linear(in_features=1536, out_features=1, bias=True)
  )
)
tr_params :: epochs = 100, patience = 20, batch_size = 256, window_size = 48, data_size = 100
Model FLOPs: 5.568M, Model Params: 4.739M
learning rate scheduling :: (optimizer, mode='min', factor=0.1, patience=5, verbose=True)
total_samples :: train_dataset = 2136000, train_dataloader = 2136000
total_samples :: valid_dataset = 283200, valid_dataloader = 283200
Epoch ::  1 || Loss: 0.42208330 || it_count: 8344 || Val Loss: 0.45105622 || Val it_count: 1107 || Current Learning Rate: 0.001 || Time: 00:03:54.32
Epoch ::  2 || Loss: 0.41871326 || it_count: 8344 || Val Loss: 0.45083484 || Val it_count: 1107 || Current Learning Rate: 0.001 || Time: 00:07:44.69
Epoch ::  3 || Loss: 0.41852444 || it_count: 8344 || Val Loss: 0.45113903 || Val it_count: 1107 || Current Learning Rate: 0.001 || Time: 00:11:36.69
Epoch ::  4 || Loss: 0.41842186 || it_count: 8344 || Val Loss: 0.45146428 || Val it_count: 1107 || Current Learning Rate: 0.001 || Time: 00:15:26.69
Epoch ::  5 || Loss: 0.41817454 || it_count: 8344 || Val Loss: 0.45109982 || Val it_count: 1107 || Current Learning Rate: 0.001 || Time: 00:19:13.35
Epoch ::  6 || Loss: 0.41806033 || it_count: 8344 || Val Loss: 0.45177551 || Val it_count: 1107 || Current Learning Rate: 0.001 || Time: 00:23:2.74
Epoch ::  7 || Loss: 0.41787712 || it_count: 8344 || Val Loss: 0.45159594 || Val it_count: 1107 || Current Learning Rate: 0.001 || Time: 00:26:55.83
Epoch ::  8 || Loss: 0.41769512 || it_count: 8344 || Val Loss: 0.45161112 || Val it_count: 1107 || Current Learning Rate: 0.001 || Time: 00:30:50.13
Epoch ::  9 || Loss: 0.41798774 || it_count: 8344 || Val Loss: 0.45012494 || Val it_count: 1107 || Current Learning Rate: 0.001 || Time: 00:34:41.09
Epoch :: 10 || Loss: 0.41767527 || it_count: 8344 || Val Loss: 0.45070077 || Val it_count: 1107 || Current Learning Rate: 0.001 || Time: 00:38:35.36
Epoch :: 11 || Loss: 0.41775877 || it_count: 8344 || Val Loss: 0.44992300 || Val it_count: 1107 || Current Learning Rate: 0.001 || Time: 00:42:27.53
Epoch :: 12 || Loss: 0.41767343 || it_count: 8344 || Val Loss: 0.44934809 || Val it_count: 1107 || Current Learning Rate: 0.001 || Time: 00:46:16.62
Epoch :: 13 || Loss: 0.41760445 || it_count: 8344 || Val Loss: 0.45003043 || Val it_count: 1107 || Current Learning Rate: 0.001 || Time: 00:49:54.91
Epoch :: 14 || Loss: 0.41755280 || it_count: 8344 || Val Loss: 0.44964754 || Val it_count: 1107 || Current Learning Rate: 0.001 || Time: 00:53:31.97
Epoch :: 15 || Loss: 0.41743337 || it_count: 8344 || Val Loss: 0.45010008 || Val it_count: 1107 || Current Learning Rate: 0.001 || Time: 00:57:9.43
Epoch :: 16 || Loss: 0.41763945 || it_count: 8344 || Val Loss: 0.45011929 || Val it_count: 1107 || Current Learning Rate: 0.001 || Time: 01:00:48.49
Epoch :: 17 || Loss: 0.41736581 || it_count: 8344 || Val Loss: 0.44988837 || Val it_count: 1107 || Current Learning Rate: 0.001 || Time: 01:04:25.01
Epoch :: 18 || Loss: 0.41742044 || it_count: 8344 || Val Loss: 0.45023587 || Val it_count: 1107 || Current Learning Rate: 0.001 || Time: 01:08:2.16
Epoch :: 19 || Loss: 0.41739711 || it_count: 8344 || Val Loss: 0.44972500 || Val it_count: 1107 || Current Learning Rate: 0.001 || Time: 01:11:40.15
Epoch :: 20 || Loss: 0.41740345 || it_count: 8344 || Val Loss: 0.45025125 || Val it_count: 1107 || Current Learning Rate: 0.001 || Time: 01:15:17.46
Epoch :: 21 || Loss: 0.41734261 || it_count: 8344 || Val Loss: 0.45023988 || Val it_count: 1107 || Current Learning Rate: 0.001 || Time: 01:18:54.06
Epoch :: 22 || Loss: 0.41732715 || it_count: 8344 || Val Loss: 0.44942955 || Val it_count: 1107 || Current Learning Rate: 0.001 || Time: 01:22:30.12
Epoch :: 23 || Loss: 0.41727900 || it_count: 8344 || Val Loss: 0.45032969 || Val it_count: 1107 || Current Learning Rate: 0.001 || Time: 01:26:7.42
Epoch :: 24 || Loss: 0.41730841 || it_count: 8344 || Val Loss: 0.45006992 || Val it_count: 1107 || Current Learning Rate: 0.001 || Time: 01:29:44.48
Epoch :: 25 || Loss: 0.41725843 || it_count: 8344 || Val Loss: 0.44914380 || Val it_count: 1107 || Current Learning Rate: 0.001 || Time: 01:33:21.48
Epoch :: 26 || Loss: 0.41718032 || it_count: 8344 || Val Loss: 0.44999574 || Val it_count: 1107 || Current Learning Rate: 0.001 || Time: 01:36:59.18
Epoch :: 27 || Loss: 0.41713999 || it_count: 8344 || Val Loss: 0.44949666 || Val it_count: 1107 || Current Learning Rate: 0.001 || Time: 01:40:36.27
Epoch :: 28 || Loss: 0.41720942 || it_count: 8344 || Val Loss: 0.44941372 || Val it_count: 1107 || Current Learning Rate: 0.001 || Time: 01:44:13.05
Epoch :: 29 || Loss: 0.41712235 || it_count: 8344 || Val Loss: 0.44949560 || Val it_count: 1107 || Current Learning Rate: 0.001 || Time: 01:47:50.09
Epoch :: 30 || Loss: 0.41709385 || it_count: 8344 || Val Loss: 0.44994494 || Val it_count: 1107 || Current Learning Rate: 0.001 || Time: 01:51:26.85
Epoch :: 31 || Loss: 0.41718576 || it_count: 8344 || Val Loss: 0.44903256 || Val it_count: 1107 || Current Learning Rate: 0.001 || Time: 01:55:5.12
Epoch :: 32 || Loss: 0.41698874 || it_count: 8344 || Val Loss: 0.44860521 || Val it_count: 1107 || Current Learning Rate: 0.001 || Time: 01:58:42.55
Epoch :: 33 || Loss: 0.41672525 || it_count: 8344 || Val Loss: 0.44918843 || Val it_count: 1107 || Current Learning Rate: 0.001 || Time: 02:02:21.55
Epoch :: 34 || Loss: 0.41679058 || it_count: 8344 || Val Loss: 0.44829654 || Val it_count: 1107 || Current Learning Rate: 0.001 || Time: 02:05:59.59
Epoch :: 35 || Loss: 0.41686804 || it_count: 8344 || Val Loss: 0.44867940 || Val it_count: 1107 || Current Learning Rate: 0.001 || Time: 02:09:37.97
Epoch :: 36 || Loss: 0.41690265 || it_count: 8344 || Val Loss: 0.44876451 || Val it_count: 1107 || Current Learning Rate: 0.001 || Time: 02:13:16.50
Epoch :: 37 || Loss: 0.41684247 || it_count: 8344 || Val Loss: 0.44874709 || Val it_count: 1107 || Current Learning Rate: 0.001 || Time: 02:16:54.82
Epoch :: 38 || Loss: 0.41673073 || it_count: 8344 || Val Loss: 0.44873432 || Val it_count: 1107 || Current Learning Rate: 0.001 || Time: 02:20:32.23
Epoch :: 39 || Loss: 0.41657460 || it_count: 8344 || Val Loss: 0.44818780 || Val it_count: 1107 || Current Learning Rate: 0.001 || Time: 02:24:8.65
Epoch :: 40 || Loss: 0.41638382 || it_count: 8344 || Val Loss: 0.44796557 || Val it_count: 1107 || Current Learning Rate: 0.001 || Time: 02:27:47.71
Epoch :: 41 || Loss: 0.41657698 || it_count: 8344 || Val Loss: 0.44793880 || Val it_count: 1107 || Current Learning Rate: 0.001 || Time: 02:31:25.64
Epoch :: 42 || Loss: 0.41646601 || it_count: 8344 || Val Loss: 0.44922010 || Val it_count: 1107 || Current Learning Rate: 0.001 || Time: 02:35:4.53
Epoch :: 43 || Loss: 0.41662877 || it_count: 8344 || Val Loss: 0.44864328 || Val it_count: 1107 || Current Learning Rate: 0.001 || Time: 02:38:43.93
Epoch :: 44 || Loss: 0.41652152 || it_count: 8344 || Val Loss: 0.44842130 || Val it_count: 1107 || Current Learning Rate: 0.001 || Time: 02:42:19.45
Epoch :: 45 || Loss: 0.41662525 || it_count: 8344 || Val Loss: 0.44842287 || Val it_count: 1107 || Current Learning Rate: 0.001 || Time: 02:46:0.02
Epoch :: 46 || Loss: 0.41662984 || it_count: 8344 || Val Loss: 0.44847540 || Val it_count: 1107 || Current Learning Rate: 0.0001 || Time: 02:49:36.93
Epoch :: 47 || Loss: 0.42338492 || it_count: 8344 || Val Loss: 0.43890855 || Val it_count: 1107 || Current Learning Rate: 0.0001 || Time: 02:53:11.25
Epoch :: 48 || Loss: 0.42103318 || it_count: 8344 || Val Loss: 0.43737335 || Val it_count: 1107 || Current Learning Rate: 0.0001 || Time: 02:56:49.26
Epoch :: 49 || Loss: 0.42055141 || it_count: 8344 || Val Loss: 0.43653204 || Val it_count: 1107 || Current Learning Rate: 0.0001 || Time: 03:00:27.90
Epoch :: 50 || Loss: 0.42027374 || it_count: 8344 || Val Loss: 0.43559786 || Val it_count: 1107 || Current Learning Rate: 0.0001 || Time: 03:04:5.15
Epoch :: 51 || Loss: 0.41995813 || it_count: 8344 || Val Loss: 0.43524040 || Val it_count: 1107 || Current Learning Rate: 0.0001 || Time: 03:07:41.97
Epoch :: 52 || Loss: 0.41992193 || it_count: 8344 || Val Loss: 0.43507759 || Val it_count: 1107 || Current Learning Rate: 0.0001 || Time: 03:11:20.22
Epoch :: 53 || Loss: 0.41973779 || it_count: 8344 || Val Loss: 0.43485266 || Val it_count: 1107 || Current Learning Rate: 0.0001 || Time: 03:14:59.13
Epoch :: 54 || Loss: 0.41962992 || it_count: 8344 || Val Loss: 0.43501738 || Val it_count: 1107 || Current Learning Rate: 0.0001 || Time: 03:18:36.76
Epoch :: 55 || Loss: 0.41948772 || it_count: 8344 || Val Loss: 0.43491153 || Val it_count: 1107 || Current Learning Rate: 0.0001 || Time: 03:22:14.17
Epoch :: 56 || Loss: 0.41929967 || it_count: 8344 || Val Loss: 0.43490799 || Val it_count: 1107 || Current Learning Rate: 0.0001 || Time: 03:25:50.79
Epoch :: 57 || Loss: 0.41919619 || it_count: 8344 || Val Loss: 0.43484536 || Val it_count: 1107 || Current Learning Rate: 0.0001 || Time: 03:29:27.70
Epoch :: 58 || Loss: 0.41899097 || it_count: 8344 || Val Loss: 0.43447801 || Val it_count: 1107 || Current Learning Rate: 0.0001 || Time: 03:33:6.77
Epoch :: 59 || Loss: 0.41903720 || it_count: 8344 || Val Loss: 0.43455247 || Val it_count: 1107 || Current Learning Rate: 0.0001 || Time: 03:36:45.28
Epoch :: 60 || Loss: 0.41891058 || it_count: 8344 || Val Loss: 0.43436191 || Val it_count: 1107 || Current Learning Rate: 0.0001 || Time: 03:40:21.62
Epoch :: 61 || Loss: 0.41877088 || it_count: 8344 || Val Loss: 0.43422540 || Val it_count: 1107 || Current Learning Rate: 0.0001 || Time: 03:44:0.80
Epoch :: 62 || Loss: 0.41871488 || it_count: 8344 || Val Loss: 0.43423313 || Val it_count: 1107 || Current Learning Rate: 0.0001 || Time: 03:47:38.92
Epoch :: 63 || Loss: 0.41863055 || it_count: 8344 || Val Loss: 0.43410873 || Val it_count: 1107 || Current Learning Rate: 0.0001 || Time: 03:51:15.69
Epoch :: 64 || Loss: 0.41851519 || it_count: 8344 || Val Loss: 0.43409201 || Val it_count: 1107 || Current Learning Rate: 0.0001 || Time: 03:54:52.61
Epoch :: 65 || Loss: 0.41849030 || it_count: 8344 || Val Loss: 0.43403064 || Val it_count: 1107 || Current Learning Rate: 0.0001 || Time: 03:58:31.68
Epoch :: 66 || Loss: 0.41838056 || it_count: 8344 || Val Loss: 0.43389650 || Val it_count: 1107 || Current Learning Rate: 0.0001 || Time: 04:02:9.81
Epoch :: 67 || Loss: 0.41827466 || it_count: 8344 || Val Loss: 0.43382133 || Val it_count: 1107 || Current Learning Rate: 0.0001 || Time: 04:05:47.86
Epoch :: 68 || Loss: 0.41820444 || it_count: 8344 || Val Loss: 0.43396893 || Val it_count: 1107 || Current Learning Rate: 0.0001 || Time: 04:09:27.49
Epoch :: 69 || Loss: 0.41812926 || it_count: 8344 || Val Loss: 0.43380632 || Val it_count: 1107 || Current Learning Rate: 0.0001 || Time: 04:13:3.09
Epoch :: 70 || Loss: 0.41813002 || it_count: 8344 || Val Loss: 0.43385879 || Val it_count: 1107 || Current Learning Rate: 0.0001 || Time: 04:16:50.31
Epoch :: 71 || Loss: 0.41805840 || it_count: 8344 || Val Loss: 0.43407289 || Val it_count: 1107 || Current Learning Rate: 0.0001 || Time: 04:20:48.38
Epoch :: 72 || Loss: 0.41789874 || it_count: 8344 || Val Loss: 0.43368887 || Val it_count: 1107 || Current Learning Rate: 0.0001 || Time: 04:24:42.71
Epoch :: 73 || Loss: 0.41788395 || it_count: 8344 || Val Loss: 0.43364586 || Val it_count: 1107 || Current Learning Rate: 0.0001 || Time: 04:28:42.84
Epoch :: 74 || Loss: 0.41785258 || it_count: 8344 || Val Loss: 0.43356708 || Val it_count: 1107 || Current Learning Rate: 0.0001 || Time: 04:32:42.08
Epoch :: 75 || Loss: 0.41776007 || it_count: 8344 || Val Loss: 0.43371672 || Val it_count: 1107 || Current Learning Rate: 0.0001 || Time: 04:36:39.28
Epoch :: 76 || Loss: 0.41771671 || it_count: 8344 || Val Loss: 0.43335451 || Val it_count: 1107 || Current Learning Rate: 0.0001 || Time: 04:40:37.85
Epoch :: 77 || Loss: 0.41758995 || it_count: 8344 || Val Loss: 0.43330927 || Val it_count: 1107 || Current Learning Rate: 0.0001 || Time: 04:44:36.11
Epoch :: 78 || Loss: 0.41758598 || it_count: 8344 || Val Loss: 0.43313007 || Val it_count: 1107 || Current Learning Rate: 0.0001 || Time: 04:48:37.15
Epoch :: 79 || Loss: 0.41744625 || it_count: 8344 || Val Loss: 0.43328126 || Val it_count: 1107 || Current Learning Rate: 0.0001 || Time: 04:52:36.52
Epoch :: 80 || Loss: 0.41746214 || it_count: 8344 || Val Loss: 0.43320893 || Val it_count: 1107 || Current Learning Rate: 0.0001 || Time: 04:56:31.62
Epoch :: 81 || Loss: 0.41742860 || it_count: 8344 || Val Loss: 0.43331233 || Val it_count: 1107 || Current Learning Rate: 0.0001 || Time: 05:00:25.20
Epoch :: 82 || Loss: 0.41739809 || it_count: 8344 || Val Loss: 0.43325266 || Val it_count: 1107 || Current Learning Rate: 0.0001 || Time: 05:04:23.67
Epoch :: 83 || Loss: 0.41735281 || it_count: 8344 || Val Loss: 0.43347674 || Val it_count: 1107 || Current Learning Rate: 0.0001 || Time: 05:08:23.21
Epoch :: 84 || Loss: 0.41728614 || it_count: 8344 || Val Loss: 0.43326271 || Val it_count: 1107 || Current Learning Rate: 1e-05 || Time: 05:12:21.20
Epoch :: 85 || Loss: 0.42114892 || it_count: 8344 || Val Loss: 0.42291099 || Val it_count: 1107 || Current Learning Rate: 1e-05 || Time: 05:16:18.13
Epoch :: 86 || Loss: 0.41897851 || it_count: 8344 || Val Loss: 0.42230389 || Val it_count: 1107 || Current Learning Rate: 1e-05 || Time: 05:20:18.69
Epoch :: 87 || Loss: 0.41869117 || it_count: 8344 || Val Loss: 0.42207362 || Val it_count: 1107 || Current Learning Rate: 1e-05 || Time: 05:24:19.09
Epoch :: 88 || Loss: 0.41852371 || it_count: 8344 || Val Loss: 0.42196846 || Val it_count: 1107 || Current Learning Rate: 1e-05 || Time: 05:28:17.37
Epoch :: 89 || Loss: 0.41847302 || it_count: 8344 || Val Loss: 0.42191883 || Val it_count: 1107 || Current Learning Rate: 1e-05 || Time: 05:32:9.46
Epoch :: 90 || Loss: 0.41834208 || it_count: 8344 || Val Loss: 0.42183622 || Val it_count: 1107 || Current Learning Rate: 1e-05 || Time: 05:36:8.03
Epoch :: 91 || Loss: 0.41832688 || it_count: 8344 || Val Loss: 0.42182141 || Val it_count: 1107 || Current Learning Rate: 1e-05 || Time: 05:40:8.35
Epoch :: 92 || Loss: 0.41825295 || it_count: 8344 || Val Loss: 0.42181816 || Val it_count: 1107 || Current Learning Rate: 1e-05 || Time: 05:44:8.57
Epoch :: 93 || Loss: 0.41827195 || it_count: 8344 || Val Loss: 0.42179875 || Val it_count: 1107 || Current Learning Rate: 1e-05 || Time: 05:48:7.36
Epoch :: 94 || Loss: 0.41819000 || it_count: 8344 || Val Loss: 0.42177701 || Val it_count: 1107 || Current Learning Rate: 1e-05 || Time: 05:52:6.41
Epoch :: 95 || Loss: 0.41816776 || it_count: 8344 || Val Loss: 0.42175776 || Val it_count: 1107 || Current Learning Rate: 1e-05 || Time: 05:56:9.12
Epoch :: 96 || Loss: 0.41814090 || it_count: 8344 || Val Loss: 0.42175790 || Val it_count: 1107 || Current Learning Rate: 1e-05 || Time: 06:00:11.48
Epoch :: 97 || Loss: 0.41815673 || it_count: 8344 || Val Loss: 0.42178972 || Val it_count: 1107 || Current Learning Rate: 1e-05 || Time: 06:04:9.01
Epoch :: 98 || Loss: 0.41814508 || it_count: 8344 || Val Loss: 0.42176417 || Val it_count: 1107 || Current Learning Rate: 1e-05 || Time: 06:08:9.08
Epoch :: 99 || Loss: 0.41807640 || it_count: 8344 || Val Loss: 0.42180353 || Val it_count: 1107 || Current Learning Rate: 1e-05 || Time: 06:12:10.73
Epoch :: 100 || Loss: 0.41806904 || it_count: 8344 || Val Loss: 0.42179337 || Val it_count: 1107 || Current Learning Rate: 1.0000000000000002e-06 || Time: 06:16:10.89
Done Total time: 06:16:10.89
best_loss: 0.4217577560966811

--------------------Testing--------------------

total_samples :: test_dataset = 139200, test_dataloader = 139200
Epoch ::  1 || Loss: 0.25006544 || it_count: 544 || Time: 00:00:13.99
MAE:  0.2618149
MSE:  0.25009185
RMSE:  0.45197877

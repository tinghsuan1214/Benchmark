--------------------Training--------------------
arch_str :: |none~0|+|lstm_1~0|lstm_3~1|[relu->linear->dropout->linear]
model :: 3N
InferCell(
  info :: nodes=3, inC=1, outC=64, [1<-(I0-L0) | 2<-(I0-L1,I1-L2)], genotype_str: none~0|lstm_1~0|lstm_3~1
  linear_layers: [relu->linear->dropout->linear]
  (layers): ModuleList(
    (0): Zero(C_in=1, C_out=64, stride=1)
    (1): LSTM(
      (lstm): LSTM(1, 64, batch_first=True)
    )
    (2): LSTM(
      (lstm): LSTM(64, 64, num_layers=3, batch_first=True)
    )
  )
  (linear_layers): ModuleList(
    (0): ReLU()
    (1): Linear(in_features=3072, out_features=1536, bias=True)
    (2): Dropout(p=0.1, inplace=False)
    (3): Linear(in_features=1536, out_features=1, bias=True)
  )
)
tr_params :: epochs = 100, patience = 20, batch_size = 256, window_size = 48, data_size = 100
Model FLOPs: 10.434M, Model Params: 4.839M
learning rate scheduling :: (optimizer, mode='min', factor=0.1, patience=5, verbose=True)
total_samples :: train_dataset = 2136000, train_dataloader = 2136000
total_samples :: valid_dataset = 283200, valid_dataloader = 283200
Epoch ::  1 || Loss: 0.42096600 || it_count: 8344 || Val Loss: 0.45980768 || Val it_count: 1107 || Current Learning Rate: 0.001 || Time: 00:08:47.79
Epoch ::  2 || Loss: 0.41841712 || it_count: 8344 || Val Loss: 0.45333928 || Val it_count: 1107 || Current Learning Rate: 0.001 || Time: 00:17:36.29
Epoch ::  3 || Loss: 0.41716653 || it_count: 8344 || Val Loss: 0.45194528 || Val it_count: 1107 || Current Learning Rate: 0.001 || Time: 00:26:26.72
Epoch ::  4 || Loss: 0.41968169 || it_count: 8344 || Val Loss: 0.45025050 || Val it_count: 1107 || Current Learning Rate: 0.001 || Time: 00:35:16.30
Epoch ::  5 || Loss: 0.41656343 || it_count: 8344 || Val Loss: 0.44818297 || Val it_count: 1107 || Current Learning Rate: 0.001 || Time: 00:44:6.39
Epoch ::  6 || Loss: 0.41619084 || it_count: 8344 || Val Loss: 0.44790531 || Val it_count: 1107 || Current Learning Rate: 0.001 || Time: 00:52:55.30
Epoch ::  7 || Loss: 0.41577958 || it_count: 8344 || Val Loss: 0.44807785 || Val it_count: 1107 || Current Learning Rate: 0.001 || Time: 01:01:45.01
Epoch ::  8 || Loss: 0.41524129 || it_count: 8344 || Val Loss: 0.44599202 || Val it_count: 1107 || Current Learning Rate: 0.001 || Time: 01:10:35.98
Epoch ::  9 || Loss: 0.41516030 || it_count: 8344 || Val Loss: 0.44466917 || Val it_count: 1107 || Current Learning Rate: 0.001 || Time: 01:19:30.02
Epoch :: 10 || Loss: 0.41484451 || it_count: 8344 || Val Loss: 0.44415190 || Val it_count: 1107 || Current Learning Rate: 0.001 || Time: 01:28:24.10
Epoch :: 11 || Loss: 0.41442782 || it_count: 8344 || Val Loss: 0.44506480 || Val it_count: 1107 || Current Learning Rate: 0.001 || Time: 01:37:18.31
Epoch :: 12 || Loss: 0.41415474 || it_count: 8344 || Val Loss: 0.44493490 || Val it_count: 1107 || Current Learning Rate: 0.001 || Time: 01:46:12.69
Epoch :: 13 || Loss: 0.41405112 || it_count: 8344 || Val Loss: 0.44431431 || Val it_count: 1107 || Current Learning Rate: 0.001 || Time: 01:55:8.01
Epoch :: 14 || Loss: 0.41392698 || it_count: 8344 || Val Loss: 0.44529607 || Val it_count: 1107 || Current Learning Rate: 0.001 || Time: 02:04:2.84
Epoch :: 15 || Loss: 0.41357243 || it_count: 8344 || Val Loss: 0.44519492 || Val it_count: 1107 || Current Learning Rate: 0.001 || Time: 02:12:58.61
Epoch :: 16 || Loss: 0.41371909 || it_count: 8344 || Val Loss: 0.44518439 || Val it_count: 1107 || Current Learning Rate: 0.001 || Time: 02:21:55.19
Epoch :: 17 || Loss: 0.41347761 || it_count: 8344 || Val Loss: 0.44488157 || Val it_count: 1107 || Current Learning Rate: 0.001 || Time: 02:30:51.32
Epoch :: 18 || Loss: 0.41340005 || it_count: 8344 || Val Loss: 0.44467607 || Val it_count: 1107 || Current Learning Rate: 0.001 || Time: 02:39:46.87
Epoch :: 19 || Loss: 0.41351623 || it_count: 8344 || Val Loss: 0.44576337 || Val it_count: 1107 || Current Learning Rate: 0.001 || Time: 02:48:42.12
Epoch :: 20 || Loss: 0.41342074 || it_count: 8344 || Val Loss: 0.44492216 || Val it_count: 1107 || Current Learning Rate: 0.001 || Time: 02:57:37.70
Epoch :: 21 || Loss: 0.41316321 || it_count: 8344 || Val Loss: 0.44566446 || Val it_count: 1107 || Current Learning Rate: 0.001 || Time: 03:06:33.40
Epoch :: 22 || Loss: 0.41311839 || it_count: 8344 || Val Loss: 0.44527816 || Val it_count: 1107 || Current Learning Rate: 0.001 || Time: 03:15:29.54
Epoch :: 23 || Loss: 0.41281130 || it_count: 8344 || Val Loss: 0.44469483 || Val it_count: 1107 || Current Learning Rate: 0.001 || Time: 03:24:25.20
Epoch 00008: reducing learning rate of group 0 to 1.0000e-04.
Epoch :: 24 || Loss: 0.41284317 || it_count: 8344 || Val Loss: 0.44493705 || Val it_count: 1107 || Current Learning Rate: 0.0001 || Time: 03:33:21.09
Epoch :: 25 || Loss: 0.42018620 || it_count: 8344 || Val Loss: 0.43293126 || Val it_count: 1107 || Current Learning Rate: 0.0001 || Time: 03:42:16.43
Epoch :: 26 || Loss: 0.41687178 || it_count: 8344 || Val Loss: 0.43175464 || Val it_count: 1107 || Current Learning Rate: 0.0001 || Time: 03:51:12.57
Epoch :: 27 || Loss: 0.41611206 || it_count: 8344 || Val Loss: 0.43088542 || Val it_count: 1107 || Current Learning Rate: 0.0001 || Time: 04:00:9.72
Epoch :: 28 || Loss: 0.41560859 || it_count: 8344 || Val Loss: 0.42994628 || Val it_count: 1107 || Current Learning Rate: 0.0001 || Time: 04:09:7.14
Epoch :: 29 || Loss: 0.41511364 || it_count: 8344 || Val Loss: 0.42946910 || Val it_count: 1107 || Current Learning Rate: 0.0001 || Time: 04:18:3.71
Epoch :: 30 || Loss: 0.41472739 || it_count: 8344 || Val Loss: 0.42908348 || Val it_count: 1107 || Current Learning Rate: 0.0001 || Time: 04:26:59.73
Epoch :: 31 || Loss: 0.41430403 || it_count: 8344 || Val Loss: 0.42872831 || Val it_count: 1107 || Current Learning Rate: 0.0001 || Time: 04:35:55.80
Epoch :: 32 || Loss: 0.41397494 || it_count: 8344 || Val Loss: 0.42851384 || Val it_count: 1107 || Current Learning Rate: 0.0001 || Time: 04:44:52.62
Epoch :: 33 || Loss: 0.41366996 || it_count: 8344 || Val Loss: 0.42823972 || Val it_count: 1107 || Current Learning Rate: 0.0001 || Time: 04:53:50.17
Epoch :: 34 || Loss: 0.41337696 || it_count: 8344 || Val Loss: 0.42796858 || Val it_count: 1107 || Current Learning Rate: 0.0001 || Time: 05:02:45.88
Epoch :: 35 || Loss: 0.41308133 || it_count: 8344 || Val Loss: 0.42767418 || Val it_count: 1107 || Current Learning Rate: 0.0001 || Time: 05:11:43.37
Epoch :: 36 || Loss: 0.41282212 || it_count: 8344 || Val Loss: 0.42741919 || Val it_count: 1107 || Current Learning Rate: 0.0001 || Time: 05:20:39.89
Epoch :: 37 || Loss: 0.41259014 || it_count: 8344 || Val Loss: 0.42715161 || Val it_count: 1107 || Current Learning Rate: 0.0001 || Time: 05:29:36.67
Epoch :: 38 || Loss: 0.41242591 || it_count: 8344 || Val Loss: 0.42680524 || Val it_count: 1107 || Current Learning Rate: 0.0001 || Time: 05:38:33.69
Epoch :: 39 || Loss: 0.41228191 || it_count: 8344 || Val Loss: 0.42679063 || Val it_count: 1107 || Current Learning Rate: 0.0001 || Time: 05:47:30.59
Epoch :: 40 || Loss: 0.41217668 || it_count: 8344 || Val Loss: 0.42652284 || Val it_count: 1107 || Current Learning Rate: 0.0001 || Time: 05:56:27.77
Epoch :: 41 || Loss: 0.41194087 || it_count: 8344 || Val Loss: 0.42651940 || Val it_count: 1107 || Current Learning Rate: 0.0001 || Time: 06:05:25.07
Epoch :: 42 || Loss: 0.41180767 || it_count: 8344 || Val Loss: 0.42630855 || Val it_count: 1107 || Current Learning Rate: 0.0001 || Time: 06:14:22.21
Epoch :: 43 || Loss: 0.41171905 || it_count: 8344 || Val Loss: 0.42629913 || Val it_count: 1107 || Current Learning Rate: 0.0001 || Time: 06:23:19.37
Epoch :: 44 || Loss: 0.41158618 || it_count: 8344 || Val Loss: 0.42617462 || Val it_count: 1107 || Current Learning Rate: 0.0001 || Time: 06:32:16.75
Epoch :: 45 || Loss: 0.41144534 || it_count: 8344 || Val Loss: 0.42615213 || Val it_count: 1107 || Current Learning Rate: 0.0001 || Time: 06:41:14.60
Epoch :: 46 || Loss: 0.41136585 || it_count: 8344 || Val Loss: 0.42610008 || Val it_count: 1107 || Current Learning Rate: 0.0001 || Time: 06:50:10.97
Epoch :: 47 || Loss: 0.41125862 || it_count: 8344 || Val Loss: 0.42603413 || Val it_count: 1107 || Current Learning Rate: 0.0001 || Time: 06:59:8.52
Epoch :: 48 || Loss: 0.41119260 || it_count: 8344 || Val Loss: 0.42601574 || Val it_count: 1107 || Current Learning Rate: 0.0001 || Time: 07:08:5.33
Epoch :: 49 || Loss: 0.41104530 || it_count: 8344 || Val Loss: 0.42616519 || Val it_count: 1107 || Current Learning Rate: 0.0001 || Time: 07:17:3.21
Epoch :: 50 || Loss: 0.41094788 || it_count: 8344 || Val Loss: 0.42624703 || Val it_count: 1107 || Current Learning Rate: 0.0001 || Time: 07:25:58.95
Epoch :: 51 || Loss: 0.41087558 || it_count: 8344 || Val Loss: 0.42622229 || Val it_count: 1107 || Current Learning Rate: 0.0001 || Time: 07:34:55.07
Epoch :: 52 || Loss: 0.41074674 || it_count: 8344 || Val Loss: 0.42625080 || Val it_count: 1107 || Current Learning Rate: 0.0001 || Time: 07:43:53.86
Epoch 00037: reducing learning rate of group 0 to 1.0000e-05.
Epoch :: 53 || Loss: 0.41066486 || it_count: 8344 || Val Loss: 0.42645149 || Val it_count: 1107 || Current Learning Rate: 1e-05 || Time: 07:52:51.06
Epoch :: 54 || Loss: 0.41411477 || it_count: 8344 || Val Loss: 0.41627678 || Val it_count: 1107 || Current Learning Rate: 1e-05 || Time: 08:01:48.41
Epoch :: 55 || Loss: 0.41223199 || it_count: 8344 || Val Loss: 0.41567779 || Val it_count: 1107 || Current Learning Rate: 1e-05 || Time: 08:10:46.88
Epoch :: 56 || Loss: 0.41193610 || it_count: 8344 || Val Loss: 0.41560563 || Val it_count: 1107 || Current Learning Rate: 1e-05 || Time: 08:19:43.68
Epoch :: 57 || Loss: 0.41181490 || it_count: 8344 || Val Loss: 0.41538684 || Val it_count: 1107 || Current Learning Rate: 1e-05 || Time: 08:28:41.81
Epoch :: 58 || Loss: 0.41166443 || it_count: 8344 || Val Loss: 0.41536969 || Val it_count: 1107 || Current Learning Rate: 1e-05 || Time: 08:37:39.51
Epoch :: 59 || Loss: 0.41163294 || it_count: 8344 || Val Loss: 0.41530300 || Val it_count: 1107 || Current Learning Rate: 1e-05 || Time: 08:46:36.50
Epoch :: 60 || Loss: 0.41161170 || it_count: 8344 || Val Loss: 0.41529305 || Val it_count: 1107 || Current Learning Rate: 1e-05 || Time: 08:55:34.23
Epoch :: 61 || Loss: 0.41155508 || it_count: 8344 || Val Loss: 0.41530703 || Val it_count: 1107 || Current Learning Rate: 1e-05 || Time: 09:04:32.32
Epoch :: 62 || Loss: 0.41148581 || it_count: 8344 || Val Loss: 0.41528974 || Val it_count: 1107 || Current Learning Rate: 1e-05 || Time: 09:13:28.52
Epoch :: 63 || Loss: 0.41149434 || it_count: 8344 || Val Loss: 0.41529995 || Val it_count: 1107 || Current Learning Rate: 1e-05 || Time: 09:22:26.23
Epoch :: 64 || Loss: 0.41143624 || it_count: 8344 || Val Loss: 0.41525909 || Val it_count: 1107 || Current Learning Rate: 1e-05 || Time: 09:31:22.98
Epoch :: 65 || Loss: 0.41142695 || it_count: 8344 || Val Loss: 0.41527938 || Val it_count: 1107 || Current Learning Rate: 1e-05 || Time: 09:40:20.66
Epoch :: 66 || Loss: 0.41136529 || it_count: 8344 || Val Loss: 0.41526734 || Val it_count: 1107 || Current Learning Rate: 1e-05 || Time: 09:49:16.96
Epoch :: 67 || Loss: 0.41130960 || it_count: 8344 || Val Loss: 0.41526375 || Val it_count: 1107 || Current Learning Rate: 1e-05 || Time: 09:58:14.48
Epoch :: 68 || Loss: 0.41128920 || it_count: 8344 || Val Loss: 0.41526780 || Val it_count: 1107 || Current Learning Rate: 1e-05 || Time: 10:07:12.07
Epoch :: 69 || Loss: 0.41130605 || it_count: 8344 || Val Loss: 0.41524070 || Val it_count: 1107 || Current Learning Rate: 1e-05 || Time: 10:16:9.86
Epoch 00054: reducing learning rate of group 0 to 1.0000e-06.
Epoch :: 70 || Loss: 0.41124577 || it_count: 8344 || Val Loss: 0.41526659 || Val it_count: 1107 || Current Learning Rate: 1.0000000000000002e-06 || Time: 10:25:6.79
Epoch :: 71 || Loss: 0.41163117 || it_count: 8344 || Val Loss: 0.41441202 || Val it_count: 1107 || Current Learning Rate: 1.0000000000000002e-06 || Time: 10:34:3.14
Epoch :: 72 || Loss: 0.41144986 || it_count: 8344 || Val Loss: 0.41429810 || Val it_count: 1107 || Current Learning Rate: 1.0000000000000002e-06 || Time: 10:43:1.04
Epoch :: 73 || Loss: 0.41140059 || it_count: 8344 || Val Loss: 0.41424675 || Val it_count: 1107 || Current Learning Rate: 1.0000000000000002e-06 || Time: 10:51:57.91
Epoch :: 74 || Loss: 0.41137958 || it_count: 8344 || Val Loss: 0.41421110 || Val it_count: 1107 || Current Learning Rate: 1.0000000000000002e-06 || Time: 11:00:55.17
Epoch :: 75 || Loss: 0.41137609 || it_count: 8344 || Val Loss: 0.41419451 || Val it_count: 1107 || Current Learning Rate: 1.0000000000000002e-06 || Time: 11:09:52.58
Epoch :: 76 || Loss: 0.41135652 || it_count: 8344 || Val Loss: 0.41418670 || Val it_count: 1107 || Current Learning Rate: 1.0000000000000002e-06 || Time: 11:18:49.92
Epoch :: 77 || Loss: 0.41135184 || it_count: 8344 || Val Loss: 0.41417448 || Val it_count: 1107 || Current Learning Rate: 1.0000000000000002e-06 || Time: 11:27:47.94
Epoch :: 78 || Loss: 0.41134601 || it_count: 8344 || Val Loss: 0.41416336 || Val it_count: 1107 || Current Learning Rate: 1.0000000000000002e-06 || Time: 11:36:44.73
Epoch :: 79 || Loss: 0.41134191 || it_count: 8344 || Val Loss: 0.41415319 || Val it_count: 1107 || Current Learning Rate: 1.0000000000000002e-06 || Time: 11:45:42.26
Epoch :: 80 || Loss: 0.41133581 || it_count: 8344 || Val Loss: 0.41414580 || Val it_count: 1107 || Current Learning Rate: 1.0000000000000002e-06 || Time: 11:54:39.87
Epoch :: 81 || Loss: 0.41134418 || it_count: 8344 || Val Loss: 0.41413664 || Val it_count: 1107 || Current Learning Rate: 1.0000000000000002e-06 || Time: 12:03:38.06
Epoch :: 82 || Loss: 0.41131315 || it_count: 8344 || Val Loss: 0.41413196 || Val it_count: 1107 || Current Learning Rate: 1.0000000000000002e-06 || Time: 12:12:37.13
Epoch :: 83 || Loss: 0.41131464 || it_count: 8344 || Val Loss: 0.41413225 || Val it_count: 1107 || Current Learning Rate: 1.0000000000000002e-06 || Time: 12:21:37.08
Epoch :: 84 || Loss: 0.41134412 || it_count: 8344 || Val Loss: 0.41412512 || Val it_count: 1107 || Current Learning Rate: 1.0000000000000002e-06 || Time: 12:30:36.53
Epoch :: 85 || Loss: 0.41130777 || it_count: 8344 || Val Loss: 0.41412097 || Val it_count: 1107 || Current Learning Rate: 1.0000000000000002e-06 || Time: 12:39:37.62
Epoch 00070: reducing learning rate of group 0 to 1.0000e-07.
Early stopping triggered due to learning rate below threshold.
Done Total time: 12:48:36.93
best_loss: 0.4141209707165272

--------------------Testing--------------------

total_samples :: test_dataset = 139200, test_dataloader = 139200
Epoch ::  1 || Loss: 0.23770051 || it_count: 544 || Time: 00:00:23.52
MAE:  0.25638425
MSE:  0.23772062
RMSE:  0.44337472

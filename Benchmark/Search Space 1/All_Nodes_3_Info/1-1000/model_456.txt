--------------------Training--------------------
arch_str :: |lstm_2~0|+|skip_connect~0|lstm_2~1|[relu->dropout->linear]
model :: 3D
InferCell(
  info :: nodes=3, inC=1, outC=64, [1<-(I0-L0) | 2<-(I0-L1,I1-L2)], genotype_str: lstm_2~0|skip_connect~0|lstm_2~1
  linear_layers: [relu->dropout->linear]
  (layers): ModuleList(
    (0): LSTM(
      (lstm): LSTM(1, 64, num_layers=2, batch_first=True)
    )
    (1): FactorizedReduce(
      C_in=1, C_out=64, stride=1
      (relu): ReLU()
      (conv): Conv1d(1, 64, kernel_size=(1,), stride=(1,), bias=False)
      (bn): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (2): LSTM(
      (lstm): LSTM(64, 64, num_layers=2, batch_first=True)
    )
  )
  (linear_layers): ModuleList(
    (0): ReLU()
    (1): Dropout(p=0.1, inplace=False)
    (2): Linear(in_features=3072, out_features=1, bias=True)
  )
)
tr_params :: epochs = 100, patience = 20, batch_size = 256, window_size = 48, data_size = 100
Model FLOPs: 5.732M, Model Params: 120.257K
learning rate scheduling :: (optimizer, mode='min', factor=0.1, patience=5, verbose=True)
total_samples :: train_dataset = 2136000, train_dataloader = 2136000
total_samples :: valid_dataset = 283200, valid_dataloader = 283200
Epoch ::  1 || Loss: 0.46918569 || it_count: 8344 || Val Loss: 0.50540285 || Val it_count: 1107 || Current Learning Rate: 0.001 || Time: 00:04:54.61
Epoch ::  2 || Loss: 0.46728181 || it_count: 8344 || Val Loss: 0.50601583 || Val it_count: 1107 || Current Learning Rate: 0.001 || Time: 00:09:41.95
Epoch ::  3 || Loss: 0.45894492 || it_count: 8344 || Val Loss: 0.51246609 || Val it_count: 1107 || Current Learning Rate: 0.001 || Time: 00:14:30.02
Epoch ::  4 || Loss: 0.45358096 || it_count: 8344 || Val Loss: 0.49796327 || Val it_count: 1107 || Current Learning Rate: 0.001 || Time: 00:19:17.68
Epoch ::  5 || Loss: 0.44614694 || it_count: 8344 || Val Loss: 0.49016645 || Val it_count: 1107 || Current Learning Rate: 0.001 || Time: 00:24:5.96
Epoch ::  6 || Loss: 0.43989649 || it_count: 8344 || Val Loss: 0.47725817 || Val it_count: 1107 || Current Learning Rate: 0.001 || Time: 00:28:52.77
Epoch ::  7 || Loss: 0.43829082 || it_count: 8344 || Val Loss: 0.48884361 || Val it_count: 1107 || Current Learning Rate: 0.001 || Time: 00:33:41.66
Epoch ::  8 || Loss: 0.43716282 || it_count: 8344 || Val Loss: 0.47069099 || Val it_count: 1107 || Current Learning Rate: 0.001 || Time: 00:38:28.54
Epoch ::  9 || Loss: 0.43690632 || it_count: 8344 || Val Loss: 0.47227765 || Val it_count: 1107 || Current Learning Rate: 0.001 || Time: 00:43:15.86
Epoch :: 10 || Loss: 0.42554301 || it_count: 8344 || Val Loss: 0.47542476 || Val it_count: 1107 || Current Learning Rate: 0.001 || Time: 00:48:4.49
Epoch :: 11 || Loss: 0.41989181 || it_count: 8344 || Val Loss: 0.47342182 || Val it_count: 1107 || Current Learning Rate: 0.001 || Time: 00:52:51.26
Epoch :: 12 || Loss: 0.41888988 || it_count: 8344 || Val Loss: 0.46557617 || Val it_count: 1107 || Current Learning Rate: 0.001 || Time: 00:57:37.69
Epoch :: 13 || Loss: 0.41740335 || it_count: 8344 || Val Loss: 0.46563284 || Val it_count: 1107 || Current Learning Rate: 0.001 || Time: 01:02:24.60
Epoch :: 14 || Loss: 0.41562323 || it_count: 8344 || Val Loss: 0.46250772 || Val it_count: 1107 || Current Learning Rate: 0.001 || Time: 01:07:11.60
Epoch :: 15 || Loss: 0.41559982 || it_count: 8344 || Val Loss: 0.46443472 || Val it_count: 1107 || Current Learning Rate: 0.001 || Time: 01:11:59.11
Epoch :: 16 || Loss: 0.41452638 || it_count: 8344 || Val Loss: 0.46678024 || Val it_count: 1107 || Current Learning Rate: 0.001 || Time: 01:16:45.70
Epoch :: 17 || Loss: 0.41363865 || it_count: 8344 || Val Loss: 0.46674316 || Val it_count: 1107 || Current Learning Rate: 0.001 || Time: 01:21:32.46
Epoch :: 18 || Loss: 0.41287970 || it_count: 8344 || Val Loss: 0.46615528 || Val it_count: 1107 || Current Learning Rate: 0.001 || Time: 01:26:19.09
Epoch :: 19 || Loss: 0.41793488 || it_count: 8344 || Val Loss: 0.46481507 || Val it_count: 1107 || Current Learning Rate: 0.001 || Time: 01:31:7.17
Epoch :: 20 || Loss: 0.41289031 || it_count: 8344 || Val Loss: 0.46536199 || Val it_count: 1107 || Current Learning Rate: 0.001 || Time: 01:35:54.95
Epoch :: 21 || Loss: 0.41218074 || it_count: 8344 || Val Loss: 0.46152767 || Val it_count: 1107 || Current Learning Rate: 0.001 || Time: 01:40:40.96
Epoch :: 22 || Loss: 0.41110573 || it_count: 8344 || Val Loss: 0.46657000 || Val it_count: 1107 || Current Learning Rate: 0.001 || Time: 01:45:27.15
Epoch :: 23 || Loss: 0.41083214 || it_count: 8344 || Val Loss: 0.46615914 || Val it_count: 1107 || Current Learning Rate: 0.001 || Time: 01:50:12.44
Epoch :: 24 || Loss: 0.40946860 || it_count: 8344 || Val Loss: 0.46472766 || Val it_count: 1107 || Current Learning Rate: 0.001 || Time: 01:54:57.79
Epoch :: 25 || Loss: 0.40949921 || it_count: 8344 || Val Loss: 0.46338469 || Val it_count: 1107 || Current Learning Rate: 0.001 || Time: 01:59:40.52
Epoch :: 26 || Loss: 0.40946621 || it_count: 8344 || Val Loss: 0.46386846 || Val it_count: 1107 || Current Learning Rate: 0.001 || Time: 02:04:8.23
Epoch :: 27 || Loss: 0.40895096 || it_count: 8344 || Val Loss: 0.46370970 || Val it_count: 1107 || Current Learning Rate: 0.0001 || Time: 02:08:32.51
Epoch :: 28 || Loss: 0.41462968 || it_count: 8344 || Val Loss: 0.45390734 || Val it_count: 1107 || Current Learning Rate: 0.0001 || Time: 02:12:58.78
Epoch :: 29 || Loss: 0.40917807 || it_count: 8344 || Val Loss: 0.45388933 || Val it_count: 1107 || Current Learning Rate: 0.0001 || Time: 02:17:23.38
Epoch :: 30 || Loss: 0.40812115 || it_count: 8344 || Val Loss: 0.45457887 || Val it_count: 1107 || Current Learning Rate: 0.0001 || Time: 02:21:47.93
Epoch :: 31 || Loss: 0.40751021 || it_count: 8344 || Val Loss: 0.45512744 || Val it_count: 1107 || Current Learning Rate: 0.0001 || Time: 02:26:13.84
Epoch :: 32 || Loss: 0.40705073 || it_count: 8344 || Val Loss: 0.45431024 || Val it_count: 1107 || Current Learning Rate: 0.0001 || Time: 02:30:38.69
Epoch :: 33 || Loss: 0.40667848 || it_count: 8344 || Val Loss: 0.45394538 || Val it_count: 1107 || Current Learning Rate: 0.0001 || Time: 02:35:4.70
Epoch :: 34 || Loss: 0.40634056 || it_count: 8344 || Val Loss: 0.45353263 || Val it_count: 1107 || Current Learning Rate: 0.0001 || Time: 02:39:31.40
Epoch :: 35 || Loss: 0.40613582 || it_count: 8344 || Val Loss: 0.45243637 || Val it_count: 1107 || Current Learning Rate: 0.0001 || Time: 02:43:58.27
Epoch :: 36 || Loss: 0.40584765 || it_count: 8344 || Val Loss: 0.45238514 || Val it_count: 1107 || Current Learning Rate: 0.0001 || Time: 02:48:24.44
Epoch :: 37 || Loss: 0.40547773 || it_count: 8344 || Val Loss: 0.45223532 || Val it_count: 1107 || Current Learning Rate: 0.0001 || Time: 02:52:50.24
Epoch :: 38 || Loss: 0.40528455 || it_count: 8344 || Val Loss: 0.45278246 || Val it_count: 1107 || Current Learning Rate: 0.0001 || Time: 02:57:15.78
Epoch :: 39 || Loss: 0.40502969 || it_count: 8344 || Val Loss: 0.45299418 || Val it_count: 1107 || Current Learning Rate: 0.0001 || Time: 03:01:42.14
Epoch :: 40 || Loss: 0.40479868 || it_count: 8344 || Val Loss: 0.45320460 || Val it_count: 1107 || Current Learning Rate: 0.0001 || Time: 03:06:7.95
Epoch :: 41 || Loss: 0.40455977 || it_count: 8344 || Val Loss: 0.45174967 || Val it_count: 1107 || Current Learning Rate: 0.0001 || Time: 03:10:33.14
Epoch :: 42 || Loss: 0.40432842 || it_count: 8344 || Val Loss: 0.45259390 || Val it_count: 1107 || Current Learning Rate: 0.0001 || Time: 03:14:58.61
Epoch :: 43 || Loss: 0.40416935 || it_count: 8344 || Val Loss: 0.45483887 || Val it_count: 1107 || Current Learning Rate: 0.0001 || Time: 03:19:25.03
Epoch :: 44 || Loss: 0.40378215 || it_count: 8344 || Val Loss: 0.45437459 || Val it_count: 1107 || Current Learning Rate: 0.0001 || Time: 03:23:51.35
Epoch :: 45 || Loss: 0.40350440 || it_count: 8344 || Val Loss: 0.45628373 || Val it_count: 1107 || Current Learning Rate: 0.0001 || Time: 03:28:17.60
Epoch :: 46 || Loss: 0.40342677 || it_count: 8344 || Val Loss: 0.45486661 || Val it_count: 1107 || Current Learning Rate: 0.0001 || Time: 03:32:43.20
Epoch :: 47 || Loss: 0.40315301 || it_count: 8344 || Val Loss: 0.45501517 || Val it_count: 1107 || Current Learning Rate: 1e-05 || Time: 03:37:8.55
Epoch :: 48 || Loss: 0.40495248 || it_count: 8344 || Val Loss: 0.44284339 || Val it_count: 1107 || Current Learning Rate: 1e-05 || Time: 03:41:31.99
Epoch :: 49 || Loss: 0.40417189 || it_count: 8344 || Val Loss: 0.44343847 || Val it_count: 1107 || Current Learning Rate: 1e-05 || Time: 03:45:59.06
Epoch :: 50 || Loss: 0.40385600 || it_count: 8344 || Val Loss: 0.44357479 || Val it_count: 1107 || Current Learning Rate: 1e-05 || Time: 03:50:25.28
Epoch :: 51 || Loss: 0.40378194 || it_count: 8344 || Val Loss: 0.44400960 || Val it_count: 1107 || Current Learning Rate: 1e-05 || Time: 03:54:50.23
Epoch :: 52 || Loss: 0.40374811 || it_count: 8344 || Val Loss: 0.44415998 || Val it_count: 1107 || Current Learning Rate: 1e-05 || Time: 03:59:15.01
Epoch :: 53 || Loss: 0.40378079 || it_count: 8344 || Val Loss: 0.44429737 || Val it_count: 1107 || Current Learning Rate: 1e-05 || Time: 04:03:40.40
Epoch :: 54 || Loss: 0.40356875 || it_count: 8344 || Val Loss: 0.44454675 || Val it_count: 1107 || Current Learning Rate: 1.0000000000000002e-06 || Time: 04:08:4.92
Epoch :: 55 || Loss: 0.40374736 || it_count: 8344 || Val Loss: 0.44109186 || Val it_count: 1107 || Current Learning Rate: 1.0000000000000002e-06 || Time: 04:12:31.94
Epoch :: 56 || Loss: 0.40359367 || it_count: 8344 || Val Loss: 0.44019883 || Val it_count: 1107 || Current Learning Rate: 1.0000000000000002e-06 || Time: 04:16:58.34
Epoch :: 57 || Loss: 0.40356026 || it_count: 8344 || Val Loss: 0.43982002 || Val it_count: 1107 || Current Learning Rate: 1.0000000000000002e-06 || Time: 04:21:24.08
Epoch :: 58 || Loss: 0.40355184 || it_count: 8344 || Val Loss: 0.43967860 || Val it_count: 1107 || Current Learning Rate: 1.0000000000000002e-06 || Time: 04:25:49.07
Epoch :: 59 || Loss: 0.40353718 || it_count: 8344 || Val Loss: 0.43959930 || Val it_count: 1107 || Current Learning Rate: 1.0000000000000002e-06 || Time: 04:30:17.10
Epoch :: 60 || Loss: 0.40352421 || it_count: 8344 || Val Loss: 0.43953482 || Val it_count: 1107 || Current Learning Rate: 1.0000000000000002e-06 || Time: 04:34:42.46
Epoch :: 61 || Loss: 0.40351090 || it_count: 8344 || Val Loss: 0.43951881 || Val it_count: 1107 || Current Learning Rate: 1.0000000000000002e-06 || Time: 04:39:7.19
Epoch :: 62 || Loss: 0.40352212 || it_count: 8344 || Val Loss: 0.43949538 || Val it_count: 1107 || Current Learning Rate: 1.0000000000000002e-06 || Time: 04:43:32.21
Epoch :: 63 || Loss: 0.40352683 || it_count: 8344 || Val Loss: 0.43954995 || Val it_count: 1107 || Current Learning Rate: 1.0000000000000002e-06 || Time: 04:47:58.73
Epoch :: 64 || Loss: 0.40348635 || it_count: 8344 || Val Loss: 0.43958075 || Val it_count: 1107 || Current Learning Rate: 1.0000000000000002e-06 || Time: 04:52:24.78
Epoch :: 65 || Loss: 0.40356447 || it_count: 8344 || Val Loss: 0.43954945 || Val it_count: 1107 || Current Learning Rate: 1.0000000000000002e-06 || Time: 04:56:51.97
Early stopping triggered due to learning rate below threshold.
Done Total time: 05:01:18.10
best_loss: 0.43949537927566346

--------------------Testing--------------------

total_samples :: test_dataset = 139200, test_dataloader = 139200
Epoch ::  1 || Loss: 0.33520279 || it_count: 544 || Time: 00:00:14.20
MAE:  0.2868027
MSE:  0.3352689
RMSE:  0.48651993

--------------------Training--------------------
arch_str :: |skip_connect~0|+|none~0|lstm_1~1|[linear->relu->linear]
model :: 3G
InferCell(
  info :: nodes=3, inC=1, outC=64, [1<-(I0-L0) | 2<-(I0-L1,I1-L2)], genotype_str: skip_connect~0|none~0|lstm_1~1
  linear_layers: [linear->relu->linear]
  (layers): ModuleList(
    (0): FactorizedReduce(
      C_in=1, C_out=64, stride=1
      (relu): ReLU()
      (conv): Conv1d(1, 64, kernel_size=(1,), stride=(1,), bias=False)
      (bn): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (1): Zero(C_in=1, C_out=64, stride=1)
    (2): LSTM(
      (lstm): LSTM(64, 64, batch_first=True)
    )
  )
  (linear_layers): ModuleList(
    (0): Linear(in_features=3072, out_features=1536, bias=True)
    (1): ReLU()
    (2): Linear(in_features=1536, out_features=1, bias=True)
  )
)
tr_params :: epochs = 100, patience = 20, batch_size = 256, window_size = 48, data_size = 100
Model FLOPs: 6.358M, Model Params: 4.755M
learning rate scheduling :: (optimizer, mode='min', factor=0.1, patience=5, verbose=True)
total_samples :: train_dataset = 2136000, train_dataloader = 2136000
total_samples :: valid_dataset = 283200, valid_dataloader = 283200
Epoch ::  1 || Loss: 0.44958101 || it_count: 8344 || Val Loss: 0.51997556 || Val it_count: 1107 || Current Learning Rate: 0.001 || Time: 00:03:54.97
Epoch ::  2 || Loss: 0.44672431 || it_count: 8344 || Val Loss: 0.53138371 || Val it_count: 1107 || Current Learning Rate: 0.001 || Time: 00:07:47.03
Epoch ::  3 || Loss: 0.43834946 || it_count: 8344 || Val Loss: 0.52157173 || Val it_count: 1107 || Current Learning Rate: 0.001 || Time: 00:11:38.12
Epoch ::  4 || Loss: 0.44010242 || it_count: 8344 || Val Loss: 0.49987691 || Val it_count: 1107 || Current Learning Rate: 0.001 || Time: 00:15:25.06
Epoch ::  5 || Loss: 0.44016655 || it_count: 8344 || Val Loss: 0.51049589 || Val it_count: 1107 || Current Learning Rate: 0.001 || Time: 00:19:16.03
Epoch ::  6 || Loss: 0.43791981 || it_count: 8344 || Val Loss: 0.49761641 || Val it_count: 1107 || Current Learning Rate: 0.001 || Time: 00:23:0.99
Epoch ::  7 || Loss: 0.44027803 || it_count: 8344 || Val Loss: 0.48724474 || Val it_count: 1107 || Current Learning Rate: 0.001 || Time: 00:26:55.53
Epoch ::  8 || Loss: 0.43650760 || it_count: 8344 || Val Loss: 0.49123783 || Val it_count: 1107 || Current Learning Rate: 0.001 || Time: 00:30:52.51
Epoch ::  9 || Loss: 0.43448712 || it_count: 8344 || Val Loss: 0.48807863 || Val it_count: 1107 || Current Learning Rate: 0.001 || Time: 00:34:51.02
Epoch :: 10 || Loss: 0.43420815 || it_count: 8344 || Val Loss: 0.48716172 || Val it_count: 1107 || Current Learning Rate: 0.001 || Time: 00:38:49.55
Epoch :: 11 || Loss: 0.43826774 || it_count: 8344 || Val Loss: 0.48653800 || Val it_count: 1107 || Current Learning Rate: 0.001 || Time: 00:42:50.13
Epoch :: 12 || Loss: 0.43395196 || it_count: 8344 || Val Loss: 0.48638850 || Val it_count: 1107 || Current Learning Rate: 0.001 || Time: 00:46:49.96
Epoch :: 13 || Loss: 0.43355603 || it_count: 8344 || Val Loss: 0.48755932 || Val it_count: 1107 || Current Learning Rate: 0.001 || Time: 00:50:48.71
Epoch :: 14 || Loss: 0.43539939 || it_count: 8344 || Val Loss: 0.48233061 || Val it_count: 1107 || Current Learning Rate: 0.001 || Time: 00:54:44.50
Epoch :: 15 || Loss: 0.43492887 || it_count: 8344 || Val Loss: 0.48178990 || Val it_count: 1107 || Current Learning Rate: 0.001 || Time: 00:58:37.19
Epoch :: 16 || Loss: 0.44131003 || it_count: 8344 || Val Loss: 0.48207479 || Val it_count: 1107 || Current Learning Rate: 0.001 || Time: 01:02:29.12
Epoch :: 17 || Loss: 0.43656013 || it_count: 8344 || Val Loss: 0.48550592 || Val it_count: 1107 || Current Learning Rate: 0.001 || Time: 01:06:21.39
Epoch :: 18 || Loss: 0.43746510 || it_count: 8344 || Val Loss: 0.48914049 || Val it_count: 1107 || Current Learning Rate: 0.001 || Time: 01:10:15.85
Epoch :: 19 || Loss: 0.43491009 || it_count: 8344 || Val Loss: 0.49570902 || Val it_count: 1107 || Current Learning Rate: 0.001 || Time: 01:14:10.69
Epoch :: 20 || Loss: 0.43132954 || it_count: 8344 || Val Loss: 0.49638717 || Val it_count: 1107 || Current Learning Rate: 0.001 || Time: 01:18:11.31
Epoch :: 21 || Loss: 0.43607881 || it_count: 8344 || Val Loss: 0.49861108 || Val it_count: 1107 || Current Learning Rate: 0.001 || Time: 01:22:8.82
Epoch :: 22 || Loss: 0.43977484 || it_count: 8344 || Val Loss: 0.49023301 || Val it_count: 1107 || Current Learning Rate: 0.001 || Time: 01:26:10.63
Epoch 00007: reducing learning rate of group 0 to 1.0000e-04.
Epoch :: 23 || Loss: 0.43815652 || it_count: 8344 || Val Loss: 0.49616811 || Val it_count: 1107 || Current Learning Rate: 0.0001 || Time: 01:30:11.09
Epoch :: 24 || Loss: 0.44358588 || it_count: 8344 || Val Loss: 0.49322232 || Val it_count: 1107 || Current Learning Rate: 0.0001 || Time: 01:34:8.91
Epoch :: 25 || Loss: 0.43317168 || it_count: 8344 || Val Loss: 0.48775630 || Val it_count: 1107 || Current Learning Rate: 0.0001 || Time: 01:38:7.42
Epoch :: 26 || Loss: 0.42968983 || it_count: 8344 || Val Loss: 0.48761345 || Val it_count: 1107 || Current Learning Rate: 0.0001 || Time: 01:42:5.30
Epoch :: 27 || Loss: 0.42689069 || it_count: 8344 || Val Loss: 0.49229536 || Val it_count: 1107 || Current Learning Rate: 0.0001 || Time: 01:46:6.54
Epoch :: 28 || Loss: 0.42402844 || it_count: 8344 || Val Loss: 0.49461450 || Val it_count: 1107 || Current Learning Rate: 0.0001 || Time: 01:50:6.97
Epoch 00013: reducing learning rate of group 0 to 1.0000e-05.
Epoch :: 29 || Loss: 0.42170432 || it_count: 8344 || Val Loss: 0.49701641 || Val it_count: 1107 || Current Learning Rate: 1e-05 || Time: 01:54:8.45
Epoch :: 30 || Loss: 0.42902662 || it_count: 8344 || Val Loss: 0.47387783 || Val it_count: 1107 || Current Learning Rate: 1e-05 || Time: 01:58:6.02
Epoch :: 31 || Loss: 0.42499385 || it_count: 8344 || Val Loss: 0.47306829 || Val it_count: 1107 || Current Learning Rate: 1e-05 || Time: 02:02:4.82
Epoch :: 32 || Loss: 0.42334760 || it_count: 8344 || Val Loss: 0.47262403 || Val it_count: 1107 || Current Learning Rate: 1e-05 || Time: 02:06:4.97
Epoch :: 33 || Loss: 0.42229364 || it_count: 8344 || Val Loss: 0.47252619 || Val it_count: 1107 || Current Learning Rate: 1e-05 || Time: 02:10:4.59
Epoch :: 34 || Loss: 0.42148064 || it_count: 8344 || Val Loss: 0.47261834 || Val it_count: 1107 || Current Learning Rate: 1e-05 || Time: 02:14:2.11
Epoch :: 35 || Loss: 0.42079923 || it_count: 8344 || Val Loss: 0.47264947 || Val it_count: 1107 || Current Learning Rate: 1e-05 || Time: 02:18:3.29
Epoch :: 36 || Loss: 0.42018708 || it_count: 8344 || Val Loss: 0.47279739 || Val it_count: 1107 || Current Learning Rate: 1e-05 || Time: 02:22:2.04
Epoch :: 37 || Loss: 0.41962587 || it_count: 8344 || Val Loss: 0.47287056 || Val it_count: 1107 || Current Learning Rate: 1e-05 || Time: 02:26:2.39
Epoch :: 38 || Loss: 0.41910099 || it_count: 8344 || Val Loss: 0.47311127 || Val it_count: 1107 || Current Learning Rate: 1e-05 || Time: 02:30:0.33
Epoch 00023: reducing learning rate of group 0 to 1.0000e-06.
Epoch :: 39 || Loss: 0.41860039 || it_count: 8344 || Val Loss: 0.47341128 || Val it_count: 1107 || Current Learning Rate: 1.0000000000000002e-06 || Time: 02:34:1.18
Epoch :: 40 || Loss: 0.42104018 || it_count: 8344 || Val Loss: 0.48064735 || Val it_count: 1107 || Current Learning Rate: 1.0000000000000002e-06 || Time: 02:37:59.46
Epoch :: 41 || Loss: 0.42051644 || it_count: 8344 || Val Loss: 0.48044485 || Val it_count: 1107 || Current Learning Rate: 1.0000000000000002e-06 || Time: 02:41:57.26
Epoch :: 42 || Loss: 0.42023009 || it_count: 8344 || Val Loss: 0.48025241 || Val it_count: 1107 || Current Learning Rate: 1.0000000000000002e-06 || Time: 02:45:56.69
Epoch :: 43 || Loss: 0.42001347 || it_count: 8344 || Val Loss: 0.48009361 || Val it_count: 1107 || Current Learning Rate: 1.0000000000000002e-06 || Time: 02:49:57.33
Epoch :: 44 || Loss: 0.41983642 || it_count: 8344 || Val Loss: 0.47994978 || Val it_count: 1107 || Current Learning Rate: 1.0000000000000002e-06 || Time: 02:54:0.47
Epoch 00029: reducing learning rate of group 0 to 1.0000e-07.
Early stopping triggered due to learning rate below threshold.
Done Total time: 02:58:0.12
best_loss: 0.4725261914138831

--------------------Testing--------------------

total_samples :: test_dataset = 139200, test_dataloader = 139200
Epoch ::  1 || Loss: 0.48749377 || it_count: 544 || Time: 00:00:13.05
MAE:  0.34612635
MSE:  0.48762128
RMSE:  0.5324152

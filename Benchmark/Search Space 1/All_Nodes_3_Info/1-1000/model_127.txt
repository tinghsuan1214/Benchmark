--------------------Training--------------------
arch_str :: |lstm_2~0|+|lstm_1~0|lstm_3~1|[dropout->linear]
model :: 3B
InferCell(
  info :: nodes=3, inC=1, outC=64, [1<-(I0-L0) | 2<-(I0-L1,I1-L2)], genotype_str: lstm_2~0|lstm_1~0|lstm_3~1
  linear_layers: [dropout->linear]
  (layers): ModuleList(
    (0): LSTM(
      (lstm): LSTM(1, 64, num_layers=2, batch_first=True)
    )
    (1): LSTM(
      (lstm): LSTM(1, 64, batch_first=True)
    )
    (2): LSTM(
      (lstm): LSTM(64, 64, num_layers=3, batch_first=True)
    )
  )
  (linear_layers): ModuleList(
    (0): Dropout(p=0.1, inplace=False)
    (1): Linear(in_features=3072, out_features=1, bias=True)
  )
)
tr_params :: epochs = 100, patience = 20, batch_size = 256, window_size = 48, data_size = 100
Model FLOPs: 8.187M, Model Params: 170.497K
learning rate scheduling :: (optimizer, mode='min', factor=0.1, patience=5, verbose=True)
total_samples :: train_dataset = 2136000, train_dataloader = 2136000
total_samples :: valid_dataset = 283200, valid_dataloader = 283200
Epoch ::  1 || Loss: 0.42204585 || it_count: 8344 || Val Loss: 0.44780128 || Val it_count: 1107 || Current Learning Rate: 0.001 || Time: 00:09:31.52
Epoch ::  2 || Loss: 0.42007210 || it_count: 8344 || Val Loss: 0.44497529 || Val it_count: 1107 || Current Learning Rate: 0.001 || Time: 00:19:0.49
Epoch ::  3 || Loss: 0.41947433 || it_count: 8344 || Val Loss: 0.44375234 || Val it_count: 1107 || Current Learning Rate: 0.001 || Time: 00:28:32.95
Epoch ::  4 || Loss: 0.41910807 || it_count: 8344 || Val Loss: 0.44307787 || Val it_count: 1107 || Current Learning Rate: 0.001 || Time: 00:38:3.34
Epoch ::  5 || Loss: 0.41859440 || it_count: 8344 || Val Loss: 0.44248558 || Val it_count: 1107 || Current Learning Rate: 0.001 || Time: 00:47:36.07
Epoch ::  6 || Loss: 0.41855442 || it_count: 8344 || Val Loss: 0.44125613 || Val it_count: 1107 || Current Learning Rate: 0.001 || Time: 00:57:8.20
Epoch ::  7 || Loss: 0.41838433 || it_count: 8344 || Val Loss: 0.44019836 || Val it_count: 1107 || Current Learning Rate: 0.001 || Time: 01:06:41.87
Epoch ::  8 || Loss: 0.41819748 || it_count: 8344 || Val Loss: 0.44090075 || Val it_count: 1107 || Current Learning Rate: 0.001 || Time: 01:16:15.46
Epoch ::  9 || Loss: 0.41807895 || it_count: 8344 || Val Loss: 0.44029804 || Val it_count: 1107 || Current Learning Rate: 0.001 || Time: 01:25:47.43
Epoch :: 10 || Loss: 0.41792010 || it_count: 8344 || Val Loss: 0.44024094 || Val it_count: 1107 || Current Learning Rate: 0.001 || Time: 01:35:19.83
Epoch :: 11 || Loss: 0.41774286 || it_count: 8344 || Val Loss: 0.44022348 || Val it_count: 1107 || Current Learning Rate: 0.001 || Time: 01:44:52.79
Epoch :: 12 || Loss: 0.41759447 || it_count: 8344 || Val Loss: 0.44158652 || Val it_count: 1107 || Current Learning Rate: 0.001 || Time: 01:54:26.91
Epoch :: 13 || Loss: 0.41750297 || it_count: 8344 || Val Loss: 0.44138780 || Val it_count: 1107 || Current Learning Rate: 0.001 || Time: 02:04:3.87
Epoch :: 14 || Loss: 0.41755121 || it_count: 8344 || Val Loss: 0.44115865 || Val it_count: 1107 || Current Learning Rate: 0.001 || Time: 02:13:38.49
Epoch :: 15 || Loss: 0.41742199 || it_count: 8344 || Val Loss: 0.44034234 || Val it_count: 1107 || Current Learning Rate: 0.001 || Time: 02:23:12.79
Epoch :: 16 || Loss: 0.41739434 || it_count: 8344 || Val Loss: 0.44083388 || Val it_count: 1107 || Current Learning Rate: 0.001 || Time: 02:32:47.03
Epoch :: 17 || Loss: 0.41727926 || it_count: 8344 || Val Loss: 0.44070236 || Val it_count: 1107 || Current Learning Rate: 0.001 || Time: 02:42:22.75
Epoch :: 18 || Loss: 0.41722688 || it_count: 8344 || Val Loss: 0.44133423 || Val it_count: 1107 || Current Learning Rate: 0.001 || Time: 02:51:59.98
Epoch :: 19 || Loss: 0.41698834 || it_count: 8344 || Val Loss: 0.44158866 || Val it_count: 1107 || Current Learning Rate: 0.001 || Time: 03:01:36.84
Epoch :: 20 || Loss: 0.41677056 || it_count: 8344 || Val Loss: 0.44058348 || Val it_count: 1107 || Current Learning Rate: 0.001 || Time: 03:11:14.39
Epoch :: 21 || Loss: 0.41710129 || it_count: 8344 || Val Loss: 0.44064442 || Val it_count: 1107 || Current Learning Rate: 0.001 || Time: 03:20:52.25
Epoch :: 22 || Loss: 0.41689991 || it_count: 8344 || Val Loss: 0.43994494 || Val it_count: 1107 || Current Learning Rate: 0.001 || Time: 03:30:32.01
Epoch :: 23 || Loss: 0.41672794 || it_count: 8344 || Val Loss: 0.44085976 || Val it_count: 1107 || Current Learning Rate: 0.001 || Time: 03:40:11.87
Epoch :: 24 || Loss: 0.41674407 || it_count: 8344 || Val Loss: 0.44116556 || Val it_count: 1107 || Current Learning Rate: 0.001 || Time: 03:49:49.67
Epoch :: 25 || Loss: 0.41679400 || it_count: 8344 || Val Loss: 0.44130014 || Val it_count: 1107 || Current Learning Rate: 0.001 || Time: 03:59:26.64
Epoch :: 26 || Loss: 0.41680509 || it_count: 8344 || Val Loss: 0.44110346 || Val it_count: 1107 || Current Learning Rate: 0.001 || Time: 04:09:2.31
Epoch :: 27 || Loss: 0.41665800 || it_count: 8344 || Val Loss: 0.44055253 || Val it_count: 1107 || Current Learning Rate: 0.001 || Time: 04:18:38.11
Epoch 00012: reducing learning rate of group 0 to 1.0000e-04.
Epoch :: 28 || Loss: 0.41671921 || it_count: 8344 || Val Loss: 0.44100669 || Val it_count: 1107 || Current Learning Rate: 0.0001 || Time: 04:28:11.08
Epoch :: 29 || Loss: 0.42190750 || it_count: 8344 || Val Loss: 0.42694758 || Val it_count: 1107 || Current Learning Rate: 0.0001 || Time: 04:37:44.65
Epoch :: 30 || Loss: 0.41820910 || it_count: 8344 || Val Loss: 0.42600767 || Val it_count: 1107 || Current Learning Rate: 0.0001 || Time: 04:47:18.40
Epoch :: 31 || Loss: 0.41761645 || it_count: 8344 || Val Loss: 0.42731198 || Val it_count: 1107 || Current Learning Rate: 0.0001 || Time: 04:56:51.31
Epoch :: 32 || Loss: 0.41724135 || it_count: 8344 || Val Loss: 0.42629998 || Val it_count: 1107 || Current Learning Rate: 0.0001 || Time: 05:06:24.65
Epoch :: 33 || Loss: 0.41729007 || it_count: 8344 || Val Loss: 0.42485678 || Val it_count: 1107 || Current Learning Rate: 0.0001 || Time: 05:15:57.56
Epoch :: 34 || Loss: 0.41698689 || it_count: 8344 || Val Loss: 0.42477085 || Val it_count: 1107 || Current Learning Rate: 0.0001 || Time: 05:25:34.00
Epoch :: 35 || Loss: 0.41688578 || it_count: 8344 || Val Loss: 0.42485763 || Val it_count: 1107 || Current Learning Rate: 0.0001 || Time: 05:35:8.79
Epoch :: 36 || Loss: 0.41678905 || it_count: 8344 || Val Loss: 0.42577608 || Val it_count: 1107 || Current Learning Rate: 0.0001 || Time: 05:44:43.43
Epoch :: 37 || Loss: 0.41685573 || it_count: 8344 || Val Loss: 0.42421386 || Val it_count: 1107 || Current Learning Rate: 0.0001 || Time: 05:54:18.50
Epoch :: 38 || Loss: 0.41670756 || it_count: 8344 || Val Loss: 0.42451837 || Val it_count: 1107 || Current Learning Rate: 0.0001 || Time: 06:03:52.82
Epoch :: 39 || Loss: 0.41671648 || it_count: 8344 || Val Loss: 0.42365238 || Val it_count: 1107 || Current Learning Rate: 0.0001 || Time: 06:13:27.46
Epoch :: 40 || Loss: 0.41666070 || it_count: 8344 || Val Loss: 0.42437992 || Val it_count: 1107 || Current Learning Rate: 0.0001 || Time: 06:23:3.04
Epoch :: 41 || Loss: 0.41658365 || it_count: 8344 || Val Loss: 0.42402766 || Val it_count: 1107 || Current Learning Rate: 0.0001 || Time: 06:32:37.23
Epoch :: 42 || Loss: 0.41654201 || it_count: 8344 || Val Loss: 0.42415475 || Val it_count: 1107 || Current Learning Rate: 0.0001 || Time: 06:42:14.70
Epoch :: 43 || Loss: 0.41638549 || it_count: 8344 || Val Loss: 0.42435272 || Val it_count: 1107 || Current Learning Rate: 0.0001 || Time: 06:51:49.93
Epoch :: 44 || Loss: 0.41640546 || it_count: 8344 || Val Loss: 0.42411810 || Val it_count: 1107 || Current Learning Rate: 0.0001 || Time: 07:01:27.14
Epoch 00029: reducing learning rate of group 0 to 1.0000e-05.
Epoch :: 45 || Loss: 0.41642768 || it_count: 8344 || Val Loss: 0.42431325 || Val it_count: 1107 || Current Learning Rate: 1e-05 || Time: 07:11:3.57
Epoch :: 46 || Loss: 0.41707030 || it_count: 8344 || Val Loss: 0.42119469 || Val it_count: 1107 || Current Learning Rate: 1e-05 || Time: 07:20:37.03
Epoch :: 47 || Loss: 0.41687147 || it_count: 8344 || Val Loss: 0.42097894 || Val it_count: 1107 || Current Learning Rate: 1e-05 || Time: 07:30:12.16
Epoch :: 48 || Loss: 0.41673635 || it_count: 8344 || Val Loss: 0.42082773 || Val it_count: 1107 || Current Learning Rate: 1e-05 || Time: 07:39:44.54
Epoch :: 49 || Loss: 0.41670028 || it_count: 8344 || Val Loss: 0.42080637 || Val it_count: 1107 || Current Learning Rate: 1e-05 || Time: 07:49:20.62
Epoch :: 50 || Loss: 0.41663834 || it_count: 8344 || Val Loss: 0.42079890 || Val it_count: 1107 || Current Learning Rate: 1e-05 || Time: 07:58:57.98
Epoch :: 51 || Loss: 0.41660019 || it_count: 8344 || Val Loss: 0.42077700 || Val it_count: 1107 || Current Learning Rate: 1e-05 || Time: 08:08:33.56
Epoch :: 52 || Loss: 0.41661118 || it_count: 8344 || Val Loss: 0.42074212 || Val it_count: 1107 || Current Learning Rate: 1e-05 || Time: 08:18:13.17
Epoch :: 53 || Loss: 0.41657894 || it_count: 8344 || Val Loss: 0.42075416 || Val it_count: 1107 || Current Learning Rate: 1e-05 || Time: 08:27:49.62
Epoch :: 54 || Loss: 0.41656612 || it_count: 8344 || Val Loss: 0.42071956 || Val it_count: 1107 || Current Learning Rate: 1e-05 || Time: 08:37:27.56
Epoch :: 55 || Loss: 0.41656359 || it_count: 8344 || Val Loss: 0.42073605 || Val it_count: 1107 || Current Learning Rate: 1e-05 || Time: 08:47:4.89
Epoch :: 56 || Loss: 0.41654948 || it_count: 8344 || Val Loss: 0.42071439 || Val it_count: 1107 || Current Learning Rate: 1e-05 || Time: 08:56:41.84
Epoch :: 57 || Loss: 0.41654234 || it_count: 8344 || Val Loss: 0.42063281 || Val it_count: 1107 || Current Learning Rate: 1e-05 || Time: 09:06:19.22
Epoch :: 58 || Loss: 0.41651671 || it_count: 8344 || Val Loss: 0.42068571 || Val it_count: 1107 || Current Learning Rate: 1e-05 || Time: 09:15:56.69
Epoch :: 59 || Loss: 0.41652235 || it_count: 8344 || Val Loss: 0.42073821 || Val it_count: 1107 || Current Learning Rate: 1e-05 || Time: 09:25:35.55
Epoch :: 60 || Loss: 0.41651012 || it_count: 8344 || Val Loss: 0.42066758 || Val it_count: 1107 || Current Learning Rate: 1e-05 || Time: 09:35:13.80
Epoch :: 61 || Loss: 0.41648971 || it_count: 8344 || Val Loss: 0.42067182 || Val it_count: 1107 || Current Learning Rate: 1e-05 || Time: 09:44:49.66
Epoch :: 62 || Loss: 0.41647501 || it_count: 8344 || Val Loss: 0.42066012 || Val it_count: 1107 || Current Learning Rate: 1e-05 || Time: 09:54:25.97
Epoch 00047: reducing learning rate of group 0 to 1.0000e-06.
Epoch :: 63 || Loss: 0.41652648 || it_count: 8344 || Val Loss: 0.42067093 || Val it_count: 1107 || Current Learning Rate: 1.0000000000000002e-06 || Time: 10:04:1.42
Epoch :: 64 || Loss: 0.41651471 || it_count: 8344 || Val Loss: 0.42063985 || Val it_count: 1107 || Current Learning Rate: 1.0000000000000002e-06 || Time: 10:13:37.50
Epoch :: 65 || Loss: 0.41646865 || it_count: 8344 || Val Loss: 0.42063396 || Val it_count: 1107 || Current Learning Rate: 1.0000000000000002e-06 || Time: 10:23:14.01
Epoch :: 66 || Loss: 0.41642293 || it_count: 8344 || Val Loss: 0.42064095 || Val it_count: 1107 || Current Learning Rate: 1.0000000000000002e-06 || Time: 10:32:50.95
Epoch :: 67 || Loss: 0.41646192 || it_count: 8344 || Val Loss: 0.42063637 || Val it_count: 1107 || Current Learning Rate: 1.0000000000000002e-06 || Time: 10:42:26.34
Epoch :: 68 || Loss: 0.41649599 || it_count: 8344 || Val Loss: 0.42063487 || Val it_count: 1107 || Current Learning Rate: 1.0000000000000002e-06 || Time: 10:52:2.47
Epoch 00053: reducing learning rate of group 0 to 1.0000e-07.
Early stopping triggered due to learning rate below threshold.
Done Total time: 11:01:37.01
best_loss: 0.420632806213397

--------------------Testing--------------------

total_samples :: test_dataset = 139200, test_dataloader = 139200
Epoch ::  1 || Loss: 0.24180737 || it_count: 544 || Time: 00:00:24.48
MAE:  0.25891253
MSE:  0.24182816
RMSE:  0.44679615

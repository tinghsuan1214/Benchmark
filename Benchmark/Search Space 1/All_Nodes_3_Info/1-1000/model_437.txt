--------------------Training--------------------
arch_str :: |lstm_3~0|+|lstm_1~0|lstm_1~1|[relu->dropout->linear]
model :: 3D
InferCell(
  info :: nodes=3, inC=1, outC=64, [1<-(I0-L0) | 2<-(I0-L1,I1-L2)], genotype_str: lstm_3~0|lstm_1~0|lstm_1~1
  linear_layers: [relu->dropout->linear]
  (layers): ModuleList(
    (0): LSTM(
      (lstm): LSTM(1, 64, num_layers=3, batch_first=True)
    )
    (1): LSTM(
      (lstm): LSTM(1, 64, batch_first=True)
    )
    (2): LSTM(
      (lstm): LSTM(64, 64, batch_first=True)
    )
  )
  (linear_layers): ModuleList(
    (0): ReLU()
    (1): Dropout(p=0.1, inplace=False)
    (2): Linear(in_features=3072, out_features=1, bias=True)
  )
)
tr_params :: epochs = 100, patience = 20, batch_size = 256, window_size = 48, data_size = 100
Model FLOPs: 6.565M, Model Params: 137.217K
learning rate scheduling :: (optimizer, mode='min', factor=0.1, patience=5, verbose=True)
total_samples :: train_dataset = 2136000, train_dataloader = 2136000
total_samples :: valid_dataset = 283200, valid_dataloader = 283200
Epoch ::  1 || Loss: 0.42296531 || it_count: 8344 || Val Loss: 0.44815271 || Val it_count: 1107 || Current Learning Rate: 0.001 || Time: 00:04:15.26
Epoch ::  2 || Loss: 0.42187913 || it_count: 8344 || Val Loss: 0.44672086 || Val it_count: 1107 || Current Learning Rate: 0.001 || Time: 00:08:28.09
Epoch ::  3 || Loss: 0.42049620 || it_count: 8344 || Val Loss: 0.44477852 || Val it_count: 1107 || Current Learning Rate: 0.001 || Time: 00:12:41.78
Epoch ::  4 || Loss: 0.41975373 || it_count: 8344 || Val Loss: 0.44381408 || Val it_count: 1107 || Current Learning Rate: 0.001 || Time: 00:16:54.86
Epoch ::  5 || Loss: 0.41900688 || it_count: 8344 || Val Loss: 0.44389229 || Val it_count: 1107 || Current Learning Rate: 0.001 || Time: 00:21:6.88
Epoch ::  6 || Loss: 0.41883005 || it_count: 8344 || Val Loss: 0.44394643 || Val it_count: 1107 || Current Learning Rate: 0.001 || Time: 00:25:22.80
Epoch ::  7 || Loss: 0.41856112 || it_count: 8344 || Val Loss: 0.44274307 || Val it_count: 1107 || Current Learning Rate: 0.001 || Time: 00:29:39.24
Epoch ::  8 || Loss: 0.41796641 || it_count: 8344 || Val Loss: 0.44194583 || Val it_count: 1107 || Current Learning Rate: 0.001 || Time: 00:33:54.61
Epoch ::  9 || Loss: 0.41805758 || it_count: 8344 || Val Loss: 0.44147430 || Val it_count: 1107 || Current Learning Rate: 0.001 || Time: 00:38:9.02
Epoch :: 10 || Loss: 0.41778097 || it_count: 8344 || Val Loss: 0.44233061 || Val it_count: 1107 || Current Learning Rate: 0.001 || Time: 00:42:23.88
Epoch :: 11 || Loss: 0.41751192 || it_count: 8344 || Val Loss: 0.44310087 || Val it_count: 1107 || Current Learning Rate: 0.001 || Time: 00:46:41.02
Epoch :: 12 || Loss: 0.41722575 || it_count: 8344 || Val Loss: 0.44369047 || Val it_count: 1107 || Current Learning Rate: 0.001 || Time: 00:50:56.49
Epoch :: 13 || Loss: 0.41737769 || it_count: 8344 || Val Loss: 0.44292132 || Val it_count: 1107 || Current Learning Rate: 0.001 || Time: 00:55:11.77
Epoch :: 14 || Loss: 0.41724160 || it_count: 8344 || Val Loss: 0.44192897 || Val it_count: 1107 || Current Learning Rate: 0.001 || Time: 00:59:29.84
Epoch :: 15 || Loss: 0.41683654 || it_count: 8344 || Val Loss: 0.44217313 || Val it_count: 1107 || Current Learning Rate: 0.001 || Time: 01:03:46.77
Epoch :: 16 || Loss: 0.41660860 || it_count: 8344 || Val Loss: 0.44150146 || Val it_count: 1107 || Current Learning Rate: 0.001 || Time: 01:08:5.29
Epoch :: 17 || Loss: 0.41629090 || it_count: 8344 || Val Loss: 0.44123177 || Val it_count: 1107 || Current Learning Rate: 0.001 || Time: 01:12:24.16
Epoch :: 18 || Loss: 0.41626459 || it_count: 8344 || Val Loss: 0.44206145 || Val it_count: 1107 || Current Learning Rate: 0.001 || Time: 01:16:42.36
Epoch :: 19 || Loss: 0.41623487 || it_count: 8344 || Val Loss: 0.44166464 || Val it_count: 1107 || Current Learning Rate: 0.001 || Time: 01:20:59.05
Epoch :: 20 || Loss: 0.41581217 || it_count: 8344 || Val Loss: 0.44286125 || Val it_count: 1107 || Current Learning Rate: 0.001 || Time: 01:25:16.67
Epoch :: 21 || Loss: 0.41585316 || it_count: 8344 || Val Loss: 0.44190987 || Val it_count: 1107 || Current Learning Rate: 0.001 || Time: 01:29:31.53
Epoch :: 22 || Loss: 0.41611545 || it_count: 8344 || Val Loss: 0.44109177 || Val it_count: 1107 || Current Learning Rate: 0.001 || Time: 01:33:48.23
Epoch :: 23 || Loss: 0.41606592 || it_count: 8344 || Val Loss: 0.44089508 || Val it_count: 1107 || Current Learning Rate: 0.001 || Time: 01:38:5.90
Epoch :: 24 || Loss: 0.42054780 || it_count: 8344 || Val Loss: 0.44110249 || Val it_count: 1107 || Current Learning Rate: 0.001 || Time: 01:42:27.31
Epoch :: 25 || Loss: 0.41605307 || it_count: 8344 || Val Loss: 0.44166238 || Val it_count: 1107 || Current Learning Rate: 0.001 || Time: 01:46:49.40
Epoch :: 26 || Loss: 0.41575013 || it_count: 8344 || Val Loss: 0.44344869 || Val it_count: 1107 || Current Learning Rate: 0.001 || Time: 01:51:15.27
Epoch :: 27 || Loss: 0.41554096 || it_count: 8344 || Val Loss: 0.44293998 || Val it_count: 1107 || Current Learning Rate: 0.001 || Time: 01:55:57.01
Epoch :: 28 || Loss: 0.41552808 || it_count: 8344 || Val Loss: 0.44216293 || Val it_count: 1107 || Current Learning Rate: 0.001 || Time: 02:00:41.17
Epoch :: 29 || Loss: 0.41529122 || it_count: 8344 || Val Loss: 0.44189028 || Val it_count: 1107 || Current Learning Rate: 0.0001 || Time: 02:05:9.95
Epoch :: 30 || Loss: 0.42147604 || it_count: 8344 || Val Loss: 0.42593597 || Val it_count: 1107 || Current Learning Rate: 0.0001 || Time: 02:09:31.72
Epoch :: 31 || Loss: 0.41748635 || it_count: 8344 || Val Loss: 0.42329672 || Val it_count: 1107 || Current Learning Rate: 0.0001 || Time: 02:13:49.56
Epoch :: 32 || Loss: 0.41686368 || it_count: 8344 || Val Loss: 0.42125547 || Val it_count: 1107 || Current Learning Rate: 0.0001 || Time: 02:18:9.71
Epoch :: 33 || Loss: 0.41636539 || it_count: 8344 || Val Loss: 0.42055893 || Val it_count: 1107 || Current Learning Rate: 0.0001 || Time: 02:22:29.91
Epoch :: 34 || Loss: 0.41585154 || it_count: 8344 || Val Loss: 0.42125466 || Val it_count: 1107 || Current Learning Rate: 0.0001 || Time: 02:26:56.92
Epoch :: 35 || Loss: 0.41571688 || it_count: 8344 || Val Loss: 0.42071597 || Val it_count: 1107 || Current Learning Rate: 0.0001 || Time: 02:31:24.66
Epoch :: 36 || Loss: 0.41536844 || it_count: 8344 || Val Loss: 0.42047594 || Val it_count: 1107 || Current Learning Rate: 0.0001 || Time: 02:35:51.18
Epoch :: 37 || Loss: 0.41498875 || it_count: 8344 || Val Loss: 0.42032907 || Val it_count: 1107 || Current Learning Rate: 0.0001 || Time: 02:40:18.79
Epoch :: 38 || Loss: 0.41446492 || it_count: 8344 || Val Loss: 0.42000329 || Val it_count: 1107 || Current Learning Rate: 0.0001 || Time: 02:44:45.36
Epoch :: 39 || Loss: 0.41373392 || it_count: 8344 || Val Loss: 0.42203744 || Val it_count: 1107 || Current Learning Rate: 0.0001 || Time: 02:49:13.16
Epoch :: 40 || Loss: 0.41354621 || it_count: 8344 || Val Loss: 0.42048363 || Val it_count: 1107 || Current Learning Rate: 0.0001 || Time: 02:53:41.25
Epoch :: 41 || Loss: 0.41330220 || it_count: 8344 || Val Loss: 0.42091729 || Val it_count: 1107 || Current Learning Rate: 0.0001 || Time: 02:57:59.56
Epoch :: 42 || Loss: 0.41313468 || it_count: 8344 || Val Loss: 0.42061175 || Val it_count: 1107 || Current Learning Rate: 0.0001 || Time: 03:02:23.04
Epoch :: 43 || Loss: 0.41294160 || it_count: 8344 || Val Loss: 0.42025782 || Val it_count: 1107 || Current Learning Rate: 0.0001 || Time: 03:06:49.85
Epoch :: 44 || Loss: 0.41300148 || it_count: 8344 || Val Loss: 0.42105244 || Val it_count: 1107 || Current Learning Rate: 1e-05 || Time: 03:11:17.11
Epoch :: 45 || Loss: 0.41465131 || it_count: 8344 || Val Loss: 0.41420727 || Val it_count: 1107 || Current Learning Rate: 1e-05 || Time: 03:15:45.06
Epoch :: 46 || Loss: 0.41333506 || it_count: 8344 || Val Loss: 0.41394715 || Val it_count: 1107 || Current Learning Rate: 1e-05 || Time: 03:20:15.27
Epoch :: 47 || Loss: 0.41317127 || it_count: 8344 || Val Loss: 0.41389525 || Val it_count: 1107 || Current Learning Rate: 1e-05 || Time: 03:24:42.29
Epoch :: 48 || Loss: 0.41316072 || it_count: 8344 || Val Loss: 0.41389626 || Val it_count: 1107 || Current Learning Rate: 1e-05 || Time: 03:29:9.66
Epoch :: 49 || Loss: 0.41291687 || it_count: 8344 || Val Loss: 0.41386343 || Val it_count: 1107 || Current Learning Rate: 1e-05 || Time: 03:33:34.51
Epoch :: 50 || Loss: 0.41307201 || it_count: 8344 || Val Loss: 0.41387366 || Val it_count: 1107 || Current Learning Rate: 1e-05 || Time: 03:37:48.63
Epoch :: 51 || Loss: 0.41293421 || it_count: 8344 || Val Loss: 0.41386905 || Val it_count: 1107 || Current Learning Rate: 1e-05 || Time: 03:42:3.87
Epoch :: 52 || Loss: 0.41290214 || it_count: 8344 || Val Loss: 0.41388339 || Val it_count: 1107 || Current Learning Rate: 1e-05 || Time: 03:46:19.16
Epoch :: 53 || Loss: 0.41291952 || it_count: 8344 || Val Loss: 0.41384467 || Val it_count: 1107 || Current Learning Rate: 1e-05 || Time: 03:50:33.38
Epoch :: 54 || Loss: 0.41288360 || it_count: 8344 || Val Loss: 0.41388397 || Val it_count: 1107 || Current Learning Rate: 1e-05 || Time: 03:54:47.64
Epoch :: 55 || Loss: 0.41269137 || it_count: 8344 || Val Loss: 0.41388294 || Val it_count: 1107 || Current Learning Rate: 1e-05 || Time: 03:59:4.45
Epoch :: 56 || Loss: 0.41283267 || it_count: 8344 || Val Loss: 0.41387796 || Val it_count: 1107 || Current Learning Rate: 1e-05 || Time: 04:03:20.11
Epoch :: 57 || Loss: 0.41277163 || it_count: 8344 || Val Loss: 0.41388453 || Val it_count: 1107 || Current Learning Rate: 1e-05 || Time: 04:07:36.85
Epoch :: 58 || Loss: 0.41276472 || it_count: 8344 || Val Loss: 0.41386621 || Val it_count: 1107 || Current Learning Rate: 1e-05 || Time: 04:11:53.36
Epoch :: 59 || Loss: 0.41269445 || it_count: 8344 || Val Loss: 0.41387885 || Val it_count: 1107 || Current Learning Rate: 1.0000000000000002e-06 || Time: 04:16:9.41
Epoch :: 60 || Loss: 0.41289726 || it_count: 8344 || Val Loss: 0.41370294 || Val it_count: 1107 || Current Learning Rate: 1.0000000000000002e-06 || Time: 04:20:26.33
Epoch :: 61 || Loss: 0.41278935 || it_count: 8344 || Val Loss: 0.41366410 || Val it_count: 1107 || Current Learning Rate: 1.0000000000000002e-06 || Time: 04:24:41.44
Epoch :: 62 || Loss: 0.41273492 || it_count: 8344 || Val Loss: 0.41365160 || Val it_count: 1107 || Current Learning Rate: 1.0000000000000002e-06 || Time: 04:28:57.79
Epoch :: 63 || Loss: 0.41276642 || it_count: 8344 || Val Loss: 0.41364266 || Val it_count: 1107 || Current Learning Rate: 1.0000000000000002e-06 || Time: 04:33:14.71
Epoch :: 64 || Loss: 0.41276202 || it_count: 8344 || Val Loss: 0.41363707 || Val it_count: 1107 || Current Learning Rate: 1.0000000000000002e-06 || Time: 04:37:30.36
Epoch :: 65 || Loss: 0.41273337 || it_count: 8344 || Val Loss: 0.41363200 || Val it_count: 1107 || Current Learning Rate: 1.0000000000000002e-06 || Time: 04:41:45.22
Epoch :: 66 || Loss: 0.41268792 || it_count: 8344 || Val Loss: 0.41363602 || Val it_count: 1107 || Current Learning Rate: 1.0000000000000002e-06 || Time: 04:45:59.22
Epoch :: 67 || Loss: 0.41272423 || it_count: 8344 || Val Loss: 0.41363938 || Val it_count: 1107 || Current Learning Rate: 1.0000000000000002e-06 || Time: 04:50:13.81
Early stopping triggered due to learning rate below threshold.
Done Total time: 04:54:30.95
best_loss: 0.41363199889126084

--------------------Testing--------------------

total_samples :: test_dataset = 139200, test_dataloader = 139200
Epoch ::  1 || Loss: 0.23634759 || it_count: 544 || Time: 00:00:13.10
MAE:  0.2543172
MSE:  0.23636746
RMSE:  0.44258308

--------------------Training--------------------
arch_str :: |none~0|+|lstm_2~0|lstm_3~1|[dropout->linear]
model :: 3B
InferCell(
  info :: nodes=3, inC=1, outC=64, [1<-(I0-L0) | 2<-(I0-L1,I1-L2)], genotype_str: none~0|lstm_2~0|lstm_3~1
  linear_layers: [dropout->linear]
  (layers): ModuleList(
    (0): Zero(C_in=1, C_out=64, stride=1)
    (1): LSTM(
      (lstm): LSTM(1, 64, num_layers=2, batch_first=True)
    )
    (2): LSTM(
      (lstm): LSTM(64, 64, num_layers=3, batch_first=True)
    )
  )
  (linear_layers): ModuleList(
    (0): Dropout(p=0.1, inplace=False)
    (1): Linear(in_features=3072, out_features=1, bias=True)
  )
)
tr_params :: epochs = 100, patience = 20, batch_size = 256, window_size = 48, data_size = 100
Model FLOPs: 7.339M, Model Params: 153.345K
learning rate scheduling :: (optimizer, mode='min', factor=0.1, patience=5, verbose=True)
total_samples :: train_dataset = 2136000, train_dataloader = 2136000
total_samples :: valid_dataset = 283200, valid_dataloader = 283200
Epoch ::  1 || Loss: 0.42253837 || it_count: 8344 || Val Loss: 0.44972850 || Val it_count: 1107 || Current Learning Rate: 0.001 || Time: 00:08:21.33
Epoch ::  2 || Loss: 0.41949192 || it_count: 8344 || Val Loss: 0.44888293 || Val it_count: 1107 || Current Learning Rate: 0.001 || Time: 00:16:40.31
Epoch ::  3 || Loss: 0.41905419 || it_count: 8344 || Val Loss: 0.44895743 || Val it_count: 1107 || Current Learning Rate: 0.001 || Time: 00:25:0.75
Epoch ::  4 || Loss: 0.41847069 || it_count: 8344 || Val Loss: 0.44853626 || Val it_count: 1107 || Current Learning Rate: 0.001 || Time: 00:33:20.92
Epoch ::  5 || Loss: 0.41827614 || it_count: 8344 || Val Loss: 0.44776640 || Val it_count: 1107 || Current Learning Rate: 0.001 || Time: 00:41:42.42
Epoch ::  6 || Loss: 0.41795790 || it_count: 8344 || Val Loss: 0.44754208 || Val it_count: 1107 || Current Learning Rate: 0.001 || Time: 00:50:3.18
Epoch ::  7 || Loss: 0.41754643 || it_count: 8344 || Val Loss: 0.44742516 || Val it_count: 1107 || Current Learning Rate: 0.001 || Time: 00:58:24.10
Epoch ::  8 || Loss: 0.41734023 || it_count: 8344 || Val Loss: 0.44767569 || Val it_count: 1107 || Current Learning Rate: 0.001 || Time: 01:06:43.76
Epoch ::  9 || Loss: 0.41709506 || it_count: 8344 || Val Loss: 0.44650388 || Val it_count: 1107 || Current Learning Rate: 0.001 || Time: 01:15:4.71
Epoch :: 10 || Loss: 0.41688604 || it_count: 8344 || Val Loss: 0.44672640 || Val it_count: 1107 || Current Learning Rate: 0.001 || Time: 01:23:25.91
Epoch :: 11 || Loss: 0.41699471 || it_count: 8344 || Val Loss: 0.44617443 || Val it_count: 1107 || Current Learning Rate: 0.001 || Time: 01:31:46.77
Epoch :: 12 || Loss: 0.41692014 || it_count: 8344 || Val Loss: 0.44603353 || Val it_count: 1107 || Current Learning Rate: 0.001 || Time: 01:40:8.54
Epoch :: 13 || Loss: 0.41678635 || it_count: 8344 || Val Loss: 0.44455587 || Val it_count: 1107 || Current Learning Rate: 0.001 || Time: 01:48:30.19
Epoch :: 14 || Loss: 0.41654346 || it_count: 8344 || Val Loss: 0.44389725 || Val it_count: 1107 || Current Learning Rate: 0.001 || Time: 01:56:50.53
Epoch :: 15 || Loss: 0.41631859 || it_count: 8344 || Val Loss: 0.44343245 || Val it_count: 1107 || Current Learning Rate: 0.001 || Time: 02:05:11.97
Epoch :: 16 || Loss: 0.41623116 || it_count: 8344 || Val Loss: 0.44417319 || Val it_count: 1107 || Current Learning Rate: 0.001 || Time: 02:13:32.84
Epoch :: 17 || Loss: 0.41622142 || it_count: 8344 || Val Loss: 0.44387588 || Val it_count: 1107 || Current Learning Rate: 0.001 || Time: 02:21:54.64
Epoch :: 18 || Loss: 0.41603231 || it_count: 8344 || Val Loss: 0.44398485 || Val it_count: 1107 || Current Learning Rate: 0.001 || Time: 02:30:16.60
Epoch :: 19 || Loss: 0.41594944 || it_count: 8344 || Val Loss: 0.44492541 || Val it_count: 1107 || Current Learning Rate: 0.001 || Time: 02:38:37.96
Epoch :: 20 || Loss: 0.41591213 || it_count: 8344 || Val Loss: 0.44522688 || Val it_count: 1107 || Current Learning Rate: 0.001 || Time: 02:46:59.13
Epoch :: 21 || Loss: 0.41568513 || it_count: 8344 || Val Loss: 0.44580653 || Val it_count: 1107 || Current Learning Rate: 0.001 || Time: 02:55:20.55
Epoch :: 22 || Loss: 0.41608979 || it_count: 8344 || Val Loss: 0.44628652 || Val it_count: 1107 || Current Learning Rate: 0.001 || Time: 03:03:45.22
Epoch 00007: reducing learning rate of group 0 to 1.0000e-04.
Epoch :: 23 || Loss: 0.41551324 || it_count: 8344 || Val Loss: 0.44737523 || Val it_count: 1107 || Current Learning Rate: 0.0001 || Time: 03:12:9.40
Epoch :: 24 || Loss: 0.42122253 || it_count: 8344 || Val Loss: 0.42743952 || Val it_count: 1107 || Current Learning Rate: 0.0001 || Time: 03:20:33.37
Epoch :: 25 || Loss: 0.41691323 || it_count: 8344 || Val Loss: 0.42542482 || Val it_count: 1107 || Current Learning Rate: 0.0001 || Time: 03:28:58.63
Epoch :: 26 || Loss: 0.41586297 || it_count: 8344 || Val Loss: 0.42406285 || Val it_count: 1107 || Current Learning Rate: 0.0001 || Time: 03:37:24.62
Epoch :: 27 || Loss: 0.41517307 || it_count: 8344 || Val Loss: 0.42359269 || Val it_count: 1107 || Current Learning Rate: 0.0001 || Time: 03:45:48.19
Epoch :: 28 || Loss: 0.41469075 || it_count: 8344 || Val Loss: 0.42310913 || Val it_count: 1107 || Current Learning Rate: 0.0001 || Time: 03:54:2.74
Epoch :: 29 || Loss: 0.41427567 || it_count: 8344 || Val Loss: 0.42245024 || Val it_count: 1107 || Current Learning Rate: 0.0001 || Time: 04:02:16.49
Epoch :: 30 || Loss: 0.41368301 || it_count: 8344 || Val Loss: 0.42085402 || Val it_count: 1107 || Current Learning Rate: 0.0001 || Time: 04:10:29.50
Epoch :: 31 || Loss: 0.41313791 || it_count: 8344 || Val Loss: 0.41976511 || Val it_count: 1107 || Current Learning Rate: 0.0001 || Time: 04:18:43.24
Epoch :: 32 || Loss: 0.41276135 || it_count: 8344 || Val Loss: 0.41931284 || Val it_count: 1107 || Current Learning Rate: 0.0001 || Time: 04:26:56.73
Epoch :: 33 || Loss: 0.41245130 || it_count: 8344 || Val Loss: 0.41924178 || Val it_count: 1107 || Current Learning Rate: 0.0001 || Time: 04:35:9.23
Epoch :: 34 || Loss: 0.41219864 || it_count: 8344 || Val Loss: 0.41897439 || Val it_count: 1107 || Current Learning Rate: 0.0001 || Time: 04:43:23.09
Epoch :: 35 || Loss: 0.41197697 || it_count: 8344 || Val Loss: 0.41896033 || Val it_count: 1107 || Current Learning Rate: 0.0001 || Time: 04:51:36.81
Epoch :: 36 || Loss: 0.41184234 || it_count: 8344 || Val Loss: 0.41886040 || Val it_count: 1107 || Current Learning Rate: 0.0001 || Time: 04:59:51.65
Epoch :: 37 || Loss: 0.41169857 || it_count: 8344 || Val Loss: 0.41910081 || Val it_count: 1107 || Current Learning Rate: 0.0001 || Time: 05:08:5.95
Epoch :: 38 || Loss: 0.41157418 || it_count: 8344 || Val Loss: 0.41900113 || Val it_count: 1107 || Current Learning Rate: 0.0001 || Time: 05:16:19.72
Epoch :: 39 || Loss: 0.41144045 || it_count: 8344 || Val Loss: 0.41905350 || Val it_count: 1107 || Current Learning Rate: 0.0001 || Time: 05:24:33.67
Epoch :: 40 || Loss: 0.41131096 || it_count: 8344 || Val Loss: 0.41895575 || Val it_count: 1107 || Current Learning Rate: 0.0001 || Time: 05:32:47.91
Epoch :: 41 || Loss: 0.41125827 || it_count: 8344 || Val Loss: 0.41913935 || Val it_count: 1107 || Current Learning Rate: 0.0001 || Time: 05:41:2.37
Epoch 00026: reducing learning rate of group 0 to 1.0000e-05.
Epoch :: 42 || Loss: 0.41121959 || it_count: 8344 || Val Loss: 0.41923216 || Val it_count: 1107 || Current Learning Rate: 1e-05 || Time: 05:49:16.57
Epoch :: 43 || Loss: 0.41269160 || it_count: 8344 || Val Loss: 0.41429552 || Val it_count: 1107 || Current Learning Rate: 1e-05 || Time: 05:57:30.30
Epoch :: 44 || Loss: 0.41198419 || it_count: 8344 || Val Loss: 0.41419759 || Val it_count: 1107 || Current Learning Rate: 1e-05 || Time: 06:05:44.99
Epoch :: 45 || Loss: 0.41192130 || it_count: 8344 || Val Loss: 0.41412428 || Val it_count: 1107 || Current Learning Rate: 1e-05 || Time: 06:13:58.35
Epoch :: 46 || Loss: 0.41181006 || it_count: 8344 || Val Loss: 0.41409236 || Val it_count: 1107 || Current Learning Rate: 1e-05 || Time: 06:22:12.23
Epoch :: 47 || Loss: 0.41177428 || it_count: 8344 || Val Loss: 0.41407131 || Val it_count: 1107 || Current Learning Rate: 1e-05 || Time: 06:30:28.04
Epoch :: 48 || Loss: 0.41172485 || it_count: 8344 || Val Loss: 0.41405474 || Val it_count: 1107 || Current Learning Rate: 1e-05 || Time: 06:38:42.95
Epoch :: 49 || Loss: 0.41170632 || it_count: 8344 || Val Loss: 0.41406355 || Val it_count: 1107 || Current Learning Rate: 1e-05 || Time: 06:46:57.34
Epoch :: 50 || Loss: 0.41163368 || it_count: 8344 || Val Loss: 0.41404685 || Val it_count: 1107 || Current Learning Rate: 1e-05 || Time: 06:55:12.64
Epoch :: 51 || Loss: 0.41161744 || it_count: 8344 || Val Loss: 0.41404998 || Val it_count: 1107 || Current Learning Rate: 1e-05 || Time: 07:03:28.02
Epoch :: 52 || Loss: 0.41156101 || it_count: 8344 || Val Loss: 0.41404649 || Val it_count: 1107 || Current Learning Rate: 1e-05 || Time: 07:11:43.25
Epoch 00037: reducing learning rate of group 0 to 1.0000e-06.
Epoch :: 53 || Loss: 0.41156405 || it_count: 8344 || Val Loss: 0.41405285 || Val it_count: 1107 || Current Learning Rate: 1.0000000000000002e-06 || Time: 07:19:58.47
Epoch :: 54 || Loss: 0.41172661 || it_count: 8344 || Val Loss: 0.41385571 || Val it_count: 1107 || Current Learning Rate: 1.0000000000000002e-06 || Time: 07:28:14.09
Epoch :: 55 || Loss: 0.41165203 || it_count: 8344 || Val Loss: 0.41385149 || Val it_count: 1107 || Current Learning Rate: 1.0000000000000002e-06 || Time: 07:36:28.53
Epoch :: 56 || Loss: 0.41167396 || it_count: 8344 || Val Loss: 0.41384951 || Val it_count: 1107 || Current Learning Rate: 1.0000000000000002e-06 || Time: 07:44:43.25
Epoch :: 57 || Loss: 0.41165625 || it_count: 8344 || Val Loss: 0.41384803 || Val it_count: 1107 || Current Learning Rate: 1.0000000000000002e-06 || Time: 07:52:57.56
Epoch :: 58 || Loss: 0.41166387 || it_count: 8344 || Val Loss: 0.41384379 || Val it_count: 1107 || Current Learning Rate: 1.0000000000000002e-06 || Time: 08:01:11.77
Epoch :: 59 || Loss: 0.41163058 || it_count: 8344 || Val Loss: 0.41384541 || Val it_count: 1107 || Current Learning Rate: 1.0000000000000002e-06 || Time: 08:09:27.22
Epoch 00044: reducing learning rate of group 0 to 1.0000e-07.
Early stopping triggered due to learning rate below threshold.
Done Total time: 08:17:41.94
best_loss: 0.4138437855227302

--------------------Testing--------------------

total_samples :: test_dataset = 139200, test_dataloader = 139200
Epoch ::  1 || Loss: 0.23672133 || it_count: 544 || Time: 00:00:21.65
MAE:  0.2543862
MSE:  0.23673986
RMSE:  0.44274274

--------------------Training--------------------
arch_str :: |lstm_1~0|+|lstm_2~0|skip_connect~1|[relu->linear]
model :: 3C
InferCell(
  info :: nodes=3, inC=1, outC=64, [1<-(I0-L0) | 2<-(I0-L1,I1-L2)], genotype_str: lstm_1~0|lstm_2~0|skip_connect~1
  linear_layers: [relu->linear]
  (layers): ModuleList(
    (0): LSTM(
      (lstm): LSTM(1, 64, batch_first=True)
    )
    (1): LSTM(
      (lstm): LSTM(1, 64, num_layers=2, batch_first=True)
    )
    (2): Identity()
  )
  (linear_layers): ModuleList(
    (0): ReLU()
    (1): Linear(in_features=3072, out_features=1, bias=True)
  )
)
tr_params :: epochs = 100, patience = 20, batch_size = 256, window_size = 48, data_size = 100
Model FLOPs: 3.321M, Model Params: 70.657K
learning rate scheduling :: (optimizer, mode='min', factor=0.1, patience=5, verbose=True)
total_samples :: train_dataset = 2136000, train_dataloader = 2136000
total_samples :: valid_dataset = 283200, valid_dataloader = 283200
Epoch ::  1 || Loss: 0.42024474 || it_count: 8344 || Val Loss: 0.44703648 || Val it_count: 1107 || Current Learning Rate: 0.001 || Time: 00:03:56.94
Epoch ::  2 || Loss: 0.41852477 || it_count: 8344 || Val Loss: 0.44797114 || Val it_count: 1107 || Current Learning Rate: 0.001 || Time: 00:07:53.59
Epoch ::  3 || Loss: 0.41789942 || it_count: 8344 || Val Loss: 0.44693015 || Val it_count: 1107 || Current Learning Rate: 0.001 || Time: 00:11:50.20
Epoch ::  4 || Loss: 0.41808708 || it_count: 8344 || Val Loss: 0.44863382 || Val it_count: 1107 || Current Learning Rate: 0.001 || Time: 00:15:50.41
Epoch ::  5 || Loss: 0.41758600 || it_count: 8344 || Val Loss: 0.44785187 || Val it_count: 1107 || Current Learning Rate: 0.001 || Time: 00:19:46.74
Epoch ::  6 || Loss: 0.41702898 || it_count: 8344 || Val Loss: 0.44840433 || Val it_count: 1107 || Current Learning Rate: 0.001 || Time: 00:23:41.22
Epoch ::  7 || Loss: 0.41675761 || it_count: 8344 || Val Loss: 0.44813009 || Val it_count: 1107 || Current Learning Rate: 0.001 || Time: 00:27:34.17
Epoch ::  8 || Loss: 0.41608097 || it_count: 8344 || Val Loss: 0.44725302 || Val it_count: 1107 || Current Learning Rate: 0.001 || Time: 00:31:30.80
Epoch ::  9 || Loss: 0.41632678 || it_count: 8344 || Val Loss: 0.44724768 || Val it_count: 1107 || Current Learning Rate: 0.001 || Time: 00:35:27.07
Epoch :: 10 || Loss: 0.41540575 || it_count: 8344 || Val Loss: 0.44291579 || Val it_count: 1107 || Current Learning Rate: 0.001 || Time: 00:39:24.44
Epoch :: 11 || Loss: 0.41448063 || it_count: 8344 || Val Loss: 0.44099159 || Val it_count: 1107 || Current Learning Rate: 0.001 || Time: 00:43:22.24
Epoch :: 12 || Loss: 0.41444653 || it_count: 8344 || Val Loss: 0.44400831 || Val it_count: 1107 || Current Learning Rate: 0.001 || Time: 00:47:17.37
Epoch :: 13 || Loss: 0.41459580 || it_count: 8344 || Val Loss: 0.44479297 || Val it_count: 1107 || Current Learning Rate: 0.001 || Time: 00:51:15.68
Epoch :: 14 || Loss: 0.41418470 || it_count: 8344 || Val Loss: 0.44433476 || Val it_count: 1107 || Current Learning Rate: 0.001 || Time: 00:55:13.11
Epoch :: 15 || Loss: 0.41399068 || it_count: 8344 || Val Loss: 0.44395682 || Val it_count: 1107 || Current Learning Rate: 0.001 || Time: 00:59:10.09
Epoch :: 16 || Loss: 0.41397072 || it_count: 8344 || Val Loss: 0.44393264 || Val it_count: 1107 || Current Learning Rate: 0.001 || Time: 01:03:6.05
Epoch :: 17 || Loss: 0.41431520 || it_count: 8344 || Val Loss: 0.44223691 || Val it_count: 1107 || Current Learning Rate: 0.001 || Time: 01:07:3.03
Epoch :: 18 || Loss: 0.41636712 || it_count: 8344 || Val Loss: 0.44523525 || Val it_count: 1107 || Current Learning Rate: 0.001 || Time: 01:11:3.10
Epoch :: 19 || Loss: 0.41517005 || it_count: 8344 || Val Loss: 0.44276305 || Val it_count: 1107 || Current Learning Rate: 0.001 || Time: 01:15:4.70
Epoch :: 20 || Loss: 0.41450328 || it_count: 8344 || Val Loss: 0.44320262 || Val it_count: 1107 || Current Learning Rate: 0.001 || Time: 01:19:1.08
Epoch :: 21 || Loss: 0.41471820 || it_count: 8344 || Val Loss: 0.44190156 || Val it_count: 1107 || Current Learning Rate: 0.001 || Time: 01:22:59.47
Epoch :: 22 || Loss: 0.41388431 || it_count: 8344 || Val Loss: 0.44060059 || Val it_count: 1107 || Current Learning Rate: 0.001 || Time: 01:26:56.10
Epoch :: 23 || Loss: 0.41397473 || it_count: 8344 || Val Loss: 0.44003327 || Val it_count: 1107 || Current Learning Rate: 0.001 || Time: 01:30:57.33
Epoch :: 24 || Loss: 0.41462423 || it_count: 8344 || Val Loss: 0.44266726 || Val it_count: 1107 || Current Learning Rate: 0.001 || Time: 01:34:59.30
Epoch :: 25 || Loss: 0.41460198 || it_count: 8344 || Val Loss: 0.44106188 || Val it_count: 1107 || Current Learning Rate: 0.001 || Time: 01:38:59.66
Epoch :: 26 || Loss: 0.41335147 || it_count: 8344 || Val Loss: 0.44067394 || Val it_count: 1107 || Current Learning Rate: 0.001 || Time: 01:42:57.71
Epoch :: 27 || Loss: 0.41325428 || it_count: 8344 || Val Loss: 0.44105837 || Val it_count: 1107 || Current Learning Rate: 0.001 || Time: 01:46:54.87
Epoch :: 28 || Loss: 0.41320913 || it_count: 8344 || Val Loss: 0.44406869 || Val it_count: 1107 || Current Learning Rate: 0.001 || Time: 01:50:53.63
Epoch 00013: reducing learning rate of group 0 to 1.0000e-04.
Epoch :: 29 || Loss: 0.41278321 || it_count: 8344 || Val Loss: 0.44287361 || Val it_count: 1107 || Current Learning Rate: 0.0001 || Time: 01:54:51.14
Epoch :: 30 || Loss: 0.41820792 || it_count: 8344 || Val Loss: 0.42136456 || Val it_count: 1107 || Current Learning Rate: 0.0001 || Time: 01:58:48.09
Epoch :: 31 || Loss: 0.41298161 || it_count: 8344 || Val Loss: 0.41989685 || Val it_count: 1107 || Current Learning Rate: 0.0001 || Time: 02:02:45.38
Epoch :: 32 || Loss: 0.41236755 || it_count: 8344 || Val Loss: 0.41975746 || Val it_count: 1107 || Current Learning Rate: 0.0001 || Time: 02:06:41.58
Epoch :: 33 || Loss: 0.41206579 || it_count: 8344 || Val Loss: 0.41952740 || Val it_count: 1107 || Current Learning Rate: 0.0001 || Time: 02:10:38.43
Epoch :: 34 || Loss: 0.41175575 || it_count: 8344 || Val Loss: 0.41951307 || Val it_count: 1107 || Current Learning Rate: 0.0001 || Time: 02:14:36.84
Epoch :: 35 || Loss: 0.41151771 || it_count: 8344 || Val Loss: 0.41934121 || Val it_count: 1107 || Current Learning Rate: 0.0001 || Time: 02:18:35.20
Epoch :: 36 || Loss: 0.41129272 || it_count: 8344 || Val Loss: 0.41915713 || Val it_count: 1107 || Current Learning Rate: 0.0001 || Time: 02:22:29.64
Epoch :: 37 || Loss: 0.41108137 || it_count: 8344 || Val Loss: 0.41897585 || Val it_count: 1107 || Current Learning Rate: 0.0001 || Time: 02:26:30.20
Epoch :: 38 || Loss: 0.41087382 || it_count: 8344 || Val Loss: 0.41884487 || Val it_count: 1107 || Current Learning Rate: 0.0001 || Time: 02:30:28.76
Epoch :: 39 || Loss: 0.41069554 || it_count: 8344 || Val Loss: 0.41877839 || Val it_count: 1107 || Current Learning Rate: 0.0001 || Time: 02:34:24.92
Epoch :: 40 || Loss: 0.41053018 || it_count: 8344 || Val Loss: 0.41867353 || Val it_count: 1107 || Current Learning Rate: 0.0001 || Time: 02:38:22.52
Epoch :: 41 || Loss: 0.41038792 || it_count: 8344 || Val Loss: 0.41875649 || Val it_count: 1107 || Current Learning Rate: 0.0001 || Time: 02:42:23.05
Epoch :: 42 || Loss: 0.41026880 || it_count: 8344 || Val Loss: 0.41868012 || Val it_count: 1107 || Current Learning Rate: 0.0001 || Time: 02:46:24.99
Epoch :: 43 || Loss: 0.41015641 || it_count: 8344 || Val Loss: 0.41861933 || Val it_count: 1107 || Current Learning Rate: 0.0001 || Time: 02:50:26.11
Epoch :: 44 || Loss: 0.41006727 || it_count: 8344 || Val Loss: 0.41844404 || Val it_count: 1107 || Current Learning Rate: 0.0001 || Time: 02:54:26.92
Epoch :: 45 || Loss: 0.40994760 || it_count: 8344 || Val Loss: 0.41834585 || Val it_count: 1107 || Current Learning Rate: 0.0001 || Time: 02:58:24.40
Epoch :: 46 || Loss: 0.40979626 || it_count: 8344 || Val Loss: 0.41841504 || Val it_count: 1107 || Current Learning Rate: 0.0001 || Time: 03:02:23.60
Epoch :: 47 || Loss: 0.40970379 || it_count: 8344 || Val Loss: 0.41843261 || Val it_count: 1107 || Current Learning Rate: 0.0001 || Time: 03:06:22.05
Epoch :: 48 || Loss: 0.40962450 || it_count: 8344 || Val Loss: 0.41853001 || Val it_count: 1107 || Current Learning Rate: 0.0001 || Time: 03:10:19.46
Epoch :: 49 || Loss: 0.40952150 || it_count: 8344 || Val Loss: 0.41846251 || Val it_count: 1107 || Current Learning Rate: 0.0001 || Time: 03:14:16.17
Epoch :: 50 || Loss: 0.40944785 || it_count: 8344 || Val Loss: 0.41831453 || Val it_count: 1107 || Current Learning Rate: 0.0001 || Time: 03:18:14.02
Epoch 00035: reducing learning rate of group 0 to 1.0000e-05.
Epoch :: 51 || Loss: 0.40934123 || it_count: 8344 || Val Loss: 0.41840657 || Val it_count: 1107 || Current Learning Rate: 1e-05 || Time: 03:22:14.48
Epoch :: 52 || Loss: 0.41078617 || it_count: 8344 || Val Loss: 0.41356340 || Val it_count: 1107 || Current Learning Rate: 1e-05 || Time: 03:26:15.95
Epoch :: 53 || Loss: 0.41027382 || it_count: 8344 || Val Loss: 0.41340199 || Val it_count: 1107 || Current Learning Rate: 1e-05 || Time: 03:30:16.56
Epoch :: 54 || Loss: 0.41005099 || it_count: 8344 || Val Loss: 0.41328705 || Val it_count: 1107 || Current Learning Rate: 1e-05 || Time: 03:34:14.71
Epoch :: 55 || Loss: 0.40997350 || it_count: 8344 || Val Loss: 0.41323736 || Val it_count: 1107 || Current Learning Rate: 1e-05 || Time: 03:38:15.46
Epoch :: 56 || Loss: 0.40991601 || it_count: 8344 || Val Loss: 0.41320360 || Val it_count: 1107 || Current Learning Rate: 1e-05 || Time: 03:42:12.27
Epoch :: 57 || Loss: 0.40987728 || it_count: 8344 || Val Loss: 0.41317180 || Val it_count: 1107 || Current Learning Rate: 1e-05 || Time: 03:46:15.14
Epoch :: 58 || Loss: 0.40984343 || it_count: 8344 || Val Loss: 0.41315221 || Val it_count: 1107 || Current Learning Rate: 1e-05 || Time: 03:50:17.31
Epoch :: 59 || Loss: 0.40981730 || it_count: 8344 || Val Loss: 0.41313727 || Val it_count: 1107 || Current Learning Rate: 1e-05 || Time: 03:54:15.30
Epoch :: 60 || Loss: 0.40979078 || it_count: 8344 || Val Loss: 0.41312759 || Val it_count: 1107 || Current Learning Rate: 1e-05 || Time: 03:58:16.10
Epoch :: 61 || Loss: 0.40976859 || it_count: 8344 || Val Loss: 0.41311673 || Val it_count: 1107 || Current Learning Rate: 1e-05 || Time: 04:02:15.08
Epoch :: 62 || Loss: 0.40974586 || it_count: 8344 || Val Loss: 0.41311337 || Val it_count: 1107 || Current Learning Rate: 1e-05 || Time: 04:06:14.77
Epoch :: 63 || Loss: 0.40972602 || it_count: 8344 || Val Loss: 0.41310306 || Val it_count: 1107 || Current Learning Rate: 1e-05 || Time: 04:10:15.60
Epoch :: 64 || Loss: 0.40970860 || it_count: 8344 || Val Loss: 0.41309873 || Val it_count: 1107 || Current Learning Rate: 1e-05 || Time: 04:14:14.06
Epoch :: 65 || Loss: 0.40969004 || it_count: 8344 || Val Loss: 0.41309016 || Val it_count: 1107 || Current Learning Rate: 1e-05 || Time: 04:18:9.32
Epoch :: 66 || Loss: 0.40967123 || it_count: 8344 || Val Loss: 0.41308060 || Val it_count: 1107 || Current Learning Rate: 1e-05 || Time: 04:22:4.78
Epoch :: 67 || Loss: 0.40965336 || it_count: 8344 || Val Loss: 0.41307339 || Val it_count: 1107 || Current Learning Rate: 1e-05 || Time: 04:26:3.17
Epoch :: 68 || Loss: 0.40963658 || it_count: 8344 || Val Loss: 0.41306207 || Val it_count: 1107 || Current Learning Rate: 1e-05 || Time: 04:30:1.16
Epoch :: 69 || Loss: 0.40961950 || it_count: 8344 || Val Loss: 0.41305382 || Val it_count: 1107 || Current Learning Rate: 1e-05 || Time: 04:33:59.78
Epoch :: 70 || Loss: 0.40960281 || it_count: 8344 || Val Loss: 0.41304206 || Val it_count: 1107 || Current Learning Rate: 1e-05 || Time: 04:37:54.98
Epoch :: 71 || Loss: 0.40958716 || it_count: 8344 || Val Loss: 0.41302825 || Val it_count: 1107 || Current Learning Rate: 1e-05 || Time: 04:41:53.29
Epoch :: 72 || Loss: 0.40956863 || it_count: 8344 || Val Loss: 0.41302013 || Val it_count: 1107 || Current Learning Rate: 1e-05 || Time: 04:45:52.26
Epoch :: 73 || Loss: 0.40955296 || it_count: 8344 || Val Loss: 0.41301405 || Val it_count: 1107 || Current Learning Rate: 1e-05 || Time: 04:49:51.22
Epoch :: 74 || Loss: 0.40953734 || it_count: 8344 || Val Loss: 0.41300688 || Val it_count: 1107 || Current Learning Rate: 1e-05 || Time: 04:53:44.35
Epoch :: 75 || Loss: 0.40952260 || it_count: 8344 || Val Loss: 0.41300058 || Val it_count: 1107 || Current Learning Rate: 1e-05 || Time: 04:57:41.77
Epoch :: 76 || Loss: 0.40950851 || it_count: 8344 || Val Loss: 0.41299256 || Val it_count: 1107 || Current Learning Rate: 1e-05 || Time: 05:01:36.93
Epoch :: 77 || Loss: 0.40949420 || it_count: 8344 || Val Loss: 0.41298501 || Val it_count: 1107 || Current Learning Rate: 1e-05 || Time: 05:05:37.21
Epoch :: 78 || Loss: 0.40948075 || it_count: 8344 || Val Loss: 0.41298143 || Val it_count: 1107 || Current Learning Rate: 1e-05 || Time: 05:09:36.91
Epoch :: 79 || Loss: 0.40946789 || it_count: 8344 || Val Loss: 0.41298124 || Val it_count: 1107 || Current Learning Rate: 1e-05 || Time: 05:13:34.68
Epoch :: 80 || Loss: 0.40945438 || it_count: 8344 || Val Loss: 0.41297138 || Val it_count: 1107 || Current Learning Rate: 1e-05 || Time: 05:17:33.55
Epoch :: 81 || Loss: 0.40944152 || it_count: 8344 || Val Loss: 0.41296794 || Val it_count: 1107 || Current Learning Rate: 1e-05 || Time: 05:21:33.16
Epoch :: 82 || Loss: 0.40942731 || it_count: 8344 || Val Loss: 0.41296312 || Val it_count: 1107 || Current Learning Rate: 1e-05 || Time: 05:25:33.54
Epoch 00067: reducing learning rate of group 0 to 1.0000e-06.
Epoch :: 83 || Loss: 0.40941394 || it_count: 8344 || Val Loss: 0.41295685 || Val it_count: 1107 || Current Learning Rate: 1.0000000000000002e-06 || Time: 05:29:30.87
Epoch :: 84 || Loss: 0.40953661 || it_count: 8344 || Val Loss: 0.41264204 || Val it_count: 1107 || Current Learning Rate: 1.0000000000000002e-06 || Time: 05:33:26.40
Epoch :: 85 || Loss: 0.40947090 || it_count: 8344 || Val Loss: 0.41260302 || Val it_count: 1107 || Current Learning Rate: 1.0000000000000002e-06 || Time: 05:37:27.26
Epoch :: 86 || Loss: 0.40945223 || it_count: 8344 || Val Loss: 0.41258928 || Val it_count: 1107 || Current Learning Rate: 1.0000000000000002e-06 || Time: 05:41:21.53
Epoch :: 87 || Loss: 0.40944243 || it_count: 8344 || Val Loss: 0.41258295 || Val it_count: 1107 || Current Learning Rate: 1.0000000000000002e-06 || Time: 05:45:16.52
Epoch :: 88 || Loss: 0.40943603 || it_count: 8344 || Val Loss: 0.41257960 || Val it_count: 1107 || Current Learning Rate: 1.0000000000000002e-06 || Time: 05:49:16.52
Epoch :: 89 || Loss: 0.40943112 || it_count: 8344 || Val Loss: 0.41257715 || Val it_count: 1107 || Current Learning Rate: 1.0000000000000002e-06 || Time: 05:53:14.87
Epoch :: 90 || Loss: 0.40942723 || it_count: 8344 || Val Loss: 0.41257552 || Val it_count: 1107 || Current Learning Rate: 1.0000000000000002e-06 || Time: 05:57:11.89
Epoch :: 91 || Loss: 0.40942397 || it_count: 8344 || Val Loss: 0.41257380 || Val it_count: 1107 || Current Learning Rate: 1.0000000000000002e-06 || Time: 06:01:4.58
Epoch 00076: reducing learning rate of group 0 to 1.0000e-07.
Early stopping triggered due to learning rate below threshold.
Done Total time: 06:04:58.90
best_loss: 0.4125738022903893

--------------------Testing--------------------

total_samples :: test_dataset = 139200, test_dataloader = 139200
Epoch ::  1 || Loss: 0.23530719 || it_count: 544 || Time: 00:00:12.31
MAE:  0.25273758
MSE:  0.23532595
RMSE:  0.44146767

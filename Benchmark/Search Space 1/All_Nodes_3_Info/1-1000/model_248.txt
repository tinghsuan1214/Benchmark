--------------------Training--------------------
arch_str :: |lstm_2~0|+|none~0|lstm_1~1|[dropout->linear]
model :: 3B
InferCell(
  info :: nodes=3, inC=1, outC=64, [1<-(I0-L0) | 2<-(I0-L1,I1-L2)], genotype_str: lstm_2~0|none~0|lstm_1~1
  linear_layers: [dropout->linear]
  (layers): ModuleList(
    (0): LSTM(
      (lstm): LSTM(1, 64, num_layers=2, batch_first=True)
    )
    (1): Zero(C_in=1, C_out=64, stride=1)
    (2): LSTM(
      (lstm): LSTM(64, 64, batch_first=True)
    )
  )
  (linear_layers): ModuleList(
    (0): Dropout(p=0.1, inplace=False)
    (1): Linear(in_features=3072, out_features=1, bias=True)
  )
)
tr_params :: epochs = 100, patience = 20, batch_size = 256, window_size = 48, data_size = 100
Model FLOPs: 4.095M, Model Params: 86.785K
learning rate scheduling :: (optimizer, mode='min', factor=0.1, patience=5, verbose=True)
total_samples :: train_dataset = 2136000, train_dataloader = 2136000
total_samples :: valid_dataset = 283200, valid_dataloader = 283200
Epoch ::  1 || Loss: 0.42477269 || it_count: 8344 || Val Loss: 0.44784943 || Val it_count: 1107 || Current Learning Rate: 0.001 || Time: 00:06:59.87
Epoch ::  2 || Loss: 0.41965184 || it_count: 8344 || Val Loss: 0.44676892 || Val it_count: 1107 || Current Learning Rate: 0.001 || Time: 00:13:56.87
Epoch ::  3 || Loss: 0.41931820 || it_count: 8344 || Val Loss: 0.44701396 || Val it_count: 1107 || Current Learning Rate: 0.001 || Time: 00:20:57.42
Epoch ::  4 || Loss: 0.41904996 || it_count: 8344 || Val Loss: 0.44806993 || Val it_count: 1107 || Current Learning Rate: 0.001 || Time: 00:27:54.74
Epoch ::  5 || Loss: 0.41897416 || it_count: 8344 || Val Loss: 0.44875260 || Val it_count: 1107 || Current Learning Rate: 0.001 || Time: 00:34:53.33
Epoch ::  6 || Loss: 0.41857784 || it_count: 8344 || Val Loss: 0.44922682 || Val it_count: 1107 || Current Learning Rate: 0.001 || Time: 00:41:53.54
Epoch ::  7 || Loss: 0.41813460 || it_count: 8344 || Val Loss: 0.44864517 || Val it_count: 1107 || Current Learning Rate: 0.001 || Time: 00:48:51.81
Epoch ::  8 || Loss: 0.41739926 || it_count: 8344 || Val Loss: 0.44932146 || Val it_count: 1107 || Current Learning Rate: 0.001 || Time: 00:55:50.72
Epoch ::  9 || Loss: 0.41718726 || it_count: 8344 || Val Loss: 0.44906288 || Val it_count: 1107 || Current Learning Rate: 0.001 || Time: 01:02:48.75
Epoch :: 10 || Loss: 0.41686918 || it_count: 8344 || Val Loss: 0.44932692 || Val it_count: 1107 || Current Learning Rate: 0.001 || Time: 01:09:48.62
Epoch :: 11 || Loss: 0.41651184 || it_count: 8344 || Val Loss: 0.44895172 || Val it_count: 1107 || Current Learning Rate: 0.001 || Time: 01:16:45.94
Epoch :: 12 || Loss: 0.41629337 || it_count: 8344 || Val Loss: 0.44886386 || Val it_count: 1107 || Current Learning Rate: 0.001 || Time: 01:23:42.24
Epoch :: 13 || Loss: 0.41576023 || it_count: 8344 || Val Loss: 0.44759100 || Val it_count: 1107 || Current Learning Rate: 0.001 || Time: 01:30:40.20
Epoch :: 14 || Loss: 0.41565491 || it_count: 8344 || Val Loss: 0.44732542 || Val it_count: 1107 || Current Learning Rate: 0.001 || Time: 01:37:39.76
Epoch :: 15 || Loss: 0.41548653 || it_count: 8344 || Val Loss: 0.44569829 || Val it_count: 1107 || Current Learning Rate: 0.001 || Time: 01:44:40.96
Epoch :: 16 || Loss: 0.41549084 || it_count: 8344 || Val Loss: 0.44584734 || Val it_count: 1107 || Current Learning Rate: 0.001 || Time: 01:51:38.54
Epoch :: 17 || Loss: 0.41549145 || it_count: 8344 || Val Loss: 0.44633354 || Val it_count: 1107 || Current Learning Rate: 0.001 || Time: 01:58:37.05
Epoch :: 18 || Loss: 0.41522614 || it_count: 8344 || Val Loss: 0.44730353 || Val it_count: 1107 || Current Learning Rate: 0.001 || Time: 02:05:36.43
Epoch :: 19 || Loss: 0.41544403 || it_count: 8344 || Val Loss: 0.44729631 || Val it_count: 1107 || Current Learning Rate: 0.001 || Time: 02:12:35.60
Epoch :: 20 || Loss: 0.41531856 || it_count: 8344 || Val Loss: 0.44746820 || Val it_count: 1107 || Current Learning Rate: 0.001 || Time: 02:19:34.30
Epoch :: 21 || Loss: 0.41612043 || it_count: 8344 || Val Loss: 0.44925978 || Val it_count: 1107 || Current Learning Rate: 0.001 || Time: 02:26:32.39
Epoch :: 22 || Loss: 0.41517876 || it_count: 8344 || Val Loss: 0.44792080 || Val it_count: 1107 || Current Learning Rate: 0.001 || Time: 02:33:31.79
Epoch :: 23 || Loss: 0.41475296 || it_count: 8344 || Val Loss: 0.44471145 || Val it_count: 1107 || Current Learning Rate: 0.001 || Time: 02:40:32.36
Epoch :: 24 || Loss: 0.41372120 || it_count: 8344 || Val Loss: 0.44477076 || Val it_count: 1107 || Current Learning Rate: 0.001 || Time: 02:47:32.20
Epoch :: 25 || Loss: 0.41336902 || it_count: 8344 || Val Loss: 0.44460590 || Val it_count: 1107 || Current Learning Rate: 0.001 || Time: 02:54:31.75
Epoch :: 26 || Loss: 0.41248592 || it_count: 8344 || Val Loss: 0.44728553 || Val it_count: 1107 || Current Learning Rate: 0.001 || Time: 03:01:30.92
Epoch :: 27 || Loss: 0.41219125 || it_count: 8344 || Val Loss: 0.44785767 || Val it_count: 1107 || Current Learning Rate: 0.001 || Time: 03:08:30.80
Epoch :: 28 || Loss: 0.41134611 || it_count: 8344 || Val Loss: 0.44623113 || Val it_count: 1107 || Current Learning Rate: 0.001 || Time: 03:15:28.77
Epoch :: 29 || Loss: 0.41157437 || it_count: 8344 || Val Loss: 0.44773190 || Val it_count: 1107 || Current Learning Rate: 0.001 || Time: 03:22:27.52
Epoch :: 30 || Loss: 0.41077261 || it_count: 8344 || Val Loss: 0.44717166 || Val it_count: 1107 || Current Learning Rate: 0.001 || Time: 03:29:27.29
Epoch 00015: reducing learning rate of group 0 to 1.0000e-04.
Epoch :: 31 || Loss: 0.41092812 || it_count: 8344 || Val Loss: 0.44575603 || Val it_count: 1107 || Current Learning Rate: 0.0001 || Time: 03:36:26.01
Epoch :: 32 || Loss: 0.41492556 || it_count: 8344 || Val Loss: 0.42200125 || Val it_count: 1107 || Current Learning Rate: 0.0001 || Time: 03:43:26.28
Epoch :: 33 || Loss: 0.41147591 || it_count: 8344 || Val Loss: 0.42116756 || Val it_count: 1107 || Current Learning Rate: 0.0001 || Time: 03:50:26.20
Epoch :: 34 || Loss: 0.41077421 || it_count: 8344 || Val Loss: 0.42097179 || Val it_count: 1107 || Current Learning Rate: 0.0001 || Time: 03:57:24.60
Epoch :: 35 || Loss: 0.41051185 || it_count: 8344 || Val Loss: 0.42093927 || Val it_count: 1107 || Current Learning Rate: 0.0001 || Time: 04:04:24.63
Epoch :: 36 || Loss: 0.41024897 || it_count: 8344 || Val Loss: 0.42082353 || Val it_count: 1107 || Current Learning Rate: 0.0001 || Time: 04:11:23.54
Epoch :: 37 || Loss: 0.40994353 || it_count: 8344 || Val Loss: 0.42092062 || Val it_count: 1107 || Current Learning Rate: 0.0001 || Time: 04:18:23.59
Epoch :: 38 || Loss: 0.40975852 || it_count: 8344 || Val Loss: 0.42064738 || Val it_count: 1107 || Current Learning Rate: 0.0001 || Time: 04:25:22.13
Epoch :: 39 || Loss: 0.40952019 || it_count: 8344 || Val Loss: 0.42040805 || Val it_count: 1107 || Current Learning Rate: 0.0001 || Time: 04:32:20.61
Epoch :: 40 || Loss: 0.40929283 || it_count: 8344 || Val Loss: 0.42041602 || Val it_count: 1107 || Current Learning Rate: 0.0001 || Time: 04:39:18.71
Epoch :: 41 || Loss: 0.40916634 || it_count: 8344 || Val Loss: 0.42017958 || Val it_count: 1107 || Current Learning Rate: 0.0001 || Time: 04:46:17.99
Epoch :: 42 || Loss: 0.40895850 || it_count: 8344 || Val Loss: 0.41994397 || Val it_count: 1107 || Current Learning Rate: 0.0001 || Time: 04:53:17.33
Epoch :: 43 || Loss: 0.40879063 || it_count: 8344 || Val Loss: 0.41969205 || Val it_count: 1107 || Current Learning Rate: 0.0001 || Time: 05:00:18.93
Epoch :: 44 || Loss: 0.40856378 || it_count: 8344 || Val Loss: 0.41963948 || Val it_count: 1107 || Current Learning Rate: 0.0001 || Time: 05:07:17.87
Epoch :: 45 || Loss: 0.40843822 || it_count: 8344 || Val Loss: 0.41943940 || Val it_count: 1107 || Current Learning Rate: 0.0001 || Time: 05:14:18.11
Epoch :: 46 || Loss: 0.40828554 || it_count: 8344 || Val Loss: 0.41951712 || Val it_count: 1107 || Current Learning Rate: 0.0001 || Time: 05:21:16.65
Epoch :: 47 || Loss: 0.40805865 || it_count: 8344 || Val Loss: 0.41968915 || Val it_count: 1107 || Current Learning Rate: 0.0001 || Time: 05:28:15.39
Epoch :: 48 || Loss: 0.40799413 || it_count: 8344 || Val Loss: 0.41891336 || Val it_count: 1107 || Current Learning Rate: 0.0001 || Time: 05:35:15.49
Epoch :: 49 || Loss: 0.40778541 || it_count: 8344 || Val Loss: 0.41880127 || Val it_count: 1107 || Current Learning Rate: 0.0001 || Time: 05:42:14.68
Epoch :: 50 || Loss: 0.40770778 || it_count: 8344 || Val Loss: 0.41927747 || Val it_count: 1107 || Current Learning Rate: 0.0001 || Time: 05:49:13.20
Epoch :: 51 || Loss: 0.40757030 || it_count: 8344 || Val Loss: 0.41909432 || Val it_count: 1107 || Current Learning Rate: 0.0001 || Time: 05:56:12.89
Epoch :: 52 || Loss: 0.40744166 || it_count: 8344 || Val Loss: 0.41869751 || Val it_count: 1107 || Current Learning Rate: 0.0001 || Time: 06:03:13.07
Epoch :: 53 || Loss: 0.40725640 || it_count: 8344 || Val Loss: 0.41877236 || Val it_count: 1107 || Current Learning Rate: 0.0001 || Time: 06:10:12.12
Epoch :: 54 || Loss: 0.40721049 || it_count: 8344 || Val Loss: 0.41913980 || Val it_count: 1107 || Current Learning Rate: 0.0001 || Time: 06:17:10.47
Epoch :: 55 || Loss: 0.40712301 || it_count: 8344 || Val Loss: 0.41890478 || Val it_count: 1107 || Current Learning Rate: 0.0001 || Time: 06:24:10.33
Epoch :: 56 || Loss: 0.40696689 || it_count: 8344 || Val Loss: 0.41900400 || Val it_count: 1107 || Current Learning Rate: 0.0001 || Time: 06:31:8.72
Epoch :: 57 || Loss: 0.40679046 || it_count: 8344 || Val Loss: 0.41873540 || Val it_count: 1107 || Current Learning Rate: 0.0001 || Time: 06:38:7.66
Epoch 00042: reducing learning rate of group 0 to 1.0000e-05.
Epoch :: 58 || Loss: 0.40669611 || it_count: 8344 || Val Loss: 0.41920556 || Val it_count: 1107 || Current Learning Rate: 1e-05 || Time: 06:45:7.54
Epoch :: 59 || Loss: 0.40915818 || it_count: 8344 || Val Loss: 0.41186333 || Val it_count: 1107 || Current Learning Rate: 1e-05 || Time: 06:52:7.19
Epoch :: 60 || Loss: 0.40792174 || it_count: 8344 || Val Loss: 0.41144334 || Val it_count: 1107 || Current Learning Rate: 1e-05 || Time: 06:59:5.98
Epoch :: 61 || Loss: 0.40773531 || it_count: 8344 || Val Loss: 0.41131196 || Val it_count: 1107 || Current Learning Rate: 1e-05 || Time: 07:06:5.79
Epoch :: 62 || Loss: 0.40758757 || it_count: 8344 || Val Loss: 0.41123682 || Val it_count: 1107 || Current Learning Rate: 1e-05 || Time: 07:13:6.76
Epoch :: 63 || Loss: 0.40750927 || it_count: 8344 || Val Loss: 0.41121246 || Val it_count: 1107 || Current Learning Rate: 1e-05 || Time: 07:20:7.23
Epoch :: 64 || Loss: 0.40745018 || it_count: 8344 || Val Loss: 0.41118520 || Val it_count: 1107 || Current Learning Rate: 1e-05 || Time: 07:27:5.36
Epoch :: 65 || Loss: 0.40737777 || it_count: 8344 || Val Loss: 0.41115425 || Val it_count: 1107 || Current Learning Rate: 1e-05 || Time: 07:34:4.41
Epoch :: 66 || Loss: 0.40734788 || it_count: 8344 || Val Loss: 0.41113972 || Val it_count: 1107 || Current Learning Rate: 1e-05 || Time: 07:41:4.29
Epoch :: 67 || Loss: 0.40726781 || it_count: 8344 || Val Loss: 0.41112916 || Val it_count: 1107 || Current Learning Rate: 1e-05 || Time: 07:48:4.39
Epoch :: 68 || Loss: 0.40722800 || it_count: 8344 || Val Loss: 0.41109641 || Val it_count: 1107 || Current Learning Rate: 1e-05 || Time: 07:55:4.06
Epoch :: 69 || Loss: 0.40723171 || it_count: 8344 || Val Loss: 0.41107434 || Val it_count: 1107 || Current Learning Rate: 1e-05 || Time: 08:02:3.92
Epoch :: 70 || Loss: 0.40715254 || it_count: 8344 || Val Loss: 0.41107760 || Val it_count: 1107 || Current Learning Rate: 1e-05 || Time: 08:09:3.75
Epoch :: 71 || Loss: 0.40716007 || it_count: 8344 || Val Loss: 0.41106521 || Val it_count: 1107 || Current Learning Rate: 1e-05 || Time: 08:16:1.99
Epoch :: 72 || Loss: 0.40708752 || it_count: 8344 || Val Loss: 0.41106064 || Val it_count: 1107 || Current Learning Rate: 1e-05 || Time: 08:23:1.74
Epoch :: 73 || Loss: 0.40702168 || it_count: 8344 || Val Loss: 0.41104957 || Val it_count: 1107 || Current Learning Rate: 1e-05 || Time: 08:30:2.75
Epoch :: 74 || Loss: 0.40705491 || it_count: 8344 || Val Loss: 0.41104995 || Val it_count: 1107 || Current Learning Rate: 1e-05 || Time: 08:37:3.24
Epoch :: 75 || Loss: 0.40703215 || it_count: 8344 || Val Loss: 0.41104914 || Val it_count: 1107 || Current Learning Rate: 1e-05 || Time: 08:44:2.30
Epoch :: 76 || Loss: 0.40695053 || it_count: 8344 || Val Loss: 0.41104944 || Val it_count: 1107 || Current Learning Rate: 1e-05 || Time: 08:51:2.90
Epoch :: 77 || Loss: 0.40694733 || it_count: 8344 || Val Loss: 0.41104524 || Val it_count: 1107 || Current Learning Rate: 1e-05 || Time: 08:58:2.46
Epoch :: 78 || Loss: 0.40689763 || it_count: 8344 || Val Loss: 0.41102039 || Val it_count: 1107 || Current Learning Rate: 1e-05 || Time: 09:05:1.94
Epoch 00063: reducing learning rate of group 0 to 1.0000e-06.
Epoch :: 79 || Loss: 0.40690189 || it_count: 8344 || Val Loss: 0.41102650 || Val it_count: 1107 || Current Learning Rate: 1.0000000000000002e-06 || Time: 09:12:2.26
Epoch :: 80 || Loss: 0.40710946 || it_count: 8344 || Val Loss: 0.41072423 || Val it_count: 1107 || Current Learning Rate: 1.0000000000000002e-06 || Time: 09:19:0.74
Epoch :: 81 || Loss: 0.40704639 || it_count: 8344 || Val Loss: 0.41067247 || Val it_count: 1107 || Current Learning Rate: 1.0000000000000002e-06 || Time: 09:26:0.69
Epoch :: 82 || Loss: 0.40699380 || it_count: 8344 || Val Loss: 0.41063944 || Val it_count: 1107 || Current Learning Rate: 1.0000000000000002e-06 || Time: 09:33:0.96
Epoch :: 83 || Loss: 0.40696566 || it_count: 8344 || Val Loss: 0.41061788 || Val it_count: 1107 || Current Learning Rate: 1.0000000000000002e-06 || Time: 09:40:0.53
Epoch :: 84 || Loss: 0.40695371 || it_count: 8344 || Val Loss: 0.41060040 || Val it_count: 1107 || Current Learning Rate: 1.0000000000000002e-06 || Time: 09:47:0.49
Epoch :: 85 || Loss: 0.40694699 || it_count: 8344 || Val Loss: 0.41059306 || Val it_count: 1107 || Current Learning Rate: 1.0000000000000002e-06 || Time: 09:54:0.14
Epoch :: 86 || Loss: 0.40694217 || it_count: 8344 || Val Loss: 0.41058545 || Val it_count: 1107 || Current Learning Rate: 1.0000000000000002e-06 || Time: 10:00:59.02
Epoch :: 87 || Loss: 0.40686324 || it_count: 8344 || Val Loss: 0.41058046 || Val it_count: 1107 || Current Learning Rate: 1.0000000000000002e-06 || Time: 10:07:59.49
Epoch :: 88 || Loss: 0.40690865 || it_count: 8344 || Val Loss: 0.41057344 || Val it_count: 1107 || Current Learning Rate: 1.0000000000000002e-06 || Time: 10:14:56.90
Epoch :: 89 || Loss: 0.40692283 || it_count: 8344 || Val Loss: 0.41056965 || Val it_count: 1107 || Current Learning Rate: 1.0000000000000002e-06 || Time: 10:21:55.54
Epoch :: 90 || Loss: 0.40689184 || it_count: 8344 || Val Loss: 0.41056553 || Val it_count: 1107 || Current Learning Rate: 1.0000000000000002e-06 || Time: 10:28:53.57
Epoch :: 91 || Loss: 0.40685187 || it_count: 8344 || Val Loss: 0.41056400 || Val it_count: 1107 || Current Learning Rate: 1.0000000000000002e-06 || Time: 10:35:53.90
Epoch :: 92 || Loss: 0.40691912 || it_count: 8344 || Val Loss: 0.41056180 || Val it_count: 1107 || Current Learning Rate: 1.0000000000000002e-06 || Time: 10:42:52.99
Epoch :: 93 || Loss: 0.40687024 || it_count: 8344 || Val Loss: 0.41056119 || Val it_count: 1107 || Current Learning Rate: 1.0000000000000002e-06 || Time: 10:49:51.77
Epoch 00078: reducing learning rate of group 0 to 1.0000e-07.
Early stopping triggered due to learning rate below threshold.
Done Total time: 10:56:49.95
best_loss: 0.41056119399961905

--------------------Testing--------------------

total_samples :: test_dataset = 139200, test_dataloader = 139200
Epoch ::  1 || Loss: 0.23436715 || it_count: 544 || Time: 00:00:20.22
MAE:  0.25094843
MSE:  0.2343826
RMSE:  0.44019866

--------------------Training--------------------
arch_str :: |lstm_3~0|+|skip_connect~0|none~1|[linear->linear]
model :: 3E
InferCell(
  info :: nodes=3, inC=1, outC=64, [1<-(I0-L0) | 2<-(I0-L1,I1-L2)], genotype_str: lstm_3~0|skip_connect~0|none~1
  linear_layers: [linear->linear]
  (layers): ModuleList(
    (0): LSTM(
      (lstm): LSTM(1, 64, num_layers=3, batch_first=True)
    )
    (1): FactorizedReduce(
      C_in=1, C_out=64, stride=1
      (relu): ReLU()
      (conv): Conv1d(1, 64, kernel_size=(1,), stride=(1,), bias=False)
      (bn): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (2): Zero(C_in=64, C_out=64, stride=1)
  )
  (linear_layers): ModuleList(
    (0): Linear(in_features=3072, out_features=1536, bias=True)
    (1): Linear(in_features=1536, out_features=1, bias=True)
  )
)
tr_params :: epochs = 100, patience = 20, batch_size = 256, window_size = 48, data_size = 100
Model FLOPs: 8.827M, Model Params: 4.806M
learning rate scheduling :: (optimizer, mode='min', factor=0.1, patience=5, verbose=True)
total_samples :: train_dataset = 2136000, train_dataloader = 2136000
total_samples :: valid_dataset = 283200, valid_dataloader = 283200
Epoch ::  1 || Loss: 0.47810366 || it_count: 8344 || Val Loss: 0.46944734 || Val it_count: 1107 || Current Learning Rate: 0.001 || Time: 00:08:38.21
Epoch ::  2 || Loss: 0.46078171 || it_count: 8344 || Val Loss: 0.47343662 || Val it_count: 1107 || Current Learning Rate: 0.001 || Time: 00:17:16.04
Epoch ::  3 || Loss: 0.45841779 || it_count: 8344 || Val Loss: 0.48449257 || Val it_count: 1107 || Current Learning Rate: 0.001 || Time: 00:25:52.05
Epoch ::  4 || Loss: 0.46018818 || it_count: 8344 || Val Loss: 0.50665524 || Val it_count: 1107 || Current Learning Rate: 0.001 || Time: 00:34:29.88
Epoch ::  5 || Loss: 0.46058018 || it_count: 8344 || Val Loss: 0.51142999 || Val it_count: 1107 || Current Learning Rate: 0.001 || Time: 00:43:5.83
Epoch ::  6 || Loss: 0.45970243 || it_count: 8344 || Val Loss: 0.49909728 || Val it_count: 1107 || Current Learning Rate: 0.001 || Time: 00:51:43.04
Epoch ::  7 || Loss: 0.46096860 || it_count: 8344 || Val Loss: 0.51377654 || Val it_count: 1107 || Current Learning Rate: 0.001 || Time: 01:00:19.62
Epoch ::  8 || Loss: 0.46046308 || it_count: 8344 || Val Loss: 0.51315316 || Val it_count: 1107 || Current Learning Rate: 0.001 || Time: 01:08:56.69
Epoch ::  9 || Loss: 0.46106848 || it_count: 8344 || Val Loss: 0.46631269 || Val it_count: 1107 || Current Learning Rate: 0.001 || Time: 01:17:32.99
Epoch :: 10 || Loss: 0.45931432 || it_count: 8344 || Val Loss: 0.48528787 || Val it_count: 1107 || Current Learning Rate: 0.001 || Time: 01:26:11.43
Epoch :: 11 || Loss: 0.45953837 || it_count: 8344 || Val Loss: 0.46373436 || Val it_count: 1107 || Current Learning Rate: 0.001 || Time: 01:34:48.93
Epoch :: 12 || Loss: 0.45989894 || it_count: 8344 || Val Loss: 0.46704188 || Val it_count: 1107 || Current Learning Rate: 0.001 || Time: 01:43:25.01
Epoch :: 13 || Loss: 0.46032987 || it_count: 8344 || Val Loss: 0.51025342 || Val it_count: 1107 || Current Learning Rate: 0.001 || Time: 01:52:0.23
Epoch :: 14 || Loss: 0.45949955 || it_count: 8344 || Val Loss: 0.46516456 || Val it_count: 1107 || Current Learning Rate: 0.001 || Time: 02:00:35.52
Epoch :: 15 || Loss: 0.45946543 || it_count: 8344 || Val Loss: 0.46135449 || Val it_count: 1107 || Current Learning Rate: 0.001 || Time: 02:09:12.23
Epoch :: 16 || Loss: 0.46013361 || it_count: 8344 || Val Loss: 0.50875526 || Val it_count: 1107 || Current Learning Rate: 0.001 || Time: 02:17:49.69
Epoch :: 17 || Loss: 0.45999635 || it_count: 8344 || Val Loss: 0.49893770 || Val it_count: 1107 || Current Learning Rate: 0.001 || Time: 02:26:26.82
Epoch :: 18 || Loss: 0.45913941 || it_count: 8344 || Val Loss: 0.51041450 || Val it_count: 1107 || Current Learning Rate: 0.001 || Time: 02:35:5.79
Epoch :: 19 || Loss: 0.45903615 || it_count: 8344 || Val Loss: 0.47169879 || Val it_count: 1107 || Current Learning Rate: 0.001 || Time: 02:43:43.28
Epoch :: 20 || Loss: 0.45893739 || it_count: 8344 || Val Loss: 0.51228743 || Val it_count: 1107 || Current Learning Rate: 0.001 || Time: 02:52:19.95
Epoch :: 21 || Loss: 0.46093246 || it_count: 8344 || Val Loss: 0.50954462 || Val it_count: 1107 || Current Learning Rate: 0.001 || Time: 03:00:58.01
Epoch :: 22 || Loss: 0.46077493 || it_count: 8344 || Val Loss: 0.52366887 || Val it_count: 1107 || Current Learning Rate: 0.001 || Time: 03:09:34.97
Epoch :: 23 || Loss: 0.45973486 || it_count: 8344 || Val Loss: 0.50238205 || Val it_count: 1107 || Current Learning Rate: 0.001 || Time: 03:18:13.18
Epoch :: 24 || Loss: 0.45867756 || it_count: 8344 || Val Loss: 0.47008922 || Val it_count: 1107 || Current Learning Rate: 0.001 || Time: 03:26:49.84
Epoch :: 25 || Loss: 0.45857922 || it_count: 8344 || Val Loss: 0.47998400 || Val it_count: 1107 || Current Learning Rate: 0.001 || Time: 03:35:28.23
Epoch :: 26 || Loss: 0.46032533 || it_count: 8344 || Val Loss: 0.48349999 || Val it_count: 1107 || Current Learning Rate: 0.001 || Time: 03:44:6.04
Epoch :: 27 || Loss: 0.45900495 || it_count: 8344 || Val Loss: 0.47696066 || Val it_count: 1107 || Current Learning Rate: 0.001 || Time: 03:52:43.11
Epoch :: 28 || Loss: 0.45946494 || it_count: 8344 || Val Loss: 0.45288280 || Val it_count: 1107 || Current Learning Rate: 0.001 || Time: 04:01:20.26
Epoch :: 29 || Loss: 0.45908795 || it_count: 8344 || Val Loss: 0.51009611 || Val it_count: 1107 || Current Learning Rate: 0.001 || Time: 04:09:55.83
Epoch :: 30 || Loss: 0.45963494 || it_count: 8344 || Val Loss: 0.46547311 || Val it_count: 1107 || Current Learning Rate: 0.001 || Time: 04:18:31.73
Epoch :: 31 || Loss: 0.45956106 || it_count: 8344 || Val Loss: 0.47108170 || Val it_count: 1107 || Current Learning Rate: 0.001 || Time: 04:27:8.23
Epoch :: 32 || Loss: 0.46200794 || it_count: 8344 || Val Loss: 0.47031998 || Val it_count: 1107 || Current Learning Rate: 0.001 || Time: 04:35:44.09
Epoch :: 33 || Loss: 0.45997673 || it_count: 8344 || Val Loss: 0.48415650 || Val it_count: 1107 || Current Learning Rate: 0.001 || Time: 04:44:20.83
Epoch 00018: reducing learning rate of group 0 to 1.0000e-04.
Epoch :: 34 || Loss: 0.46141465 || it_count: 8344 || Val Loss: 0.46221030 || Val it_count: 1107 || Current Learning Rate: 0.0001 || Time: 04:52:56.99
Epoch :: 35 || Loss: 0.49711378 || it_count: 8344 || Val Loss: 0.45688020 || Val it_count: 1107 || Current Learning Rate: 0.0001 || Time: 05:01:33.93
Epoch :: 36 || Loss: 0.49485159 || it_count: 8344 || Val Loss: 0.45637936 || Val it_count: 1107 || Current Learning Rate: 0.0001 || Time: 05:10:9.90
Epoch :: 37 || Loss: 0.49425647 || it_count: 8344 || Val Loss: 0.45510464 || Val it_count: 1107 || Current Learning Rate: 0.0001 || Time: 05:18:46.37
Epoch :: 38 || Loss: 0.49395661 || it_count: 8344 || Val Loss: 0.45475408 || Val it_count: 1107 || Current Learning Rate: 0.0001 || Time: 05:27:22.37
Epoch :: 39 || Loss: 0.49383938 || it_count: 8344 || Val Loss: 0.45453075 || Val it_count: 1107 || Current Learning Rate: 0.0001 || Time: 05:35:59.24
Epoch 00024: reducing learning rate of group 0 to 1.0000e-05.
Epoch :: 40 || Loss: 0.49393481 || it_count: 8344 || Val Loss: 0.45477497 || Val it_count: 1107 || Current Learning Rate: 1e-05 || Time: 05:44:35.82
Epoch :: 41 || Loss: 0.51735119 || it_count: 8344 || Val Loss: 0.45963208 || Val it_count: 1107 || Current Learning Rate: 1e-05 || Time: 05:53:11.47
Epoch :: 42 || Loss: 0.51553347 || it_count: 8344 || Val Loss: 0.45800538 || Val it_count: 1107 || Current Learning Rate: 1e-05 || Time: 06:01:47.15
Epoch :: 43 || Loss: 0.51472456 || it_count: 8344 || Val Loss: 0.45746472 || Val it_count: 1107 || Current Learning Rate: 1e-05 || Time: 06:10:22.40
Epoch :: 44 || Loss: 0.51395981 || it_count: 8344 || Val Loss: 0.45723943 || Val it_count: 1107 || Current Learning Rate: 1e-05 || Time: 06:18:58.39
Epoch :: 45 || Loss: 0.51347008 || it_count: 8344 || Val Loss: 0.45741887 || Val it_count: 1107 || Current Learning Rate: 1e-05 || Time: 06:27:34.81
Epoch 00030: reducing learning rate of group 0 to 1.0000e-06.
Epoch :: 46 || Loss: 0.51310588 || it_count: 8344 || Val Loss: 0.45722739 || Val it_count: 1107 || Current Learning Rate: 1.0000000000000002e-06 || Time: 06:36:10.34
Epoch :: 47 || Loss: 0.51685407 || it_count: 8344 || Val Loss: 0.46552582 || Val it_count: 1107 || Current Learning Rate: 1.0000000000000002e-06 || Time: 06:44:45.79
Epoch :: 48 || Loss: 0.51626956 || it_count: 8344 || Val Loss: 0.46506799 || Val it_count: 1107 || Current Learning Rate: 1.0000000000000002e-06 || Time: 06:53:22.52
Early stopping triggered due to patience exceeded.
Done Total time: 06:53:22.52
best_loss: 0.45288280495265754

--------------------Testing--------------------

total_samples :: test_dataset = 139200, test_dataloader = 139200
Epoch ::  1 || Loss: 0.33139214 || it_count: 544 || Time: 00:00:24.68
MAE:  0.30717003
MSE:  0.33146378
RMSE:  0.50600904

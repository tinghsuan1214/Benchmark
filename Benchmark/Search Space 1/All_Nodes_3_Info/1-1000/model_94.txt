--------------------Training--------------------
arch_str :: |none~0|+|lstm_1~0|lstm_3~1|[linear]
model :: 3A
InferCell(
  info :: nodes=3, inC=1, outC=64, [1<-(I0-L0) | 2<-(I0-L1,I1-L2)], genotype_str: none~0|lstm_1~0|lstm_3~1
  linear_layers: [linear]
  (layers): ModuleList(
    (0): Zero(C_in=1, C_out=64, stride=1)
    (1): LSTM(
      (lstm): LSTM(1, 64, batch_first=True)
    )
    (2): LSTM(
      (lstm): LSTM(64, 64, num_layers=3, batch_first=True)
    )
  )
  (linear_layers): ModuleList(
    (0): Linear(in_features=3072, out_features=1, bias=True)
  )
)
tr_params :: epochs = 100, patience = 20, batch_size = 256, window_size = 48, data_size = 100
Model FLOPs: 5.717M, Model Params: 120.065K
learning rate scheduling :: (optimizer, mode='min', factor=0.1, patience=5, verbose=True)
total_samples :: train_dataset = 2136000, train_dataloader = 2136000
total_samples :: valid_dataset = 283200, valid_dataloader = 283200
Epoch ::  1 || Loss: 0.42129818 || it_count: 8344 || Val Loss: 0.44856702 || Val it_count: 1107 || Current Learning Rate: 0.001 || Time: 00:08:46.62
Epoch ::  2 || Loss: 0.41938345 || it_count: 8344 || Val Loss: 0.44782590 || Val it_count: 1107 || Current Learning Rate: 0.001 || Time: 00:17:32.70
Epoch ::  3 || Loss: 0.41884860 || it_count: 8344 || Val Loss: 0.44682769 || Val it_count: 1107 || Current Learning Rate: 0.001 || Time: 00:26:21.41
Epoch ::  4 || Loss: 0.41839950 || it_count: 8344 || Val Loss: 0.44572122 || Val it_count: 1107 || Current Learning Rate: 0.001 || Time: 00:35:10.10
Epoch ::  5 || Loss: 0.41817933 || it_count: 8344 || Val Loss: 0.44493026 || Val it_count: 1107 || Current Learning Rate: 0.001 || Time: 00:43:59.34
Epoch ::  6 || Loss: 0.41806602 || it_count: 8344 || Val Loss: 0.44436397 || Val it_count: 1107 || Current Learning Rate: 0.001 || Time: 00:52:48.86
Epoch ::  7 || Loss: 0.41796183 || it_count: 8344 || Val Loss: 0.44396684 || Val it_count: 1107 || Current Learning Rate: 0.001 || Time: 01:01:39.22
Epoch ::  8 || Loss: 0.41781709 || it_count: 8344 || Val Loss: 0.44269320 || Val it_count: 1107 || Current Learning Rate: 0.001 || Time: 01:10:28.13
Epoch ::  9 || Loss: 0.41756376 || it_count: 8344 || Val Loss: 0.44182567 || Val it_count: 1107 || Current Learning Rate: 0.001 || Time: 01:19:18.03
Epoch :: 10 || Loss: 0.41730465 || it_count: 8344 || Val Loss: 0.44129497 || Val it_count: 1107 || Current Learning Rate: 0.001 || Time: 01:28:8.40
Epoch :: 11 || Loss: 0.41701119 || it_count: 8344 || Val Loss: 0.44115315 || Val it_count: 1107 || Current Learning Rate: 0.001 || Time: 01:36:58.38
Epoch :: 12 || Loss: 0.41675744 || it_count: 8344 || Val Loss: 0.44074338 || Val it_count: 1107 || Current Learning Rate: 0.001 || Time: 01:45:48.24
Epoch :: 13 || Loss: 0.41660788 || it_count: 8344 || Val Loss: 0.44068883 || Val it_count: 1107 || Current Learning Rate: 0.001 || Time: 01:54:38.12
Epoch :: 14 || Loss: 0.41646458 || it_count: 8344 || Val Loss: 0.44078099 || Val it_count: 1107 || Current Learning Rate: 0.001 || Time: 02:03:28.36
Epoch :: 15 || Loss: 0.41631000 || it_count: 8344 || Val Loss: 0.44123756 || Val it_count: 1107 || Current Learning Rate: 0.001 || Time: 02:12:18.98
Epoch :: 16 || Loss: 0.41623360 || it_count: 8344 || Val Loss: 0.44081810 || Val it_count: 1107 || Current Learning Rate: 0.001 || Time: 02:21:9.39
Epoch :: 17 || Loss: 0.41604660 || it_count: 8344 || Val Loss: 0.44063392 || Val it_count: 1107 || Current Learning Rate: 0.001 || Time: 02:30:0.04
Epoch :: 18 || Loss: 0.41606429 || it_count: 8344 || Val Loss: 0.44000070 || Val it_count: 1107 || Current Learning Rate: 0.001 || Time: 02:38:50.37
Epoch :: 19 || Loss: 0.41587744 || it_count: 8344 || Val Loss: 0.44017541 || Val it_count: 1107 || Current Learning Rate: 0.001 || Time: 02:47:41.37
Epoch :: 20 || Loss: 0.41553379 || it_count: 8344 || Val Loss: 0.44042294 || Val it_count: 1107 || Current Learning Rate: 0.001 || Time: 02:56:32.22
Epoch :: 21 || Loss: 0.41551324 || it_count: 8344 || Val Loss: 0.44068784 || Val it_count: 1107 || Current Learning Rate: 0.001 || Time: 03:05:23.88
Epoch :: 22 || Loss: 0.41549720 || it_count: 8344 || Val Loss: 0.44105109 || Val it_count: 1107 || Current Learning Rate: 0.001 || Time: 03:14:14.50
Epoch :: 23 || Loss: 0.41547243 || it_count: 8344 || Val Loss: 0.44131178 || Val it_count: 1107 || Current Learning Rate: 0.001 || Time: 03:23:4.96
Epoch 00008: reducing learning rate of group 0 to 1.0000e-04.
Epoch :: 24 || Loss: 0.41543513 || it_count: 8344 || Val Loss: 0.44120330 || Val it_count: 1107 || Current Learning Rate: 0.0001 || Time: 03:31:55.92
Epoch :: 25 || Loss: 0.42068582 || it_count: 8344 || Val Loss: 0.42563643 || Val it_count: 1107 || Current Learning Rate: 0.0001 || Time: 03:40:46.07
Epoch :: 26 || Loss: 0.41712676 || it_count: 8344 || Val Loss: 0.42418283 || Val it_count: 1107 || Current Learning Rate: 0.0001 || Time: 03:49:36.50
Epoch :: 27 || Loss: 0.41620429 || it_count: 8344 || Val Loss: 0.42351368 || Val it_count: 1107 || Current Learning Rate: 0.0001 || Time: 03:58:26.93
Epoch :: 28 || Loss: 0.41585029 || it_count: 8344 || Val Loss: 0.42330728 || Val it_count: 1107 || Current Learning Rate: 0.0001 || Time: 04:07:10.06
Epoch :: 29 || Loss: 0.41567826 || it_count: 8344 || Val Loss: 0.42324105 || Val it_count: 1107 || Current Learning Rate: 0.0001 || Time: 04:15:53.37
Epoch :: 30 || Loss: 0.41557070 || it_count: 8344 || Val Loss: 0.42320888 || Val it_count: 1107 || Current Learning Rate: 0.0001 || Time: 04:24:35.34
Epoch :: 31 || Loss: 0.41550652 || it_count: 8344 || Val Loss: 0.42320803 || Val it_count: 1107 || Current Learning Rate: 0.0001 || Time: 04:33:17.68
Epoch :: 32 || Loss: 0.41544280 || it_count: 8344 || Val Loss: 0.42320325 || Val it_count: 1107 || Current Learning Rate: 0.0001 || Time: 04:42:0.70
Epoch :: 33 || Loss: 0.41538628 || it_count: 8344 || Val Loss: 0.42319948 || Val it_count: 1107 || Current Learning Rate: 0.0001 || Time: 04:50:43.67
Epoch :: 34 || Loss: 0.41533035 || it_count: 8344 || Val Loss: 0.42319860 || Val it_count: 1107 || Current Learning Rate: 0.0001 || Time: 04:59:26.34
Epoch :: 35 || Loss: 0.41527567 || it_count: 8344 || Val Loss: 0.42319788 || Val it_count: 1107 || Current Learning Rate: 0.0001 || Time: 05:08:8.74
Epoch :: 36 || Loss: 0.41522217 || it_count: 8344 || Val Loss: 0.42318370 || Val it_count: 1107 || Current Learning Rate: 0.0001 || Time: 05:16:50.62
Epoch :: 37 || Loss: 0.41516504 || it_count: 8344 || Val Loss: 0.42312661 || Val it_count: 1107 || Current Learning Rate: 0.0001 || Time: 05:25:33.82
Epoch :: 38 || Loss: 0.41510876 || it_count: 8344 || Val Loss: 0.42310062 || Val it_count: 1107 || Current Learning Rate: 0.0001 || Time: 05:34:19.95
Epoch :: 39 || Loss: 0.41505415 || it_count: 8344 || Val Loss: 0.42307868 || Val it_count: 1107 || Current Learning Rate: 0.0001 || Time: 05:43:3.85
Epoch :: 40 || Loss: 0.41500525 || it_count: 8344 || Val Loss: 0.42303856 || Val it_count: 1107 || Current Learning Rate: 0.0001 || Time: 05:51:48.81
Epoch :: 41 || Loss: 0.41494910 || it_count: 8344 || Val Loss: 0.42300174 || Val it_count: 1107 || Current Learning Rate: 0.0001 || Time: 06:00:39.49
Epoch :: 42 || Loss: 0.41489106 || it_count: 8344 || Val Loss: 0.42295225 || Val it_count: 1107 || Current Learning Rate: 0.0001 || Time: 06:09:29.98
Epoch :: 43 || Loss: 0.41482980 || it_count: 8344 || Val Loss: 0.42289015 || Val it_count: 1107 || Current Learning Rate: 0.0001 || Time: 06:18:20.62
Epoch :: 44 || Loss: 0.41476025 || it_count: 8344 || Val Loss: 0.42282428 || Val it_count: 1107 || Current Learning Rate: 0.0001 || Time: 06:27:10.68
Epoch :: 45 || Loss: 0.41469652 || it_count: 8344 || Val Loss: 0.42271718 || Val it_count: 1107 || Current Learning Rate: 0.0001 || Time: 06:36:1.00
Epoch :: 46 || Loss: 0.41461754 || it_count: 8344 || Val Loss: 0.42261691 || Val it_count: 1107 || Current Learning Rate: 0.0001 || Time: 06:44:51.43
Epoch :: 47 || Loss: 0.41454488 || it_count: 8344 || Val Loss: 0.42248137 || Val it_count: 1107 || Current Learning Rate: 0.0001 || Time: 06:53:42.47
Epoch :: 48 || Loss: 0.41446130 || it_count: 8344 || Val Loss: 0.42233880 || Val it_count: 1107 || Current Learning Rate: 0.0001 || Time: 07:02:33.08
Epoch :: 49 || Loss: 0.41438494 || it_count: 8344 || Val Loss: 0.42216652 || Val it_count: 1107 || Current Learning Rate: 0.0001 || Time: 07:11:23.44
Epoch :: 50 || Loss: 0.41428957 || it_count: 8344 || Val Loss: 0.42199232 || Val it_count: 1107 || Current Learning Rate: 0.0001 || Time: 07:20:14.52
Epoch :: 51 || Loss: 0.41419581 || it_count: 8344 || Val Loss: 0.42179821 || Val it_count: 1107 || Current Learning Rate: 0.0001 || Time: 07:29:5.20
Epoch :: 52 || Loss: 0.41409592 || it_count: 8344 || Val Loss: 0.42160120 || Val it_count: 1107 || Current Learning Rate: 0.0001 || Time: 07:37:55.28
Epoch :: 53 || Loss: 0.41398970 || it_count: 8344 || Val Loss: 0.42140827 || Val it_count: 1107 || Current Learning Rate: 0.0001 || Time: 07:46:46.22
Epoch :: 54 || Loss: 0.41387671 || it_count: 8344 || Val Loss: 0.42122602 || Val it_count: 1107 || Current Learning Rate: 0.0001 || Time: 07:55:37.22
Epoch :: 55 || Loss: 0.41375671 || it_count: 8344 || Val Loss: 0.42106272 || Val it_count: 1107 || Current Learning Rate: 0.0001 || Time: 08:04:28.06
Epoch :: 56 || Loss: 0.41363556 || it_count: 8344 || Val Loss: 0.42091762 || Val it_count: 1107 || Current Learning Rate: 0.0001 || Time: 08:13:19.43
Epoch :: 57 || Loss: 0.41352070 || it_count: 8344 || Val Loss: 0.42078781 || Val it_count: 1107 || Current Learning Rate: 0.0001 || Time: 08:22:9.86
Epoch :: 58 || Loss: 0.41340733 || it_count: 8344 || Val Loss: 0.42069444 || Val it_count: 1107 || Current Learning Rate: 0.0001 || Time: 08:31:0.04
Epoch :: 59 || Loss: 0.41330642 || it_count: 8344 || Val Loss: 0.42063540 || Val it_count: 1107 || Current Learning Rate: 0.0001 || Time: 08:39:51.06
Epoch :: 60 || Loss: 0.41321213 || it_count: 8344 || Val Loss: 0.42060815 || Val it_count: 1107 || Current Learning Rate: 0.0001 || Time: 08:48:41.35
Epoch :: 61 || Loss: 0.41312736 || it_count: 8344 || Val Loss: 0.42060989 || Val it_count: 1107 || Current Learning Rate: 0.0001 || Time: 08:57:32.10
Epoch :: 62 || Loss: 0.41303630 || it_count: 8344 || Val Loss: 0.42066426 || Val it_count: 1107 || Current Learning Rate: 0.0001 || Time: 09:06:23.34
Epoch :: 63 || Loss: 0.41296995 || it_count: 8344 || Val Loss: 0.42070210 || Val it_count: 1107 || Current Learning Rate: 0.0001 || Time: 09:15:14.08
Epoch :: 64 || Loss: 0.41291058 || it_count: 8344 || Val Loss: 0.42071903 || Val it_count: 1107 || Current Learning Rate: 0.0001 || Time: 09:24:4.95
Epoch 00049: reducing learning rate of group 0 to 1.0000e-05.
Epoch :: 65 || Loss: 0.41284985 || it_count: 8344 || Val Loss: 0.42075234 || Val it_count: 1107 || Current Learning Rate: 1e-05 || Time: 09:32:56.57
Epoch :: 66 || Loss: 0.41408572 || it_count: 8344 || Val Loss: 0.41674927 || Val it_count: 1107 || Current Learning Rate: 1e-05 || Time: 09:41:46.98
Epoch :: 67 || Loss: 0.41346873 || it_count: 8344 || Val Loss: 0.41670840 || Val it_count: 1107 || Current Learning Rate: 1e-05 || Time: 09:50:37.19
Epoch :: 68 || Loss: 0.41333385 || it_count: 8344 || Val Loss: 0.41671395 || Val it_count: 1107 || Current Learning Rate: 1e-05 || Time: 09:59:27.07
Epoch :: 69 || Loss: 0.41327280 || it_count: 8344 || Val Loss: 0.41669810 || Val it_count: 1107 || Current Learning Rate: 1e-05 || Time: 10:08:16.64
Epoch :: 70 || Loss: 0.41323109 || it_count: 8344 || Val Loss: 0.41668654 || Val it_count: 1107 || Current Learning Rate: 1e-05 || Time: 10:17:5.92
Epoch :: 71 || Loss: 0.41319611 || it_count: 8344 || Val Loss: 0.41667273 || Val it_count: 1107 || Current Learning Rate: 1e-05 || Time: 10:25:55.83
Epoch :: 72 || Loss: 0.41317043 || it_count: 8344 || Val Loss: 0.41666128 || Val it_count: 1107 || Current Learning Rate: 1e-05 || Time: 10:34:45.41
Epoch :: 73 || Loss: 0.41314862 || it_count: 8344 || Val Loss: 0.41665108 || Val it_count: 1107 || Current Learning Rate: 1e-05 || Time: 10:43:34.90
Epoch :: 74 || Loss: 0.41312947 || it_count: 8344 || Val Loss: 0.41664171 || Val it_count: 1107 || Current Learning Rate: 1e-05 || Time: 10:52:24.08
Epoch :: 75 || Loss: 0.41311227 || it_count: 8344 || Val Loss: 0.41663299 || Val it_count: 1107 || Current Learning Rate: 1e-05 || Time: 11:01:14.28
Epoch :: 76 || Loss: 0.41309660 || it_count: 8344 || Val Loss: 0.41662484 || Val it_count: 1107 || Current Learning Rate: 1e-05 || Time: 11:10:4.50
Epoch :: 77 || Loss: 0.41308214 || it_count: 8344 || Val Loss: 0.41661727 || Val it_count: 1107 || Current Learning Rate: 1e-05 || Time: 11:18:54.92
Epoch :: 78 || Loss: 0.41306869 || it_count: 8344 || Val Loss: 0.41661025 || Val it_count: 1107 || Current Learning Rate: 1e-05 || Time: 11:27:45.84
Epoch :: 79 || Loss: 0.41305608 || it_count: 8344 || Val Loss: 0.41660379 || Val it_count: 1107 || Current Learning Rate: 1e-05 || Time: 11:36:36.39
Epoch :: 80 || Loss: 0.41304419 || it_count: 8344 || Val Loss: 0.41659784 || Val it_count: 1107 || Current Learning Rate: 1e-05 || Time: 11:45:27.12
Epoch :: 81 || Loss: 0.41303658 || it_count: 8344 || Val Loss: 0.41659550 || Val it_count: 1107 || Current Learning Rate: 1e-05 || Time: 11:54:17.54
Epoch :: 82 || Loss: 0.41302594 || it_count: 8344 || Val Loss: 0.41659155 || Val it_count: 1107 || Current Learning Rate: 1e-05 || Time: 12:03:8.33
Epoch :: 83 || Loss: 0.41301568 || it_count: 8344 || Val Loss: 0.41658729 || Val it_count: 1107 || Current Learning Rate: 1e-05 || Time: 12:11:58.60
Epoch :: 84 || Loss: 0.41300581 || it_count: 8344 || Val Loss: 0.41658318 || Val it_count: 1107 || Current Learning Rate: 1e-05 || Time: 12:20:48.44
Epoch 00069: reducing learning rate of group 0 to 1.0000e-06.
Epoch :: 85 || Loss: 0.41299630 || it_count: 8344 || Val Loss: 0.41657930 || Val it_count: 1107 || Current Learning Rate: 1.0000000000000002e-06 || Time: 12:29:38.64
Epoch :: 86 || Loss: 0.41313280 || it_count: 8344 || Val Loss: 0.41629337 || Val it_count: 1107 || Current Learning Rate: 1.0000000000000002e-06 || Time: 12:38:29.71
Epoch :: 87 || Loss: 0.41309152 || it_count: 8344 || Val Loss: 0.41625456 || Val it_count: 1107 || Current Learning Rate: 1.0000000000000002e-06 || Time: 12:47:21.34
Epoch :: 88 || Loss: 0.41308296 || it_count: 8344 || Val Loss: 0.41623529 || Val it_count: 1107 || Current Learning Rate: 1.0000000000000002e-06 || Time: 12:56:12.57
Epoch :: 89 || Loss: 0.41307750 || it_count: 8344 || Val Loss: 0.41622499 || Val it_count: 1107 || Current Learning Rate: 1.0000000000000002e-06 || Time: 13:05:2.55
Epoch :: 90 || Loss: 0.41307355 || it_count: 8344 || Val Loss: 0.41621891 || Val it_count: 1107 || Current Learning Rate: 1.0000000000000002e-06 || Time: 13:13:52.97
Epoch :: 91 || Loss: 0.41307043 || it_count: 8344 || Val Loss: 0.41621499 || Val it_count: 1107 || Current Learning Rate: 1.0000000000000002e-06 || Time: 13:22:43.86
Epoch :: 92 || Loss: 0.41306782 || it_count: 8344 || Val Loss: 0.41621223 || Val it_count: 1107 || Current Learning Rate: 1.0000000000000002e-06 || Time: 13:31:33.89
Epoch :: 93 || Loss: 0.41306553 || it_count: 8344 || Val Loss: 0.41621014 || Val it_count: 1107 || Current Learning Rate: 1.0000000000000002e-06 || Time: 13:40:24.62
Epoch 00078: reducing learning rate of group 0 to 1.0000e-07.
Early stopping triggered due to learning rate below threshold.
Done Total time: 13:49:15.32
best_loss: 0.4162101409299063

--------------------Testing--------------------

total_samples :: test_dataset = 139200, test_dataloader = 139200
Epoch ::  1 || Loss: 0.23811005 || it_count: 544 || Time: 00:00:24.55
MAE:  0.25594828
MSE:  0.23813033
RMSE:  0.44416398

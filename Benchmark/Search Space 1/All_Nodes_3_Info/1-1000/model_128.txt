--------------------Training--------------------
arch_str :: |lstm_3~0|+|lstm_1~0|lstm_2~1|[dropout->linear]
model :: 3B
InferCell(
  info :: nodes=3, inC=1, outC=64, [1<-(I0-L0) | 2<-(I0-L1,I1-L2)], genotype_str: lstm_3~0|lstm_1~0|lstm_2~1
  linear_layers: [dropout->linear]
  (layers): ModuleList(
    (0): LSTM(
      (lstm): LSTM(1, 64, num_layers=3, batch_first=True)
    )
    (1): LSTM(
      (lstm): LSTM(1, 64, batch_first=True)
    )
    (2): LSTM(
      (lstm): LSTM(64, 64, num_layers=2, batch_first=True)
    )
  )
  (linear_layers): ModuleList(
    (0): Dropout(p=0.1, inplace=False)
    (1): Linear(in_features=3072, out_features=1, bias=True)
  )
)
tr_params :: epochs = 100, patience = 20, batch_size = 256, window_size = 48, data_size = 100
Model FLOPs: 8.187M, Model Params: 170.497K
learning rate scheduling :: (optimizer, mode='min', factor=0.1, patience=5, verbose=True)
total_samples :: train_dataset = 2136000, train_dataloader = 2136000
total_samples :: valid_dataset = 283200, valid_dataloader = 283200
Epoch ::  1 || Loss: 0.42187493 || it_count: 8344 || Val Loss: 0.44747240 || Val it_count: 1107 || Current Learning Rate: 0.001 || Time: 00:09:24.06
Epoch ::  2 || Loss: 0.42015729 || it_count: 8344 || Val Loss: 0.44503897 || Val it_count: 1107 || Current Learning Rate: 0.001 || Time: 00:18:43.82
Epoch ::  3 || Loss: 0.41961317 || it_count: 8344 || Val Loss: 0.44442111 || Val it_count: 1107 || Current Learning Rate: 0.001 || Time: 00:28:6.63
Epoch ::  4 || Loss: 0.41917955 || it_count: 8344 || Val Loss: 0.44406654 || Val it_count: 1107 || Current Learning Rate: 0.001 || Time: 00:37:31.03
Epoch ::  5 || Loss: 0.41891730 || it_count: 8344 || Val Loss: 0.44340451 || Val it_count: 1107 || Current Learning Rate: 0.001 || Time: 00:46:54.10
Epoch ::  6 || Loss: 0.41870306 || it_count: 8344 || Val Loss: 0.44285359 || Val it_count: 1107 || Current Learning Rate: 0.001 || Time: 00:56:16.87
Epoch ::  7 || Loss: 0.41854122 || it_count: 8344 || Val Loss: 0.44252239 || Val it_count: 1107 || Current Learning Rate: 0.001 || Time: 01:05:41.40
Epoch ::  8 || Loss: 0.41840817 || it_count: 8344 || Val Loss: 0.44208955 || Val it_count: 1107 || Current Learning Rate: 0.001 || Time: 01:15:6.30
Epoch ::  9 || Loss: 0.41816791 || it_count: 8344 || Val Loss: 0.44105820 || Val it_count: 1107 || Current Learning Rate: 0.001 || Time: 01:24:30.90
Epoch :: 10 || Loss: 0.41808742 || it_count: 8344 || Val Loss: 0.44101960 || Val it_count: 1107 || Current Learning Rate: 0.001 || Time: 01:33:58.53
Epoch :: 11 || Loss: 0.41792448 || it_count: 8344 || Val Loss: 0.44111454 || Val it_count: 1107 || Current Learning Rate: 0.001 || Time: 01:43:24.48
Epoch :: 12 || Loss: 0.41781034 || it_count: 8344 || Val Loss: 0.44173804 || Val it_count: 1107 || Current Learning Rate: 0.001 || Time: 01:52:50.35
Epoch :: 13 || Loss: 0.41775783 || it_count: 8344 || Val Loss: 0.44174626 || Val it_count: 1107 || Current Learning Rate: 0.001 || Time: 02:02:16.47
Epoch :: 14 || Loss: 0.41761623 || it_count: 8344 || Val Loss: 0.44199953 || Val it_count: 1107 || Current Learning Rate: 0.001 || Time: 02:11:42.76
Epoch :: 15 || Loss: 0.41762342 || it_count: 8344 || Val Loss: 0.44093577 || Val it_count: 1107 || Current Learning Rate: 0.001 || Time: 02:21:7.76
Epoch :: 16 || Loss: 0.41751807 || it_count: 8344 || Val Loss: 0.44156409 || Val it_count: 1107 || Current Learning Rate: 0.001 || Time: 02:30:33.29
Epoch :: 17 || Loss: 0.41753952 || it_count: 8344 || Val Loss: 0.44107734 || Val it_count: 1107 || Current Learning Rate: 0.001 || Time: 02:39:57.54
Epoch :: 18 || Loss: 0.41753767 || it_count: 8344 || Val Loss: 0.44176609 || Val it_count: 1107 || Current Learning Rate: 0.001 || Time: 02:49:24.97
Epoch :: 19 || Loss: 0.41747112 || it_count: 8344 || Val Loss: 0.44105454 || Val it_count: 1107 || Current Learning Rate: 0.001 || Time: 02:58:51.57
Epoch :: 20 || Loss: 0.41736771 || it_count: 8344 || Val Loss: 0.44119544 || Val it_count: 1107 || Current Learning Rate: 0.001 || Time: 03:08:16.68
Epoch :: 21 || Loss: 0.41717626 || it_count: 8344 || Val Loss: 0.44064813 || Val it_count: 1107 || Current Learning Rate: 0.001 || Time: 03:17:40.60
Epoch :: 22 || Loss: 0.41716221 || it_count: 8344 || Val Loss: 0.43982977 || Val it_count: 1107 || Current Learning Rate: 0.001 || Time: 03:27:4.42
Epoch :: 23 || Loss: 0.41702452 || it_count: 8344 || Val Loss: 0.44027310 || Val it_count: 1107 || Current Learning Rate: 0.001 || Time: 03:36:31.79
Epoch :: 24 || Loss: 0.41702235 || it_count: 8344 || Val Loss: 0.44004472 || Val it_count: 1107 || Current Learning Rate: 0.001 || Time: 03:45:58.09
Epoch :: 25 || Loss: 0.41689045 || it_count: 8344 || Val Loss: 0.43967817 || Val it_count: 1107 || Current Learning Rate: 0.001 || Time: 03:55:26.96
Epoch :: 26 || Loss: 0.41670981 || it_count: 8344 || Val Loss: 0.43988008 || Val it_count: 1107 || Current Learning Rate: 0.001 || Time: 04:04:55.56
Epoch :: 27 || Loss: 0.41666414 || it_count: 8344 || Val Loss: 0.44004198 || Val it_count: 1107 || Current Learning Rate: 0.001 || Time: 04:14:23.11
Epoch :: 28 || Loss: 0.41653118 || it_count: 8344 || Val Loss: 0.43995878 || Val it_count: 1107 || Current Learning Rate: 0.001 || Time: 04:23:50.65
Epoch :: 29 || Loss: 0.41638551 || it_count: 8344 || Val Loss: 0.43923318 || Val it_count: 1107 || Current Learning Rate: 0.001 || Time: 04:33:18.85
Epoch :: 30 || Loss: 0.41636243 || it_count: 8344 || Val Loss: 0.44045469 || Val it_count: 1107 || Current Learning Rate: 0.001 || Time: 04:42:46.20
Epoch :: 31 || Loss: 0.41655194 || it_count: 8344 || Val Loss: 0.43974263 || Val it_count: 1107 || Current Learning Rate: 0.001 || Time: 04:52:13.18
Epoch :: 32 || Loss: 0.41658930 || it_count: 8344 || Val Loss: 0.43988588 || Val it_count: 1107 || Current Learning Rate: 0.001 || Time: 05:01:41.10
Epoch :: 33 || Loss: 0.41656864 || it_count: 8344 || Val Loss: 0.44093144 || Val it_count: 1107 || Current Learning Rate: 0.001 || Time: 05:11:7.98
Epoch :: 34 || Loss: 0.41661700 || it_count: 8344 || Val Loss: 0.44040875 || Val it_count: 1107 || Current Learning Rate: 0.001 || Time: 05:20:34.49
Epoch 00019: reducing learning rate of group 0 to 1.0000e-04.
Epoch :: 35 || Loss: 0.41660408 || it_count: 8344 || Val Loss: 0.44046866 || Val it_count: 1107 || Current Learning Rate: 0.0001 || Time: 05:30:1.70
Epoch :: 36 || Loss: 0.42188752 || it_count: 8344 || Val Loss: 0.42715711 || Val it_count: 1107 || Current Learning Rate: 0.0001 || Time: 05:39:28.86
Epoch :: 37 || Loss: 0.41826821 || it_count: 8344 || Val Loss: 0.42596895 || Val it_count: 1107 || Current Learning Rate: 0.0001 || Time: 05:48:56.54
Epoch :: 38 || Loss: 0.41746510 || it_count: 8344 || Val Loss: 0.42564169 || Val it_count: 1107 || Current Learning Rate: 0.0001 || Time: 05:58:23.85
Epoch :: 39 || Loss: 0.41724978 || it_count: 8344 || Val Loss: 0.42539426 || Val it_count: 1107 || Current Learning Rate: 0.0001 || Time: 06:07:51.90
Epoch :: 40 || Loss: 0.41708087 || it_count: 8344 || Val Loss: 0.42528240 || Val it_count: 1107 || Current Learning Rate: 0.0001 || Time: 06:17:20.13
Epoch :: 41 || Loss: 0.41696501 || it_count: 8344 || Val Loss: 0.42509435 || Val it_count: 1107 || Current Learning Rate: 0.0001 || Time: 06:26:46.95
Epoch :: 42 || Loss: 0.41681805 || it_count: 8344 || Val Loss: 0.42496042 || Val it_count: 1107 || Current Learning Rate: 0.0001 || Time: 06:36:13.41
Epoch :: 43 || Loss: 0.41680766 || it_count: 8344 || Val Loss: 0.42495854 || Val it_count: 1107 || Current Learning Rate: 0.0001 || Time: 06:45:40.66
Epoch :: 44 || Loss: 0.41669591 || it_count: 8344 || Val Loss: 0.42472707 || Val it_count: 1107 || Current Learning Rate: 0.0001 || Time: 06:55:8.87
Epoch :: 45 || Loss: 0.41663507 || it_count: 8344 || Val Loss: 0.42471684 || Val it_count: 1107 || Current Learning Rate: 0.0001 || Time: 07:04:36.35
Epoch :: 46 || Loss: 0.41659096 || it_count: 8344 || Val Loss: 0.42462956 || Val it_count: 1107 || Current Learning Rate: 0.0001 || Time: 07:14:3.68
Epoch :: 47 || Loss: 0.41656666 || it_count: 8344 || Val Loss: 0.42479442 || Val it_count: 1107 || Current Learning Rate: 0.0001 || Time: 07:23:30.78
Epoch :: 48 || Loss: 0.41646332 || it_count: 8344 || Val Loss: 0.42450372 || Val it_count: 1107 || Current Learning Rate: 0.0001 || Time: 07:32:58.48
Epoch :: 49 || Loss: 0.41638170 || it_count: 8344 || Val Loss: 0.42445278 || Val it_count: 1107 || Current Learning Rate: 0.0001 || Time: 07:42:26.36
Epoch :: 50 || Loss: 0.41634642 || it_count: 8344 || Val Loss: 0.42422510 || Val it_count: 1107 || Current Learning Rate: 0.0001 || Time: 07:51:53.45
Epoch :: 51 || Loss: 0.41627657 || it_count: 8344 || Val Loss: 0.42419905 || Val it_count: 1107 || Current Learning Rate: 0.0001 || Time: 08:01:19.66
Epoch :: 52 || Loss: 0.41630977 || it_count: 8344 || Val Loss: 0.42413833 || Val it_count: 1107 || Current Learning Rate: 0.0001 || Time: 08:10:47.42
Epoch :: 53 || Loss: 0.41614421 || it_count: 8344 || Val Loss: 0.42385075 || Val it_count: 1107 || Current Learning Rate: 0.0001 || Time: 08:20:15.09
Epoch :: 54 || Loss: 0.41610744 || it_count: 8344 || Val Loss: 0.42373342 || Val it_count: 1107 || Current Learning Rate: 0.0001 || Time: 08:29:41.85
Epoch :: 55 || Loss: 0.41593672 || it_count: 8344 || Val Loss: 0.42351859 || Val it_count: 1107 || Current Learning Rate: 0.0001 || Time: 08:39:10.71
Epoch :: 56 || Loss: 0.41588083 || it_count: 8344 || Val Loss: 0.42317736 || Val it_count: 1107 || Current Learning Rate: 0.0001 || Time: 08:48:38.23
Epoch :: 57 || Loss: 0.41579207 || it_count: 8344 || Val Loss: 0.42301339 || Val it_count: 1107 || Current Learning Rate: 0.0001 || Time: 08:58:6.77
Epoch :: 58 || Loss: 0.41571566 || it_count: 8344 || Val Loss: 0.42276851 || Val it_count: 1107 || Current Learning Rate: 0.0001 || Time: 09:07:33.79
Epoch :: 59 || Loss: 0.41561471 || it_count: 8344 || Val Loss: 0.42267432 || Val it_count: 1107 || Current Learning Rate: 0.0001 || Time: 09:17:0.26
Epoch :: 60 || Loss: 0.41547392 || it_count: 8344 || Val Loss: 0.42227864 || Val it_count: 1107 || Current Learning Rate: 0.0001 || Time: 09:26:27.32
Epoch :: 61 || Loss: 0.41543753 || it_count: 8344 || Val Loss: 0.42223857 || Val it_count: 1107 || Current Learning Rate: 0.0001 || Time: 09:35:53.47
Epoch :: 62 || Loss: 0.41527067 || it_count: 8344 || Val Loss: 0.42200222 || Val it_count: 1107 || Current Learning Rate: 0.0001 || Time: 09:45:21.51
Epoch :: 63 || Loss: 0.41529233 || it_count: 8344 || Val Loss: 0.42204066 || Val it_count: 1107 || Current Learning Rate: 0.0001 || Time: 09:54:49.39
Epoch :: 64 || Loss: 0.41518645 || it_count: 8344 || Val Loss: 0.42276117 || Val it_count: 1107 || Current Learning Rate: 0.0001 || Time: 10:04:15.97
Epoch :: 65 || Loss: 0.41522224 || it_count: 8344 || Val Loss: 0.42189609 || Val it_count: 1107 || Current Learning Rate: 0.0001 || Time: 10:13:42.45
Epoch :: 66 || Loss: 0.41500902 || it_count: 8344 || Val Loss: 0.42228502 || Val it_count: 1107 || Current Learning Rate: 0.0001 || Time: 10:23:10.41
Epoch :: 67 || Loss: 0.41495214 || it_count: 8344 || Val Loss: 0.42232183 || Val it_count: 1107 || Current Learning Rate: 0.0001 || Time: 10:32:37.58
Epoch :: 68 || Loss: 0.41484099 || it_count: 8344 || Val Loss: 0.42200422 || Val it_count: 1107 || Current Learning Rate: 0.0001 || Time: 10:42:4.43
Epoch :: 69 || Loss: 0.41473669 || it_count: 8344 || Val Loss: 0.42179800 || Val it_count: 1107 || Current Learning Rate: 0.0001 || Time: 10:51:30.64
Epoch :: 70 || Loss: 0.41472865 || it_count: 8344 || Val Loss: 0.42153726 || Val it_count: 1107 || Current Learning Rate: 0.0001 || Time: 11:00:57.72
Epoch :: 71 || Loss: 0.41458368 || it_count: 8344 || Val Loss: 0.42166738 || Val it_count: 1107 || Current Learning Rate: 0.0001 || Time: 11:10:26.11
Epoch :: 72 || Loss: 0.41458153 || it_count: 8344 || Val Loss: 0.42193307 || Val it_count: 1107 || Current Learning Rate: 0.0001 || Time: 11:19:52.44
Epoch :: 73 || Loss: 0.41453555 || it_count: 8344 || Val Loss: 0.42138911 || Val it_count: 1107 || Current Learning Rate: 0.0001 || Time: 11:29:19.67
Epoch :: 74 || Loss: 0.41439104 || it_count: 8344 || Val Loss: 0.42163599 || Val it_count: 1107 || Current Learning Rate: 0.0001 || Time: 11:38:46.46
Epoch :: 75 || Loss: 0.41437598 || it_count: 8344 || Val Loss: 0.42171037 || Val it_count: 1107 || Current Learning Rate: 0.0001 || Time: 11:48:12.50
Epoch :: 76 || Loss: 0.41432670 || it_count: 8344 || Val Loss: 0.42160693 || Val it_count: 1107 || Current Learning Rate: 0.0001 || Time: 11:57:39.91
Epoch :: 77 || Loss: 0.41425021 || it_count: 8344 || Val Loss: 0.42146715 || Val it_count: 1107 || Current Learning Rate: 0.0001 || Time: 12:07:6.78
Epoch :: 78 || Loss: 0.41412377 || it_count: 8344 || Val Loss: 0.42199129 || Val it_count: 1107 || Current Learning Rate: 0.0001 || Time: 12:16:33.26
Epoch 00063: reducing learning rate of group 0 to 1.0000e-05.
Epoch :: 79 || Loss: 0.41411723 || it_count: 8344 || Val Loss: 0.42167871 || Val it_count: 1107 || Current Learning Rate: 1e-05 || Time: 12:25:59.46
Epoch :: 80 || Loss: 0.41530642 || it_count: 8344 || Val Loss: 0.41760287 || Val it_count: 1107 || Current Learning Rate: 1e-05 || Time: 12:35:26.05
Epoch :: 81 || Loss: 0.41491013 || it_count: 8344 || Val Loss: 0.41750734 || Val it_count: 1107 || Current Learning Rate: 1e-05 || Time: 12:44:52.99
Epoch :: 82 || Loss: 0.41477025 || it_count: 8344 || Val Loss: 0.41751151 || Val it_count: 1107 || Current Learning Rate: 1e-05 || Time: 12:54:20.18
Epoch :: 83 || Loss: 0.41462033 || it_count: 8344 || Val Loss: 0.41748953 || Val it_count: 1107 || Current Learning Rate: 1e-05 || Time: 13:03:46.97
Epoch :: 84 || Loss: 0.41455691 || it_count: 8344 || Val Loss: 0.41751739 || Val it_count: 1107 || Current Learning Rate: 1e-05 || Time: 13:13:14.40
Epoch :: 85 || Loss: 0.41452311 || it_count: 8344 || Val Loss: 0.41748397 || Val it_count: 1107 || Current Learning Rate: 1e-05 || Time: 13:22:41.02
Epoch :: 86 || Loss: 0.41449005 || it_count: 8344 || Val Loss: 0.41745856 || Val it_count: 1107 || Current Learning Rate: 1e-05 || Time: 13:32:7.99
Epoch :: 87 || Loss: 0.41444005 || it_count: 8344 || Val Loss: 0.41750101 || Val it_count: 1107 || Current Learning Rate: 1e-05 || Time: 13:41:35.82
Epoch :: 88 || Loss: 0.41450464 || it_count: 8344 || Val Loss: 0.41747329 || Val it_count: 1107 || Current Learning Rate: 1e-05 || Time: 13:51:2.50
Epoch :: 89 || Loss: 0.41445723 || it_count: 8344 || Val Loss: 0.41741663 || Val it_count: 1107 || Current Learning Rate: 1e-05 || Time: 14:00:29.76
Epoch :: 90 || Loss: 0.41443007 || it_count: 8344 || Val Loss: 0.41740959 || Val it_count: 1107 || Current Learning Rate: 1e-05 || Time: 14:09:57.09
Epoch :: 91 || Loss: 0.41440742 || it_count: 8344 || Val Loss: 0.41738593 || Val it_count: 1107 || Current Learning Rate: 1e-05 || Time: 14:19:24.46
Epoch :: 92 || Loss: 0.41434872 || it_count: 8344 || Val Loss: 0.41738487 || Val it_count: 1107 || Current Learning Rate: 1e-05 || Time: 14:28:50.49
Epoch :: 93 || Loss: 0.41434331 || it_count: 8344 || Val Loss: 0.41737826 || Val it_count: 1107 || Current Learning Rate: 1e-05 || Time: 14:38:17.87
Epoch :: 94 || Loss: 0.41436595 || it_count: 8344 || Val Loss: 0.41739073 || Val it_count: 1107 || Current Learning Rate: 1e-05 || Time: 14:47:44.34
Epoch :: 95 || Loss: 0.41434823 || it_count: 8344 || Val Loss: 0.41736936 || Val it_count: 1107 || Current Learning Rate: 1e-05 || Time: 14:57:11.27
Epoch :: 96 || Loss: 0.41433661 || it_count: 8344 || Val Loss: 0.41732443 || Val it_count: 1107 || Current Learning Rate: 1e-05 || Time: 15:06:36.85
Epoch :: 97 || Loss: 0.41429252 || it_count: 8344 || Val Loss: 0.41729901 || Val it_count: 1107 || Current Learning Rate: 1e-05 || Time: 15:16:2.28
Epoch :: 98 || Loss: 0.41431881 || it_count: 8344 || Val Loss: 0.41732591 || Val it_count: 1107 || Current Learning Rate: 1e-05 || Time: 15:25:28.52
Epoch :: 99 || Loss: 0.41432553 || it_count: 8344 || Val Loss: 0.41727651 || Val it_count: 1107 || Current Learning Rate: 1e-05 || Time: 15:34:56.11
Epoch :: 100 || Loss: 0.41429115 || it_count: 8344 || Val Loss: 0.41731036 || Val it_count: 1107 || Current Learning Rate: 1e-05 || Time: 15:44:22.68
Done Total time: 15:44:22.68
best_loss: 0.41727650973473135

--------------------Testing--------------------

total_samples :: test_dataset = 139200, test_dataloader = 139200
Epoch ::  1 || Loss: 0.23798124 || it_count: 544 || Time: 00:00:24.38
MAE:  0.25585532
MSE:  0.23800433
RMSE:  0.44420254

--------------------Training--------------------
arch_str :: |none~0|+|lstm_2~0|lstm_1~1|[linear->dropout->linear]
model :: 3F
InferCell(
  info :: nodes=3, inC=1, outC=64, [1<-(I0-L0) | 2<-(I0-L1,I1-L2)], genotype_str: none~0|lstm_2~0|lstm_1~1
  linear_layers: [linear->dropout->linear]
  (layers): ModuleList(
    (0): Zero(C_in=1, C_out=64, stride=1)
    (1): LSTM(
      (lstm): LSTM(1, 64, num_layers=2, batch_first=True)
    )
    (2): LSTM(
      (lstm): LSTM(64, 64, batch_first=True)
    )
  )
  (linear_layers): ModuleList(
    (0): Linear(in_features=3072, out_features=1536, bias=True)
    (1): Dropout(p=0.1, inplace=False)
    (2): Linear(in_features=1536, out_features=1, bias=True)
  )
)
tr_params :: epochs = 100, patience = 20, batch_size = 256, window_size = 48, data_size = 100
Model FLOPs: 8.812M, Model Params: 4.805M
learning rate scheduling :: (optimizer, mode='min', factor=0.1, patience=5, verbose=True)
total_samples :: train_dataset = 2136000, train_dataloader = 2136000
total_samples :: valid_dataset = 283200, valid_dataloader = 283200
Epoch ::  1 || Loss: 0.42452999 || it_count: 8344 || Val Loss: 0.46852677 || Val it_count: 1107 || Current Learning Rate: 0.001 || Time: 00:10:54.29
Epoch ::  2 || Loss: 0.41739855 || it_count: 8344 || Val Loss: 0.44832432 || Val it_count: 1107 || Current Learning Rate: 0.001 || Time: 00:21:45.65
Epoch ::  3 || Loss: 0.41638493 || it_count: 8344 || Val Loss: 0.44648832 || Val it_count: 1107 || Current Learning Rate: 0.001 || Time: 00:32:37.41
Epoch ::  4 || Loss: 0.41607320 || it_count: 8344 || Val Loss: 0.44605916 || Val it_count: 1107 || Current Learning Rate: 0.001 || Time: 00:43:30.96
Epoch ::  5 || Loss: 0.41595938 || it_count: 8344 || Val Loss: 0.44531999 || Val it_count: 1107 || Current Learning Rate: 0.001 || Time: 00:54:25.04
Epoch ::  6 || Loss: 0.41565720 || it_count: 8344 || Val Loss: 0.44523556 || Val it_count: 1107 || Current Learning Rate: 0.001 || Time: 01:05:19.64
Epoch ::  7 || Loss: 0.41554699 || it_count: 8344 || Val Loss: 0.44600580 || Val it_count: 1107 || Current Learning Rate: 0.001 || Time: 01:16:16.17
Epoch ::  8 || Loss: 0.41538768 || it_count: 8344 || Val Loss: 0.44644127 || Val it_count: 1107 || Current Learning Rate: 0.001 || Time: 01:27:15.44
Epoch ::  9 || Loss: 0.41520921 || it_count: 8344 || Val Loss: 0.44628385 || Val it_count: 1107 || Current Learning Rate: 0.001 || Time: 01:38:15.46
Epoch :: 10 || Loss: 0.41487201 || it_count: 8344 || Val Loss: 0.44541101 || Val it_count: 1107 || Current Learning Rate: 0.001 || Time: 01:49:14.96
Epoch :: 11 || Loss: 0.41458763 || it_count: 8344 || Val Loss: 0.44520785 || Val it_count: 1107 || Current Learning Rate: 0.001 || Time: 02:00:15.54
Epoch :: 12 || Loss: 0.41440246 || it_count: 8344 || Val Loss: 0.44622249 || Val it_count: 1107 || Current Learning Rate: 0.001 || Time: 02:11:16.99
Epoch :: 13 || Loss: 0.41410117 || it_count: 8344 || Val Loss: 0.44645078 || Val it_count: 1107 || Current Learning Rate: 0.001 || Time: 02:22:18.16
Epoch :: 14 || Loss: 0.41371453 || it_count: 8344 || Val Loss: 0.44713560 || Val it_count: 1107 || Current Learning Rate: 0.001 || Time: 02:33:19.40
Epoch :: 15 || Loss: 0.41345097 || it_count: 8344 || Val Loss: 0.44795011 || Val it_count: 1107 || Current Learning Rate: 0.001 || Time: 02:44:20.08
Epoch :: 16 || Loss: 0.41315510 || it_count: 8344 || Val Loss: 0.44843164 || Val it_count: 1107 || Current Learning Rate: 0.001 || Time: 02:55:21.92
Epoch :: 17 || Loss: 0.41291537 || it_count: 8344 || Val Loss: 0.44880319 || Val it_count: 1107 || Current Learning Rate: 0.001 || Time: 03:06:23.24
Epoch :: 18 || Loss: 0.41254285 || it_count: 8344 || Val Loss: 0.44912364 || Val it_count: 1107 || Current Learning Rate: 0.001 || Time: 03:17:24.42
Epoch :: 19 || Loss: 0.41211857 || it_count: 8344 || Val Loss: 0.44866034 || Val it_count: 1107 || Current Learning Rate: 0.001 || Time: 03:28:25.31
Epoch :: 20 || Loss: 0.41170195 || it_count: 8344 || Val Loss: 0.44924906 || Val it_count: 1107 || Current Learning Rate: 0.001 || Time: 03:39:27.08
Epoch :: 21 || Loss: 0.41124022 || it_count: 8344 || Val Loss: 0.44955354 || Val it_count: 1107 || Current Learning Rate: 0.001 || Time: 03:50:29.45
Epoch :: 22 || Loss: 0.41079624 || it_count: 8344 || Val Loss: 0.44998884 || Val it_count: 1107 || Current Learning Rate: 0.001 || Time: 04:01:30.57
Epoch :: 23 || Loss: 0.41032642 || it_count: 8344 || Val Loss: 0.45057830 || Val it_count: 1107 || Current Learning Rate: 0.001 || Time: 04:12:31.75
Epoch :: 24 || Loss: 0.40993938 || it_count: 8344 || Val Loss: 0.45033166 || Val it_count: 1107 || Current Learning Rate: 0.001 || Time: 04:23:33.88
Epoch 00009: reducing learning rate of group 0 to 1.0000e-04.
Epoch :: 25 || Loss: 0.40939718 || it_count: 8344 || Val Loss: 0.45107347 || Val it_count: 1107 || Current Learning Rate: 0.0001 || Time: 04:34:36.22
Epoch :: 26 || Loss: 0.41693739 || it_count: 8344 || Val Loss: 0.43341007 || Val it_count: 1107 || Current Learning Rate: 0.0001 || Time: 04:45:37.91
Epoch :: 27 || Loss: 0.41334590 || it_count: 8344 || Val Loss: 0.43205259 || Val it_count: 1107 || Current Learning Rate: 0.0001 || Time: 04:56:39.05
Epoch :: 28 || Loss: 0.41229578 || it_count: 8344 || Val Loss: 0.43116671 || Val it_count: 1107 || Current Learning Rate: 0.0001 || Time: 05:07:41.13
Epoch :: 29 || Loss: 0.41150492 || it_count: 8344 || Val Loss: 0.43034805 || Val it_count: 1107 || Current Learning Rate: 0.0001 || Time: 05:18:42.79
Epoch :: 30 || Loss: 0.41083994 || it_count: 8344 || Val Loss: 0.42994846 || Val it_count: 1107 || Current Learning Rate: 0.0001 || Time: 05:29:44.53
Epoch :: 31 || Loss: 0.41037234 || it_count: 8344 || Val Loss: 0.42953963 || Val it_count: 1107 || Current Learning Rate: 0.0001 || Time: 05:40:45.70
Epoch :: 32 || Loss: 0.41005633 || it_count: 8344 || Val Loss: 0.42959103 || Val it_count: 1107 || Current Learning Rate: 0.0001 || Time: 05:51:47.81
Epoch :: 33 || Loss: 0.40984058 || it_count: 8344 || Val Loss: 0.42946896 || Val it_count: 1107 || Current Learning Rate: 0.0001 || Time: 06:02:49.72
Epoch :: 34 || Loss: 0.40957032 || it_count: 8344 || Val Loss: 0.42931180 || Val it_count: 1107 || Current Learning Rate: 0.0001 || Time: 06:13:51.24
Epoch :: 35 || Loss: 0.40933413 || it_count: 8344 || Val Loss: 0.42934126 || Val it_count: 1107 || Current Learning Rate: 0.0001 || Time: 06:24:52.31
Epoch :: 36 || Loss: 0.40913491 || it_count: 8344 || Val Loss: 0.42938318 || Val it_count: 1107 || Current Learning Rate: 0.0001 || Time: 06:35:54.39
Epoch :: 37 || Loss: 0.40894947 || it_count: 8344 || Val Loss: 0.42920364 || Val it_count: 1107 || Current Learning Rate: 0.0001 || Time: 06:46:56.36
Epoch :: 38 || Loss: 0.40874153 || it_count: 8344 || Val Loss: 0.42921795 || Val it_count: 1107 || Current Learning Rate: 0.0001 || Time: 06:57:57.38
Epoch :: 39 || Loss: 0.40860517 || it_count: 8344 || Val Loss: 0.42932976 || Val it_count: 1107 || Current Learning Rate: 0.0001 || Time: 07:08:58.27
Epoch :: 40 || Loss: 0.40843317 || it_count: 8344 || Val Loss: 0.42921476 || Val it_count: 1107 || Current Learning Rate: 0.0001 || Time: 07:20:0.91
Epoch :: 41 || Loss: 0.40825729 || it_count: 8344 || Val Loss: 0.42927855 || Val it_count: 1107 || Current Learning Rate: 0.0001 || Time: 07:31:2.99
Epoch :: 42 || Loss: 0.40810881 || it_count: 8344 || Val Loss: 0.42926705 || Val it_count: 1107 || Current Learning Rate: 0.0001 || Time: 07:42:4.44
Epoch 00027: reducing learning rate of group 0 to 1.0000e-05.
Epoch :: 43 || Loss: 0.40792547 || it_count: 8344 || Val Loss: 0.42924289 || Val it_count: 1107 || Current Learning Rate: 1e-05 || Time: 07:53:5.08
Epoch :: 44 || Loss: 0.41185529 || it_count: 8344 || Val Loss: 0.41562569 || Val it_count: 1107 || Current Learning Rate: 1e-05 || Time: 08:04:7.09
Epoch :: 45 || Loss: 0.40981980 || it_count: 8344 || Val Loss: 0.41498983 || Val it_count: 1107 || Current Learning Rate: 1e-05 || Time: 08:15:8.88
Epoch :: 46 || Loss: 0.40955016 || it_count: 8344 || Val Loss: 0.41488833 || Val it_count: 1107 || Current Learning Rate: 1e-05 || Time: 08:26:9.91
Epoch :: 47 || Loss: 0.40937941 || it_count: 8344 || Val Loss: 0.41492368 || Val it_count: 1107 || Current Learning Rate: 1e-05 || Time: 08:37:10.99
Epoch :: 48 || Loss: 0.40928523 || it_count: 8344 || Val Loss: 0.41491530 || Val it_count: 1107 || Current Learning Rate: 1e-05 || Time: 08:48:13.14
Epoch :: 49 || Loss: 0.40922385 || it_count: 8344 || Val Loss: 0.41497287 || Val it_count: 1107 || Current Learning Rate: 1e-05 || Time: 08:59:15.43
Epoch :: 50 || Loss: 0.40914506 || it_count: 8344 || Val Loss: 0.41498147 || Val it_count: 1107 || Current Learning Rate: 1e-05 || Time: 09:10:16.71
Epoch :: 51 || Loss: 0.40910138 || it_count: 8344 || Val Loss: 0.41496768 || Val it_count: 1107 || Current Learning Rate: 1e-05 || Time: 09:21:17.82
Epoch 00036: reducing learning rate of group 0 to 1.0000e-06.
Epoch :: 52 || Loss: 0.40905269 || it_count: 8344 || Val Loss: 0.41497785 || Val it_count: 1107 || Current Learning Rate: 1.0000000000000002e-06 || Time: 09:32:19.75
Epoch :: 53 || Loss: 0.40949072 || it_count: 8344 || Val Loss: 0.41369574 || Val it_count: 1107 || Current Learning Rate: 1.0000000000000002e-06 || Time: 09:43:21.88
Epoch :: 54 || Loss: 0.40925549 || it_count: 8344 || Val Loss: 0.41355491 || Val it_count: 1107 || Current Learning Rate: 1.0000000000000002e-06 || Time: 09:54:22.94
Epoch :: 55 || Loss: 0.40918693 || it_count: 8344 || Val Loss: 0.41351113 || Val it_count: 1107 || Current Learning Rate: 1.0000000000000002e-06 || Time: 10:05:23.95
Epoch :: 56 || Loss: 0.40918624 || it_count: 8344 || Val Loss: 0.41350170 || Val it_count: 1107 || Current Learning Rate: 1.0000000000000002e-06 || Time: 10:16:26.10
Epoch :: 57 || Loss: 0.40916765 || it_count: 8344 || Val Loss: 0.41348798 || Val it_count: 1107 || Current Learning Rate: 1.0000000000000002e-06 || Time: 10:27:27.53
Epoch :: 58 || Loss: 0.40910582 || it_count: 8344 || Val Loss: 0.41347798 || Val it_count: 1107 || Current Learning Rate: 1.0000000000000002e-06 || Time: 10:38:28.66
Epoch :: 59 || Loss: 0.40911262 || it_count: 8344 || Val Loss: 0.41347140 || Val it_count: 1107 || Current Learning Rate: 1.0000000000000002e-06 || Time: 10:49:29.82
Epoch :: 60 || Loss: 0.40911334 || it_count: 8344 || Val Loss: 0.41346732 || Val it_count: 1107 || Current Learning Rate: 1.0000000000000002e-06 || Time: 11:00:32.13
Epoch :: 61 || Loss: 0.40914801 || it_count: 8344 || Val Loss: 0.41345901 || Val it_count: 1107 || Current Learning Rate: 1.0000000000000002e-06 || Time: 11:11:34.34
Epoch :: 62 || Loss: 0.40910807 || it_count: 8344 || Val Loss: 0.41345654 || Val it_count: 1107 || Current Learning Rate: 1.0000000000000002e-06 || Time: 11:22:35.68
Epoch :: 63 || Loss: 0.40910701 || it_count: 8344 || Val Loss: 0.41344521 || Val it_count: 1107 || Current Learning Rate: 1.0000000000000002e-06 || Time: 11:33:36.96
Epoch :: 64 || Loss: 0.40908543 || it_count: 8344 || Val Loss: 0.41344119 || Val it_count: 1107 || Current Learning Rate: 1.0000000000000002e-06 || Time: 11:44:39.33
Epoch :: 65 || Loss: 0.40909045 || it_count: 8344 || Val Loss: 0.41343538 || Val it_count: 1107 || Current Learning Rate: 1.0000000000000002e-06 || Time: 11:55:41.25
Epoch 00050: reducing learning rate of group 0 to 1.0000e-07.
Early stopping triggered due to learning rate below threshold.
Done Total time: 12:06:42.57
best_loss: 0.4134353807346387

--------------------Testing--------------------

total_samples :: test_dataset = 139200, test_dataloader = 139200
Epoch ::  1 || Loss: 0.23660082 || it_count: 544 || Time: 00:00:25.97
MAE:  0.25380737
MSE:  0.2366198
RMSE:  0.44196725

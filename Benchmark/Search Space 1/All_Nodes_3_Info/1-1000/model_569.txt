--------------------Training--------------------
arch_str :: |skip_connect~0|+|none~0|lstm_2~1|[linear->linear]
model :: 3E
InferCell(
  info :: nodes=3, inC=1, outC=64, [1<-(I0-L0) | 2<-(I0-L1,I1-L2)], genotype_str: skip_connect~0|none~0|lstm_2~1
  linear_layers: [linear->linear]
  (layers): ModuleList(
    (0): FactorizedReduce(
      C_in=1, C_out=64, stride=1
      (relu): ReLU()
      (conv): Conv1d(1, 64, kernel_size=(1,), stride=(1,), bias=False)
      (bn): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (1): Zero(C_in=1, C_out=64, stride=1)
    (2): LSTM(
      (lstm): LSTM(64, 64, num_layers=2, batch_first=True)
    )
  )
  (linear_layers): ModuleList(
    (0): Linear(in_features=3072, out_features=1536, bias=True)
    (1): Linear(in_features=1536, out_features=1, bias=True)
  )
)
tr_params :: epochs = 100, patience = 20, batch_size = 256, window_size = 48, data_size = 100
Model FLOPs: 7.980M, Model Params: 4.788M
learning rate scheduling :: (optimizer, mode='min', factor=0.1, patience=5, verbose=True)
total_samples :: train_dataset = 2136000, train_dataloader = 2136000
total_samples :: valid_dataset = 283200, valid_dataloader = 283200
Epoch ::  1 || Loss: 0.45374322 || it_count: 8344 || Val Loss: 0.50951286 || Val it_count: 1107 || Current Learning Rate: 0.001 || Time: 00:07:59.95
Epoch ::  2 || Loss: 0.45522721 || it_count: 8344 || Val Loss: 0.54146369 || Val it_count: 1107 || Current Learning Rate: 0.001 || Time: 00:16:1.29
Epoch ::  3 || Loss: 0.45074442 || it_count: 8344 || Val Loss: 0.53979741 || Val it_count: 1107 || Current Learning Rate: 0.001 || Time: 00:24:2.11
Epoch ::  4 || Loss: 0.44630876 || it_count: 8344 || Val Loss: 0.53892224 || Val it_count: 1107 || Current Learning Rate: 0.001 || Time: 00:32:3.84
Epoch ::  5 || Loss: 0.45051456 || it_count: 8344 || Val Loss: 0.53331997 || Val it_count: 1107 || Current Learning Rate: 0.001 || Time: 00:40:5.48
Epoch ::  6 || Loss: 0.44678058 || it_count: 8344 || Val Loss: 0.53046334 || Val it_count: 1107 || Current Learning Rate: 0.001 || Time: 00:48:6.99
Epoch ::  7 || Loss: 0.44881546 || it_count: 8344 || Val Loss: 0.51825623 || Val it_count: 1107 || Current Learning Rate: 0.001 || Time: 00:56:7.81
Epoch ::  8 || Loss: 0.44640015 || it_count: 8344 || Val Loss: 0.52491333 || Val it_count: 1107 || Current Learning Rate: 0.001 || Time: 01:04:8.91
Epoch ::  9 || Loss: 0.44637252 || it_count: 8344 || Val Loss: 0.50876946 || Val it_count: 1107 || Current Learning Rate: 0.001 || Time: 01:12:10.67
Epoch :: 10 || Loss: 0.44295910 || it_count: 8344 || Val Loss: 0.50494082 || Val it_count: 1107 || Current Learning Rate: 0.001 || Time: 01:20:11.47
Epoch :: 11 || Loss: 0.44146360 || it_count: 8344 || Val Loss: 0.50281180 || Val it_count: 1107 || Current Learning Rate: 0.001 || Time: 01:28:11.92
Epoch :: 12 || Loss: 0.44050804 || it_count: 8344 || Val Loss: 0.49698768 || Val it_count: 1107 || Current Learning Rate: 0.001 || Time: 01:36:13.63
Epoch :: 13 || Loss: 0.44094545 || it_count: 8344 || Val Loss: 0.49532697 || Val it_count: 1107 || Current Learning Rate: 0.001 || Time: 01:44:13.65
Epoch :: 14 || Loss: 0.44057758 || it_count: 8344 || Val Loss: 0.49279259 || Val it_count: 1107 || Current Learning Rate: 0.001 || Time: 01:52:14.23
Epoch :: 15 || Loss: 0.43999397 || it_count: 8344 || Val Loss: 0.49834561 || Val it_count: 1107 || Current Learning Rate: 0.001 || Time: 02:00:15.00
Epoch :: 16 || Loss: 0.44178127 || it_count: 8344 || Val Loss: 0.50509662 || Val it_count: 1107 || Current Learning Rate: 0.001 || Time: 02:08:14.74
Epoch :: 17 || Loss: 0.43986018 || it_count: 8344 || Val Loss: 0.50474015 || Val it_count: 1107 || Current Learning Rate: 0.001 || Time: 02:16:16.90
Epoch :: 18 || Loss: 0.44428094 || it_count: 8344 || Val Loss: 0.51429458 || Val it_count: 1107 || Current Learning Rate: 0.001 || Time: 02:24:17.99
Epoch :: 19 || Loss: 0.44923179 || it_count: 8344 || Val Loss: 0.52749546 || Val it_count: 1107 || Current Learning Rate: 0.001 || Time: 02:32:18.66
Epoch :: 20 || Loss: 0.45117268 || it_count: 8344 || Val Loss: 0.52397810 || Val it_count: 1107 || Current Learning Rate: 0.001 || Time: 02:40:21.13
Epoch :: 21 || Loss: 0.44333427 || it_count: 8344 || Val Loss: 0.51560065 || Val it_count: 1107 || Current Learning Rate: 0.001 || Time: 02:48:22.72
Epoch :: 22 || Loss: 0.44262116 || it_count: 8344 || Val Loss: 0.50774980 || Val it_count: 1107 || Current Learning Rate: 0.001 || Time: 02:56:24.70
Epoch :: 23 || Loss: 0.44327881 || it_count: 8344 || Val Loss: 0.50179950 || Val it_count: 1107 || Current Learning Rate: 0.001 || Time: 03:04:26.32
Epoch :: 24 || Loss: 0.44071577 || it_count: 8344 || Val Loss: 0.50673422 || Val it_count: 1107 || Current Learning Rate: 0.001 || Time: 03:12:27.05
Epoch :: 25 || Loss: 0.43894434 || it_count: 8344 || Val Loss: 0.49685401 || Val it_count: 1107 || Current Learning Rate: 0.001 || Time: 03:20:29.08
Epoch :: 26 || Loss: 0.43856123 || it_count: 8344 || Val Loss: 0.49892878 || Val it_count: 1107 || Current Learning Rate: 0.001 || Time: 03:28:31.11
Epoch :: 27 || Loss: 0.43683812 || it_count: 8344 || Val Loss: 0.50520064 || Val it_count: 1107 || Current Learning Rate: 0.001 || Time: 03:36:33.52
Epoch :: 28 || Loss: 0.43550439 || it_count: 8344 || Val Loss: 0.50178872 || Val it_count: 1107 || Current Learning Rate: 0.001 || Time: 03:44:35.34
Epoch :: 29 || Loss: 0.43503733 || it_count: 8344 || Val Loss: 0.50403130 || Val it_count: 1107 || Current Learning Rate: 0.001 || Time: 03:52:36.82
Epoch :: 30 || Loss: 0.43435683 || it_count: 8344 || Val Loss: 0.50043115 || Val it_count: 1107 || Current Learning Rate: 0.001 || Time: 04:00:39.06
Epoch 00015: reducing learning rate of group 0 to 1.0000e-04.
Epoch :: 31 || Loss: 0.43345545 || it_count: 8344 || Val Loss: 0.50104695 || Val it_count: 1107 || Current Learning Rate: 0.0001 || Time: 04:08:40.58
Epoch :: 32 || Loss: 0.43888329 || it_count: 8344 || Val Loss: 0.48952200 || Val it_count: 1107 || Current Learning Rate: 0.0001 || Time: 04:16:41.71
Epoch :: 33 || Loss: 0.43063847 || it_count: 8344 || Val Loss: 0.48869836 || Val it_count: 1107 || Current Learning Rate: 0.0001 || Time: 04:24:43.56
Epoch :: 34 || Loss: 0.42743019 || it_count: 8344 || Val Loss: 0.48973938 || Val it_count: 1107 || Current Learning Rate: 0.0001 || Time: 04:32:44.02
Epoch :: 35 || Loss: 0.42473477 || it_count: 8344 || Val Loss: 0.48983139 || Val it_count: 1107 || Current Learning Rate: 0.0001 || Time: 04:40:45.39
Epoch :: 36 || Loss: 0.42291919 || it_count: 8344 || Val Loss: 0.49062415 || Val it_count: 1107 || Current Learning Rate: 0.0001 || Time: 04:48:46.29
Epoch :: 37 || Loss: 0.42190269 || it_count: 8344 || Val Loss: 0.49050803 || Val it_count: 1107 || Current Learning Rate: 0.0001 || Time: 04:56:47.79
Epoch :: 38 || Loss: 0.42146100 || it_count: 8344 || Val Loss: 0.48847841 || Val it_count: 1107 || Current Learning Rate: 0.0001 || Time: 05:04:49.92
Epoch :: 39 || Loss: 0.42059250 || it_count: 8344 || Val Loss: 0.48872261 || Val it_count: 1107 || Current Learning Rate: 0.0001 || Time: 05:12:51.23
Epoch :: 40 || Loss: 0.42023037 || it_count: 8344 || Val Loss: 0.48628504 || Val it_count: 1107 || Current Learning Rate: 0.0001 || Time: 05:20:52.69
Epoch :: 41 || Loss: 0.41970240 || it_count: 8344 || Val Loss: 0.48487688 || Val it_count: 1107 || Current Learning Rate: 0.0001 || Time: 05:28:54.50
Epoch :: 42 || Loss: 0.41934574 || it_count: 8344 || Val Loss: 0.48362247 || Val it_count: 1107 || Current Learning Rate: 0.0001 || Time: 05:36:56.14
Epoch :: 43 || Loss: 0.41890391 || it_count: 8344 || Val Loss: 0.48219412 || Val it_count: 1107 || Current Learning Rate: 0.0001 || Time: 05:44:57.72
Epoch :: 44 || Loss: 0.41846700 || it_count: 8344 || Val Loss: 0.48181053 || Val it_count: 1107 || Current Learning Rate: 0.0001 || Time: 05:52:59.36
Epoch :: 45 || Loss: 0.41811864 || it_count: 8344 || Val Loss: 0.48404292 || Val it_count: 1107 || Current Learning Rate: 0.0001 || Time: 06:01:1.83
Epoch :: 46 || Loss: 0.41768957 || it_count: 8344 || Val Loss: 0.48227063 || Val it_count: 1107 || Current Learning Rate: 0.0001 || Time: 06:09:3.76
Epoch :: 47 || Loss: 0.41727906 || it_count: 8344 || Val Loss: 0.48173194 || Val it_count: 1107 || Current Learning Rate: 0.0001 || Time: 06:17:5.73
Epoch :: 48 || Loss: 0.41670319 || it_count: 8344 || Val Loss: 0.48274797 || Val it_count: 1107 || Current Learning Rate: 0.0001 || Time: 06:25:7.36
Epoch :: 49 || Loss: 0.41630166 || it_count: 8344 || Val Loss: 0.48333585 || Val it_count: 1107 || Current Learning Rate: 0.0001 || Time: 06:33:7.54
Epoch :: 50 || Loss: 0.41583101 || it_count: 8344 || Val Loss: 0.48426198 || Val it_count: 1107 || Current Learning Rate: 0.0001 || Time: 06:41:9.75
Epoch :: 51 || Loss: 0.41542233 || it_count: 8344 || Val Loss: 0.48595852 || Val it_count: 1107 || Current Learning Rate: 0.0001 || Time: 06:49:11.49
Epoch :: 52 || Loss: 0.41506022 || it_count: 8344 || Val Loss: 0.48665583 || Val it_count: 1107 || Current Learning Rate: 0.0001 || Time: 06:57:12.94
Epoch 00037: reducing learning rate of group 0 to 1.0000e-05.
Epoch :: 53 || Loss: 0.41478783 || it_count: 8344 || Val Loss: 0.48764054 || Val it_count: 1107 || Current Learning Rate: 1e-05 || Time: 07:05:13.69
Epoch :: 54 || Loss: 0.42591853 || it_count: 8344 || Val Loss: 0.47227863 || Val it_count: 1107 || Current Learning Rate: 1e-05 || Time: 07:13:14.62
Epoch :: 55 || Loss: 0.42050426 || it_count: 8344 || Val Loss: 0.47482564 || Val it_count: 1107 || Current Learning Rate: 1e-05 || Time: 07:21:15.94
Epoch :: 56 || Loss: 0.41820895 || it_count: 8344 || Val Loss: 0.47559676 || Val it_count: 1107 || Current Learning Rate: 1e-05 || Time: 07:29:18.46
Epoch :: 57 || Loss: 0.41708788 || it_count: 8344 || Val Loss: 0.47561836 || Val it_count: 1107 || Current Learning Rate: 1e-05 || Time: 07:37:20.64
Epoch :: 58 || Loss: 0.41664449 || it_count: 8344 || Val Loss: 0.47559657 || Val it_count: 1107 || Current Learning Rate: 1e-05 || Time: 07:45:22.46
Epoch :: 59 || Loss: 0.41639620 || it_count: 8344 || Val Loss: 0.47562885 || Val it_count: 1107 || Current Learning Rate: 1e-05 || Time: 07:53:24.07
Epoch 00044: reducing learning rate of group 0 to 1.0000e-06.
Epoch :: 60 || Loss: 0.41621718 || it_count: 8344 || Val Loss: 0.47567453 || Val it_count: 1107 || Current Learning Rate: 1.0000000000000002e-06 || Time: 08:01:25.78
Epoch :: 61 || Loss: 0.41922067 || it_count: 8344 || Val Loss: 0.48074506 || Val it_count: 1107 || Current Learning Rate: 1.0000000000000002e-06 || Time: 08:09:27.87
Epoch :: 62 || Loss: 0.41863739 || it_count: 8344 || Val Loss: 0.48013120 || Val it_count: 1107 || Current Learning Rate: 1.0000000000000002e-06 || Time: 08:17:29.57
Epoch :: 63 || Loss: 0.41842504 || it_count: 8344 || Val Loss: 0.47977098 || Val it_count: 1107 || Current Learning Rate: 1.0000000000000002e-06 || Time: 08:25:31.64
Epoch :: 64 || Loss: 0.41831538 || it_count: 8344 || Val Loss: 0.47957654 || Val it_count: 1107 || Current Learning Rate: 1.0000000000000002e-06 || Time: 08:33:33.81
Epoch :: 65 || Loss: 0.41824159 || it_count: 8344 || Val Loss: 0.47947558 || Val it_count: 1107 || Current Learning Rate: 1.0000000000000002e-06 || Time: 08:41:36.72
Epoch 00050: reducing learning rate of group 0 to 1.0000e-07.
Early stopping triggered due to learning rate below threshold.
Done Total time: 08:49:38.94
best_loss: 0.4722786286604562

--------------------Testing--------------------

total_samples :: test_dataset = 139200, test_dataloader = 139200
Epoch ::  1 || Loss: 0.47258872 || it_count: 544 || Time: 00:00:24.90
MAE:  0.326837
MSE:  0.47270048
RMSE:  0.52529573

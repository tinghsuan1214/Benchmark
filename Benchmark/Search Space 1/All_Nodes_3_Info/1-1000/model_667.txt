--------------------Training--------------------
arch_str :: |lstm_3~0|+|lstm_1~0|skip_connect~1|[linear->dropout->linear]
model :: 3F
InferCell(
  info :: nodes=3, inC=1, outC=64, [1<-(I0-L0) | 2<-(I0-L1,I1-L2)], genotype_str: lstm_3~0|lstm_1~0|skip_connect~1
  linear_layers: [linear->dropout->linear]
  (layers): ModuleList(
    (0): LSTM(
      (lstm): LSTM(1, 64, num_layers=3, batch_first=True)
    )
    (1): LSTM(
      (lstm): LSTM(1, 64, batch_first=True)
    )
    (2): Identity()
  )
  (linear_layers): ModuleList(
    (0): Linear(in_features=3072, out_features=1536, bias=True)
    (1): Dropout(p=0.1, inplace=False)
    (2): Linear(in_features=1536, out_features=1, bias=True)
  )
)
tr_params :: epochs = 100, patience = 20, batch_size = 256, window_size = 48, data_size = 100
Model FLOPs: 9.660M, Model Params: 4.823M
learning rate scheduling :: (optimizer, mode='min', factor=0.1, patience=5, verbose=True)
total_samples :: train_dataset = 2136000, train_dataloader = 2136000
total_samples :: valid_dataset = 283200, valid_dataloader = 283200
Epoch ::  1 || Loss: 0.42290959 || it_count: 8344 || Val Loss: 0.45938223 || Val it_count: 1107 || Current Learning Rate: 0.001 || Time: 00:04:37.47
Epoch ::  2 || Loss: 0.41770133 || it_count: 8344 || Val Loss: 0.44710097 || Val it_count: 1107 || Current Learning Rate: 0.001 || Time: 00:09:7.25
Epoch ::  3 || Loss: 0.41727373 || it_count: 8344 || Val Loss: 0.44950468 || Val it_count: 1107 || Current Learning Rate: 0.001 || Time: 00:13:39.11
Epoch ::  4 || Loss: 0.41722930 || it_count: 8344 || Val Loss: 0.44918494 || Val it_count: 1107 || Current Learning Rate: 0.001 || Time: 00:18:11.04
Epoch ::  5 || Loss: 0.41735398 || it_count: 8344 || Val Loss: 0.44812408 || Val it_count: 1107 || Current Learning Rate: 0.001 || Time: 00:22:43.49
Epoch ::  6 || Loss: 0.41752381 || it_count: 8344 || Val Loss: 0.44766131 || Val it_count: 1107 || Current Learning Rate: 0.001 || Time: 00:27:16.37
Epoch ::  7 || Loss: 0.41736265 || it_count: 8344 || Val Loss: 0.44786950 || Val it_count: 1107 || Current Learning Rate: 0.001 || Time: 00:31:49.23
Epoch ::  8 || Loss: 0.41730369 || it_count: 8344 || Val Loss: 0.44769504 || Val it_count: 1107 || Current Learning Rate: 0.001 || Time: 00:36:22.62
Epoch ::  9 || Loss: 0.41716359 || it_count: 8344 || Val Loss: 0.44768093 || Val it_count: 1107 || Current Learning Rate: 0.001 || Time: 00:40:55.84
Epoch :: 10 || Loss: 0.41717519 || it_count: 8344 || Val Loss: 0.44744133 || Val it_count: 1107 || Current Learning Rate: 0.001 || Time: 00:45:27.85
Epoch :: 11 || Loss: 0.41712845 || it_count: 8344 || Val Loss: 0.44731392 || Val it_count: 1107 || Current Learning Rate: 0.001 || Time: 00:50:1.16
Epoch :: 12 || Loss: 0.41694831 || it_count: 8344 || Val Loss: 0.44717690 || Val it_count: 1107 || Current Learning Rate: 0.001 || Time: 00:54:33.43
Epoch :: 13 || Loss: 0.41689255 || it_count: 8344 || Val Loss: 0.44759070 || Val it_count: 1107 || Current Learning Rate: 0.001 || Time: 00:59:7.95
Epoch :: 14 || Loss: 0.41675481 || it_count: 8344 || Val Loss: 0.44855271 || Val it_count: 1107 || Current Learning Rate: 0.001 || Time: 01:03:45.11
Epoch :: 15 || Loss: 0.41702435 || it_count: 8344 || Val Loss: 0.44759757 || Val it_count: 1107 || Current Learning Rate: 0.001 || Time: 01:08:21.87
Epoch :: 16 || Loss: 0.41692762 || it_count: 8344 || Val Loss: 0.44808941 || Val it_count: 1107 || Current Learning Rate: 0.001 || Time: 01:12:55.13
Epoch :: 17 || Loss: 0.41687680 || it_count: 8344 || Val Loss: 0.44796393 || Val it_count: 1107 || Current Learning Rate: 0.001 || Time: 01:17:29.25
Epoch :: 18 || Loss: 0.41684143 || it_count: 8344 || Val Loss: 0.44765416 || Val it_count: 1107 || Current Learning Rate: 0.001 || Time: 01:22:8.33
Epoch :: 19 || Loss: 0.41682985 || it_count: 8344 || Val Loss: 0.44709504 || Val it_count: 1107 || Current Learning Rate: 0.001 || Time: 01:26:41.09
Epoch :: 20 || Loss: 0.41683857 || it_count: 8344 || Val Loss: 0.44692313 || Val it_count: 1107 || Current Learning Rate: 0.001 || Time: 01:31:13.39
Epoch :: 21 || Loss: 0.41681760 || it_count: 8344 || Val Loss: 0.44682775 || Val it_count: 1107 || Current Learning Rate: 0.001 || Time: 01:35:46.56
Epoch :: 22 || Loss: 0.41690975 || it_count: 8344 || Val Loss: 0.44692500 || Val it_count: 1107 || Current Learning Rate: 0.001 || Time: 01:40:18.36
Epoch :: 23 || Loss: 0.41689755 || it_count: 8344 || Val Loss: 0.44630680 || Val it_count: 1107 || Current Learning Rate: 0.001 || Time: 01:44:50.15
Epoch :: 24 || Loss: 0.41690875 || it_count: 8344 || Val Loss: 0.44630188 || Val it_count: 1107 || Current Learning Rate: 0.001 || Time: 01:49:22.62
Epoch :: 25 || Loss: 0.41682805 || it_count: 8344 || Val Loss: 0.44625740 || Val it_count: 1107 || Current Learning Rate: 0.001 || Time: 01:53:58.96
Epoch :: 26 || Loss: 0.41690920 || it_count: 8344 || Val Loss: 0.44619992 || Val it_count: 1107 || Current Learning Rate: 0.001 || Time: 01:58:35.22
Epoch :: 27 || Loss: 0.41684836 || it_count: 8344 || Val Loss: 0.44644967 || Val it_count: 1107 || Current Learning Rate: 0.001 || Time: 02:03:8.11
Epoch :: 28 || Loss: 0.41677473 || it_count: 8344 || Val Loss: 0.44668435 || Val it_count: 1107 || Current Learning Rate: 0.001 || Time: 02:07:40.62
Epoch :: 29 || Loss: 0.41693151 || it_count: 8344 || Val Loss: 0.44663228 || Val it_count: 1107 || Current Learning Rate: 0.001 || Time: 02:12:14.61
Epoch :: 30 || Loss: 0.41673581 || it_count: 8344 || Val Loss: 0.44626186 || Val it_count: 1107 || Current Learning Rate: 0.001 || Time: 02:16:51.83
Epoch :: 31 || Loss: 0.41664484 || it_count: 8344 || Val Loss: 0.44634119 || Val it_count: 1107 || Current Learning Rate: 0.001 || Time: 02:21:28.39
Epoch :: 32 || Loss: 0.41650919 || it_count: 8344 || Val Loss: 0.44628396 || Val it_count: 1107 || Current Learning Rate: 0.0001 || Time: 02:26:4.74
Epoch :: 33 || Loss: 0.42313268 || it_count: 8344 || Val Loss: 0.43871612 || Val it_count: 1107 || Current Learning Rate: 0.0001 || Time: 02:30:42.21
Epoch :: 34 || Loss: 0.42083353 || it_count: 8344 || Val Loss: 0.43745055 || Val it_count: 1107 || Current Learning Rate: 0.0001 || Time: 02:35:18.91
Epoch :: 35 || Loss: 0.42045747 || it_count: 8344 || Val Loss: 0.43640665 || Val it_count: 1107 || Current Learning Rate: 0.0001 || Time: 02:39:56.07
Epoch :: 36 || Loss: 0.42014051 || it_count: 8344 || Val Loss: 0.43548960 || Val it_count: 1107 || Current Learning Rate: 0.0001 || Time: 02:44:37.26
Epoch :: 37 || Loss: 0.41990105 || it_count: 8344 || Val Loss: 0.43481820 || Val it_count: 1107 || Current Learning Rate: 0.0001 || Time: 02:49:16.69
Epoch :: 38 || Loss: 0.41973038 || it_count: 8344 || Val Loss: 0.43421041 || Val it_count: 1107 || Current Learning Rate: 0.0001 || Time: 02:53:56.22
Epoch :: 39 || Loss: 0.41952354 || it_count: 8344 || Val Loss: 0.43403728 || Val it_count: 1107 || Current Learning Rate: 0.0001 || Time: 02:58:34.08
Epoch :: 40 || Loss: 0.41937638 || it_count: 8344 || Val Loss: 0.43369775 || Val it_count: 1107 || Current Learning Rate: 0.0001 || Time: 03:03:13.61
Epoch :: 41 || Loss: 0.41920852 || it_count: 8344 || Val Loss: 0.43346473 || Val it_count: 1107 || Current Learning Rate: 0.0001 || Time: 03:07:50.40
Epoch :: 42 || Loss: 0.41905613 || it_count: 8344 || Val Loss: 0.43343196 || Val it_count: 1107 || Current Learning Rate: 0.0001 || Time: 03:12:28.30
Epoch :: 43 || Loss: 0.41893401 || it_count: 8344 || Val Loss: 0.43328536 || Val it_count: 1107 || Current Learning Rate: 0.0001 || Time: 03:17:6.87
Epoch :: 44 || Loss: 0.41880979 || it_count: 8344 || Val Loss: 0.43307855 || Val it_count: 1107 || Current Learning Rate: 0.0001 || Time: 03:21:44.31
Epoch :: 45 || Loss: 0.41867269 || it_count: 8344 || Val Loss: 0.43305314 || Val it_count: 1107 || Current Learning Rate: 0.0001 || Time: 03:26:22.34
Epoch :: 46 || Loss: 0.41856706 || it_count: 8344 || Val Loss: 0.43293970 || Val it_count: 1107 || Current Learning Rate: 0.0001 || Time: 03:30:58.63
Epoch :: 47 || Loss: 0.41847121 || it_count: 8344 || Val Loss: 0.43288462 || Val it_count: 1107 || Current Learning Rate: 0.0001 || Time: 03:35:37.30
Epoch :: 48 || Loss: 0.41841935 || it_count: 8344 || Val Loss: 0.43283134 || Val it_count: 1107 || Current Learning Rate: 0.0001 || Time: 03:40:15.47
Epoch :: 49 || Loss: 0.41833323 || it_count: 8344 || Val Loss: 0.43273215 || Val it_count: 1107 || Current Learning Rate: 0.0001 || Time: 03:44:53.79
Epoch :: 50 || Loss: 0.41829334 || it_count: 8344 || Val Loss: 0.43281230 || Val it_count: 1107 || Current Learning Rate: 0.0001 || Time: 03:49:31.74
Epoch :: 51 || Loss: 0.41820986 || it_count: 8344 || Val Loss: 0.43269584 || Val it_count: 1107 || Current Learning Rate: 0.0001 || Time: 03:54:8.86
Epoch :: 52 || Loss: 0.41811196 || it_count: 8344 || Val Loss: 0.43271848 || Val it_count: 1107 || Current Learning Rate: 0.0001 || Time: 03:58:46.76
Epoch :: 53 || Loss: 0.41811384 || it_count: 8344 || Val Loss: 0.43267470 || Val it_count: 1107 || Current Learning Rate: 0.0001 || Time: 04:03:24.19
Epoch :: 54 || Loss: 0.41803747 || it_count: 8344 || Val Loss: 0.43263828 || Val it_count: 1107 || Current Learning Rate: 0.0001 || Time: 04:08:2.29
Epoch :: 55 || Loss: 0.41793282 || it_count: 8344 || Val Loss: 0.43269595 || Val it_count: 1107 || Current Learning Rate: 0.0001 || Time: 04:12:40.86
Epoch :: 56 || Loss: 0.41789938 || it_count: 8344 || Val Loss: 0.43275910 || Val it_count: 1107 || Current Learning Rate: 0.0001 || Time: 04:17:18.46
Epoch :: 57 || Loss: 0.41781158 || it_count: 8344 || Val Loss: 0.43276820 || Val it_count: 1107 || Current Learning Rate: 0.0001 || Time: 04:21:56.16
Epoch :: 58 || Loss: 0.41778533 || it_count: 8344 || Val Loss: 0.43290927 || Val it_count: 1107 || Current Learning Rate: 0.0001 || Time: 04:26:36.01
Epoch :: 59 || Loss: 0.41773567 || it_count: 8344 || Val Loss: 0.43297590 || Val it_count: 1107 || Current Learning Rate: 1e-05 || Time: 04:31:16.53
Epoch :: 60 || Loss: 0.42069320 || it_count: 8344 || Val Loss: 0.42396926 || Val it_count: 1107 || Current Learning Rate: 1e-05 || Time: 04:35:56.88
Epoch :: 61 || Loss: 0.41909588 || it_count: 8344 || Val Loss: 0.42337049 || Val it_count: 1107 || Current Learning Rate: 1e-05 || Time: 04:40:36.84
Epoch :: 62 || Loss: 0.41862978 || it_count: 8344 || Val Loss: 0.42305183 || Val it_count: 1107 || Current Learning Rate: 1e-05 || Time: 04:45:18.39
Epoch :: 63 || Loss: 0.41847923 || it_count: 8344 || Val Loss: 0.42286543 || Val it_count: 1107 || Current Learning Rate: 1e-05 || Time: 04:49:58.32
Epoch :: 64 || Loss: 0.41832990 || it_count: 8344 || Val Loss: 0.42271988 || Val it_count: 1107 || Current Learning Rate: 1e-05 || Time: 04:54:39.42
Epoch :: 65 || Loss: 0.41819884 || it_count: 8344 || Val Loss: 0.42260863 || Val it_count: 1107 || Current Learning Rate: 1e-05 || Time: 04:59:19.76
Epoch :: 66 || Loss: 0.41815893 || it_count: 8344 || Val Loss: 0.42251081 || Val it_count: 1107 || Current Learning Rate: 1e-05 || Time: 05:04:0.98
Epoch :: 67 || Loss: 0.41811334 || it_count: 8344 || Val Loss: 0.42246420 || Val it_count: 1107 || Current Learning Rate: 1e-05 || Time: 05:08:40.90
Epoch :: 68 || Loss: 0.41803765 || it_count: 8344 || Val Loss: 0.42239908 || Val it_count: 1107 || Current Learning Rate: 1e-05 || Time: 05:13:19.94
Epoch :: 69 || Loss: 0.41800953 || it_count: 8344 || Val Loss: 0.42236482 || Val it_count: 1107 || Current Learning Rate: 1e-05 || Time: 05:18:0.02
Epoch :: 70 || Loss: 0.41798373 || it_count: 8344 || Val Loss: 0.42228545 || Val it_count: 1107 || Current Learning Rate: 1e-05 || Time: 05:22:42.60
Epoch :: 71 || Loss: 0.41793976 || it_count: 8344 || Val Loss: 0.42228139 || Val it_count: 1107 || Current Learning Rate: 1e-05 || Time: 05:27:26.57
Epoch :: 72 || Loss: 0.41789726 || it_count: 8344 || Val Loss: 0.42223750 || Val it_count: 1107 || Current Learning Rate: 1e-05 || Time: 05:32:6.14
Epoch :: 73 || Loss: 0.41785739 || it_count: 8344 || Val Loss: 0.42220852 || Val it_count: 1107 || Current Learning Rate: 1e-05 || Time: 05:36:46.67
Epoch :: 74 || Loss: 0.41784285 || it_count: 8344 || Val Loss: 0.42218801 || Val it_count: 1107 || Current Learning Rate: 1e-05 || Time: 05:41:28.36
Epoch :: 75 || Loss: 0.41780680 || it_count: 8344 || Val Loss: 0.42216344 || Val it_count: 1107 || Current Learning Rate: 1e-05 || Time: 05:46:7.63
Epoch :: 76 || Loss: 0.41778261 || it_count: 8344 || Val Loss: 0.42214964 || Val it_count: 1107 || Current Learning Rate: 1e-05 || Time: 05:50:49.78
Epoch :: 77 || Loss: 0.41773748 || it_count: 8344 || Val Loss: 0.42214288 || Val it_count: 1107 || Current Learning Rate: 1e-05 || Time: 05:55:28.78
Epoch :: 78 || Loss: 0.41772960 || it_count: 8344 || Val Loss: 0.42214183 || Val it_count: 1107 || Current Learning Rate: 1e-05 || Time: 06:00:9.78
Epoch :: 79 || Loss: 0.41772990 || it_count: 8344 || Val Loss: 0.42212448 || Val it_count: 1107 || Current Learning Rate: 1e-05 || Time: 06:04:51.31
Epoch :: 80 || Loss: 0.41771406 || it_count: 8344 || Val Loss: 0.42211098 || Val it_count: 1107 || Current Learning Rate: 1e-05 || Time: 06:09:34.04
Epoch :: 81 || Loss: 0.41770179 || it_count: 8344 || Val Loss: 0.42211395 || Val it_count: 1107 || Current Learning Rate: 1e-05 || Time: 06:14:15.90
Epoch :: 82 || Loss: 0.41768999 || it_count: 8344 || Val Loss: 0.42211194 || Val it_count: 1107 || Current Learning Rate: 1e-05 || Time: 06:18:57.37
Epoch :: 83 || Loss: 0.41765404 || it_count: 8344 || Val Loss: 0.42211475 || Val it_count: 1107 || Current Learning Rate: 1.0000000000000002e-06 || Time: 06:23:37.31
Epoch :: 84 || Loss: 0.41796295 || it_count: 8344 || Val Loss: 0.42111540 || Val it_count: 1107 || Current Learning Rate: 1.0000000000000002e-06 || Time: 06:28:17.56
Epoch :: 85 || Loss: 0.41783493 || it_count: 8344 || Val Loss: 0.42100891 || Val it_count: 1107 || Current Learning Rate: 1.0000000000000002e-06 || Time: 06:32:58.03
Epoch :: 86 || Loss: 0.41777251 || it_count: 8344 || Val Loss: 0.42095229 || Val it_count: 1107 || Current Learning Rate: 1.0000000000000002e-06 || Time: 06:37:38.12
Epoch :: 87 || Loss: 0.41774797 || it_count: 8344 || Val Loss: 0.42092144 || Val it_count: 1107 || Current Learning Rate: 1.0000000000000002e-06 || Time: 06:42:17.88
Epoch :: 88 || Loss: 0.41774115 || it_count: 8344 || Val Loss: 0.42089863 || Val it_count: 1107 || Current Learning Rate: 1.0000000000000002e-06 || Time: 06:46:58.34
Epoch :: 89 || Loss: 0.41771015 || it_count: 8344 || Val Loss: 0.42088723 || Val it_count: 1107 || Current Learning Rate: 1.0000000000000002e-06 || Time: 06:51:39.14
Epoch :: 90 || Loss: 0.41772578 || it_count: 8344 || Val Loss: 0.42087743 || Val it_count: 1107 || Current Learning Rate: 1.0000000000000002e-06 || Time: 06:56:19.95
Epoch :: 91 || Loss: 0.41771666 || it_count: 8344 || Val Loss: 0.42087155 || Val it_count: 1107 || Current Learning Rate: 1.0000000000000002e-06 || Time: 07:01:0.73
Epoch :: 92 || Loss: 0.41770803 || it_count: 8344 || Val Loss: 0.42086433 || Val it_count: 1107 || Current Learning Rate: 1.0000000000000002e-06 || Time: 07:05:41.70
Epoch :: 93 || Loss: 0.41769479 || it_count: 8344 || Val Loss: 0.42086579 || Val it_count: 1107 || Current Learning Rate: 1.0000000000000002e-06 || Time: 07:10:23.71
Early stopping triggered due to learning rate below threshold.
Done Total time: 07:15:5.08
best_loss: 0.4208643283453493

--------------------Testing--------------------

total_samples :: test_dataset = 139200, test_dataloader = 139200
Epoch ::  1 || Loss: 0.24753038 || it_count: 544 || Time: 00:00:14.16
MAE:  0.261493
MSE:  0.24755338
RMSE:  0.45058778

--------------------Training--------------------
arch_str :: |lstm_3~0|+|lstm_2~0|skip_connect~1|[dropout->linear]
model :: 3B
InferCell(
  info :: nodes=3, inC=1, outC=64, [1<-(I0-L0) | 2<-(I0-L1,I1-L2)], genotype_str: lstm_3~0|lstm_2~0|skip_connect~1
  linear_layers: [dropout->linear]
  (layers): ModuleList(
    (0): LSTM(
      (lstm): LSTM(1, 64, num_layers=3, batch_first=True)
    )
    (1): LSTM(
      (lstm): LSTM(1, 64, num_layers=2, batch_first=True)
    )
    (2): Identity()
  )
  (linear_layers): ModuleList(
    (0): Dropout(p=0.1, inplace=False)
    (1): Linear(in_features=3072, out_features=1, bias=True)
  )
)
tr_params :: epochs = 100, patience = 20, batch_size = 256, window_size = 48, data_size = 100
Model FLOPs: 6.565M, Model Params: 137.217K
learning rate scheduling :: (optimizer, mode='min', factor=0.1, patience=5, verbose=True)
total_samples :: train_dataset = 2136000, train_dataloader = 2136000
total_samples :: valid_dataset = 283200, valid_dataloader = 283200
Epoch ::  1 || Loss: 0.42252170 || it_count: 8344 || Val Loss: 0.44982866 || Val it_count: 1107 || Current Learning Rate: 0.001 || Time: 00:08:17.66
Epoch ::  2 || Loss: 0.41971230 || it_count: 8344 || Val Loss: 0.44890355 || Val it_count: 1107 || Current Learning Rate: 0.001 || Time: 00:16:33.37
Epoch ::  3 || Loss: 0.41925545 || it_count: 8344 || Val Loss: 0.44824919 || Val it_count: 1107 || Current Learning Rate: 0.001 || Time: 00:24:49.20
Epoch ::  4 || Loss: 0.41891467 || it_count: 8344 || Val Loss: 0.44802714 || Val it_count: 1107 || Current Learning Rate: 0.001 || Time: 00:33:8.37
Epoch ::  5 || Loss: 0.41854585 || it_count: 8344 || Val Loss: 0.44768525 || Val it_count: 1107 || Current Learning Rate: 0.001 || Time: 00:41:25.84
Epoch ::  6 || Loss: 0.41789196 || it_count: 8344 || Val Loss: 0.44719285 || Val it_count: 1107 || Current Learning Rate: 0.001 || Time: 00:49:44.18
Epoch ::  7 || Loss: 0.41753794 || it_count: 8344 || Val Loss: 0.44783038 || Val it_count: 1107 || Current Learning Rate: 0.001 || Time: 00:58:2.42
Epoch ::  8 || Loss: 0.41717298 || it_count: 8344 || Val Loss: 0.44788821 || Val it_count: 1107 || Current Learning Rate: 0.001 || Time: 01:06:20.37
Epoch ::  9 || Loss: 0.41721840 || it_count: 8344 || Val Loss: 0.44814031 || Val it_count: 1107 || Current Learning Rate: 0.001 || Time: 01:14:39.32
Epoch :: 10 || Loss: 0.41689836 || it_count: 8344 || Val Loss: 0.44762812 || Val it_count: 1107 || Current Learning Rate: 0.001 || Time: 01:22:57.61
Epoch :: 11 || Loss: 0.41659887 || it_count: 8344 || Val Loss: 0.44667141 || Val it_count: 1107 || Current Learning Rate: 0.001 || Time: 01:31:15.60
Epoch :: 12 || Loss: 0.41683277 || it_count: 8344 || Val Loss: 0.44599361 || Val it_count: 1107 || Current Learning Rate: 0.001 || Time: 01:39:33.32
Epoch :: 13 || Loss: 0.41632820 || it_count: 8344 || Val Loss: 0.44570175 || Val it_count: 1107 || Current Learning Rate: 0.001 || Time: 01:47:52.73
Epoch :: 14 || Loss: 0.41643071 || it_count: 8344 || Val Loss: 0.44701753 || Val it_count: 1107 || Current Learning Rate: 0.001 || Time: 01:56:13.15
Epoch :: 15 || Loss: 0.41617346 || it_count: 8344 || Val Loss: 0.44669935 || Val it_count: 1107 || Current Learning Rate: 0.001 || Time: 02:04:31.94
Epoch :: 16 || Loss: 0.41644166 || it_count: 8344 || Val Loss: 0.44660293 || Val it_count: 1107 || Current Learning Rate: 0.001 || Time: 02:12:51.87
Epoch :: 17 || Loss: 0.41594192 || it_count: 8344 || Val Loss: 0.44634438 || Val it_count: 1107 || Current Learning Rate: 0.001 || Time: 02:21:10.08
Epoch :: 18 || Loss: 0.41603686 || it_count: 8344 || Val Loss: 0.44743911 || Val it_count: 1107 || Current Learning Rate: 0.001 || Time: 02:29:27.24
Epoch :: 19 || Loss: 0.41596648 || it_count: 8344 || Val Loss: 0.44764433 || Val it_count: 1107 || Current Learning Rate: 0.001 || Time: 02:37:47.00
Epoch :: 20 || Loss: 0.41624971 || it_count: 8344 || Val Loss: 0.44749383 || Val it_count: 1107 || Current Learning Rate: 0.001 || Time: 02:46:5.99
Epoch :: 21 || Loss: 0.41600811 || it_count: 8344 || Val Loss: 0.44762090 || Val it_count: 1107 || Current Learning Rate: 0.001 || Time: 02:54:21.01
Epoch :: 22 || Loss: 0.41552700 || it_count: 8344 || Val Loss: 0.44569206 || Val it_count: 1107 || Current Learning Rate: 0.001 || Time: 03:02:36.99
Epoch :: 23 || Loss: 0.41542220 || it_count: 8344 || Val Loss: 0.44562866 || Val it_count: 1107 || Current Learning Rate: 0.001 || Time: 03:10:51.46
Epoch :: 24 || Loss: 0.41535052 || it_count: 8344 || Val Loss: 0.44620003 || Val it_count: 1107 || Current Learning Rate: 0.001 || Time: 03:19:7.17
Epoch :: 25 || Loss: 0.41528701 || it_count: 8344 || Val Loss: 0.44763117 || Val it_count: 1107 || Current Learning Rate: 0.001 || Time: 03:27:23.75
Epoch :: 26 || Loss: 0.41506853 || it_count: 8344 || Val Loss: 0.44846070 || Val it_count: 1107 || Current Learning Rate: 0.001 || Time: 03:35:41.15
Epoch :: 27 || Loss: 0.41491559 || it_count: 8344 || Val Loss: 0.44857074 || Val it_count: 1107 || Current Learning Rate: 0.001 || Time: 03:43:57.36
Epoch :: 28 || Loss: 0.41501759 || it_count: 8344 || Val Loss: 0.44865434 || Val it_count: 1107 || Current Learning Rate: 0.001 || Time: 03:52:14.89
Epoch 00013: reducing learning rate of group 0 to 1.0000e-04.
Epoch :: 29 || Loss: 0.41458372 || it_count: 8344 || Val Loss: 0.44897550 || Val it_count: 1107 || Current Learning Rate: 0.0001 || Time: 04:00:30.28
Epoch :: 30 || Loss: 0.42095125 || it_count: 8344 || Val Loss: 0.42762748 || Val it_count: 1107 || Current Learning Rate: 0.0001 || Time: 04:08:46.65
Epoch :: 31 || Loss: 0.41657677 || it_count: 8344 || Val Loss: 0.42606218 || Val it_count: 1107 || Current Learning Rate: 0.0001 || Time: 04:17:2.28
Epoch :: 32 || Loss: 0.41518078 || it_count: 8344 || Val Loss: 0.42565438 || Val it_count: 1107 || Current Learning Rate: 0.0001 || Time: 04:25:19.02
Epoch :: 33 || Loss: 0.41434604 || it_count: 8344 || Val Loss: 0.42559025 || Val it_count: 1107 || Current Learning Rate: 0.0001 || Time: 04:33:36.25
Epoch :: 34 || Loss: 0.41372610 || it_count: 8344 || Val Loss: 0.42551055 || Val it_count: 1107 || Current Learning Rate: 0.0001 || Time: 04:41:53.10
Epoch :: 35 || Loss: 0.41332082 || it_count: 8344 || Val Loss: 0.42559339 || Val it_count: 1107 || Current Learning Rate: 0.0001 || Time: 04:50:11.54
Epoch :: 36 || Loss: 0.41289730 || it_count: 8344 || Val Loss: 0.42555400 || Val it_count: 1107 || Current Learning Rate: 0.0001 || Time: 04:58:29.22
Epoch :: 37 || Loss: 0.41267774 || it_count: 8344 || Val Loss: 0.42537535 || Val it_count: 1107 || Current Learning Rate: 0.0001 || Time: 05:06:47.12
Epoch :: 38 || Loss: 0.41247357 || it_count: 8344 || Val Loss: 0.42555059 || Val it_count: 1107 || Current Learning Rate: 0.0001 || Time: 05:15:4.62
Epoch :: 39 || Loss: 0.41229394 || it_count: 8344 || Val Loss: 0.42534194 || Val it_count: 1107 || Current Learning Rate: 0.0001 || Time: 05:23:21.62
Epoch :: 40 || Loss: 0.41212787 || it_count: 8344 || Val Loss: 0.42510051 || Val it_count: 1107 || Current Learning Rate: 0.0001 || Time: 05:31:38.66
Epoch :: 41 || Loss: 0.41188375 || it_count: 8344 || Val Loss: 0.42467551 || Val it_count: 1107 || Current Learning Rate: 0.0001 || Time: 05:39:56.56
Epoch :: 42 || Loss: 0.41170937 || it_count: 8344 || Val Loss: 0.42434005 || Val it_count: 1107 || Current Learning Rate: 0.0001 || Time: 05:48:15.58
Epoch :: 43 || Loss: 0.41154704 || it_count: 8344 || Val Loss: 0.42389830 || Val it_count: 1107 || Current Learning Rate: 0.0001 || Time: 05:56:32.18
Epoch :: 44 || Loss: 0.41134688 || it_count: 8344 || Val Loss: 0.42359432 || Val it_count: 1107 || Current Learning Rate: 0.0001 || Time: 06:04:48.93
Epoch :: 45 || Loss: 0.41128021 || it_count: 8344 || Val Loss: 0.42326993 || Val it_count: 1107 || Current Learning Rate: 0.0001 || Time: 06:13:5.43
Epoch :: 46 || Loss: 0.41114317 || it_count: 8344 || Val Loss: 0.42338224 || Val it_count: 1107 || Current Learning Rate: 0.0001 || Time: 06:21:21.52
Epoch :: 47 || Loss: 0.41101916 || it_count: 8344 || Val Loss: 0.42313405 || Val it_count: 1107 || Current Learning Rate: 0.0001 || Time: 06:29:39.31
Epoch :: 48 || Loss: 0.41094610 || it_count: 8344 || Val Loss: 0.42188030 || Val it_count: 1107 || Current Learning Rate: 0.0001 || Time: 06:37:56.89
Epoch :: 49 || Loss: 0.41082499 || it_count: 8344 || Val Loss: 0.42110444 || Val it_count: 1107 || Current Learning Rate: 0.0001 || Time: 06:46:13.87
Epoch :: 50 || Loss: 0.41054069 || it_count: 8344 || Val Loss: 0.42163945 || Val it_count: 1107 || Current Learning Rate: 0.0001 || Time: 06:54:31.62
Epoch :: 51 || Loss: 0.41045493 || it_count: 8344 || Val Loss: 0.42122065 || Val it_count: 1107 || Current Learning Rate: 0.0001 || Time: 07:02:50.12
Epoch :: 52 || Loss: 0.41031308 || it_count: 8344 || Val Loss: 0.42083616 || Val it_count: 1107 || Current Learning Rate: 0.0001 || Time: 07:11:9.08
Epoch :: 53 || Loss: 0.41025152 || it_count: 8344 || Val Loss: 0.42063491 || Val it_count: 1107 || Current Learning Rate: 0.0001 || Time: 07:19:26.98
Epoch :: 54 || Loss: 0.41011954 || it_count: 8344 || Val Loss: 0.42071455 || Val it_count: 1107 || Current Learning Rate: 0.0001 || Time: 07:27:43.79
Epoch :: 55 || Loss: 0.40990383 || it_count: 8344 || Val Loss: 0.42045342 || Val it_count: 1107 || Current Learning Rate: 0.0001 || Time: 07:36:1.38
Epoch :: 56 || Loss: 0.40983158 || it_count: 8344 || Val Loss: 0.42005367 || Val it_count: 1107 || Current Learning Rate: 0.0001 || Time: 07:44:19.52
Epoch :: 57 || Loss: 0.40968134 || it_count: 8344 || Val Loss: 0.42155700 || Val it_count: 1107 || Current Learning Rate: 0.0001 || Time: 07:52:38.11
Epoch :: 58 || Loss: 0.40960983 || it_count: 8344 || Val Loss: 0.41972642 || Val it_count: 1107 || Current Learning Rate: 0.0001 || Time: 08:00:54.55
Epoch :: 59 || Loss: 0.40954252 || it_count: 8344 || Val Loss: 0.42028450 || Val it_count: 1107 || Current Learning Rate: 0.0001 || Time: 08:09:11.70
Epoch :: 60 || Loss: 0.40938763 || it_count: 8344 || Val Loss: 0.42000047 || Val it_count: 1107 || Current Learning Rate: 0.0001 || Time: 08:17:29.58
Epoch :: 61 || Loss: 0.40929657 || it_count: 8344 || Val Loss: 0.41973867 || Val it_count: 1107 || Current Learning Rate: 0.0001 || Time: 08:25:48.98
Epoch :: 62 || Loss: 0.40923535 || it_count: 8344 || Val Loss: 0.41980271 || Val it_count: 1107 || Current Learning Rate: 0.0001 || Time: 08:34:6.27
Epoch :: 63 || Loss: 0.40919508 || it_count: 8344 || Val Loss: 0.42029929 || Val it_count: 1107 || Current Learning Rate: 0.0001 || Time: 08:42:24.51
Epoch 00048: reducing learning rate of group 0 to 1.0000e-05.
Epoch :: 64 || Loss: 0.40913000 || it_count: 8344 || Val Loss: 0.42233748 || Val it_count: 1107 || Current Learning Rate: 1e-05 || Time: 08:50:43.54
Epoch :: 65 || Loss: 0.41158974 || it_count: 8344 || Val Loss: 0.41287909 || Val it_count: 1107 || Current Learning Rate: 1e-05 || Time: 08:59:1.97
Epoch :: 66 || Loss: 0.41017643 || it_count: 8344 || Val Loss: 0.41263495 || Val it_count: 1107 || Current Learning Rate: 1e-05 || Time: 09:07:19.65
Epoch :: 67 || Loss: 0.40994242 || it_count: 8344 || Val Loss: 0.41258077 || Val it_count: 1107 || Current Learning Rate: 1e-05 || Time: 09:15:36.90
Epoch :: 68 || Loss: 0.40985350 || it_count: 8344 || Val Loss: 0.41255937 || Val it_count: 1107 || Current Learning Rate: 1e-05 || Time: 09:23:55.33
Epoch :: 69 || Loss: 0.40978758 || it_count: 8344 || Val Loss: 0.41256246 || Val it_count: 1107 || Current Learning Rate: 1e-05 || Time: 09:32:13.39
Epoch :: 70 || Loss: 0.40980024 || it_count: 8344 || Val Loss: 0.41253788 || Val it_count: 1107 || Current Learning Rate: 1e-05 || Time: 09:40:31.25
Epoch :: 71 || Loss: 0.40968332 || it_count: 8344 || Val Loss: 0.41252036 || Val it_count: 1107 || Current Learning Rate: 1e-05 || Time: 09:48:49.07
Epoch :: 72 || Loss: 0.40967486 || it_count: 8344 || Val Loss: 0.41251689 || Val it_count: 1107 || Current Learning Rate: 1e-05 || Time: 09:57:6.94
Epoch :: 73 || Loss: 0.40961608 || it_count: 8344 || Val Loss: 0.41248421 || Val it_count: 1107 || Current Learning Rate: 1e-05 || Time: 10:05:24.59
Epoch :: 74 || Loss: 0.40960671 || it_count: 8344 || Val Loss: 0.41250168 || Val it_count: 1107 || Current Learning Rate: 1e-05 || Time: 10:13:43.05
Epoch :: 75 || Loss: 0.40953694 || it_count: 8344 || Val Loss: 0.41246938 || Val it_count: 1107 || Current Learning Rate: 1e-05 || Time: 10:22:1.86
Epoch :: 76 || Loss: 0.40947511 || it_count: 8344 || Val Loss: 0.41244556 || Val it_count: 1107 || Current Learning Rate: 1e-05 || Time: 10:30:20.06
Epoch :: 77 || Loss: 0.40947492 || it_count: 8344 || Val Loss: 0.41244605 || Val it_count: 1107 || Current Learning Rate: 1e-05 || Time: 10:38:38.98
Epoch :: 78 || Loss: 0.40944867 || it_count: 8344 || Val Loss: 0.41241576 || Val it_count: 1107 || Current Learning Rate: 1e-05 || Time: 10:46:54.96
Epoch :: 79 || Loss: 0.40945435 || it_count: 8344 || Val Loss: 0.41241709 || Val it_count: 1107 || Current Learning Rate: 1e-05 || Time: 10:55:12.48
Epoch :: 80 || Loss: 0.40943885 || it_count: 8344 || Val Loss: 0.41242531 || Val it_count: 1107 || Current Learning Rate: 1e-05 || Time: 11:03:29.30
Epoch :: 81 || Loss: 0.40939803 || it_count: 8344 || Val Loss: 0.41242053 || Val it_count: 1107 || Current Learning Rate: 1e-05 || Time: 11:11:45.88
Epoch :: 82 || Loss: 0.40936106 || it_count: 8344 || Val Loss: 0.41239412 || Val it_count: 1107 || Current Learning Rate: 1e-05 || Time: 11:20:2.84
Epoch :: 83 || Loss: 0.40930972 || it_count: 8344 || Val Loss: 0.41236179 || Val it_count: 1107 || Current Learning Rate: 1e-05 || Time: 11:28:20.71
Epoch :: 84 || Loss: 0.40930852 || it_count: 8344 || Val Loss: 0.41237105 || Val it_count: 1107 || Current Learning Rate: 1e-05 || Time: 11:36:38.29
Epoch :: 85 || Loss: 0.40929969 || it_count: 8344 || Val Loss: 0.41234685 || Val it_count: 1107 || Current Learning Rate: 1e-05 || Time: 11:44:56.53
Epoch :: 86 || Loss: 0.40928614 || it_count: 8344 || Val Loss: 0.41236397 || Val it_count: 1107 || Current Learning Rate: 1e-05 || Time: 11:53:14.70
Epoch :: 87 || Loss: 0.40920858 || it_count: 8344 || Val Loss: 0.41232827 || Val it_count: 1107 || Current Learning Rate: 1e-05 || Time: 12:01:31.30
Epoch :: 88 || Loss: 0.40927687 || it_count: 8344 || Val Loss: 0.41235660 || Val it_count: 1107 || Current Learning Rate: 1e-05 || Time: 12:09:50.03
Epoch 00073: reducing learning rate of group 0 to 1.0000e-06.
Epoch :: 89 || Loss: 0.40923625 || it_count: 8344 || Val Loss: 0.41232110 || Val it_count: 1107 || Current Learning Rate: 1.0000000000000002e-06 || Time: 12:18:7.21
Epoch :: 90 || Loss: 0.40946871 || it_count: 8344 || Val Loss: 0.41189397 || Val it_count: 1107 || Current Learning Rate: 1.0000000000000002e-06 || Time: 12:26:24.30
Epoch :: 91 || Loss: 0.40939845 || it_count: 8344 || Val Loss: 0.41183534 || Val it_count: 1107 || Current Learning Rate: 1.0000000000000002e-06 || Time: 12:34:42.50
Epoch :: 92 || Loss: 0.40935403 || it_count: 8344 || Val Loss: 0.41180662 || Val it_count: 1107 || Current Learning Rate: 1.0000000000000002e-06 || Time: 12:43:0.63
Epoch :: 93 || Loss: 0.40931670 || it_count: 8344 || Val Loss: 0.41179519 || Val it_count: 1107 || Current Learning Rate: 1.0000000000000002e-06 || Time: 12:51:18.83
Epoch :: 94 || Loss: 0.40931607 || it_count: 8344 || Val Loss: 0.41178700 || Val it_count: 1107 || Current Learning Rate: 1.0000000000000002e-06 || Time: 12:59:35.97
Epoch :: 95 || Loss: 0.40931905 || it_count: 8344 || Val Loss: 0.41178127 || Val it_count: 1107 || Current Learning Rate: 1.0000000000000002e-06 || Time: 13:07:55.27
Epoch :: 96 || Loss: 0.40932235 || it_count: 8344 || Val Loss: 0.41177636 || Val it_count: 1107 || Current Learning Rate: 1.0000000000000002e-06 || Time: 13:16:14.41
Epoch :: 97 || Loss: 0.40929921 || it_count: 8344 || Val Loss: 0.41176941 || Val it_count: 1107 || Current Learning Rate: 1.0000000000000002e-06 || Time: 13:24:31.48
Epoch :: 98 || Loss: 0.40935249 || it_count: 8344 || Val Loss: 0.41176552 || Val it_count: 1107 || Current Learning Rate: 1.0000000000000002e-06 || Time: 13:32:49.73
Epoch :: 99 || Loss: 0.40929870 || it_count: 8344 || Val Loss: 0.41176725 || Val it_count: 1107 || Current Learning Rate: 1.0000000000000002e-06 || Time: 13:41:8.59
Epoch 00084: reducing learning rate of group 0 to 1.0000e-07.
Early stopping triggered due to learning rate below threshold.
Done Total time: 13:49:25.96
best_loss: 0.41176551707222553

--------------------Testing--------------------

total_samples :: test_dataset = 139200, test_dataloader = 139200
Epoch ::  1 || Loss: 0.23545074 || it_count: 544 || Time: 00:00:21.58
MAE:  0.25261816
MSE:  0.23546727
RMSE:  0.44125733

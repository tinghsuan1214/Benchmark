--------------------Training--------------------
arch_str :: |none~0|+|skip_connect~0|lstm_1~1|[linear->dropout->linear]
model :: 3F
InferCell(
  info :: nodes=3, inC=1, outC=64, [1<-(I0-L0) | 2<-(I0-L1,I1-L2)], genotype_str: none~0|skip_connect~0|lstm_1~1
  linear_layers: [linear->dropout->linear]
  (layers): ModuleList(
    (0): Zero(C_in=1, C_out=64, stride=1)
    (1): FactorizedReduce(
      C_in=1, C_out=64, stride=1
      (relu): ReLU()
      (conv): Conv1d(1, 64, kernel_size=(1,), stride=(1,), bias=False)
      (bn): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (2): LSTM(
      (lstm): LSTM(64, 64, batch_first=True)
    )
  )
  (linear_layers): ModuleList(
    (0): Linear(in_features=3072, out_features=1536, bias=True)
    (1): Dropout(p=0.1, inplace=False)
    (2): Linear(in_features=1536, out_features=1, bias=True)
  )
)
tr_params :: epochs = 100, patience = 20, batch_size = 256, window_size = 48, data_size = 100
Model FLOPs: 6.358M, Model Params: 4.755M
learning rate scheduling :: (optimizer, mode='min', factor=0.1, patience=5, verbose=True)
total_samples :: train_dataset = 2136000, train_dataloader = 2136000
total_samples :: valid_dataset = 283200, valid_dataloader = 283200
Epoch ::  1 || Loss: 0.47760575 || it_count: 8344 || Val Loss: 0.49687870 || Val it_count: 1107 || Current Learning Rate: 0.001 || Time: 00:04:47.12
Epoch ::  2 || Loss: 0.46101457 || it_count: 8344 || Val Loss: 0.50127857 || Val it_count: 1107 || Current Learning Rate: 0.001 || Time: 00:09:25.02
Epoch ::  3 || Loss: 0.46066650 || it_count: 8344 || Val Loss: 0.50322231 || Val it_count: 1107 || Current Learning Rate: 0.001 || Time: 00:14:5.83
Epoch ::  4 || Loss: 0.46090815 || it_count: 8344 || Val Loss: 0.50071994 || Val it_count: 1107 || Current Learning Rate: 0.001 || Time: 00:18:46.48
Epoch ::  5 || Loss: 0.46045628 || it_count: 8344 || Val Loss: 0.46719088 || Val it_count: 1107 || Current Learning Rate: 0.001 || Time: 00:23:26.52
Epoch ::  6 || Loss: 0.46121538 || it_count: 8344 || Val Loss: 0.47160049 || Val it_count: 1107 || Current Learning Rate: 0.001 || Time: 00:28:5.19
Epoch ::  7 || Loss: 0.46047149 || it_count: 8344 || Val Loss: 0.47224945 || Val it_count: 1107 || Current Learning Rate: 0.001 || Time: 00:32:42.20
Epoch ::  8 || Loss: 0.46018867 || it_count: 8344 || Val Loss: 0.48721714 || Val it_count: 1107 || Current Learning Rate: 0.001 || Time: 00:37:21.95
Epoch ::  9 || Loss: 0.45982643 || it_count: 8344 || Val Loss: 0.46284640 || Val it_count: 1107 || Current Learning Rate: 0.001 || Time: 00:41:59.45
Epoch :: 10 || Loss: 0.46033767 || it_count: 8344 || Val Loss: 0.46494018 || Val it_count: 1107 || Current Learning Rate: 0.001 || Time: 00:46:39.23
Epoch :: 11 || Loss: 0.45975704 || it_count: 8344 || Val Loss: 0.51087292 || Val it_count: 1107 || Current Learning Rate: 0.001 || Time: 00:51:18.43
Epoch :: 12 || Loss: 0.46092371 || it_count: 8344 || Val Loss: 0.46439118 || Val it_count: 1107 || Current Learning Rate: 0.001 || Time: 00:55:59.71
Epoch :: 13 || Loss: 0.46020700 || it_count: 8344 || Val Loss: 0.47237632 || Val it_count: 1107 || Current Learning Rate: 0.001 || Time: 01:00:36.45
Epoch :: 14 || Loss: 0.46030987 || it_count: 8344 || Val Loss: 0.46161836 || Val it_count: 1107 || Current Learning Rate: 0.001 || Time: 01:05:16.38
Epoch :: 15 || Loss: 0.46018275 || it_count: 8344 || Val Loss: 0.49231199 || Val it_count: 1107 || Current Learning Rate: 0.001 || Time: 01:09:55.32
Epoch :: 16 || Loss: 0.46055026 || it_count: 8344 || Val Loss: 0.47728195 || Val it_count: 1107 || Current Learning Rate: 0.001 || Time: 01:14:34.80
Epoch :: 17 || Loss: 0.46048054 || it_count: 8344 || Val Loss: 0.49501729 || Val it_count: 1107 || Current Learning Rate: 0.001 || Time: 01:19:13.48
Epoch :: 18 || Loss: 0.45953953 || it_count: 8344 || Val Loss: 0.51424841 || Val it_count: 1107 || Current Learning Rate: 0.001 || Time: 01:23:48.10
Epoch :: 19 || Loss: 0.45968402 || it_count: 8344 || Val Loss: 0.47235328 || Val it_count: 1107 || Current Learning Rate: 0.001 || Time: 01:28:27.34
Epoch :: 20 || Loss: 0.46001173 || it_count: 8344 || Val Loss: 0.50793355 || Val it_count: 1107 || Current Learning Rate: 0.001 || Time: 01:33:3.94
Epoch :: 21 || Loss: 0.45992143 || it_count: 8344 || Val Loss: 0.48025132 || Val it_count: 1107 || Current Learning Rate: 0.001 || Time: 01:37:43.57
Epoch :: 22 || Loss: 0.46073335 || it_count: 8344 || Val Loss: 0.46595922 || Val it_count: 1107 || Current Learning Rate: 0.001 || Time: 01:42:17.63
Epoch :: 23 || Loss: 0.46007269 || it_count: 8344 || Val Loss: 0.48478599 || Val it_count: 1107 || Current Learning Rate: 0.001 || Time: 01:46:58.16
Epoch :: 24 || Loss: 0.45979621 || it_count: 8344 || Val Loss: 0.51430051 || Val it_count: 1107 || Current Learning Rate: 0.001 || Time: 01:51:28.88
Epoch :: 25 || Loss: 0.46202818 || it_count: 8344 || Val Loss: 0.45969578 || Val it_count: 1107 || Current Learning Rate: 0.001 || Time: 01:56:2.78
Epoch :: 26 || Loss: 0.46002719 || it_count: 8344 || Val Loss: 0.46974862 || Val it_count: 1107 || Current Learning Rate: 0.001 || Time: 02:00:39.82
Epoch :: 27 || Loss: 0.46070820 || it_count: 8344 || Val Loss: 0.46147085 || Val it_count: 1107 || Current Learning Rate: 0.001 || Time: 02:05:11.71
Epoch :: 28 || Loss: 0.45930385 || it_count: 8344 || Val Loss: 0.50499754 || Val it_count: 1107 || Current Learning Rate: 0.001 || Time: 02:09:44.87
Epoch :: 29 || Loss: 0.46077112 || it_count: 8344 || Val Loss: 0.46000120 || Val it_count: 1107 || Current Learning Rate: 0.001 || Time: 02:14:16.96
Epoch :: 30 || Loss: 0.46103876 || it_count: 8344 || Val Loss: 0.45944837 || Val it_count: 1107 || Current Learning Rate: 0.001 || Time: 02:18:55.45
Epoch :: 31 || Loss: 0.45979597 || it_count: 8344 || Val Loss: 0.46912264 || Val it_count: 1107 || Current Learning Rate: 0.001 || Time: 02:23:29.55
Epoch :: 32 || Loss: 0.46025732 || it_count: 8344 || Val Loss: 0.45901777 || Val it_count: 1107 || Current Learning Rate: 0.001 || Time: 02:28:3.18
Epoch :: 33 || Loss: 0.46047695 || it_count: 8344 || Val Loss: 0.50927086 || Val it_count: 1107 || Current Learning Rate: 0.001 || Time: 02:32:36.26
Epoch :: 34 || Loss: 0.46018835 || it_count: 8344 || Val Loss: 0.46379430 || Val it_count: 1107 || Current Learning Rate: 0.001 || Time: 02:37:14.12
Epoch :: 35 || Loss: 0.46009955 || it_count: 8344 || Val Loss: 0.52895209 || Val it_count: 1107 || Current Learning Rate: 0.001 || Time: 02:41:47.37
Epoch :: 36 || Loss: 0.46200471 || it_count: 8344 || Val Loss: 0.48378652 || Val it_count: 1107 || Current Learning Rate: 0.001 || Time: 02:46:19.69
Epoch :: 37 || Loss: 0.46009568 || it_count: 8344 || Val Loss: 0.48530258 || Val it_count: 1107 || Current Learning Rate: 0.001 || Time: 02:50:53.36
Epoch :: 38 || Loss: 0.45956395 || it_count: 8344 || Val Loss: 0.46293227 || Val it_count: 1107 || Current Learning Rate: 0.0001 || Time: 02:55:31.97
Epoch :: 39 || Loss: 0.49553750 || it_count: 8344 || Val Loss: 0.46123412 || Val it_count: 1107 || Current Learning Rate: 0.0001 || Time: 03:00:7.83
Epoch :: 40 || Loss: 0.49401690 || it_count: 8344 || Val Loss: 0.45805872 || Val it_count: 1107 || Current Learning Rate: 0.0001 || Time: 03:04:42.18
Epoch :: 41 || Loss: 0.49506120 || it_count: 8344 || Val Loss: 0.45666809 || Val it_count: 1107 || Current Learning Rate: 0.0001 || Time: 03:09:15.73
Epoch :: 42 || Loss: 0.49505412 || it_count: 8344 || Val Loss: 0.45790956 || Val it_count: 1107 || Current Learning Rate: 0.0001 || Time: 03:13:52.05
Epoch :: 43 || Loss: 0.49432798 || it_count: 8344 || Val Loss: 0.45725269 || Val it_count: 1107 || Current Learning Rate: 0.0001 || Time: 03:18:28.36
Epoch :: 44 || Loss: 0.49415979 || it_count: 8344 || Val Loss: 0.45737325 || Val it_count: 1107 || Current Learning Rate: 0.0001 || Time: 03:23:2.07
Epoch :: 45 || Loss: 0.49480124 || it_count: 8344 || Val Loss: 0.45688173 || Val it_count: 1107 || Current Learning Rate: 0.0001 || Time: 03:27:33.47
Epoch :: 46 || Loss: 0.49436250 || it_count: 8344 || Val Loss: 0.45610898 || Val it_count: 1107 || Current Learning Rate: 0.0001 || Time: 03:32:8.64
Epoch :: 47 || Loss: 0.49467793 || it_count: 8344 || Val Loss: 0.45689285 || Val it_count: 1107 || Current Learning Rate: 0.0001 || Time: 03:36:45.02
Epoch :: 48 || Loss: 0.49477030 || it_count: 8344 || Val Loss: 0.45749225 || Val it_count: 1107 || Current Learning Rate: 0.0001 || Time: 03:41:18.05
Epoch :: 49 || Loss: 0.49464372 || it_count: 8344 || Val Loss: 0.45618348 || Val it_count: 1107 || Current Learning Rate: 0.0001 || Time: 03:45:51.65
Epoch :: 50 || Loss: 0.49489407 || it_count: 8344 || Val Loss: 0.45900438 || Val it_count: 1107 || Current Learning Rate: 0.0001 || Time: 03:50:26.60
Epoch :: 51 || Loss: 0.49468812 || it_count: 8344 || Val Loss: 0.45709348 || Val it_count: 1107 || Current Learning Rate: 0.0001 || Time: 03:55:1.71
Epoch :: 52 || Loss: 0.49439600 || it_count: 8344 || Val Loss: 0.45591318 || Val it_count: 1107 || Current Learning Rate: 0.0001 || Time: 03:59:35.94
Epoch :: 53 || Loss: 0.49442873 || it_count: 8344 || Val Loss: 0.45752544 || Val it_count: 1107 || Current Learning Rate: 0.0001 || Time: 04:04:8.77
Epoch :: 54 || Loss: 0.49507270 || it_count: 8344 || Val Loss: 0.45381415 || Val it_count: 1107 || Current Learning Rate: 0.0001 || Time: 04:08:44.28
Epoch :: 55 || Loss: 0.49500429 || it_count: 8344 || Val Loss: 0.45568906 || Val it_count: 1107 || Current Learning Rate: 0.0001 || Time: 04:13:21.32
Epoch :: 56 || Loss: 0.49517785 || it_count: 8344 || Val Loss: 0.45539199 || Val it_count: 1107 || Current Learning Rate: 0.0001 || Time: 04:17:54.90
Epoch :: 57 || Loss: 0.49488300 || it_count: 8344 || Val Loss: 0.45726400 || Val it_count: 1107 || Current Learning Rate: 0.0001 || Time: 04:22:27.26
Epoch :: 58 || Loss: 0.49486025 || it_count: 8344 || Val Loss: 0.45670298 || Val it_count: 1107 || Current Learning Rate: 0.0001 || Time: 04:27:3.58
Epoch :: 59 || Loss: 0.49552873 || it_count: 8344 || Val Loss: 0.45785264 || Val it_count: 1107 || Current Learning Rate: 0.0001 || Time: 04:31:40.73
Epoch :: 60 || Loss: 0.49525862 || it_count: 8344 || Val Loss: 0.45421210 || Val it_count: 1107 || Current Learning Rate: 1e-05 || Time: 04:36:14.80
Epoch :: 61 || Loss: 0.51800538 || it_count: 8344 || Val Loss: 0.45889614 || Val it_count: 1107 || Current Learning Rate: 1e-05 || Time: 04:40:48.45
Epoch :: 62 || Loss: 0.51556379 || it_count: 8344 || Val Loss: 0.45742164 || Val it_count: 1107 || Current Learning Rate: 1e-05 || Time: 04:45:22.93
Epoch :: 63 || Loss: 0.51438190 || it_count: 8344 || Val Loss: 0.45716142 || Val it_count: 1107 || Current Learning Rate: 1e-05 || Time: 04:50:0.14
Epoch :: 64 || Loss: 0.51376206 || it_count: 8344 || Val Loss: 0.45708732 || Val it_count: 1107 || Current Learning Rate: 1e-05 || Time: 04:54:33.61
Epoch :: 65 || Loss: 0.51321208 || it_count: 8344 || Val Loss: 0.45690105 || Val it_count: 1107 || Current Learning Rate: 1e-05 || Time: 04:59:8.34
Epoch :: 66 || Loss: 0.51269858 || it_count: 8344 || Val Loss: 0.45679838 || Val it_count: 1107 || Current Learning Rate: 1.0000000000000002e-06 || Time: 05:03:42.06
Epoch :: 67 || Loss: 0.51659887 || it_count: 8344 || Val Loss: 0.46524604 || Val it_count: 1107 || Current Learning Rate: 1.0000000000000002e-06 || Time: 05:08:19.29
Epoch :: 68 || Loss: 0.51611796 || it_count: 8344 || Val Loss: 0.46510042 || Val it_count: 1107 || Current Learning Rate: 1.0000000000000002e-06 || Time: 05:12:52.34
Epoch :: 69 || Loss: 0.51587755 || it_count: 8344 || Val Loss: 0.46454450 || Val it_count: 1107 || Current Learning Rate: 1.0000000000000002e-06 || Time: 05:17:24.92
Epoch :: 70 || Loss: 0.51575523 || it_count: 8344 || Val Loss: 0.46407261 || Val it_count: 1107 || Current Learning Rate: 1.0000000000000002e-06 || Time: 05:22:2.26
Epoch :: 71 || Loss: 0.51566970 || it_count: 8344 || Val Loss: 0.46380807 || Val it_count: 1107 || Current Learning Rate: 1.0000000000000002e-06 || Time: 05:26:39.78
Early stopping triggered due to learning rate below threshold.
Done Total time: 05:31:12.70
best_loss: 0.4538141481343574

--------------------Testing--------------------

total_samples :: test_dataset = 139200, test_dataloader = 139200
Epoch ::  1 || Loss: 0.33903485 || it_count: 544 || Time: 00:00:15.90
MAE:  0.309655
MSE:  0.33911043
RMSE:  0.50992674

--------------------Training--------------------
arch_str :: |lstm_2~0|+|skip_connect~0|none~1|[linear->dropout->linear]
model :: 3F
InferCell(
  info :: nodes=3, inC=1, outC=64, [1<-(I0-L0) | 2<-(I0-L1,I1-L2)], genotype_str: lstm_2~0|skip_connect~0|none~1
  linear_layers: [linear->dropout->linear]
  (layers): ModuleList(
    (0): LSTM(
      (lstm): LSTM(1, 64, num_layers=2, batch_first=True)
    )
    (1): FactorizedReduce(
      C_in=1, C_out=64, stride=1
      (relu): ReLU()
      (conv): Conv1d(1, 64, kernel_size=(1,), stride=(1,), bias=False)
      (bn): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (2): Zero(C_in=64, C_out=64, stride=1)
  )
  (linear_layers): ModuleList(
    (0): Linear(in_features=3072, out_features=1536, bias=True)
    (1): Dropout(p=0.1, inplace=False)
    (2): Linear(in_features=1536, out_features=1, bias=True)
  )
)
tr_params :: epochs = 100, patience = 20, batch_size = 256, window_size = 48, data_size = 100
Model FLOPs: 7.205M, Model Params: 4.772M
learning rate scheduling :: (optimizer, mode='min', factor=0.1, patience=5, verbose=True)
total_samples :: train_dataset = 2136000, train_dataloader = 2136000
total_samples :: valid_dataset = 283200, valid_dataloader = 283200
Epoch ::  1 || Loss: 0.47977722 || it_count: 8344 || Val Loss: 0.50157207 || Val it_count: 1107 || Current Learning Rate: 0.001 || Time: 00:03:54.20
Epoch ::  2 || Loss: 0.46120313 || it_count: 8344 || Val Loss: 0.50391297 || Val it_count: 1107 || Current Learning Rate: 0.001 || Time: 00:07:44.61
Epoch ::  3 || Loss: 0.46018240 || it_count: 8344 || Val Loss: 0.50272088 || Val it_count: 1107 || Current Learning Rate: 0.001 || Time: 00:11:34.69
Epoch ::  4 || Loss: 0.45980403 || it_count: 8344 || Val Loss: 0.45929453 || Val it_count: 1107 || Current Learning Rate: 0.001 || Time: 00:15:24.81
Epoch ::  5 || Loss: 0.46132391 || it_count: 8344 || Val Loss: 0.47434615 || Val it_count: 1107 || Current Learning Rate: 0.001 || Time: 00:19:14.93
Epoch ::  6 || Loss: 0.46041632 || it_count: 8344 || Val Loss: 0.45785322 || Val it_count: 1107 || Current Learning Rate: 0.001 || Time: 00:23:4.58
Epoch ::  7 || Loss: 0.46014826 || it_count: 8344 || Val Loss: 0.51703086 || Val it_count: 1107 || Current Learning Rate: 0.001 || Time: 00:26:56.16
Epoch ::  8 || Loss: 0.46070370 || it_count: 8344 || Val Loss: 0.47690110 || Val it_count: 1107 || Current Learning Rate: 0.001 || Time: 00:30:49.04
Epoch ::  9 || Loss: 0.46045922 || it_count: 8344 || Val Loss: 0.50115335 || Val it_count: 1107 || Current Learning Rate: 0.001 || Time: 00:34:38.93
Epoch :: 10 || Loss: 0.46096711 || it_count: 8344 || Val Loss: 0.45341009 || Val it_count: 1107 || Current Learning Rate: 0.001 || Time: 00:38:30.09
Epoch :: 11 || Loss: 0.46020735 || it_count: 8344 || Val Loss: 0.45707372 || Val it_count: 1107 || Current Learning Rate: 0.001 || Time: 00:42:22.24
Epoch :: 12 || Loss: 0.46021605 || it_count: 8344 || Val Loss: 0.46568255 || Val it_count: 1107 || Current Learning Rate: 0.001 || Time: 00:46:12.89
Epoch :: 13 || Loss: 0.46083743 || it_count: 8344 || Val Loss: 0.46651641 || Val it_count: 1107 || Current Learning Rate: 0.001 || Time: 00:50:2.77
Epoch :: 14 || Loss: 0.46030026 || it_count: 8344 || Val Loss: 0.46926098 || Val it_count: 1107 || Current Learning Rate: 0.001 || Time: 00:53:53.38
Epoch :: 15 || Loss: 0.45945882 || it_count: 8344 || Val Loss: 0.45565634 || Val it_count: 1107 || Current Learning Rate: 0.001 || Time: 00:57:44.03
Epoch :: 16 || Loss: 0.45943763 || it_count: 8344 || Val Loss: 0.50492824 || Val it_count: 1107 || Current Learning Rate: 0.001 || Time: 01:01:33.69
Epoch :: 17 || Loss: 0.46137408 || it_count: 8344 || Val Loss: 0.47352975 || Val it_count: 1107 || Current Learning Rate: 0.001 || Time: 01:05:25.00
Epoch :: 18 || Loss: 0.46026837 || it_count: 8344 || Val Loss: 0.46738965 || Val it_count: 1107 || Current Learning Rate: 0.001 || Time: 01:09:17.93
Epoch :: 19 || Loss: 0.46020426 || it_count: 8344 || Val Loss: 0.50507835 || Val it_count: 1107 || Current Learning Rate: 0.001 || Time: 01:13:10.21
Epoch :: 20 || Loss: 0.45973693 || it_count: 8344 || Val Loss: 0.49068611 || Val it_count: 1107 || Current Learning Rate: 0.001 || Time: 01:17:2.77
Epoch :: 21 || Loss: 0.46042967 || it_count: 8344 || Val Loss: 0.46213514 || Val it_count: 1107 || Current Learning Rate: 0.001 || Time: 01:20:55.78
Epoch :: 22 || Loss: 0.46037727 || it_count: 8344 || Val Loss: 0.46518135 || Val it_count: 1107 || Current Learning Rate: 0.001 || Time: 01:24:47.13
Epoch :: 23 || Loss: 0.46111575 || it_count: 8344 || Val Loss: 0.49530991 || Val it_count: 1107 || Current Learning Rate: 0.001 || Time: 01:28:39.49
Epoch :: 24 || Loss: 0.46017284 || it_count: 8344 || Val Loss: 0.50276730 || Val it_count: 1107 || Current Learning Rate: 0.001 || Time: 01:32:30.98
Epoch :: 25 || Loss: 0.46078146 || it_count: 8344 || Val Loss: 0.46901825 || Val it_count: 1107 || Current Learning Rate: 0.001 || Time: 01:36:22.84
Epoch :: 26 || Loss: 0.46077803 || it_count: 8344 || Val Loss: 0.50566307 || Val it_count: 1107 || Current Learning Rate: 0.001 || Time: 01:40:16.05
Epoch :: 27 || Loss: 0.46213240 || it_count: 8344 || Val Loss: 0.45681134 || Val it_count: 1107 || Current Learning Rate: 0.001 || Time: 01:44:5.94
Epoch :: 28 || Loss: 0.45986993 || it_count: 8344 || Val Loss: 0.47110519 || Val it_count: 1107 || Current Learning Rate: 0.001 || Time: 01:47:56.61
Epoch :: 29 || Loss: 0.45994042 || it_count: 8344 || Val Loss: 0.45244580 || Val it_count: 1107 || Current Learning Rate: 0.001 || Time: 01:51:49.12
Epoch :: 30 || Loss: 0.45940191 || it_count: 8344 || Val Loss: 0.46096948 || Val it_count: 1107 || Current Learning Rate: 0.001 || Time: 01:55:39.02
Epoch :: 31 || Loss: 0.46014538 || it_count: 8344 || Val Loss: 0.51160845 || Val it_count: 1107 || Current Learning Rate: 0.001 || Time: 01:59:29.08
Epoch :: 32 || Loss: 0.46005215 || it_count: 8344 || Val Loss: 0.47056005 || Val it_count: 1107 || Current Learning Rate: 0.001 || Time: 02:03:20.12
Epoch :: 33 || Loss: 0.46040371 || it_count: 8344 || Val Loss: 0.48677825 || Val it_count: 1107 || Current Learning Rate: 0.001 || Time: 02:07:10.44
Epoch :: 34 || Loss: 0.46110345 || it_count: 8344 || Val Loss: 0.46605980 || Val it_count: 1107 || Current Learning Rate: 0.001 || Time: 02:11:0.95
Epoch 00019: reducing learning rate of group 0 to 1.0000e-04.
Epoch :: 35 || Loss: 0.46028465 || it_count: 8344 || Val Loss: 0.47768320 || Val it_count: 1107 || Current Learning Rate: 0.0001 || Time: 02:14:51.49
Epoch :: 36 || Loss: 0.49646214 || it_count: 8344 || Val Loss: 0.45737995 || Val it_count: 1107 || Current Learning Rate: 0.0001 || Time: 02:18:41.42
Epoch :: 37 || Loss: 0.49366937 || it_count: 8344 || Val Loss: 0.45879121 || Val it_count: 1107 || Current Learning Rate: 0.0001 || Time: 02:22:31.00
Epoch :: 38 || Loss: 0.49454430 || it_count: 8344 || Val Loss: 0.45547400 || Val it_count: 1107 || Current Learning Rate: 0.0001 || Time: 02:26:21.39
Epoch :: 39 || Loss: 0.49447052 || it_count: 8344 || Val Loss: 0.45728327 || Val it_count: 1107 || Current Learning Rate: 0.0001 || Time: 02:30:11.00
Epoch :: 40 || Loss: 0.49508869 || it_count: 8344 || Val Loss: 0.45518080 || Val it_count: 1107 || Current Learning Rate: 0.0001 || Time: 02:33:59.32
Epoch 00025: reducing learning rate of group 0 to 1.0000e-05.
Epoch :: 41 || Loss: 0.49447360 || it_count: 8344 || Val Loss: 0.45796188 || Val it_count: 1107 || Current Learning Rate: 1e-05 || Time: 02:37:50.42
Epoch :: 42 || Loss: 0.51794996 || it_count: 8344 || Val Loss: 0.46074288 || Val it_count: 1107 || Current Learning Rate: 1e-05 || Time: 02:41:39.69
Epoch :: 43 || Loss: 0.51529762 || it_count: 8344 || Val Loss: 0.45894917 || Val it_count: 1107 || Current Learning Rate: 1e-05 || Time: 02:45:28.76
Epoch :: 44 || Loss: 0.51419948 || it_count: 8344 || Val Loss: 0.45833009 || Val it_count: 1107 || Current Learning Rate: 1e-05 || Time: 02:49:20.00
Epoch :: 45 || Loss: 0.51349070 || it_count: 8344 || Val Loss: 0.45816764 || Val it_count: 1107 || Current Learning Rate: 1e-05 || Time: 02:53:9.81
Epoch :: 46 || Loss: 0.51305623 || it_count: 8344 || Val Loss: 0.45833383 || Val it_count: 1107 || Current Learning Rate: 1e-05 || Time: 02:57:1.49
Epoch 00031: reducing learning rate of group 0 to 1.0000e-06.
Epoch :: 47 || Loss: 0.51275631 || it_count: 8344 || Val Loss: 0.45794374 || Val it_count: 1107 || Current Learning Rate: 1.0000000000000002e-06 || Time: 03:00:50.71
Epoch :: 48 || Loss: 0.51670356 || it_count: 8344 || Val Loss: 0.46633438 || Val it_count: 1107 || Current Learning Rate: 1.0000000000000002e-06 || Time: 03:04:41.43
Epoch :: 49 || Loss: 0.51619710 || it_count: 8344 || Val Loss: 0.46575853 || Val it_count: 1107 || Current Learning Rate: 1.0000000000000002e-06 || Time: 03:08:31.33
Early stopping triggered due to patience exceeded.
Done Total time: 03:08:31.33
best_loss: 0.4524457950794402

--------------------Testing--------------------

total_samples :: test_dataset = 139200, test_dataloader = 139200
Epoch ::  1 || Loss: 0.33099964 || it_count: 544 || Time: 00:00:12.55
MAE:  0.2974462
MSE:  0.33107248
RMSE:  0.5052802

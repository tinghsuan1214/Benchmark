--------------------Training--------------------
arch_str :: |skip_connect~0|+|none~0|lstm_2~1|[linear]
model :: 3A
InferCell(
  info :: nodes=3, inC=1, outC=64, [1<-(I0-L0) | 2<-(I0-L1,I1-L2)], genotype_str: skip_connect~0|none~0|lstm_2~1
  linear_layers: [linear]
  (layers): ModuleList(
    (0): FactorizedReduce(
      C_in=1, C_out=64, stride=1
      (relu): ReLU()
      (conv): Conv1d(1, 64, kernel_size=(1,), stride=(1,), bias=False)
      (bn): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (1): Zero(C_in=1, C_out=64, stride=1)
    (2): LSTM(
      (lstm): LSTM(64, 64, num_layers=2, batch_first=True)
    )
  )
  (linear_layers): ModuleList(
    (0): Linear(in_features=3072, out_features=1, bias=True)
  )
)
tr_params :: epochs = 100, patience = 20, batch_size = 256, window_size = 48, data_size = 100
Model FLOPs: 3.262M, Model Params: 69.825K
learning rate scheduling :: (optimizer, mode='min', factor=0.1, patience=5, verbose=True)
total_samples :: train_dataset = 2136000, train_dataloader = 2136000
total_samples :: valid_dataset = 283200, valid_dataloader = 283200
Epoch ::  1 || Loss: 0.46440519 || it_count: 8344 || Val Loss: 0.48935754 || Val it_count: 1107 || Current Learning Rate: 0.001 || Time: 00:03:47.50
Epoch ::  2 || Loss: 0.46106490 || it_count: 8344 || Val Loss: 0.48936050 || Val it_count: 1107 || Current Learning Rate: 0.001 || Time: 00:07:31.20
Epoch ::  3 || Loss: 0.45660422 || it_count: 8344 || Val Loss: 0.49696122 || Val it_count: 1107 || Current Learning Rate: 0.001 || Time: 00:11:14.53
Epoch ::  4 || Loss: 0.45755761 || it_count: 8344 || Val Loss: 0.50107494 || Val it_count: 1107 || Current Learning Rate: 0.001 || Time: 00:14:58.22
Epoch ::  5 || Loss: 0.45924666 || it_count: 8344 || Val Loss: 0.48671324 || Val it_count: 1107 || Current Learning Rate: 0.001 || Time: 00:18:40.94
Epoch ::  6 || Loss: 0.46837136 || it_count: 8344 || Val Loss: 0.48794859 || Val it_count: 1107 || Current Learning Rate: 0.001 || Time: 00:22:25.08
Epoch ::  7 || Loss: 0.45682896 || it_count: 8344 || Val Loss: 0.48574508 || Val it_count: 1107 || Current Learning Rate: 0.001 || Time: 00:26:8.87
Epoch ::  8 || Loss: 0.45922905 || it_count: 8344 || Val Loss: 0.49677313 || Val it_count: 1107 || Current Learning Rate: 0.001 || Time: 00:29:51.89
Epoch ::  9 || Loss: 0.45154497 || it_count: 8344 || Val Loss: 0.50269778 || Val it_count: 1107 || Current Learning Rate: 0.001 || Time: 00:33:34.85
Epoch :: 10 || Loss: 0.45945906 || it_count: 8344 || Val Loss: 0.49026006 || Val it_count: 1107 || Current Learning Rate: 0.001 || Time: 00:37:17.71
Epoch :: 11 || Loss: 0.46138450 || it_count: 8344 || Val Loss: 0.49661583 || Val it_count: 1107 || Current Learning Rate: 0.001 || Time: 00:41:0.59
Epoch :: 12 || Loss: 0.45953485 || it_count: 8344 || Val Loss: 0.50073942 || Val it_count: 1107 || Current Learning Rate: 0.001 || Time: 00:44:45.87
Epoch :: 13 || Loss: 0.46410271 || it_count: 8344 || Val Loss: 0.49397042 || Val it_count: 1107 || Current Learning Rate: 0.001 || Time: 00:48:28.69
Epoch :: 14 || Loss: 0.45758152 || it_count: 8344 || Val Loss: 0.50164512 || Val it_count: 1107 || Current Learning Rate: 0.001 || Time: 00:52:11.05
Epoch :: 15 || Loss: 0.45681502 || it_count: 8344 || Val Loss: 0.49818864 || Val it_count: 1107 || Current Learning Rate: 0.001 || Time: 00:55:54.86
Epoch :: 16 || Loss: 0.45618451 || it_count: 8344 || Val Loss: 0.48826474 || Val it_count: 1107 || Current Learning Rate: 0.001 || Time: 00:59:39.66
Epoch :: 17 || Loss: 0.45513673 || it_count: 8344 || Val Loss: 0.49908589 || Val it_count: 1107 || Current Learning Rate: 0.001 || Time: 01:03:23.85
Epoch :: 18 || Loss: 0.45128209 || it_count: 8344 || Val Loss: 0.49976888 || Val it_count: 1107 || Current Learning Rate: 0.001 || Time: 01:07:8.50
Epoch :: 19 || Loss: 0.45055560 || it_count: 8344 || Val Loss: 0.49376310 || Val it_count: 1107 || Current Learning Rate: 0.001 || Time: 01:10:54.25
Epoch :: 20 || Loss: 0.45155665 || it_count: 8344 || Val Loss: 0.49936538 || Val it_count: 1107 || Current Learning Rate: 0.001 || Time: 01:14:39.47
Epoch :: 21 || Loss: 0.44984761 || it_count: 8344 || Val Loss: 0.49209033 || Val it_count: 1107 || Current Learning Rate: 0.001 || Time: 01:18:24.29
Epoch :: 22 || Loss: 0.45270727 || it_count: 8344 || Val Loss: 0.48896850 || Val it_count: 1107 || Current Learning Rate: 0.001 || Time: 01:22:6.66
Epoch :: 23 || Loss: 0.45937340 || it_count: 8344 || Val Loss: 0.49803995 || Val it_count: 1107 || Current Learning Rate: 0.001 || Time: 01:25:48.79
Epoch :: 24 || Loss: 0.45492434 || it_count: 8344 || Val Loss: 0.48997158 || Val it_count: 1107 || Current Learning Rate: 0.001 || Time: 01:29:30.73
Epoch :: 25 || Loss: 0.45435446 || it_count: 8344 || Val Loss: 0.48491184 || Val it_count: 1107 || Current Learning Rate: 0.001 || Time: 01:33:14.32
Epoch :: 26 || Loss: 0.45791582 || it_count: 8344 || Val Loss: 0.48447877 || Val it_count: 1107 || Current Learning Rate: 0.001 || Time: 01:36:58.15
Epoch :: 27 || Loss: 0.45128702 || it_count: 8344 || Val Loss: 0.49335833 || Val it_count: 1107 || Current Learning Rate: 0.001 || Time: 01:40:42.50
Epoch :: 28 || Loss: 0.45253705 || it_count: 8344 || Val Loss: 0.49319753 || Val it_count: 1107 || Current Learning Rate: 0.001 || Time: 01:44:22.12
Epoch :: 29 || Loss: 0.45852385 || it_count: 8344 || Val Loss: 0.49355822 || Val it_count: 1107 || Current Learning Rate: 0.001 || Time: 01:48:4.86
Epoch :: 30 || Loss: 0.45468205 || it_count: 8344 || Val Loss: 0.49244304 || Val it_count: 1107 || Current Learning Rate: 0.001 || Time: 01:51:48.53
Epoch :: 31 || Loss: 0.45205045 || it_count: 8344 || Val Loss: 0.48712682 || Val it_count: 1107 || Current Learning Rate: 0.001 || Time: 01:55:32.57
Epoch 00016: reducing learning rate of group 0 to 1.0000e-04.
Epoch :: 32 || Loss: 0.45696851 || it_count: 8344 || Val Loss: 0.49443949 || Val it_count: 1107 || Current Learning Rate: 0.0001 || Time: 01:59:16.26
Epoch :: 33 || Loss: 0.45127655 || it_count: 8344 || Val Loss: 0.49561493 || Val it_count: 1107 || Current Learning Rate: 0.0001 || Time: 02:02:59.27
Epoch :: 34 || Loss: 0.43803615 || it_count: 8344 || Val Loss: 0.48595163 || Val it_count: 1107 || Current Learning Rate: 0.0001 || Time: 02:06:43.20
Epoch :: 35 || Loss: 0.43428826 || it_count: 8344 || Val Loss: 0.48195331 || Val it_count: 1107 || Current Learning Rate: 0.0001 || Time: 02:10:28.24
Epoch :: 36 || Loss: 0.43236459 || it_count: 8344 || Val Loss: 0.48269699 || Val it_count: 1107 || Current Learning Rate: 0.0001 || Time: 02:14:11.56
Epoch :: 37 || Loss: 0.43073734 || it_count: 8344 || Val Loss: 0.48242269 || Val it_count: 1107 || Current Learning Rate: 0.0001 || Time: 02:17:55.54
Epoch :: 38 || Loss: 0.42963272 || it_count: 8344 || Val Loss: 0.48324160 || Val it_count: 1107 || Current Learning Rate: 0.0001 || Time: 02:21:39.92
Epoch :: 39 || Loss: 0.42862564 || it_count: 8344 || Val Loss: 0.48264072 || Val it_count: 1107 || Current Learning Rate: 0.0001 || Time: 02:25:22.36
Epoch :: 40 || Loss: 0.42765736 || it_count: 8344 || Val Loss: 0.48388410 || Val it_count: 1107 || Current Learning Rate: 0.0001 || Time: 02:29:5.70
Epoch 00025: reducing learning rate of group 0 to 1.0000e-05.
Epoch :: 41 || Loss: 0.42686146 || it_count: 8344 || Val Loss: 0.48419874 || Val it_count: 1107 || Current Learning Rate: 1e-05 || Time: 02:32:48.96
Epoch :: 42 || Loss: 0.43174642 || it_count: 8344 || Val Loss: 0.47568872 || Val it_count: 1107 || Current Learning Rate: 1e-05 || Time: 02:36:31.72
Epoch :: 43 || Loss: 0.42869129 || it_count: 8344 || Val Loss: 0.47548651 || Val it_count: 1107 || Current Learning Rate: 1e-05 || Time: 02:40:15.21
Epoch :: 44 || Loss: 0.42764774 || it_count: 8344 || Val Loss: 0.47527238 || Val it_count: 1107 || Current Learning Rate: 1e-05 || Time: 02:43:58.27
Epoch :: 45 || Loss: 0.42687175 || it_count: 8344 || Val Loss: 0.47505321 || Val it_count: 1107 || Current Learning Rate: 1e-05 || Time: 02:47:40.81
Epoch :: 46 || Loss: 0.42631168 || it_count: 8344 || Val Loss: 0.47489652 || Val it_count: 1107 || Current Learning Rate: 1e-05 || Time: 02:51:23.58
Epoch :: 47 || Loss: 0.42583884 || it_count: 8344 || Val Loss: 0.47482920 || Val it_count: 1107 || Current Learning Rate: 1e-05 || Time: 02:55:7.65
Epoch :: 48 || Loss: 0.42542574 || it_count: 8344 || Val Loss: 0.47482506 || Val it_count: 1107 || Current Learning Rate: 1e-05 || Time: 02:58:52.92
Epoch :: 49 || Loss: 0.42505437 || it_count: 8344 || Val Loss: 0.47485457 || Val it_count: 1107 || Current Learning Rate: 1e-05 || Time: 03:02:35.90
Epoch :: 50 || Loss: 0.42471230 || it_count: 8344 || Val Loss: 0.47491142 || Val it_count: 1107 || Current Learning Rate: 1e-05 || Time: 03:06:17.96
Epoch :: 51 || Loss: 0.42439201 || it_count: 8344 || Val Loss: 0.47498261 || Val it_count: 1107 || Current Learning Rate: 1e-05 || Time: 03:10:1.34
Epoch :: 52 || Loss: 0.42408832 || it_count: 8344 || Val Loss: 0.47505897 || Val it_count: 1107 || Current Learning Rate: 1e-05 || Time: 03:13:44.07
Epoch 00037: reducing learning rate of group 0 to 1.0000e-06.
Epoch :: 53 || Loss: 0.42379792 || it_count: 8344 || Val Loss: 0.47513098 || Val it_count: 1107 || Current Learning Rate: 1.0000000000000002e-06 || Time: 03:17:27.96
Epoch :: 54 || Loss: 0.42626342 || it_count: 8344 || Val Loss: 0.47860570 || Val it_count: 1107 || Current Learning Rate: 1.0000000000000002e-06 || Time: 03:21:12.33
Epoch :: 55 || Loss: 0.42579136 || it_count: 8344 || Val Loss: 0.47879634 || Val it_count: 1107 || Current Learning Rate: 1.0000000000000002e-06 || Time: 03:24:55.03
Epoch :: 56 || Loss: 0.42560449 || it_count: 8344 || Val Loss: 0.47881119 || Val it_count: 1107 || Current Learning Rate: 1.0000000000000002e-06 || Time: 03:28:38.06
Epoch :: 57 || Loss: 0.42547441 || it_count: 8344 || Val Loss: 0.47874285 || Val it_count: 1107 || Current Learning Rate: 1.0000000000000002e-06 || Time: 03:32:21.93
Epoch :: 58 || Loss: 0.42537280 || it_count: 8344 || Val Loss: 0.47865248 || Val it_count: 1107 || Current Learning Rate: 1.0000000000000002e-06 || Time: 03:36:4.66
Epoch 00043: reducing learning rate of group 0 to 1.0000e-07.
Early stopping triggered due to learning rate below threshold.
Done Total time: 03:39:47.11
best_loss: 0.474825060733894

--------------------Testing--------------------

total_samples :: test_dataset = 139200, test_dataloader = 139200
Epoch ::  1 || Loss: 0.46930034 || it_count: 544 || Time: 00:00:12.03
MAE:  0.33249858
MSE:  0.46942082
RMSE:  0.5274002

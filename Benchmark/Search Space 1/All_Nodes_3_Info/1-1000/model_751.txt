--------------------Training--------------------
arch_str :: |skip_connect~0|+|none~0|lstm_3~1|[linear->relu->linear]
model :: 3G
InferCell(
  info :: nodes=3, inC=1, outC=64, [1<-(I0-L0) | 2<-(I0-L1,I1-L2)], genotype_str: skip_connect~0|none~0|lstm_3~1
  linear_layers: [linear->relu->linear]
  (layers): ModuleList(
    (0): FactorizedReduce(
      C_in=1, C_out=64, stride=1
      (relu): ReLU()
      (conv): Conv1d(1, 64, kernel_size=(1,), stride=(1,), bias=False)
      (bn): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (1): Zero(C_in=1, C_out=64, stride=1)
    (2): LSTM(
      (lstm): LSTM(64, 64, num_layers=3, batch_first=True)
    )
  )
  (linear_layers): ModuleList(
    (0): Linear(in_features=3072, out_features=1536, bias=True)
    (1): ReLU()
    (2): Linear(in_features=1536, out_features=1, bias=True)
  )
)
tr_params :: epochs = 100, patience = 20, batch_size = 256, window_size = 48, data_size = 100
Model FLOPs: 9.602M, Model Params: 4.822M
learning rate scheduling :: (optimizer, mode='min', factor=0.1, patience=5, verbose=True)
total_samples :: train_dataset = 2136000, train_dataloader = 2136000
total_samples :: valid_dataset = 283200, valid_dataloader = 283200
Epoch ::  1 || Loss: 0.45140057 || it_count: 8344 || Val Loss: 0.49971719 || Val it_count: 1107 || Current Learning Rate: 0.001 || Time: 00:05:47.70
Epoch ::  2 || Loss: 0.45307755 || it_count: 8344 || Val Loss: 0.49112449 || Val it_count: 1107 || Current Learning Rate: 0.001 || Time: 00:11:28.37
Epoch ::  3 || Loss: 0.44410419 || it_count: 8344 || Val Loss: 0.48932606 || Val it_count: 1107 || Current Learning Rate: 0.001 || Time: 00:17:20.14
Epoch ::  4 || Loss: 0.44055358 || it_count: 8344 || Val Loss: 0.49195722 || Val it_count: 1107 || Current Learning Rate: 0.001 || Time: 00:23:2.10
Epoch ::  5 || Loss: 0.44051434 || it_count: 8344 || Val Loss: 0.49407414 || Val it_count: 1107 || Current Learning Rate: 0.001 || Time: 00:28:43.96
Epoch ::  6 || Loss: 0.43870129 || it_count: 8344 || Val Loss: 0.49556484 || Val it_count: 1107 || Current Learning Rate: 0.001 || Time: 00:34:25.77
Epoch ::  7 || Loss: 0.43687856 || it_count: 8344 || Val Loss: 0.49068617 || Val it_count: 1107 || Current Learning Rate: 0.001 || Time: 00:40:15.55
Epoch ::  8 || Loss: 0.43659005 || it_count: 8344 || Val Loss: 0.48737253 || Val it_count: 1107 || Current Learning Rate: 0.001 || Time: 00:45:33.13
Epoch ::  9 || Loss: 0.43583757 || it_count: 8344 || Val Loss: 0.49024285 || Val it_count: 1107 || Current Learning Rate: 0.001 || Time: 00:50:52.94
Epoch :: 10 || Loss: 0.43240072 || it_count: 8344 || Val Loss: 0.49272864 || Val it_count: 1107 || Current Learning Rate: 0.001 || Time: 00:56:13.94
Epoch :: 11 || Loss: 0.43887942 || it_count: 8344 || Val Loss: 0.49172915 || Val it_count: 1107 || Current Learning Rate: 0.001 || Time: 01:01:34.70
Epoch :: 12 || Loss: 0.43547944 || it_count: 8344 || Val Loss: 0.49779308 || Val it_count: 1107 || Current Learning Rate: 0.001 || Time: 01:06:55.86
Epoch :: 13 || Loss: 0.43128766 || it_count: 8344 || Val Loss: 0.49602803 || Val it_count: 1107 || Current Learning Rate: 0.001 || Time: 01:12:17.71
Epoch :: 14 || Loss: 0.42959262 || it_count: 8344 || Val Loss: 0.50027594 || Val it_count: 1107 || Current Learning Rate: 0.001 || Time: 01:17:39.46
Epoch :: 15 || Loss: 0.43047640 || it_count: 8344 || Val Loss: 0.49216778 || Val it_count: 1107 || Current Learning Rate: 0.001 || Time: 01:22:42.69
Epoch :: 16 || Loss: 0.42442480 || it_count: 8344 || Val Loss: 0.49316012 || Val it_count: 1107 || Current Learning Rate: 0.001 || Time: 01:27:4.66
Epoch :: 17 || Loss: 0.42102515 || it_count: 8344 || Val Loss: 0.49123147 || Val it_count: 1107 || Current Learning Rate: 0.001 || Time: 01:31:23.11
Epoch :: 18 || Loss: 0.42053149 || it_count: 8344 || Val Loss: 0.49889735 || Val it_count: 1107 || Current Learning Rate: 0.001 || Time: 01:35:44.30
Epoch :: 19 || Loss: 0.41331145 || it_count: 8344 || Val Loss: 0.49568733 || Val it_count: 1107 || Current Learning Rate: 0.001 || Time: 01:40:6.27
Epoch :: 20 || Loss: 0.44011804 || it_count: 8344 || Val Loss: 0.50582365 || Val it_count: 1107 || Current Learning Rate: 0.001 || Time: 01:44:27.74
Epoch :: 21 || Loss: 0.45789793 || it_count: 8344 || Val Loss: 0.49242712 || Val it_count: 1107 || Current Learning Rate: 0.001 || Time: 01:48:50.15
Epoch :: 22 || Loss: 0.44976143 || it_count: 8344 || Val Loss: 0.49185199 || Val it_count: 1107 || Current Learning Rate: 0.001 || Time: 01:53:10.35
Epoch 00007: reducing learning rate of group 0 to 1.0000e-04.
Epoch :: 23 || Loss: 0.45287145 || it_count: 8344 || Val Loss: 0.50200561 || Val it_count: 1107 || Current Learning Rate: 0.0001 || Time: 01:57:33.02
Epoch :: 24 || Loss: 0.44867897 || it_count: 8344 || Val Loss: 0.48640214 || Val it_count: 1107 || Current Learning Rate: 0.0001 || Time: 02:01:54.69
Epoch :: 25 || Loss: 0.43636392 || it_count: 8344 || Val Loss: 0.47905057 || Val it_count: 1107 || Current Learning Rate: 0.0001 || Time: 02:06:15.59
Epoch :: 26 || Loss: 0.43239895 || it_count: 8344 || Val Loss: 0.47791190 || Val it_count: 1107 || Current Learning Rate: 0.0001 || Time: 02:10:34.28
Epoch :: 27 || Loss: 0.43003665 || it_count: 8344 || Val Loss: 0.47964753 || Val it_count: 1107 || Current Learning Rate: 0.0001 || Time: 02:14:51.24
Epoch :: 28 || Loss: 0.42786778 || it_count: 8344 || Val Loss: 0.48324626 || Val it_count: 1107 || Current Learning Rate: 0.0001 || Time: 02:19:12.92
Epoch :: 29 || Loss: 0.42582081 || it_count: 8344 || Val Loss: 0.48571581 || Val it_count: 1107 || Current Learning Rate: 0.0001 || Time: 02:23:33.88
Epoch :: 30 || Loss: 0.42360036 || it_count: 8344 || Val Loss: 0.49112822 || Val it_count: 1107 || Current Learning Rate: 0.0001 || Time: 02:27:54.95
Epoch :: 31 || Loss: 0.42189354 || it_count: 8344 || Val Loss: 0.49350343 || Val it_count: 1107 || Current Learning Rate: 0.0001 || Time: 02:32:13.72
Epoch 00016: reducing learning rate of group 0 to 1.0000e-05.
Epoch :: 32 || Loss: 0.42053386 || it_count: 8344 || Val Loss: 0.49772870 || Val it_count: 1107 || Current Learning Rate: 1e-05 || Time: 02:36:37.20
Epoch :: 33 || Loss: 0.42891871 || it_count: 8344 || Val Loss: 0.47057346 || Val it_count: 1107 || Current Learning Rate: 1e-05 || Time: 02:40:56.25
Epoch :: 34 || Loss: 0.42298179 || it_count: 8344 || Val Loss: 0.47069950 || Val it_count: 1107 || Current Learning Rate: 1e-05 || Time: 02:45:18.97
Epoch :: 35 || Loss: 0.42047373 || it_count: 8344 || Val Loss: 0.47133462 || Val it_count: 1107 || Current Learning Rate: 1e-05 || Time: 02:49:37.99
Epoch :: 36 || Loss: 0.41890294 || it_count: 8344 || Val Loss: 0.47112440 || Val it_count: 1107 || Current Learning Rate: 1e-05 || Time: 02:54:0.37
Epoch :: 37 || Loss: 0.41800315 || it_count: 8344 || Val Loss: 0.47143627 || Val it_count: 1107 || Current Learning Rate: 1e-05 || Time: 02:58:19.72
Epoch :: 38 || Loss: 0.41726925 || it_count: 8344 || Val Loss: 0.47156678 || Val it_count: 1107 || Current Learning Rate: 1e-05 || Time: 03:02:40.90
Epoch 00023: reducing learning rate of group 0 to 1.0000e-06.
Epoch :: 39 || Loss: 0.41684052 || it_count: 8344 || Val Loss: 0.47167090 || Val it_count: 1107 || Current Learning Rate: 1.0000000000000002e-06 || Time: 03:07:1.80
Epoch :: 40 || Loss: 0.41963985 || it_count: 8344 || Val Loss: 0.47211202 || Val it_count: 1107 || Current Learning Rate: 1.0000000000000002e-06 || Time: 03:11:20.58
Epoch :: 41 || Loss: 0.41894473 || it_count: 8344 || Val Loss: 0.47162558 || Val it_count: 1107 || Current Learning Rate: 1.0000000000000002e-06 || Time: 03:15:41.69
Epoch :: 42 || Loss: 0.41867575 || it_count: 8344 || Val Loss: 0.47130539 || Val it_count: 1107 || Current Learning Rate: 1.0000000000000002e-06 || Time: 03:20:5.86
Epoch :: 43 || Loss: 0.41854219 || it_count: 8344 || Val Loss: 0.47106694 || Val it_count: 1107 || Current Learning Rate: 1.0000000000000002e-06 || Time: 03:24:30.32
Epoch :: 44 || Loss: 0.41846254 || it_count: 8344 || Val Loss: 0.47087337 || Val it_count: 1107 || Current Learning Rate: 1.0000000000000002e-06 || Time: 03:28:49.80
Epoch 00029: reducing learning rate of group 0 to 1.0000e-07.
Early stopping triggered due to learning rate below threshold.
Done Total time: 03:33:8.98
best_loss: 0.47057345782010007

--------------------Testing--------------------

total_samples :: test_dataset = 139200, test_dataloader = 139200
Epoch ::  1 || Loss: 0.43438505 || it_count: 544 || Time: 00:00:14.03
MAE:  0.33404127
MSE:  0.43448848
RMSE:  0.52004933

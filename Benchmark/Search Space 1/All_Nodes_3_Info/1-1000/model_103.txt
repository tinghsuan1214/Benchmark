--------------------Training--------------------
arch_str :: |lstm_3~0|+|lstm_2~0|none~1|[linear]
model :: 3A
InferCell(
  info :: nodes=3, inC=1, outC=64, [1<-(I0-L0) | 2<-(I0-L1,I1-L2)], genotype_str: lstm_3~0|lstm_2~0|none~1
  linear_layers: [linear]
  (layers): ModuleList(
    (0): LSTM(
      (lstm): LSTM(1, 64, num_layers=3, batch_first=True)
    )
    (1): LSTM(
      (lstm): LSTM(1, 64, num_layers=2, batch_first=True)
    )
    (2): Zero(C_in=64, C_out=64, stride=1)
  )
  (linear_layers): ModuleList(
    (0): Linear(in_features=3072, out_features=1, bias=True)
  )
)
tr_params :: epochs = 100, patience = 20, batch_size = 256, window_size = 48, data_size = 100
Model FLOPs: 6.565M, Model Params: 137.217K
learning rate scheduling :: (optimizer, mode='min', factor=0.1, patience=5, verbose=True)
total_samples :: train_dataset = 2136000, train_dataloader = 2136000
total_samples :: valid_dataset = 283200, valid_dataloader = 283200
Epoch ::  1 || Loss: 0.42178382 || it_count: 8344 || Val Loss: 0.44891064 || Val it_count: 1107 || Current Learning Rate: 0.001 || Time: 00:09:59.94
Epoch ::  2 || Loss: 0.41878682 || it_count: 8344 || Val Loss: 0.44939506 || Val it_count: 1107 || Current Learning Rate: 0.001 || Time: 00:19:48.42
Epoch ::  3 || Loss: 0.41814677 || it_count: 8344 || Val Loss: 0.44868669 || Val it_count: 1107 || Current Learning Rate: 0.001 || Time: 00:29:33.97
Epoch ::  4 || Loss: 0.41796789 || it_count: 8344 || Val Loss: 0.44845461 || Val it_count: 1107 || Current Learning Rate: 0.001 || Time: 00:39:26.34
Epoch ::  5 || Loss: 0.41807627 || it_count: 8344 || Val Loss: 0.44801151 || Val it_count: 1107 || Current Learning Rate: 0.001 || Time: 00:49:20.35
Epoch ::  6 || Loss: 0.41741797 || it_count: 8344 || Val Loss: 0.44720887 || Val it_count: 1107 || Current Learning Rate: 0.001 || Time: 00:59:10.67
Epoch ::  7 || Loss: 0.41703374 || it_count: 8344 || Val Loss: 0.44722028 || Val it_count: 1107 || Current Learning Rate: 0.001 || Time: 01:09:2.60
Epoch ::  8 || Loss: 0.41694144 || it_count: 8344 || Val Loss: 0.44660316 || Val it_count: 1107 || Current Learning Rate: 0.001 || Time: 01:18:59.32
Epoch ::  9 || Loss: 0.41669947 || it_count: 8344 || Val Loss: 0.44622173 || Val it_count: 1107 || Current Learning Rate: 0.001 || Time: 01:28:53.40
Epoch :: 10 || Loss: 0.41626932 || it_count: 8344 || Val Loss: 0.44613198 || Val it_count: 1107 || Current Learning Rate: 0.001 || Time: 01:38:43.48
Epoch :: 11 || Loss: 0.41589547 || it_count: 8344 || Val Loss: 0.44554268 || Val it_count: 1107 || Current Learning Rate: 0.001 || Time: 01:48:38.64
Epoch :: 12 || Loss: 0.41542271 || it_count: 8344 || Val Loss: 0.44480200 || Val it_count: 1107 || Current Learning Rate: 0.001 || Time: 01:58:39.07
Epoch :: 13 || Loss: 0.41516062 || it_count: 8344 || Val Loss: 0.44425179 || Val it_count: 1107 || Current Learning Rate: 0.001 || Time: 02:08:33.05
Epoch :: 14 || Loss: 0.41489096 || it_count: 8344 || Val Loss: 0.44416296 || Val it_count: 1107 || Current Learning Rate: 0.001 || Time: 02:18:28.94
Epoch :: 15 || Loss: 0.41454059 || it_count: 8344 || Val Loss: 0.44545015 || Val it_count: 1107 || Current Learning Rate: 0.001 || Time: 02:28:19.71
Epoch :: 16 || Loss: 0.41428638 || it_count: 8344 || Val Loss: 0.44602008 || Val it_count: 1107 || Current Learning Rate: 0.001 || Time: 02:38:15.62
Epoch :: 17 || Loss: 0.41397457 || it_count: 8344 || Val Loss: 0.44688297 || Val it_count: 1107 || Current Learning Rate: 0.001 || Time: 02:48:7.40
Epoch :: 18 || Loss: 0.41399765 || it_count: 8344 || Val Loss: 0.44661191 || Val it_count: 1107 || Current Learning Rate: 0.001 || Time: 02:57:50.74
Epoch :: 19 || Loss: 0.41378643 || it_count: 8344 || Val Loss: 0.44637698 || Val it_count: 1107 || Current Learning Rate: 0.001 || Time: 03:07:35.10
Epoch :: 20 || Loss: 0.41327456 || it_count: 8344 || Val Loss: 0.44612868 || Val it_count: 1107 || Current Learning Rate: 0.001 || Time: 03:17:26.73
Epoch :: 21 || Loss: 0.41273227 || it_count: 8344 || Val Loss: 0.44002471 || Val it_count: 1107 || Current Learning Rate: 0.001 || Time: 03:27:16.76
Epoch :: 22 || Loss: 0.41179171 || it_count: 8344 || Val Loss: 0.43864019 || Val it_count: 1107 || Current Learning Rate: 0.001 || Time: 03:37:3.40
Epoch :: 23 || Loss: 0.41129862 || it_count: 8344 || Val Loss: 0.44017570 || Val it_count: 1107 || Current Learning Rate: 0.001 || Time: 03:46:50.82
Epoch :: 24 || Loss: 0.41118251 || it_count: 8344 || Val Loss: 0.44265234 || Val it_count: 1107 || Current Learning Rate: 0.001 || Time: 03:56:45.39
Epoch :: 25 || Loss: 0.41049505 || it_count: 8344 || Val Loss: 0.44397905 || Val it_count: 1107 || Current Learning Rate: 0.001 || Time: 04:06:38.74
Epoch :: 26 || Loss: 0.41046661 || it_count: 8344 || Val Loss: 0.44438627 || Val it_count: 1107 || Current Learning Rate: 0.001 || Time: 04:16:24.88
Epoch :: 27 || Loss: 0.41010799 || it_count: 8344 || Val Loss: 0.44431490 || Val it_count: 1107 || Current Learning Rate: 0.001 || Time: 04:26:12.89
Epoch 00012: reducing learning rate of group 0 to 1.0000e-04.
Epoch :: 28 || Loss: 0.40978043 || it_count: 8344 || Val Loss: 0.44247079 || Val it_count: 1107 || Current Learning Rate: 0.0001 || Time: 04:36:9.39
Epoch :: 29 || Loss: 0.41485975 || it_count: 8344 || Val Loss: 0.41936696 || Val it_count: 1107 || Current Learning Rate: 0.0001 || Time: 04:46:1.17
Epoch :: 30 || Loss: 0.41059034 || it_count: 8344 || Val Loss: 0.41852058 || Val it_count: 1107 || Current Learning Rate: 0.0001 || Time: 04:55:46.45
Epoch :: 31 || Loss: 0.40997595 || it_count: 8344 || Val Loss: 0.41843256 || Val it_count: 1107 || Current Learning Rate: 0.0001 || Time: 05:05:35.30
Epoch :: 32 || Loss: 0.40958817 || it_count: 8344 || Val Loss: 0.41844303 || Val it_count: 1107 || Current Learning Rate: 0.0001 || Time: 05:15:32.17
Epoch :: 33 || Loss: 0.40931294 || it_count: 8344 || Val Loss: 0.41840648 || Val it_count: 1107 || Current Learning Rate: 0.0001 || Time: 05:25:24.91
Epoch :: 34 || Loss: 0.40906755 || it_count: 8344 || Val Loss: 0.41840047 || Val it_count: 1107 || Current Learning Rate: 0.0001 || Time: 05:35:10.79
Epoch :: 35 || Loss: 0.40885031 || it_count: 8344 || Val Loss: 0.41836590 || Val it_count: 1107 || Current Learning Rate: 0.0001 || Time: 05:45:0.34
Epoch :: 36 || Loss: 0.40864673 || it_count: 8344 || Val Loss: 0.41830442 || Val it_count: 1107 || Current Learning Rate: 0.0001 || Time: 05:54:55.23
Epoch :: 37 || Loss: 0.40842801 || it_count: 8344 || Val Loss: 0.41827196 || Val it_count: 1107 || Current Learning Rate: 0.0001 || Time: 06:04:47.20
Epoch :: 38 || Loss: 0.40824507 || it_count: 8344 || Val Loss: 0.41817688 || Val it_count: 1107 || Current Learning Rate: 0.0001 || Time: 06:14:40.54
Epoch :: 39 || Loss: 0.40806246 || it_count: 8344 || Val Loss: 0.41808912 || Val it_count: 1107 || Current Learning Rate: 0.0001 || Time: 06:24:33.37
Epoch :: 40 || Loss: 0.40790403 || it_count: 8344 || Val Loss: 0.41800519 || Val it_count: 1107 || Current Learning Rate: 0.0001 || Time: 06:34:32.46
Epoch :: 41 || Loss: 0.40775428 || it_count: 8344 || Val Loss: 0.41795792 || Val it_count: 1107 || Current Learning Rate: 0.0001 || Time: 06:44:30.40
Epoch :: 42 || Loss: 0.40761955 || it_count: 8344 || Val Loss: 0.41789555 || Val it_count: 1107 || Current Learning Rate: 0.0001 || Time: 06:54:25.02
Epoch :: 43 || Loss: 0.40749639 || it_count: 8344 || Val Loss: 0.41780684 || Val it_count: 1107 || Current Learning Rate: 0.0001 || Time: 07:04:19.14
Epoch :: 44 || Loss: 0.40737280 || it_count: 8344 || Val Loss: 0.41773972 || Val it_count: 1107 || Current Learning Rate: 0.0001 || Time: 07:14:18.14
Epoch :: 45 || Loss: 0.40725815 || it_count: 8344 || Val Loss: 0.41767616 || Val it_count: 1107 || Current Learning Rate: 0.0001 || Time: 07:24:17.25
Epoch :: 46 || Loss: 0.40714673 || it_count: 8344 || Val Loss: 0.41761566 || Val it_count: 1107 || Current Learning Rate: 0.0001 || Time: 07:34:13.19
Epoch :: 47 || Loss: 0.40705653 || it_count: 8344 || Val Loss: 0.41757275 || Val it_count: 1107 || Current Learning Rate: 0.0001 || Time: 07:44:8.49
Epoch :: 48 || Loss: 0.40695055 || it_count: 8344 || Val Loss: 0.41754845 || Val it_count: 1107 || Current Learning Rate: 0.0001 || Time: 07:54:6.10
Epoch :: 49 || Loss: 0.40686419 || it_count: 8344 || Val Loss: 0.41752317 || Val it_count: 1107 || Current Learning Rate: 0.0001 || Time: 08:04:3.68
Epoch :: 50 || Loss: 0.40676040 || it_count: 8344 || Val Loss: 0.41748228 || Val it_count: 1107 || Current Learning Rate: 0.0001 || Time: 08:13:59.01
Epoch :: 51 || Loss: 0.40666280 || it_count: 8344 || Val Loss: 0.41744273 || Val it_count: 1107 || Current Learning Rate: 0.0001 || Time: 08:23:52.44
Epoch :: 52 || Loss: 0.40656260 || it_count: 8344 || Val Loss: 0.41735917 || Val it_count: 1107 || Current Learning Rate: 0.0001 || Time: 08:33:51.68
Epoch :: 53 || Loss: 0.40645753 || it_count: 8344 || Val Loss: 0.41731364 || Val it_count: 1107 || Current Learning Rate: 0.0001 || Time: 08:43:50.70
Epoch :: 54 || Loss: 0.40635830 || it_count: 8344 || Val Loss: 0.41726751 || Val it_count: 1107 || Current Learning Rate: 0.0001 || Time: 08:53:45.08
Epoch :: 55 || Loss: 0.40627074 || it_count: 8344 || Val Loss: 0.41722354 || Val it_count: 1107 || Current Learning Rate: 0.0001 || Time: 09:03:39.47
Epoch :: 56 || Loss: 0.40617672 || it_count: 8344 || Val Loss: 0.41725635 || Val it_count: 1107 || Current Learning Rate: 0.0001 || Time: 09:13:37.80
Epoch :: 57 || Loss: 0.40608876 || it_count: 8344 || Val Loss: 0.41724298 || Val it_count: 1107 || Current Learning Rate: 0.0001 || Time: 09:23:35.34
Epoch :: 58 || Loss: 0.40601709 || it_count: 8344 || Val Loss: 0.41731413 || Val it_count: 1107 || Current Learning Rate: 0.0001 || Time: 09:33:30.27
Epoch :: 59 || Loss: 0.40593469 || it_count: 8344 || Val Loss: 0.41731723 || Val it_count: 1107 || Current Learning Rate: 0.0001 || Time: 09:43:23.38
Epoch :: 60 || Loss: 0.40585971 || it_count: 8344 || Val Loss: 0.41737258 || Val it_count: 1107 || Current Learning Rate: 0.0001 || Time: 09:53:21.90
Epoch 00045: reducing learning rate of group 0 to 1.0000e-05.
Epoch :: 61 || Loss: 0.40579322 || it_count: 8344 || Val Loss: 0.41745470 || Val it_count: 1107 || Current Learning Rate: 1e-05 || Time: 10:03:19.31
Epoch :: 62 || Loss: 0.40829424 || it_count: 8344 || Val Loss: 0.41241948 || Val it_count: 1107 || Current Learning Rate: 1e-05 || Time: 10:13:13.61
Epoch :: 63 || Loss: 0.40723668 || it_count: 8344 || Val Loss: 0.41210012 || Val it_count: 1107 || Current Learning Rate: 1e-05 || Time: 10:23:5.91
Epoch :: 64 || Loss: 0.40703861 || it_count: 8344 || Val Loss: 0.41202960 || Val it_count: 1107 || Current Learning Rate: 1e-05 || Time: 10:33:8.57
Epoch :: 65 || Loss: 0.40695134 || it_count: 8344 || Val Loss: 0.41200334 || Val it_count: 1107 || Current Learning Rate: 1e-05 || Time: 10:43:10.23
Epoch :: 66 || Loss: 0.40689163 || it_count: 8344 || Val Loss: 0.41198813 || Val it_count: 1107 || Current Learning Rate: 1e-05 || Time: 10:53:6.62
Epoch :: 67 || Loss: 0.40684374 || it_count: 8344 || Val Loss: 0.41197659 || Val it_count: 1107 || Current Learning Rate: 1e-05 || Time: 11:03:4.19
Epoch :: 68 || Loss: 0.40680448 || it_count: 8344 || Val Loss: 0.41196505 || Val it_count: 1107 || Current Learning Rate: 1e-05 || Time: 11:13:5.91
Epoch :: 69 || Loss: 0.40676982 || it_count: 8344 || Val Loss: 0.41195446 || Val it_count: 1107 || Current Learning Rate: 1e-05 || Time: 11:23:6.59
Epoch :: 70 || Loss: 0.40673821 || it_count: 8344 || Val Loss: 0.41194523 || Val it_count: 1107 || Current Learning Rate: 1e-05 || Time: 11:33:3.59
Epoch :: 71 || Loss: 0.40670991 || it_count: 8344 || Val Loss: 0.41193579 || Val it_count: 1107 || Current Learning Rate: 1e-05 || Time: 11:43:1.62
Epoch :: 72 || Loss: 0.40668329 || it_count: 8344 || Val Loss: 0.41192739 || Val it_count: 1107 || Current Learning Rate: 1e-05 || Time: 11:53:4.70
Epoch :: 73 || Loss: 0.40665823 || it_count: 8344 || Val Loss: 0.41191920 || Val it_count: 1107 || Current Learning Rate: 1e-05 || Time: 12:03:3.55
Epoch :: 74 || Loss: 0.40663422 || it_count: 8344 || Val Loss: 0.41191177 || Val it_count: 1107 || Current Learning Rate: 1e-05 || Time: 12:12:59.63
Epoch :: 75 || Loss: 0.40660864 || it_count: 8344 || Val Loss: 0.41190431 || Val it_count: 1107 || Current Learning Rate: 1e-05 || Time: 12:22:57.05
Epoch :: 76 || Loss: 0.40658680 || it_count: 8344 || Val Loss: 0.41189826 || Val it_count: 1107 || Current Learning Rate: 1e-05 || Time: 12:32:58.49
Epoch :: 77 || Loss: 0.40656577 || it_count: 8344 || Val Loss: 0.41189312 || Val it_count: 1107 || Current Learning Rate: 1e-05 || Time: 12:42:59.16
Epoch :: 78 || Loss: 0.40654548 || it_count: 8344 || Val Loss: 0.41188888 || Val it_count: 1107 || Current Learning Rate: 1e-05 || Time: 12:52:56.19
Epoch :: 79 || Loss: 0.40652580 || it_count: 8344 || Val Loss: 0.41188548 || Val it_count: 1107 || Current Learning Rate: 1e-05 || Time: 13:02:53.21
Epoch :: 80 || Loss: 0.40650664 || it_count: 8344 || Val Loss: 0.41188287 || Val it_count: 1107 || Current Learning Rate: 1e-05 || Time: 13:12:55.50
Epoch :: 81 || Loss: 0.40648794 || it_count: 8344 || Val Loss: 0.41188099 || Val it_count: 1107 || Current Learning Rate: 1e-05 || Time: 13:22:56.58
Epoch 00066: reducing learning rate of group 0 to 1.0000e-06.
Epoch :: 82 || Loss: 0.40646963 || it_count: 8344 || Val Loss: 0.41187975 || Val it_count: 1107 || Current Learning Rate: 1.0000000000000002e-06 || Time: 13:32:53.48
Epoch :: 83 || Loss: 0.40672174 || it_count: 8344 || Val Loss: 0.41161057 || Val it_count: 1107 || Current Learning Rate: 1.0000000000000002e-06 || Time: 13:42:49.79
Epoch :: 84 || Loss: 0.40665144 || it_count: 8344 || Val Loss: 0.41156114 || Val it_count: 1107 || Current Learning Rate: 1.0000000000000002e-06 || Time: 13:52:52.27
Epoch :: 85 || Loss: 0.40661885 || it_count: 8344 || Val Loss: 0.41153266 || Val it_count: 1107 || Current Learning Rate: 1.0000000000000002e-06 || Time: 14:02:52.75
Epoch :: 86 || Loss: 0.40660003 || it_count: 8344 || Val Loss: 0.41151315 || Val it_count: 1107 || Current Learning Rate: 1.0000000000000002e-06 || Time: 14:12:49.07
Epoch :: 87 || Loss: 0.40658790 || it_count: 8344 || Val Loss: 0.41149979 || Val it_count: 1107 || Current Learning Rate: 1.0000000000000002e-06 || Time: 14:22:46.84
Epoch :: 88 || Loss: 0.40657935 || it_count: 8344 || Val Loss: 0.41149009 || Val it_count: 1107 || Current Learning Rate: 1.0000000000000002e-06 || Time: 14:32:49.86
Epoch :: 89 || Loss: 0.40657281 || it_count: 8344 || Val Loss: 0.41148269 || Val it_count: 1107 || Current Learning Rate: 1.0000000000000002e-06 || Time: 14:42:50.46
Epoch :: 90 || Loss: 0.40656747 || it_count: 8344 || Val Loss: 0.41147681 || Val it_count: 1107 || Current Learning Rate: 1.0000000000000002e-06 || Time: 14:52:48.56
Epoch :: 91 || Loss: 0.40656290 || it_count: 8344 || Val Loss: 0.41147197 || Val it_count: 1107 || Current Learning Rate: 1.0000000000000002e-06 || Time: 15:02:46.73
Epoch :: 92 || Loss: 0.40655885 || it_count: 8344 || Val Loss: 0.41146786 || Val it_count: 1107 || Current Learning Rate: 1.0000000000000002e-06 || Time: 15:12:49.75
Epoch :: 93 || Loss: 0.40655517 || it_count: 8344 || Val Loss: 0.41146428 || Val it_count: 1107 || Current Learning Rate: 1.0000000000000002e-06 || Time: 15:22:50.62
Epoch :: 94 || Loss: 0.40655177 || it_count: 8344 || Val Loss: 0.41146110 || Val it_count: 1107 || Current Learning Rate: 1.0000000000000002e-06 || Time: 15:32:47.97
Epoch :: 95 || Loss: 0.40654859 || it_count: 8344 || Val Loss: 0.41145820 || Val it_count: 1107 || Current Learning Rate: 1.0000000000000002e-06 || Time: 15:42:45.08
Epoch :: 96 || Loss: 0.40654558 || it_count: 8344 || Val Loss: 0.41145553 || Val it_count: 1107 || Current Learning Rate: 1.0000000000000002e-06 || Time: 15:52:47.43
Epoch 00081: reducing learning rate of group 0 to 1.0000e-07.
Early stopping triggered due to learning rate below threshold.
Done Total time: 16:02:49.11
best_loss: 0.41145553277178004

--------------------Testing--------------------

total_samples :: test_dataset = 139200, test_dataloader = 139200
Epoch ::  1 || Loss: 0.23559744 || it_count: 544 || Time: 00:00:24.37
MAE:  0.2519425
MSE:  0.23561318
RMSE:  0.441105

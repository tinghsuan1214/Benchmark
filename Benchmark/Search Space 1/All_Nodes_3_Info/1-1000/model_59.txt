--------------------Training--------------------
arch_str :: |none~0|+|lstm_3~0|lstm_2~1|[linear]
model :: 3A
InferCell(
  info :: nodes=3, inC=1, outC=64, [1<-(I0-L0) | 2<-(I0-L1,I1-L2)], genotype_str: none~0|lstm_3~0|lstm_2~1
  linear_layers: [linear]
  (layers): ModuleList(
    (0): Zero(C_in=1, C_out=64, stride=1)
    (1): LSTM(
      (lstm): LSTM(1, 64, num_layers=3, batch_first=True)
    )
    (2): LSTM(
      (lstm): LSTM(64, 64, num_layers=2, batch_first=True)
    )
  )
  (linear_layers): ModuleList(
    (0): Linear(in_features=3072, out_features=1, bias=True)
  )
)
tr_params :: epochs = 100, patience = 20, batch_size = 256, window_size = 48, data_size = 100
Model FLOPs: 7.339M, Model Params: 153.345K
learning rate scheduling :: (optimizer, mode='min', factor=0.1, patience=5, verbose=True)
total_samples :: train_dataset = 2136000, train_dataloader = 2136000
total_samples :: valid_dataset = 283200, valid_dataloader = 283200
Epoch ::  1 || Loss: 0.42433947 || it_count: 8344 || Val Loss: 0.45065998 || Val it_count: 1107 || Current Learning Rate: 0.001 || Time: 00:04:26.05
Epoch ::  2 || Loss: 0.41885386 || it_count: 8344 || Val Loss: 0.45044846 || Val it_count: 1107 || Current Learning Rate: 0.001 || Time: 00:09:53.52
Epoch ::  3 || Loss: 0.41872212 || it_count: 8344 || Val Loss: 0.45053578 || Val it_count: 1107 || Current Learning Rate: 0.001 || Time: 00:15:45.86
Epoch ::  4 || Loss: 0.41850013 || it_count: 8344 || Val Loss: 0.45148219 || Val it_count: 1107 || Current Learning Rate: 0.001 || Time: 00:21:35.43
Epoch ::  5 || Loss: 0.41815567 || it_count: 8344 || Val Loss: 0.45357266 || Val it_count: 1107 || Current Learning Rate: 0.001 || Time: 00:27:32.28
Epoch ::  6 || Loss: 0.41790237 || it_count: 8344 || Val Loss: 0.45287533 || Val it_count: 1107 || Current Learning Rate: 0.001 || Time: 00:33:25.23
Epoch ::  7 || Loss: 0.41718226 || it_count: 8344 || Val Loss: 0.45320884 || Val it_count: 1107 || Current Learning Rate: 0.001 || Time: 00:39:21.76
Epoch ::  8 || Loss: 0.41694842 || it_count: 8344 || Val Loss: 0.45255465 || Val it_count: 1107 || Current Learning Rate: 0.001 || Time: 00:45:17.19
Epoch ::  9 || Loss: 0.41634935 || it_count: 8344 || Val Loss: 0.45139492 || Val it_count: 1107 || Current Learning Rate: 0.001 || Time: 00:51:14.32
Epoch :: 10 || Loss: 0.41582529 || it_count: 8344 || Val Loss: 0.45180434 || Val it_count: 1107 || Current Learning Rate: 0.001 || Time: 00:57:9.24
Epoch :: 11 || Loss: 0.41548739 || it_count: 8344 || Val Loss: 0.44932151 || Val it_count: 1107 || Current Learning Rate: 0.001 || Time: 01:03:4.97
Epoch :: 12 || Loss: 0.41501616 || it_count: 8344 || Val Loss: 0.45134971 || Val it_count: 1107 || Current Learning Rate: 0.001 || Time: 01:08:59.37
Epoch :: 13 || Loss: 0.41519511 || it_count: 8344 || Val Loss: 0.44956864 || Val it_count: 1107 || Current Learning Rate: 0.001 || Time: 01:13:32.56
Epoch :: 14 || Loss: 0.41515880 || it_count: 8344 || Val Loss: 0.44915219 || Val it_count: 1107 || Current Learning Rate: 0.001 || Time: 01:18:2.66
Epoch :: 15 || Loss: 0.41512526 || it_count: 8344 || Val Loss: 0.44825197 || Val it_count: 1107 || Current Learning Rate: 0.001 || Time: 01:22:30.62
Epoch :: 16 || Loss: 0.41473525 || it_count: 8344 || Val Loss: 0.44838872 || Val it_count: 1107 || Current Learning Rate: 0.001 || Time: 01:26:58.27
Epoch :: 17 || Loss: 0.41445494 || it_count: 8344 || Val Loss: 0.44778838 || Val it_count: 1107 || Current Learning Rate: 0.001 || Time: 01:31:22.04
Epoch :: 18 || Loss: 0.41436996 || it_count: 8344 || Val Loss: 0.44659953 || Val it_count: 1107 || Current Learning Rate: 0.001 || Time: 01:35:53.32
Epoch :: 19 || Loss: 0.41376127 || it_count: 8344 || Val Loss: 0.44699879 || Val it_count: 1107 || Current Learning Rate: 0.001 || Time: 01:40:25.08
Epoch :: 20 || Loss: 0.41296448 || it_count: 8344 || Val Loss: 0.44520992 || Val it_count: 1107 || Current Learning Rate: 0.001 || Time: 01:44:49.28
Epoch :: 21 || Loss: 0.41229078 || it_count: 8344 || Val Loss: 0.44218163 || Val it_count: 1107 || Current Learning Rate: 0.001 || Time: 01:49:14.04
Epoch :: 22 || Loss: 0.41168272 || it_count: 8344 || Val Loss: 0.44001441 || Val it_count: 1107 || Current Learning Rate: 0.001 || Time: 01:53:39.40
Epoch :: 23 || Loss: 0.41165311 || it_count: 8344 || Val Loss: 0.44300990 || Val it_count: 1107 || Current Learning Rate: 0.001 || Time: 01:58:8.49
Epoch :: 24 || Loss: 0.41113515 || it_count: 8344 || Val Loss: 0.44053645 || Val it_count: 1107 || Current Learning Rate: 0.001 || Time: 02:02:32.61
Epoch :: 25 || Loss: 0.41033993 || it_count: 8344 || Val Loss: 0.44168471 || Val it_count: 1107 || Current Learning Rate: 0.001 || Time: 02:06:59.89
Epoch :: 26 || Loss: 0.40975956 || it_count: 8344 || Val Loss: 0.44288185 || Val it_count: 1107 || Current Learning Rate: 0.001 || Time: 02:11:26.50
Epoch :: 27 || Loss: 0.40992489 || it_count: 8344 || Val Loss: 0.44241253 || Val it_count: 1107 || Current Learning Rate: 0.001 || Time: 02:15:52.81
Epoch 00012: reducing learning rate of group 0 to 1.0000e-04.
Epoch :: 28 || Loss: 0.40957599 || it_count: 8344 || Val Loss: 0.44542689 || Val it_count: 1107 || Current Learning Rate: 0.0001 || Time: 02:20:25.98
Epoch :: 29 || Loss: 0.41424125 || it_count: 8344 || Val Loss: 0.41996558 || Val it_count: 1107 || Current Learning Rate: 0.0001 || Time: 02:24:47.84
Epoch :: 30 || Loss: 0.41092285 || it_count: 8344 || Val Loss: 0.41938815 || Val it_count: 1107 || Current Learning Rate: 0.0001 || Time: 02:29:8.04
Epoch :: 31 || Loss: 0.41012600 || it_count: 8344 || Val Loss: 0.41937367 || Val it_count: 1107 || Current Learning Rate: 0.0001 || Time: 02:33:31.71
Epoch :: 32 || Loss: 0.40963036 || it_count: 8344 || Val Loss: 0.41950392 || Val it_count: 1107 || Current Learning Rate: 0.0001 || Time: 02:37:56.84
Epoch :: 33 || Loss: 0.40923879 || it_count: 8344 || Val Loss: 0.41961587 || Val it_count: 1107 || Current Learning Rate: 0.0001 || Time: 02:42:20.75
Epoch :: 34 || Loss: 0.40890318 || it_count: 8344 || Val Loss: 0.41963109 || Val it_count: 1107 || Current Learning Rate: 0.0001 || Time: 02:46:44.34
Epoch :: 35 || Loss: 0.40860246 || it_count: 8344 || Val Loss: 0.41963170 || Val it_count: 1107 || Current Learning Rate: 0.0001 || Time: 02:51:7.66
Epoch 00020: reducing learning rate of group 0 to 1.0000e-05.
Epoch :: 36 || Loss: 0.40833141 || it_count: 8344 || Val Loss: 0.41965184 || Val it_count: 1107 || Current Learning Rate: 1e-05 || Time: 02:55:30.79
Epoch :: 37 || Loss: 0.41024538 || it_count: 8344 || Val Loss: 0.41326051 || Val it_count: 1107 || Current Learning Rate: 1e-05 || Time: 02:59:59.45
Epoch :: 38 || Loss: 0.40901085 || it_count: 8344 || Val Loss: 0.41270820 || Val it_count: 1107 || Current Learning Rate: 1e-05 || Time: 03:04:26.20
Epoch :: 39 || Loss: 0.40881578 || it_count: 8344 || Val Loss: 0.41256864 || Val it_count: 1107 || Current Learning Rate: 1e-05 || Time: 03:08:58.70
Epoch :: 40 || Loss: 0.40871831 || it_count: 8344 || Val Loss: 0.41248335 || Val it_count: 1107 || Current Learning Rate: 1e-05 || Time: 03:13:28.37
Epoch :: 41 || Loss: 0.40864904 || it_count: 8344 || Val Loss: 0.41241893 || Val it_count: 1107 || Current Learning Rate: 1e-05 || Time: 03:17:54.35
Epoch :: 42 || Loss: 0.40859088 || it_count: 8344 || Val Loss: 0.41236505 || Val it_count: 1107 || Current Learning Rate: 1e-05 || Time: 03:22:13.53
Epoch :: 43 || Loss: 0.40854313 || it_count: 8344 || Val Loss: 0.41232400 || Val it_count: 1107 || Current Learning Rate: 1e-05 || Time: 03:26:39.21
Epoch :: 44 || Loss: 0.40849515 || it_count: 8344 || Val Loss: 0.41229628 || Val it_count: 1107 || Current Learning Rate: 1e-05 || Time: 03:31:2.55
Epoch :: 45 || Loss: 0.40845067 || it_count: 8344 || Val Loss: 0.41227166 || Val it_count: 1107 || Current Learning Rate: 1e-05 || Time: 03:35:26.62
Epoch :: 46 || Loss: 0.40841002 || it_count: 8344 || Val Loss: 0.41224820 || Val it_count: 1107 || Current Learning Rate: 1e-05 || Time: 03:39:52.32
Epoch :: 47 || Loss: 0.40837146 || it_count: 8344 || Val Loss: 0.41222668 || Val it_count: 1107 || Current Learning Rate: 1e-05 || Time: 03:44:13.15
Epoch :: 48 || Loss: 0.40833450 || it_count: 8344 || Val Loss: 0.41220678 || Val it_count: 1107 || Current Learning Rate: 1e-05 || Time: 03:49:13.33
Epoch :: 49 || Loss: 0.40829884 || it_count: 8344 || Val Loss: 0.41218819 || Val it_count: 1107 || Current Learning Rate: 1e-05 || Time: 03:54:25.13
Epoch :: 50 || Loss: 0.40826426 || it_count: 8344 || Val Loss: 0.41217048 || Val it_count: 1107 || Current Learning Rate: 1e-05 || Time: 03:59:40.06
Epoch :: 51 || Loss: 0.40823062 || it_count: 8344 || Val Loss: 0.41215350 || Val it_count: 1107 || Current Learning Rate: 1e-05 || Time: 04:04:57.91
Epoch :: 52 || Loss: 0.40819784 || it_count: 8344 || Val Loss: 0.41213716 || Val it_count: 1107 || Current Learning Rate: 1e-05 || Time: 04:09:25.16
Epoch :: 53 || Loss: 0.40816584 || it_count: 8344 || Val Loss: 0.41212136 || Val it_count: 1107 || Current Learning Rate: 1e-05 || Time: 04:14:20.23
Epoch :: 54 || Loss: 0.40813453 || it_count: 8344 || Val Loss: 0.41210604 || Val it_count: 1107 || Current Learning Rate: 1e-05 || Time: 04:19:39.22
Epoch :: 55 || Loss: 0.40810673 || it_count: 8344 || Val Loss: 0.41209635 || Val it_count: 1107 || Current Learning Rate: 1e-05 || Time: 04:24:57.76
Epoch :: 56 || Loss: 0.40807358 || it_count: 8344 || Val Loss: 0.41207850 || Val it_count: 1107 || Current Learning Rate: 1e-05 || Time: 04:30:14.20
Epoch :: 57 || Loss: 0.40804394 || it_count: 8344 || Val Loss: 0.41206362 || Val it_count: 1107 || Current Learning Rate: 1e-05 || Time: 04:34:43.06
Epoch :: 58 || Loss: 0.40801794 || it_count: 8344 || Val Loss: 0.41205415 || Val it_count: 1107 || Current Learning Rate: 1e-05 || Time: 04:39:24.87
Epoch :: 59 || Loss: 0.40798555 || it_count: 8344 || Val Loss: 0.41203902 || Val it_count: 1107 || Current Learning Rate: 1e-05 || Time: 04:44:41.27
Epoch :: 60 || Loss: 0.40796063 || it_count: 8344 || Val Loss: 0.41202977 || Val it_count: 1107 || Current Learning Rate: 1e-05 || Time: 04:49:59.33
Epoch :: 61 || Loss: 0.40792831 || it_count: 8344 || Val Loss: 0.41201704 || Val it_count: 1107 || Current Learning Rate: 1e-05 || Time: 04:55:16.23
Epoch :: 62 || Loss: 0.40790435 || it_count: 8344 || Val Loss: 0.41200866 || Val it_count: 1107 || Current Learning Rate: 1e-05 || Time: 04:59:56.75
Epoch :: 63 || Loss: 0.40787194 || it_count: 8344 || Val Loss: 0.41200008 || Val it_count: 1107 || Current Learning Rate: 1e-05 || Time: 05:04:24.53
Epoch :: 64 || Loss: 0.40784883 || it_count: 8344 || Val Loss: 0.41199221 || Val it_count: 1107 || Current Learning Rate: 1e-05 || Time: 05:08:55.06
Epoch :: 65 || Loss: 0.40781657 || it_count: 8344 || Val Loss: 0.41198614 || Val it_count: 1107 || Current Learning Rate: 1e-05 || Time: 05:13:27.02
Epoch :: 66 || Loss: 0.40779362 || it_count: 8344 || Val Loss: 0.41198056 || Val it_count: 1107 || Current Learning Rate: 1e-05 || Time: 05:18:28.57
Epoch :: 67 || Loss: 0.40776193 || it_count: 8344 || Val Loss: 0.41197412 || Val it_count: 1107 || Current Learning Rate: 1e-05 || Time: 05:23:40.87
Epoch :: 68 || Loss: 0.40773972 || it_count: 8344 || Val Loss: 0.41196817 || Val it_count: 1107 || Current Learning Rate: 1e-05 || Time: 05:28:52.71
Epoch :: 69 || Loss: 0.40770878 || it_count: 8344 || Val Loss: 0.41196021 || Val it_count: 1107 || Current Learning Rate: 1e-05 || Time: 05:34:5.81
Epoch :: 70 || Loss: 0.40768663 || it_count: 8344 || Val Loss: 0.41195554 || Val it_count: 1107 || Current Learning Rate: 1e-05 || Time: 05:38:49.98
Epoch :: 71 || Loss: 0.40765576 || it_count: 8344 || Val Loss: 0.41194668 || Val it_count: 1107 || Current Learning Rate: 1e-05 || Time: 05:43:16.43
Epoch :: 72 || Loss: 0.40763355 || it_count: 8344 || Val Loss: 0.41194308 || Val it_count: 1107 || Current Learning Rate: 1e-05 || Time: 05:47:40.52
Epoch 00057: reducing learning rate of group 0 to 1.0000e-06.
Epoch :: 73 || Loss: 0.40760360 || it_count: 8344 || Val Loss: 0.41193298 || Val it_count: 1107 || Current Learning Rate: 1.0000000000000002e-06 || Time: 05:52:5.49
Epoch :: 74 || Loss: 0.40768930 || it_count: 8344 || Val Loss: 0.41173136 || Val it_count: 1107 || Current Learning Rate: 1.0000000000000002e-06 || Time: 05:56:29.03
Epoch :: 75 || Loss: 0.40762574 || it_count: 8344 || Val Loss: 0.41169664 || Val it_count: 1107 || Current Learning Rate: 1.0000000000000002e-06 || Time: 06:00:52.34
Epoch :: 76 || Loss: 0.40760037 || it_count: 8344 || Val Loss: 0.41167752 || Val it_count: 1107 || Current Learning Rate: 1.0000000000000002e-06 || Time: 06:05:16.65
Epoch :: 77 || Loss: 0.40758580 || it_count: 8344 || Val Loss: 0.41166591 || Val it_count: 1107 || Current Learning Rate: 1.0000000000000002e-06 || Time: 06:09:40.56
Epoch :: 78 || Loss: 0.40757615 || it_count: 8344 || Val Loss: 0.41165855 || Val it_count: 1107 || Current Learning Rate: 1.0000000000000002e-06 || Time: 06:14:4.86
Epoch :: 79 || Loss: 0.40756902 || it_count: 8344 || Val Loss: 0.41165371 || Val it_count: 1107 || Current Learning Rate: 1.0000000000000002e-06 || Time: 06:18:28.72
Epoch :: 80 || Loss: 0.40756331 || it_count: 8344 || Val Loss: 0.41165042 || Val it_count: 1107 || Current Learning Rate: 1.0000000000000002e-06 || Time: 06:22:57.07
Epoch :: 81 || Loss: 0.40755845 || it_count: 8344 || Val Loss: 0.41164812 || Val it_count: 1107 || Current Learning Rate: 1.0000000000000002e-06 || Time: 06:27:27.09
Epoch 00066: reducing learning rate of group 0 to 1.0000e-07.
Early stopping triggered due to learning rate below threshold.
Done Total time: 06:31:50.99
best_loss: 0.41164812219331215

--------------------Testing--------------------

total_samples :: test_dataset = 139200, test_dataloader = 139200
Epoch ::  1 || Loss: 0.23570740 || it_count: 544 || Time: 00:00:13.95
MAE:  0.25198147
MSE:  0.23572512
RMSE:  0.44125205

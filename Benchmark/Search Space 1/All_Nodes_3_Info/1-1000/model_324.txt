--------------------Training--------------------
arch_str :: |lstm_1~0|+|skip_connect~0|lstm_3~1|[relu->linear]
model :: 3C
InferCell(
  info :: nodes=3, inC=1, outC=64, [1<-(I0-L0) | 2<-(I0-L1,I1-L2)], genotype_str: lstm_1~0|skip_connect~0|lstm_3~1
  linear_layers: [relu->linear]
  (layers): ModuleList(
    (0): LSTM(
      (lstm): LSTM(1, 64, batch_first=True)
    )
    (1): FactorizedReduce(
      C_in=1, C_out=64, stride=1
      (relu): ReLU()
      (conv): Conv1d(1, 64, kernel_size=(1,), stride=(1,), bias=False)
      (bn): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (2): LSTM(
      (lstm): LSTM(64, 64, num_layers=3, batch_first=True)
    )
  )
  (linear_layers): ModuleList(
    (0): ReLU()
    (1): Linear(in_features=3072, out_features=1, bias=True)
  )
)
tr_params :: epochs = 100, patience = 20, batch_size = 256, window_size = 48, data_size = 100
Model FLOPs: 5.732M, Model Params: 120.257K
learning rate scheduling :: (optimizer, mode='min', factor=0.1, patience=5, verbose=True)
total_samples :: train_dataset = 2136000, train_dataloader = 2136000
total_samples :: valid_dataset = 283200, valid_dataloader = 283200
Epoch ::  1 || Loss: 0.46097910 || it_count: 8344 || Val Loss: 0.57035827 || Val it_count: 1107 || Current Learning Rate: 0.001 || Time: 00:05:18.18
Epoch ::  2 || Loss: 0.45982584 || it_count: 8344 || Val Loss: 0.49888807 || Val it_count: 1107 || Current Learning Rate: 0.001 || Time: 00:10:30.97
Epoch ::  3 || Loss: 0.43425899 || it_count: 8344 || Val Loss: 0.47695318 || Val it_count: 1107 || Current Learning Rate: 0.001 || Time: 00:15:43.77
Epoch ::  4 || Loss: 0.42955327 || it_count: 8344 || Val Loss: 0.47043951 || Val it_count: 1107 || Current Learning Rate: 0.001 || Time: 00:20:56.42
Epoch ::  5 || Loss: 0.42926115 || it_count: 8344 || Val Loss: 0.48702169 || Val it_count: 1107 || Current Learning Rate: 0.001 || Time: 00:26:9.79
Epoch ::  6 || Loss: 0.42818021 || it_count: 8344 || Val Loss: 0.48205501 || Val it_count: 1107 || Current Learning Rate: 0.001 || Time: 00:31:22.02
Epoch ::  7 || Loss: 0.42826122 || it_count: 8344 || Val Loss: 0.48273528 || Val it_count: 1107 || Current Learning Rate: 0.001 || Time: 00:36:34.95
Epoch ::  8 || Loss: 0.43208529 || it_count: 8344 || Val Loss: 0.48273478 || Val it_count: 1107 || Current Learning Rate: 0.001 || Time: 00:41:48.12
Epoch ::  9 || Loss: 0.42754802 || it_count: 8344 || Val Loss: 0.47733795 || Val it_count: 1107 || Current Learning Rate: 0.001 || Time: 00:47:0.62
Epoch :: 10 || Loss: 0.42276486 || it_count: 8344 || Val Loss: 0.46252003 || Val it_count: 1107 || Current Learning Rate: 0.001 || Time: 00:52:14.33
Epoch :: 11 || Loss: 0.42135232 || it_count: 8344 || Val Loss: 0.46825697 || Val it_count: 1107 || Current Learning Rate: 0.001 || Time: 00:57:27.62
Epoch :: 12 || Loss: 0.41846542 || it_count: 8344 || Val Loss: 0.47373916 || Val it_count: 1107 || Current Learning Rate: 0.001 || Time: 01:02:39.66
Epoch :: 13 || Loss: 0.41877873 || it_count: 8344 || Val Loss: 0.47103898 || Val it_count: 1107 || Current Learning Rate: 0.001 || Time: 01:07:54.21
Epoch :: 14 || Loss: 0.41452662 || it_count: 8344 || Val Loss: 0.46723950 || Val it_count: 1107 || Current Learning Rate: 0.001 || Time: 01:13:8.61
Epoch :: 15 || Loss: 0.41374047 || it_count: 8344 || Val Loss: 0.46631470 || Val it_count: 1107 || Current Learning Rate: 0.001 || Time: 01:18:21.58
Epoch :: 16 || Loss: 0.41279092 || it_count: 8344 || Val Loss: 0.46703844 || Val it_count: 1107 || Current Learning Rate: 0.001 || Time: 01:23:33.84
Epoch :: 17 || Loss: 0.41210845 || it_count: 8344 || Val Loss: 0.46546490 || Val it_count: 1107 || Current Learning Rate: 0.001 || Time: 01:28:47.36
Epoch :: 18 || Loss: 0.41129906 || it_count: 8344 || Val Loss: 0.46329392 || Val it_count: 1107 || Current Learning Rate: 0.001 || Time: 01:34:0.62
Epoch :: 19 || Loss: 0.41052065 || it_count: 8344 || Val Loss: 0.46203516 || Val it_count: 1107 || Current Learning Rate: 0.001 || Time: 01:39:14.48
Epoch :: 20 || Loss: 0.40984585 || it_count: 8344 || Val Loss: 0.46645048 || Val it_count: 1107 || Current Learning Rate: 0.001 || Time: 01:44:27.72
Epoch :: 21 || Loss: 0.40999432 || it_count: 8344 || Val Loss: 0.47072170 || Val it_count: 1107 || Current Learning Rate: 0.001 || Time: 01:49:41.57
Epoch :: 22 || Loss: 0.40946844 || it_count: 8344 || Val Loss: 0.47064351 || Val it_count: 1107 || Current Learning Rate: 0.001 || Time: 01:54:55.47
Epoch :: 23 || Loss: 0.40877039 || it_count: 8344 || Val Loss: 0.46728230 || Val it_count: 1107 || Current Learning Rate: 0.001 || Time: 02:00:9.37
Epoch :: 24 || Loss: 0.40807762 || it_count: 8344 || Val Loss: 0.46806260 || Val it_count: 1107 || Current Learning Rate: 0.001 || Time: 02:05:22.75
Epoch 00009: reducing learning rate of group 0 to 1.0000e-04.
Epoch :: 25 || Loss: 0.40820402 || it_count: 8344 || Val Loss: 0.46622441 || Val it_count: 1107 || Current Learning Rate: 0.0001 || Time: 02:10:34.80
Epoch :: 26 || Loss: 0.41061376 || it_count: 8344 || Val Loss: 0.45213616 || Val it_count: 1107 || Current Learning Rate: 0.0001 || Time: 02:15:47.10
Epoch :: 27 || Loss: 0.40700061 || it_count: 8344 || Val Loss: 0.45278468 || Val it_count: 1107 || Current Learning Rate: 0.0001 || Time: 02:20:59.93
Epoch :: 28 || Loss: 0.40642575 || it_count: 8344 || Val Loss: 0.45213856 || Val it_count: 1107 || Current Learning Rate: 0.0001 || Time: 02:26:13.58
Epoch :: 29 || Loss: 0.40596827 || it_count: 8344 || Val Loss: 0.45226851 || Val it_count: 1107 || Current Learning Rate: 0.0001 || Time: 02:31:26.33
Epoch :: 30 || Loss: 0.40559642 || it_count: 8344 || Val Loss: 0.45291926 || Val it_count: 1107 || Current Learning Rate: 0.0001 || Time: 02:36:39.41
Epoch :: 31 || Loss: 0.40528028 || it_count: 8344 || Val Loss: 0.45320064 || Val it_count: 1107 || Current Learning Rate: 0.0001 || Time: 02:41:52.90
Epoch 00016: reducing learning rate of group 0 to 1.0000e-05.
Epoch :: 32 || Loss: 0.40496923 || it_count: 8344 || Val Loss: 0.45311796 || Val it_count: 1107 || Current Learning Rate: 1e-05 || Time: 02:47:5.93
Epoch :: 33 || Loss: 0.40636617 || it_count: 8344 || Val Loss: 0.44428728 || Val it_count: 1107 || Current Learning Rate: 1e-05 || Time: 02:52:19.59
Epoch :: 34 || Loss: 0.40552245 || it_count: 8344 || Val Loss: 0.44399687 || Val it_count: 1107 || Current Learning Rate: 1e-05 || Time: 02:57:33.40
Epoch :: 35 || Loss: 0.40533285 || it_count: 8344 || Val Loss: 0.44429682 || Val it_count: 1107 || Current Learning Rate: 1e-05 || Time: 03:02:46.70
Epoch :: 36 || Loss: 0.40523765 || it_count: 8344 || Val Loss: 0.44436687 || Val it_count: 1107 || Current Learning Rate: 1e-05 || Time: 03:08:0.28
Epoch :: 37 || Loss: 0.40516596 || it_count: 8344 || Val Loss: 0.44440302 || Val it_count: 1107 || Current Learning Rate: 1e-05 || Time: 03:13:12.96
Epoch :: 38 || Loss: 0.40510537 || it_count: 8344 || Val Loss: 0.44448308 || Val it_count: 1107 || Current Learning Rate: 1e-05 || Time: 03:18:26.64
Epoch :: 39 || Loss: 0.40505408 || it_count: 8344 || Val Loss: 0.44473260 || Val it_count: 1107 || Current Learning Rate: 1e-05 || Time: 03:23:40.44
Epoch 00024: reducing learning rate of group 0 to 1.0000e-06.
Epoch :: 40 || Loss: 0.40500457 || it_count: 8344 || Val Loss: 0.44505924 || Val it_count: 1107 || Current Learning Rate: 1.0000000000000002e-06 || Time: 03:28:52.98
Epoch :: 41 || Loss: 0.40514244 || it_count: 8344 || Val Loss: 0.44389058 || Val it_count: 1107 || Current Learning Rate: 1.0000000000000002e-06 || Time: 03:34:6.87
Epoch :: 42 || Loss: 0.40502298 || it_count: 8344 || Val Loss: 0.44357766 || Val it_count: 1107 || Current Learning Rate: 1.0000000000000002e-06 || Time: 03:39:19.91
Epoch :: 43 || Loss: 0.40499555 || it_count: 8344 || Val Loss: 0.44345759 || Val it_count: 1107 || Current Learning Rate: 1.0000000000000002e-06 || Time: 03:44:33.07
Epoch :: 44 || Loss: 0.40498218 || it_count: 8344 || Val Loss: 0.44340905 || Val it_count: 1107 || Current Learning Rate: 1.0000000000000002e-06 || Time: 03:49:46.59
Epoch :: 45 || Loss: 0.40497279 || it_count: 8344 || Val Loss: 0.44338415 || Val it_count: 1107 || Current Learning Rate: 1.0000000000000002e-06 || Time: 03:54:58.87
Epoch :: 46 || Loss: 0.40496501 || it_count: 8344 || Val Loss: 0.44337268 || Val it_count: 1107 || Current Learning Rate: 1.0000000000000002e-06 || Time: 04:00:11.61
Epoch :: 47 || Loss: 0.40495826 || it_count: 8344 || Val Loss: 0.44336820 || Val it_count: 1107 || Current Learning Rate: 1.0000000000000002e-06 || Time: 04:05:24.71
Epoch :: 48 || Loss: 0.40495195 || it_count: 8344 || Val Loss: 0.44336313 || Val it_count: 1107 || Current Learning Rate: 1.0000000000000002e-06 || Time: 04:10:37.50
Epoch :: 49 || Loss: 0.40494606 || it_count: 8344 || Val Loss: 0.44335818 || Val it_count: 1107 || Current Learning Rate: 1.0000000000000002e-06 || Time: 04:15:51.75
Epoch :: 50 || Loss: 0.40494043 || it_count: 8344 || Val Loss: 0.44336025 || Val it_count: 1107 || Current Learning Rate: 1.0000000000000002e-06 || Time: 04:21:5.51
Epoch :: 51 || Loss: 0.40493501 || it_count: 8344 || Val Loss: 0.44336491 || Val it_count: 1107 || Current Learning Rate: 1.0000000000000002e-06 || Time: 04:26:18.50
Epoch :: 52 || Loss: 0.40492974 || it_count: 8344 || Val Loss: 0.44337344 || Val it_count: 1107 || Current Learning Rate: 1.0000000000000002e-06 || Time: 04:31:31.14
Epoch :: 53 || Loss: 0.40492462 || it_count: 8344 || Val Loss: 0.44338425 || Val it_count: 1107 || Current Learning Rate: 1.0000000000000002e-06 || Time: 04:36:45.11
Epoch 00038: reducing learning rate of group 0 to 1.0000e-07.
Early stopping triggered due to learning rate below threshold.
Done Total time: 04:41:59.14
best_loss: 0.4433581799437993

--------------------Testing--------------------

total_samples :: test_dataset = 139200, test_dataloader = 139200
Epoch ::  1 || Loss: 0.36973711 || it_count: 544 || Time: 00:00:16.75
MAE:  0.29109168
MSE:  0.36981657
RMSE:  0.4914701

--------------------Training--------------------
arch_str :: |none~0|+|lstm_2~0|lstm_3~1|[linear]
model :: 3A
InferCell(
  info :: nodes=3, inC=1, outC=64, [1<-(I0-L0) | 2<-(I0-L1,I1-L2)], genotype_str: none~0|lstm_2~0|lstm_3~1
  linear_layers: [linear]
  (layers): ModuleList(
    (0): Zero(C_in=1, C_out=64, stride=1)
    (1): LSTM(
      (lstm): LSTM(1, 64, num_layers=2, batch_first=True)
    )
    (2): LSTM(
      (lstm): LSTM(64, 64, num_layers=3, batch_first=True)
    )
  )
  (linear_layers): ModuleList(
    (0): Linear(in_features=3072, out_features=1, bias=True)
  )
)
tr_params :: epochs = 100, patience = 20, batch_size = 256, window_size = 48, data_size = 100
Model FLOPs: 7.339M, Model Params: 153.345K
learning rate scheduling :: (optimizer, mode='min', factor=0.1, patience=5, verbose=True)
total_samples :: train_dataset = 2136000, train_dataloader = 2136000
total_samples :: valid_dataset = 283200, valid_dataloader = 283200
Epoch ::  1 || Loss: 0.42196449 || it_count: 8344 || Val Loss: 0.44949726 || Val it_count: 1107 || Current Learning Rate: 0.001 || Time: 00:04:58.89
Epoch ::  2 || Loss: 0.41887769 || it_count: 8344 || Val Loss: 0.44908044 || Val it_count: 1107 || Current Learning Rate: 0.001 || Time: 00:09:55.15
Epoch ::  3 || Loss: 0.41832225 || it_count: 8344 || Val Loss: 0.45074406 || Val it_count: 1107 || Current Learning Rate: 0.001 || Time: 00:14:51.93
Epoch ::  4 || Loss: 0.41784316 || it_count: 8344 || Val Loss: 0.45068081 || Val it_count: 1107 || Current Learning Rate: 0.001 || Time: 00:19:49.17
Epoch ::  5 || Loss: 0.41840789 || it_count: 8344 || Val Loss: 0.44927295 || Val it_count: 1107 || Current Learning Rate: 0.001 || Time: 00:24:46.06
Epoch ::  6 || Loss: 0.41756291 || it_count: 8344 || Val Loss: 0.44834937 || Val it_count: 1107 || Current Learning Rate: 0.001 || Time: 00:29:42.86
Epoch ::  7 || Loss: 0.41745065 || it_count: 8344 || Val Loss: 0.44720501 || Val it_count: 1107 || Current Learning Rate: 0.001 || Time: 00:34:40.82
Epoch ::  8 || Loss: 0.41754302 || it_count: 8344 || Val Loss: 0.44693535 || Val it_count: 1107 || Current Learning Rate: 0.001 || Time: 00:39:38.58
Epoch ::  9 || Loss: 0.41723164 || it_count: 8344 || Val Loss: 0.44579904 || Val it_count: 1107 || Current Learning Rate: 0.001 || Time: 00:44:37.50
Epoch :: 10 || Loss: 0.41685985 || it_count: 8344 || Val Loss: 0.44438216 || Val it_count: 1107 || Current Learning Rate: 0.001 || Time: 00:49:33.88
Epoch :: 11 || Loss: 0.41613990 || it_count: 8344 || Val Loss: 0.44366988 || Val it_count: 1107 || Current Learning Rate: 0.001 || Time: 00:54:32.09
Epoch :: 12 || Loss: 0.41578751 || it_count: 8344 || Val Loss: 0.44350596 || Val it_count: 1107 || Current Learning Rate: 0.001 || Time: 00:59:29.42
Epoch :: 13 || Loss: 0.41548356 || it_count: 8344 || Val Loss: 0.44398097 || Val it_count: 1107 || Current Learning Rate: 0.001 || Time: 01:04:26.46
Epoch :: 14 || Loss: 0.41551164 || it_count: 8344 || Val Loss: 0.44382857 || Val it_count: 1107 || Current Learning Rate: 0.001 || Time: 01:09:23.20
Epoch :: 15 || Loss: 0.41524388 || it_count: 8344 || Val Loss: 0.44325804 || Val it_count: 1107 || Current Learning Rate: 0.001 || Time: 01:14:21.38
Epoch :: 16 || Loss: 0.41481897 || it_count: 8344 || Val Loss: 0.44276643 || Val it_count: 1107 || Current Learning Rate: 0.001 || Time: 01:19:19.61
Epoch :: 17 || Loss: 0.41433222 || it_count: 8344 || Val Loss: 0.44424053 || Val it_count: 1107 || Current Learning Rate: 0.001 || Time: 01:24:16.61
Epoch :: 18 || Loss: 0.41361711 || it_count: 8344 || Val Loss: 0.44536289 || Val it_count: 1107 || Current Learning Rate: 0.001 || Time: 01:29:14.60
Epoch :: 19 || Loss: 0.41307818 || it_count: 8344 || Val Loss: 0.44436914 || Val it_count: 1107 || Current Learning Rate: 0.001 || Time: 01:34:13.53
Epoch :: 20 || Loss: 0.41340690 || it_count: 8344 || Val Loss: 0.44195411 || Val it_count: 1107 || Current Learning Rate: 0.001 || Time: 01:38:53.69
Epoch :: 21 || Loss: 0.41282338 || it_count: 8344 || Val Loss: 0.44317214 || Val it_count: 1107 || Current Learning Rate: 0.001 || Time: 01:43:30.68
Epoch :: 22 || Loss: 0.41259060 || it_count: 8344 || Val Loss: 0.45293422 || Val it_count: 1107 || Current Learning Rate: 0.001 || Time: 01:48:7.92
Epoch :: 23 || Loss: 0.41192612 || it_count: 8344 || Val Loss: 0.45317281 || Val it_count: 1107 || Current Learning Rate: 0.001 || Time: 01:52:47.02
Epoch :: 24 || Loss: 0.41181219 || it_count: 8344 || Val Loss: 0.45432818 || Val it_count: 1107 || Current Learning Rate: 0.001 || Time: 01:57:26.14
Epoch :: 25 || Loss: 0.41140719 || it_count: 8344 || Val Loss: 0.45135075 || Val it_count: 1107 || Current Learning Rate: 0.001 || Time: 02:02:3.67
Epoch 00010: reducing learning rate of group 0 to 1.0000e-04.
Epoch :: 26 || Loss: 0.41116162 || it_count: 8344 || Val Loss: 0.44523632 || Val it_count: 1107 || Current Learning Rate: 0.0001 || Time: 02:06:43.18
Epoch :: 27 || Loss: 0.41640046 || it_count: 8344 || Val Loss: 0.42120095 || Val it_count: 1107 || Current Learning Rate: 0.0001 || Time: 02:11:18.44
Epoch :: 28 || Loss: 0.41178473 || it_count: 8344 || Val Loss: 0.42068675 || Val it_count: 1107 || Current Learning Rate: 0.0001 || Time: 02:15:56.81
Epoch :: 29 || Loss: 0.41121773 || it_count: 8344 || Val Loss: 0.42070080 || Val it_count: 1107 || Current Learning Rate: 0.0001 || Time: 02:20:35.64
Epoch :: 30 || Loss: 0.41091985 || it_count: 8344 || Val Loss: 0.42069474 || Val it_count: 1107 || Current Learning Rate: 0.0001 || Time: 02:25:13.36
Epoch :: 31 || Loss: 0.41064910 || it_count: 8344 || Val Loss: 0.42066494 || Val it_count: 1107 || Current Learning Rate: 0.0001 || Time: 02:29:50.59
Epoch :: 32 || Loss: 0.41040755 || it_count: 8344 || Val Loss: 0.42062900 || Val it_count: 1107 || Current Learning Rate: 0.0001 || Time: 02:34:27.30
Epoch :: 33 || Loss: 0.41017962 || it_count: 8344 || Val Loss: 0.42055526 || Val it_count: 1107 || Current Learning Rate: 0.0001 || Time: 02:39:4.57
Epoch :: 34 || Loss: 0.40997635 || it_count: 8344 || Val Loss: 0.42048148 || Val it_count: 1107 || Current Learning Rate: 0.0001 || Time: 02:43:43.15
Epoch :: 35 || Loss: 0.40979313 || it_count: 8344 || Val Loss: 0.42041822 || Val it_count: 1107 || Current Learning Rate: 0.0001 || Time: 02:48:20.31
Epoch :: 36 || Loss: 0.40960987 || it_count: 8344 || Val Loss: 0.42031189 || Val it_count: 1107 || Current Learning Rate: 0.0001 || Time: 02:52:58.83
Epoch :: 37 || Loss: 0.40943441 || it_count: 8344 || Val Loss: 0.42022773 || Val it_count: 1107 || Current Learning Rate: 0.0001 || Time: 02:57:34.34
Epoch :: 38 || Loss: 0.40926333 || it_count: 8344 || Val Loss: 0.42016774 || Val it_count: 1107 || Current Learning Rate: 0.0001 || Time: 03:02:9.24
Epoch :: 39 || Loss: 0.40909568 || it_count: 8344 || Val Loss: 0.42013041 || Val it_count: 1107 || Current Learning Rate: 0.0001 || Time: 03:06:42.75
Epoch :: 40 || Loss: 0.40893077 || it_count: 8344 || Val Loss: 0.42011505 || Val it_count: 1107 || Current Learning Rate: 0.0001 || Time: 03:11:18.90
Epoch :: 41 || Loss: 0.40876555 || it_count: 8344 || Val Loss: 0.42009445 || Val it_count: 1107 || Current Learning Rate: 0.0001 || Time: 03:15:51.51
Epoch :: 42 || Loss: 0.40860305 || it_count: 8344 || Val Loss: 0.42008797 || Val it_count: 1107 || Current Learning Rate: 0.0001 || Time: 03:20:25.97
Epoch :: 43 || Loss: 0.40846907 || it_count: 8344 || Val Loss: 0.42007026 || Val it_count: 1107 || Current Learning Rate: 0.0001 || Time: 03:25:2.59
Epoch :: 44 || Loss: 0.40830482 || it_count: 8344 || Val Loss: 0.42004604 || Val it_count: 1107 || Current Learning Rate: 0.0001 || Time: 03:29:35.87
Epoch :: 45 || Loss: 0.40815869 || it_count: 8344 || Val Loss: 0.42000049 || Val it_count: 1107 || Current Learning Rate: 0.0001 || Time: 03:34:10.52
Epoch :: 46 || Loss: 0.40801677 || it_count: 8344 || Val Loss: 0.41995629 || Val it_count: 1107 || Current Learning Rate: 0.0001 || Time: 03:38:42.51
Epoch :: 47 || Loss: 0.40787392 || it_count: 8344 || Val Loss: 0.41991092 || Val it_count: 1107 || Current Learning Rate: 0.0001 || Time: 03:43:15.21
Epoch :: 48 || Loss: 0.40774267 || it_count: 8344 || Val Loss: 0.41987765 || Val it_count: 1107 || Current Learning Rate: 0.0001 || Time: 03:47:52.12
Epoch :: 49 || Loss: 0.40762223 || it_count: 8344 || Val Loss: 0.41985783 || Val it_count: 1107 || Current Learning Rate: 0.0001 || Time: 03:52:24.10
Epoch :: 50 || Loss: 0.40750807 || it_count: 8344 || Val Loss: 0.41986236 || Val it_count: 1107 || Current Learning Rate: 0.0001 || Time: 03:56:55.26
Epoch :: 51 || Loss: 0.40739803 || it_count: 8344 || Val Loss: 0.41987990 || Val it_count: 1107 || Current Learning Rate: 0.0001 || Time: 04:01:29.58
Epoch :: 52 || Loss: 0.40729275 || it_count: 8344 || Val Loss: 0.41990499 || Val it_count: 1107 || Current Learning Rate: 0.0001 || Time: 04:06:2.36
Epoch :: 53 || Loss: 0.40719590 || it_count: 8344 || Val Loss: 0.41991969 || Val it_count: 1107 || Current Learning Rate: 0.0001 || Time: 04:10:36.04
Epoch :: 54 || Loss: 0.40709969 || it_count: 8344 || Val Loss: 0.41996348 || Val it_count: 1107 || Current Learning Rate: 0.0001 || Time: 04:15:8.20
Epoch 00039: reducing learning rate of group 0 to 1.0000e-05.
Epoch :: 55 || Loss: 0.40700517 || it_count: 8344 || Val Loss: 0.42002042 || Val it_count: 1107 || Current Learning Rate: 1e-05 || Time: 04:19:41.78
Epoch :: 56 || Loss: 0.40894952 || it_count: 8344 || Val Loss: 0.41454721 || Val it_count: 1107 || Current Learning Rate: 1e-05 || Time: 04:24:14.80
Epoch :: 57 || Loss: 0.40806764 || it_count: 8344 || Val Loss: 0.41427557 || Val it_count: 1107 || Current Learning Rate: 1e-05 || Time: 04:28:47.09
Epoch :: 58 || Loss: 0.40793073 || it_count: 8344 || Val Loss: 0.41417451 || Val it_count: 1107 || Current Learning Rate: 1e-05 || Time: 04:33:21.97
Epoch :: 59 || Loss: 0.40785670 || it_count: 8344 || Val Loss: 0.41412174 || Val it_count: 1107 || Current Learning Rate: 1e-05 || Time: 04:38:0.44
Epoch :: 60 || Loss: 0.40780413 || it_count: 8344 || Val Loss: 0.41408363 || Val it_count: 1107 || Current Learning Rate: 1e-05 || Time: 04:42:32.22
Epoch :: 61 || Loss: 0.40776323 || it_count: 8344 || Val Loss: 0.41405673 || Val it_count: 1107 || Current Learning Rate: 1e-05 || Time: 04:47:6.23
Epoch :: 62 || Loss: 0.40772588 || it_count: 8344 || Val Loss: 0.41403554 || Val it_count: 1107 || Current Learning Rate: 1e-05 || Time: 04:51:43.62
Epoch :: 63 || Loss: 0.40769283 || it_count: 8344 || Val Loss: 0.41401824 || Val it_count: 1107 || Current Learning Rate: 1e-05 || Time: 04:56:16.60
Epoch :: 64 || Loss: 0.40766264 || it_count: 8344 || Val Loss: 0.41400400 || Val it_count: 1107 || Current Learning Rate: 1e-05 || Time: 05:00:45.07
Epoch :: 65 || Loss: 0.40763456 || it_count: 8344 || Val Loss: 0.41399202 || Val it_count: 1107 || Current Learning Rate: 1e-05 || Time: 05:05:14.91
Epoch :: 66 || Loss: 0.40760812 || it_count: 8344 || Val Loss: 0.41398160 || Val it_count: 1107 || Current Learning Rate: 1e-05 || Time: 05:09:44.16
Epoch :: 67 || Loss: 0.40758296 || it_count: 8344 || Val Loss: 0.41397225 || Val it_count: 1107 || Current Learning Rate: 1e-05 || Time: 05:14:14.32
Epoch :: 68 || Loss: 0.40755885 || it_count: 8344 || Val Loss: 0.41396367 || Val it_count: 1107 || Current Learning Rate: 1e-05 || Time: 05:18:46.66
Epoch :: 69 || Loss: 0.40753559 || it_count: 8344 || Val Loss: 0.41395561 || Val it_count: 1107 || Current Learning Rate: 1e-05 || Time: 05:23:17.86
Epoch :: 70 || Loss: 0.40751308 || it_count: 8344 || Val Loss: 0.41394795 || Val it_count: 1107 || Current Learning Rate: 1e-05 || Time: 05:27:49.69
Epoch :: 71 || Loss: 0.40749121 || it_count: 8344 || Val Loss: 0.41394060 || Val it_count: 1107 || Current Learning Rate: 1e-05 || Time: 05:32:18.31
Epoch :: 72 || Loss: 0.40746990 || it_count: 8344 || Val Loss: 0.41393348 || Val it_count: 1107 || Current Learning Rate: 1e-05 || Time: 05:36:45.71
Epoch :: 73 || Loss: 0.40744534 || it_count: 8344 || Val Loss: 0.41392632 || Val it_count: 1107 || Current Learning Rate: 1e-05 || Time: 05:41:16.20
Epoch :: 74 || Loss: 0.40742931 || it_count: 8344 || Val Loss: 0.41391687 || Val it_count: 1107 || Current Learning Rate: 1e-05 || Time: 05:45:43.16
Epoch :: 75 || Loss: 0.40740512 || it_count: 8344 || Val Loss: 0.41390954 || Val it_count: 1107 || Current Learning Rate: 1e-05 || Time: 05:50:12.87
Epoch :: 76 || Loss: 0.40738630 || it_count: 8344 || Val Loss: 0.41390065 || Val it_count: 1107 || Current Learning Rate: 1e-05 || Time: 05:54:41.77
Epoch :: 77 || Loss: 0.40736691 || it_count: 8344 || Val Loss: 0.41389343 || Val it_count: 1107 || Current Learning Rate: 1e-05 || Time: 05:59:12.57
Epoch :: 78 || Loss: 0.40734786 || it_count: 8344 || Val Loss: 0.41388667 || Val it_count: 1107 || Current Learning Rate: 1e-05 || Time: 06:03:46.27
Epoch :: 79 || Loss: 0.40732908 || it_count: 8344 || Val Loss: 0.41388009 || Val it_count: 1107 || Current Learning Rate: 1e-05 || Time: 06:08:16.44
Epoch :: 80 || Loss: 0.40731051 || it_count: 8344 || Val Loss: 0.41387350 || Val it_count: 1107 || Current Learning Rate: 1e-05 || Time: 06:12:48.39
Epoch :: 81 || Loss: 0.40729213 || it_count: 8344 || Val Loss: 0.41386678 || Val it_count: 1107 || Current Learning Rate: 1e-05 || Time: 06:17:18.16
Epoch :: 82 || Loss: 0.40727392 || it_count: 8344 || Val Loss: 0.41385986 || Val it_count: 1107 || Current Learning Rate: 1e-05 || Time: 06:21:48.49
Epoch :: 83 || Loss: 0.40725586 || it_count: 8344 || Val Loss: 0.41385272 || Val it_count: 1107 || Current Learning Rate: 1e-05 || Time: 06:26:17.16
Epoch :: 84 || Loss: 0.40723796 || it_count: 8344 || Val Loss: 0.41384539 || Val it_count: 1107 || Current Learning Rate: 1e-05 || Time: 06:30:51.05
Epoch :: 85 || Loss: 0.40722023 || it_count: 8344 || Val Loss: 0.41383797 || Val it_count: 1107 || Current Learning Rate: 1e-05 || Time: 06:35:16.41
Epoch :: 86 || Loss: 0.40720265 || it_count: 8344 || Val Loss: 0.41383064 || Val it_count: 1107 || Current Learning Rate: 1e-05 || Time: 06:39:43.28
Epoch 00071: reducing learning rate of group 0 to 1.0000e-06.
Epoch :: 87 || Loss: 0.40718849 || it_count: 8344 || Val Loss: 0.41382609 || Val it_count: 1107 || Current Learning Rate: 1.0000000000000002e-06 || Time: 06:44:10.61
Epoch :: 88 || Loss: 0.40744253 || it_count: 8344 || Val Loss: 0.41352680 || Val it_count: 1107 || Current Learning Rate: 1.0000000000000002e-06 || Time: 06:48:39.97
Epoch :: 89 || Loss: 0.40735335 || it_count: 8344 || Val Loss: 0.41350025 || Val it_count: 1107 || Current Learning Rate: 1.0000000000000002e-06 || Time: 06:53:4.01
Epoch :: 90 || Loss: 0.40732317 || it_count: 8344 || Val Loss: 0.41348659 || Val it_count: 1107 || Current Learning Rate: 1.0000000000000002e-06 || Time: 06:57:30.17
Epoch :: 91 || Loss: 0.40730843 || it_count: 8344 || Val Loss: 0.41347708 || Val it_count: 1107 || Current Learning Rate: 1.0000000000000002e-06 || Time: 07:01:50.47
Epoch :: 92 || Loss: 0.40729931 || it_count: 8344 || Val Loss: 0.41346902 || Val it_count: 1107 || Current Learning Rate: 1.0000000000000002e-06 || Time: 07:06:13.76
Epoch :: 93 || Loss: 0.40729283 || it_count: 8344 || Val Loss: 0.41346176 || Val it_count: 1107 || Current Learning Rate: 1.0000000000000002e-06 || Time: 07:10:42.60
Epoch :: 94 || Loss: 0.40728776 || it_count: 8344 || Val Loss: 0.41345527 || Val it_count: 1107 || Current Learning Rate: 1.0000000000000002e-06 || Time: 07:15:6.64
Epoch :: 95 || Loss: 0.40728352 || it_count: 8344 || Val Loss: 0.41344948 || Val it_count: 1107 || Current Learning Rate: 1.0000000000000002e-06 || Time: 07:19:29.05
Epoch :: 96 || Loss: 0.40727982 || it_count: 8344 || Val Loss: 0.41344429 || Val it_count: 1107 || Current Learning Rate: 1.0000000000000002e-06 || Time: 07:24:1.77
Epoch 00081: reducing learning rate of group 0 to 1.0000e-07.
Early stopping triggered due to learning rate below threshold.
Done Total time: 07:28:29.37
best_loss: 0.4134442867383735

--------------------Testing--------------------

total_samples :: test_dataset = 139200, test_dataloader = 139200
Epoch ::  1 || Loss: 0.23654708 || it_count: 544 || Time: 00:00:13.69
MAE:  0.25274485
MSE:  0.23656508
RMSE:  0.4418199

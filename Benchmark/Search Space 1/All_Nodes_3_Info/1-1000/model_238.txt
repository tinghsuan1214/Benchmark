--------------------Training--------------------
arch_str :: |skip_connect~0|+|lstm_2~0|lstm_3~1|[dropout->linear]
model :: 3B
InferCell(
  info :: nodes=3, inC=1, outC=64, [1<-(I0-L0) | 2<-(I0-L1,I1-L2)], genotype_str: skip_connect~0|lstm_2~0|lstm_3~1
  linear_layers: [dropout->linear]
  (layers): ModuleList(
    (0): FactorizedReduce(
      C_in=1, C_out=64, stride=1
      (relu): ReLU()
      (conv): Conv1d(1, 64, kernel_size=(1,), stride=(1,), bias=False)
      (bn): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (1): LSTM(
      (lstm): LSTM(1, 64, num_layers=2, batch_first=True)
    )
    (2): LSTM(
      (lstm): LSTM(64, 64, num_layers=3, batch_first=True)
    )
  )
  (linear_layers): ModuleList(
    (0): Dropout(p=0.1, inplace=False)
    (1): Linear(in_features=3072, out_features=1, bias=True)
  )
)
tr_params :: epochs = 100, patience = 20, batch_size = 256, window_size = 48, data_size = 100
Model FLOPs: 7.354M, Model Params: 153.537K
learning rate scheduling :: (optimizer, mode='min', factor=0.1, patience=5, verbose=True)
total_samples :: train_dataset = 2136000, train_dataloader = 2136000
total_samples :: valid_dataset = 283200, valid_dataloader = 283200
Epoch ::  1 || Loss: 0.42129821 || it_count: 8344 || Val Loss: 0.45737564 || Val it_count: 1107 || Current Learning Rate: 0.001 || Time: 00:08:31.53
Epoch ::  2 || Loss: 0.41597725 || it_count: 8344 || Val Loss: 0.45501982 || Val it_count: 1107 || Current Learning Rate: 0.001 || Time: 00:17:3.71
Epoch ::  3 || Loss: 0.41348265 || it_count: 8344 || Val Loss: 0.45481059 || Val it_count: 1107 || Current Learning Rate: 0.001 || Time: 00:25:38.51
Epoch ::  4 || Loss: 0.41432891 || it_count: 8344 || Val Loss: 0.44868340 || Val it_count: 1107 || Current Learning Rate: 0.001 || Time: 00:34:12.87
Epoch ::  5 || Loss: 0.41248029 || it_count: 8344 || Val Loss: 0.44946972 || Val it_count: 1107 || Current Learning Rate: 0.001 || Time: 00:42:49.51
Epoch ::  6 || Loss: 0.41173917 || it_count: 8344 || Val Loss: 0.44892653 || Val it_count: 1107 || Current Learning Rate: 0.001 || Time: 00:51:24.64
Epoch ::  7 || Loss: 0.41166148 || it_count: 8344 || Val Loss: 0.44796108 || Val it_count: 1107 || Current Learning Rate: 0.001 || Time: 01:00:1.55
Epoch ::  8 || Loss: 0.41031540 || it_count: 8344 || Val Loss: 0.44791172 || Val it_count: 1107 || Current Learning Rate: 0.001 || Time: 01:08:38.26
Epoch ::  9 || Loss: 0.40936967 || it_count: 8344 || Val Loss: 0.44888846 || Val it_count: 1107 || Current Learning Rate: 0.001 || Time: 01:17:13.46
Epoch :: 10 || Loss: 0.41070726 || it_count: 8344 || Val Loss: 0.44842498 || Val it_count: 1107 || Current Learning Rate: 0.001 || Time: 01:25:50.49
Epoch :: 11 || Loss: 0.40951187 || it_count: 8344 || Val Loss: 0.45084900 || Val it_count: 1107 || Current Learning Rate: 0.001 || Time: 01:34:26.74
Epoch :: 12 || Loss: 0.40926884 || it_count: 8344 || Val Loss: 0.44793656 || Val it_count: 1107 || Current Learning Rate: 0.001 || Time: 01:43:3.43
Epoch :: 13 || Loss: 0.40974110 || it_count: 8344 || Val Loss: 0.44878998 || Val it_count: 1107 || Current Learning Rate: 0.001 || Time: 01:51:42.00
Epoch :: 14 || Loss: 0.40903009 || it_count: 8344 || Val Loss: 0.44746732 || Val it_count: 1107 || Current Learning Rate: 0.001 || Time: 02:00:18.25
Epoch :: 15 || Loss: 0.40868970 || it_count: 8344 || Val Loss: 0.44809267 || Val it_count: 1107 || Current Learning Rate: 0.001 || Time: 02:08:56.94
Epoch :: 16 || Loss: 0.40871272 || it_count: 8344 || Val Loss: 0.44761381 || Val it_count: 1107 || Current Learning Rate: 0.001 || Time: 02:17:34.74
Epoch :: 17 || Loss: 0.40844183 || it_count: 8344 || Val Loss: 0.44889059 || Val it_count: 1107 || Current Learning Rate: 0.001 || Time: 02:26:13.21
Epoch :: 18 || Loss: 0.40817294 || it_count: 8344 || Val Loss: 0.45073525 || Val it_count: 1107 || Current Learning Rate: 0.001 || Time: 02:34:51.34
Epoch :: 19 || Loss: 0.40920273 || it_count: 8344 || Val Loss: 0.44904440 || Val it_count: 1107 || Current Learning Rate: 0.001 || Time: 02:43:30.07
Epoch :: 20 || Loss: 0.40961278 || it_count: 8344 || Val Loss: 0.44757174 || Val it_count: 1107 || Current Learning Rate: 0.001 || Time: 02:52:9.14
Epoch :: 21 || Loss: 0.41116983 || it_count: 8344 || Val Loss: 0.44834973 || Val it_count: 1107 || Current Learning Rate: 0.001 || Time: 03:00:48.87
Epoch :: 22 || Loss: 0.41042059 || it_count: 8344 || Val Loss: 0.45005565 || Val it_count: 1107 || Current Learning Rate: 0.001 || Time: 03:09:28.90
Epoch :: 23 || Loss: 0.40952615 || it_count: 8344 || Val Loss: 0.45036197 || Val it_count: 1107 || Current Learning Rate: 0.001 || Time: 03:18:9.45
Epoch :: 24 || Loss: 0.40913319 || it_count: 8344 || Val Loss: 0.45029766 || Val it_count: 1107 || Current Learning Rate: 0.001 || Time: 03:26:50.36
Epoch :: 25 || Loss: 0.40866739 || it_count: 8344 || Val Loss: 0.44935678 || Val it_count: 1107 || Current Learning Rate: 0.001 || Time: 03:35:33.56
Epoch 00010: reducing learning rate of group 0 to 1.0000e-04.
Epoch :: 26 || Loss: 0.40832095 || it_count: 8344 || Val Loss: 0.44940523 || Val it_count: 1107 || Current Learning Rate: 0.0001 || Time: 03:44:16.52
Epoch :: 27 || Loss: 0.41240584 || it_count: 8344 || Val Loss: 0.44285410 || Val it_count: 1107 || Current Learning Rate: 0.0001 || Time: 03:53:0.26
Epoch :: 28 || Loss: 0.40819747 || it_count: 8344 || Val Loss: 0.44280437 || Val it_count: 1107 || Current Learning Rate: 0.0001 || Time: 04:01:44.49
Epoch :: 29 || Loss: 0.40683807 || it_count: 8344 || Val Loss: 0.44257214 || Val it_count: 1107 || Current Learning Rate: 0.0001 || Time: 04:10:26.30
Epoch :: 30 || Loss: 0.40601448 || it_count: 8344 || Val Loss: 0.44250740 || Val it_count: 1107 || Current Learning Rate: 0.0001 || Time: 04:19:8.37
Epoch :: 31 || Loss: 0.40539087 || it_count: 8344 || Val Loss: 0.44234815 || Val it_count: 1107 || Current Learning Rate: 0.0001 || Time: 04:27:51.49
Epoch :: 32 || Loss: 0.40497451 || it_count: 8344 || Val Loss: 0.44271125 || Val it_count: 1107 || Current Learning Rate: 0.0001 || Time: 04:36:33.29
Epoch :: 33 || Loss: 0.40462273 || it_count: 8344 || Val Loss: 0.44256183 || Val it_count: 1107 || Current Learning Rate: 0.0001 || Time: 04:45:16.71
Epoch :: 34 || Loss: 0.40428096 || it_count: 8344 || Val Loss: 0.44287861 || Val it_count: 1107 || Current Learning Rate: 0.0001 || Time: 04:53:59.24
Epoch :: 35 || Loss: 0.40404473 || it_count: 8344 || Val Loss: 0.44291567 || Val it_count: 1107 || Current Learning Rate: 0.0001 || Time: 05:02:41.55
Epoch :: 36 || Loss: 0.40375840 || it_count: 8344 || Val Loss: 0.44298327 || Val it_count: 1107 || Current Learning Rate: 0.0001 || Time: 05:11:23.51
Epoch 00021: reducing learning rate of group 0 to 1.0000e-05.
Epoch :: 37 || Loss: 0.40357147 || it_count: 8344 || Val Loss: 0.44319023 || Val it_count: 1107 || Current Learning Rate: 1e-05 || Time: 05:20:4.57
Epoch :: 38 || Loss: 0.40522663 || it_count: 8344 || Val Loss: 0.43844882 || Val it_count: 1107 || Current Learning Rate: 1e-05 || Time: 05:28:46.44
Epoch :: 39 || Loss: 0.40462976 || it_count: 8344 || Val Loss: 0.43828827 || Val it_count: 1107 || Current Learning Rate: 1e-05 || Time: 05:37:26.86
Epoch :: 40 || Loss: 0.40448235 || it_count: 8344 || Val Loss: 0.43841192 || Val it_count: 1107 || Current Learning Rate: 1e-05 || Time: 05:46:8.62
Epoch :: 41 || Loss: 0.40439679 || it_count: 8344 || Val Loss: 0.43854816 || Val it_count: 1107 || Current Learning Rate: 1e-05 || Time: 05:54:49.78
Epoch :: 42 || Loss: 0.40430468 || it_count: 8344 || Val Loss: 0.43869375 || Val it_count: 1107 || Current Learning Rate: 1e-05 || Time: 06:03:32.91
Epoch :: 43 || Loss: 0.40424287 || it_count: 8344 || Val Loss: 0.43880393 || Val it_count: 1107 || Current Learning Rate: 1e-05 || Time: 06:12:15.60
Epoch :: 44 || Loss: 0.40414902 || it_count: 8344 || Val Loss: 0.43896348 || Val it_count: 1107 || Current Learning Rate: 1e-05 || Time: 06:20:55.91
Epoch 00029: reducing learning rate of group 0 to 1.0000e-06.
Epoch :: 45 || Loss: 0.40415890 || it_count: 8344 || Val Loss: 0.43909780 || Val it_count: 1107 || Current Learning Rate: 1.0000000000000002e-06 || Time: 06:29:36.22
Epoch :: 46 || Loss: 0.40445513 || it_count: 8344 || Val Loss: 0.43870797 || Val it_count: 1107 || Current Learning Rate: 1.0000000000000002e-06 || Time: 06:38:18.35
Epoch :: 47 || Loss: 0.40429933 || it_count: 8344 || Val Loss: 0.43856991 || Val it_count: 1107 || Current Learning Rate: 1.0000000000000002e-06 || Time: 06:46:59.54
Epoch :: 48 || Loss: 0.40431379 || it_count: 8344 || Val Loss: 0.43849206 || Val it_count: 1107 || Current Learning Rate: 1.0000000000000002e-06 || Time: 06:55:39.95
Epoch :: 49 || Loss: 0.40425359 || it_count: 8344 || Val Loss: 0.43842282 || Val it_count: 1107 || Current Learning Rate: 1.0000000000000002e-06 || Time: 07:04:22.03
Epoch :: 50 || Loss: 0.40425587 || it_count: 8344 || Val Loss: 0.43838343 || Val it_count: 1107 || Current Learning Rate: 1.0000000000000002e-06 || Time: 07:13:1.92
Epoch 00035: reducing learning rate of group 0 to 1.0000e-07.
Early stopping triggered due to learning rate below threshold.
Done Total time: 07:21:45.04
best_loss: 0.43828826529776865

--------------------Testing--------------------

total_samples :: test_dataset = 139200, test_dataloader = 139200
Epoch ::  1 || Loss: 0.27723590 || it_count: 544 || Time: 00:00:22.31
MAE:  0.27616194
MSE:  0.27727875
RMSE:  0.46797645

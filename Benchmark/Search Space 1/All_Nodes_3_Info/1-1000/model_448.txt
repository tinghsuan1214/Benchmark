--------------------Training--------------------
arch_str :: |lstm_1~0|+|lstm_1~0|lstm_2~1|[relu->dropout->linear]
model :: 3D
InferCell(
  info :: nodes=3, inC=1, outC=64, [1<-(I0-L0) | 2<-(I0-L1,I1-L2)], genotype_str: lstm_1~0|lstm_1~0|lstm_2~1
  linear_layers: [relu->dropout->linear]
  (layers): ModuleList(
    (0-1): 2 x LSTM(
      (lstm): LSTM(1, 64, batch_first=True)
    )
    (2): LSTM(
      (lstm): LSTM(64, 64, num_layers=2, batch_first=True)
    )
  )
  (linear_layers): ModuleList(
    (0): ReLU()
    (1): Dropout(p=0.1, inplace=False)
    (2): Linear(in_features=3072, out_features=1, bias=True)
  )
)
tr_params :: epochs = 100, patience = 20, batch_size = 256, window_size = 48, data_size = 100
Model FLOPs: 4.943M, Model Params: 103.937K
learning rate scheduling :: (optimizer, mode='min', factor=0.1, patience=5, verbose=True)
total_samples :: train_dataset = 2136000, train_dataloader = 2136000
total_samples :: valid_dataset = 283200, valid_dataloader = 283200
Epoch ::  1 || Loss: 0.42201288 || it_count: 8344 || Val Loss: 0.44880662 || Val it_count: 1107 || Current Learning Rate: 0.001 || Time: 00:08:12.52
Epoch ::  2 || Loss: 0.42055777 || it_count: 8344 || Val Loss: 0.44776503 || Val it_count: 1107 || Current Learning Rate: 0.001 || Time: 00:16:23.10
Epoch ::  3 || Loss: 0.42035753 || it_count: 8344 || Val Loss: 0.44474069 || Val it_count: 1107 || Current Learning Rate: 0.001 || Time: 00:24:36.38
Epoch ::  4 || Loss: 0.42060801 || it_count: 8344 || Val Loss: 0.44475216 || Val it_count: 1107 || Current Learning Rate: 0.001 || Time: 00:32:49.79
Epoch ::  5 || Loss: 0.41940927 || it_count: 8344 || Val Loss: 0.44345433 || Val it_count: 1107 || Current Learning Rate: 0.001 || Time: 00:41:2.68
Epoch ::  6 || Loss: 0.41859813 || it_count: 8344 || Val Loss: 0.44170185 || Val it_count: 1107 || Current Learning Rate: 0.001 || Time: 00:49:15.01
Epoch ::  7 || Loss: 0.41785795 || it_count: 8344 || Val Loss: 0.44063001 || Val it_count: 1107 || Current Learning Rate: 0.001 || Time: 00:57:28.19
Epoch ::  8 || Loss: 0.41738117 || it_count: 8344 || Val Loss: 0.44169309 || Val it_count: 1107 || Current Learning Rate: 0.001 || Time: 01:05:41.32
Epoch ::  9 || Loss: 0.41682264 || it_count: 8344 || Val Loss: 0.44082879 || Val it_count: 1107 || Current Learning Rate: 0.001 || Time: 01:13:54.17
Epoch :: 10 || Loss: 0.41611317 || it_count: 8344 || Val Loss: 0.44120879 || Val it_count: 1107 || Current Learning Rate: 0.001 || Time: 01:22:6.68
Epoch :: 11 || Loss: 0.41787304 || it_count: 8344 || Val Loss: 0.44108314 || Val it_count: 1107 || Current Learning Rate: 0.001 || Time: 01:30:20.64
Epoch :: 12 || Loss: 0.41677328 || it_count: 8344 || Val Loss: 0.44047789 || Val it_count: 1107 || Current Learning Rate: 0.001 || Time: 01:38:33.17
Epoch :: 13 || Loss: 0.41638672 || it_count: 8344 || Val Loss: 0.44060082 || Val it_count: 1107 || Current Learning Rate: 0.001 || Time: 01:46:46.04
Epoch :: 14 || Loss: 0.41618131 || it_count: 8344 || Val Loss: 0.44111639 || Val it_count: 1107 || Current Learning Rate: 0.001 || Time: 01:55:0.44
Epoch :: 15 || Loss: 0.41634138 || it_count: 8344 || Val Loss: 0.44115438 || Val it_count: 1107 || Current Learning Rate: 0.001 || Time: 02:03:14.80
Epoch :: 16 || Loss: 0.41638956 || it_count: 8344 || Val Loss: 0.44124907 || Val it_count: 1107 || Current Learning Rate: 0.001 || Time: 02:11:29.69
Epoch :: 17 || Loss: 0.41642236 || it_count: 8344 || Val Loss: 0.43964339 || Val it_count: 1107 || Current Learning Rate: 0.001 || Time: 02:19:42.79
Epoch :: 18 || Loss: 0.41589585 || it_count: 8344 || Val Loss: 0.44088443 || Val it_count: 1107 || Current Learning Rate: 0.001 || Time: 02:27:56.42
Epoch :: 19 || Loss: 0.41582407 || it_count: 8344 || Val Loss: 0.44062065 || Val it_count: 1107 || Current Learning Rate: 0.001 || Time: 02:36:10.57
Epoch :: 20 || Loss: 0.41572265 || it_count: 8344 || Val Loss: 0.44077774 || Val it_count: 1107 || Current Learning Rate: 0.001 || Time: 02:44:24.21
Epoch :: 21 || Loss: 0.41570367 || it_count: 8344 || Val Loss: 0.44222533 || Val it_count: 1107 || Current Learning Rate: 0.001 || Time: 02:52:39.62
Epoch :: 22 || Loss: 0.41544989 || it_count: 8344 || Val Loss: 0.44150594 || Val it_count: 1107 || Current Learning Rate: 0.001 || Time: 03:00:53.83
Epoch 00007: reducing learning rate of group 0 to 1.0000e-04.
Epoch :: 23 || Loss: 0.41516687 || it_count: 8344 || Val Loss: 0.44240172 || Val it_count: 1107 || Current Learning Rate: 0.0001 || Time: 03:09:8.44
Epoch :: 24 || Loss: 0.42081185 || it_count: 8344 || Val Loss: 0.42354225 || Val it_count: 1107 || Current Learning Rate: 0.0001 || Time: 03:17:22.59
Epoch :: 25 || Loss: 0.41681906 || it_count: 8344 || Val Loss: 0.42197260 || Val it_count: 1107 || Current Learning Rate: 0.0001 || Time: 03:25:36.12
Epoch :: 26 || Loss: 0.41595444 || it_count: 8344 || Val Loss: 0.42156172 || Val it_count: 1107 || Current Learning Rate: 0.0001 || Time: 03:33:50.52
Epoch :: 27 || Loss: 0.41559502 || it_count: 8344 || Val Loss: 0.42132035 || Val it_count: 1107 || Current Learning Rate: 0.0001 || Time: 03:42:4.42
Epoch :: 28 || Loss: 0.41521521 || it_count: 8344 || Val Loss: 0.42123063 || Val it_count: 1107 || Current Learning Rate: 0.0001 || Time: 03:50:17.17
Epoch :: 29 || Loss: 0.41493654 || it_count: 8344 || Val Loss: 0.42099286 || Val it_count: 1107 || Current Learning Rate: 0.0001 || Time: 03:58:31.76
Epoch :: 30 || Loss: 0.41456498 || it_count: 8344 || Val Loss: 0.42093371 || Val it_count: 1107 || Current Learning Rate: 0.0001 || Time: 04:06:45.97
Epoch :: 31 || Loss: 0.41432840 || it_count: 8344 || Val Loss: 0.42080712 || Val it_count: 1107 || Current Learning Rate: 0.0001 || Time: 04:15:1.14
Epoch :: 32 || Loss: 0.41410561 || it_count: 8344 || Val Loss: 0.42068100 || Val it_count: 1107 || Current Learning Rate: 0.0001 || Time: 04:23:15.65
Epoch :: 33 || Loss: 0.41377290 || it_count: 8344 || Val Loss: 0.42052096 || Val it_count: 1107 || Current Learning Rate: 0.0001 || Time: 04:31:30.73
Epoch :: 34 || Loss: 0.41357539 || it_count: 8344 || Val Loss: 0.42048119 || Val it_count: 1107 || Current Learning Rate: 0.0001 || Time: 04:39:45.24
Epoch :: 35 || Loss: 0.41351556 || it_count: 8344 || Val Loss: 0.42046632 || Val it_count: 1107 || Current Learning Rate: 0.0001 || Time: 04:48:0.87
Epoch :: 36 || Loss: 0.41324813 || it_count: 8344 || Val Loss: 0.42032309 || Val it_count: 1107 || Current Learning Rate: 0.0001 || Time: 04:56:14.56
Epoch :: 37 || Loss: 0.41303383 || it_count: 8344 || Val Loss: 0.42037840 || Val it_count: 1107 || Current Learning Rate: 0.0001 || Time: 05:04:27.79
Epoch :: 38 || Loss: 0.41287330 || it_count: 8344 || Val Loss: 0.42059223 || Val it_count: 1107 || Current Learning Rate: 0.0001 || Time: 05:12:40.86
Epoch :: 39 || Loss: 0.41289080 || it_count: 8344 || Val Loss: 0.42045276 || Val it_count: 1107 || Current Learning Rate: 0.0001 || Time: 05:20:54.98
Epoch :: 40 || Loss: 0.41282115 || it_count: 8344 || Val Loss: 0.42027843 || Val it_count: 1107 || Current Learning Rate: 0.0001 || Time: 05:29:8.54
Epoch :: 41 || Loss: 0.41254950 || it_count: 8344 || Val Loss: 0.42034515 || Val it_count: 1107 || Current Learning Rate: 0.0001 || Time: 05:37:23.15
Epoch :: 42 || Loss: 0.41245246 || it_count: 8344 || Val Loss: 0.42024128 || Val it_count: 1107 || Current Learning Rate: 0.0001 || Time: 05:45:36.61
Epoch :: 43 || Loss: 0.41240508 || it_count: 8344 || Val Loss: 0.42018607 || Val it_count: 1107 || Current Learning Rate: 0.0001 || Time: 05:53:50.91
Epoch :: 44 || Loss: 0.41222322 || it_count: 8344 || Val Loss: 0.42088970 || Val it_count: 1107 || Current Learning Rate: 0.0001 || Time: 06:02:5.26
Epoch :: 45 || Loss: 0.41200093 || it_count: 8344 || Val Loss: 0.42005955 || Val it_count: 1107 || Current Learning Rate: 0.0001 || Time: 06:10:22.18
Epoch :: 46 || Loss: 0.41212203 || it_count: 8344 || Val Loss: 0.42037619 || Val it_count: 1107 || Current Learning Rate: 0.0001 || Time: 06:18:36.54
Epoch :: 47 || Loss: 0.41195870 || it_count: 8344 || Val Loss: 0.42031832 || Val it_count: 1107 || Current Learning Rate: 0.0001 || Time: 06:26:51.25
Epoch :: 48 || Loss: 0.41181317 || it_count: 8344 || Val Loss: 0.41990579 || Val it_count: 1107 || Current Learning Rate: 0.0001 || Time: 06:35:6.28
Epoch :: 49 || Loss: 0.41175119 || it_count: 8344 || Val Loss: 0.41998127 || Val it_count: 1107 || Current Learning Rate: 0.0001 || Time: 06:43:20.72
Epoch :: 50 || Loss: 0.41160610 || it_count: 8344 || Val Loss: 0.42007721 || Val it_count: 1107 || Current Learning Rate: 0.0001 || Time: 06:51:35.45
Epoch :: 51 || Loss: 0.41153837 || it_count: 8344 || Val Loss: 0.42000150 || Val it_count: 1107 || Current Learning Rate: 0.0001 || Time: 06:59:48.99
Epoch :: 52 || Loss: 0.41147314 || it_count: 8344 || Val Loss: 0.41999384 || Val it_count: 1107 || Current Learning Rate: 0.0001 || Time: 07:08:3.46
Epoch :: 53 || Loss: 0.41137895 || it_count: 8344 || Val Loss: 0.41987312 || Val it_count: 1107 || Current Learning Rate: 0.0001 || Time: 07:16:19.25
Epoch :: 54 || Loss: 0.41106567 || it_count: 8344 || Val Loss: 0.41985496 || Val it_count: 1107 || Current Learning Rate: 0.0001 || Time: 07:24:34.25
Epoch :: 55 || Loss: 0.41110547 || it_count: 8344 || Val Loss: 0.42014467 || Val it_count: 1107 || Current Learning Rate: 0.0001 || Time: 07:32:49.41
Epoch :: 56 || Loss: 0.41104392 || it_count: 8344 || Val Loss: 0.41984678 || Val it_count: 1107 || Current Learning Rate: 0.0001 || Time: 07:41:3.72
Epoch :: 57 || Loss: 0.41083953 || it_count: 8344 || Val Loss: 0.42014042 || Val it_count: 1107 || Current Learning Rate: 0.0001 || Time: 07:49:19.68
Epoch :: 58 || Loss: 0.41086970 || it_count: 8344 || Val Loss: 0.42010304 || Val it_count: 1107 || Current Learning Rate: 0.0001 || Time: 07:57:33.81
Epoch :: 59 || Loss: 0.41076860 || it_count: 8344 || Val Loss: 0.42008265 || Val it_count: 1107 || Current Learning Rate: 0.0001 || Time: 08:05:48.83
Epoch 00044: reducing learning rate of group 0 to 1.0000e-05.
Epoch :: 60 || Loss: 0.41068185 || it_count: 8344 || Val Loss: 0.42001452 || Val it_count: 1107 || Current Learning Rate: 1e-05 || Time: 08:14:4.97
Epoch :: 61 || Loss: 0.41230555 || it_count: 8344 || Val Loss: 0.41383469 || Val it_count: 1107 || Current Learning Rate: 1e-05 || Time: 08:22:20.15
Epoch :: 62 || Loss: 0.41139142 || it_count: 8344 || Val Loss: 0.41377691 || Val it_count: 1107 || Current Learning Rate: 1e-05 || Time: 08:30:34.13
Epoch :: 63 || Loss: 0.41135169 || it_count: 8344 || Val Loss: 0.41372381 || Val it_count: 1107 || Current Learning Rate: 1e-05 || Time: 08:38:50.05
Epoch :: 64 || Loss: 0.41122687 || it_count: 8344 || Val Loss: 0.41374191 || Val it_count: 1107 || Current Learning Rate: 1e-05 || Time: 08:47:3.13
Epoch :: 65 || Loss: 0.41116802 || it_count: 8344 || Val Loss: 0.41371229 || Val it_count: 1107 || Current Learning Rate: 1e-05 || Time: 08:55:17.49
Epoch :: 66 || Loss: 0.41117384 || it_count: 8344 || Val Loss: 0.41370637 || Val it_count: 1107 || Current Learning Rate: 1e-05 || Time: 09:03:33.19
Epoch :: 67 || Loss: 0.41115715 || it_count: 8344 || Val Loss: 0.41367553 || Val it_count: 1107 || Current Learning Rate: 1e-05 || Time: 09:11:47.79
Epoch :: 68 || Loss: 0.41112410 || it_count: 8344 || Val Loss: 0.41365042 || Val it_count: 1107 || Current Learning Rate: 1e-05 || Time: 09:20:1.27
Epoch :: 69 || Loss: 0.41107561 || it_count: 8344 || Val Loss: 0.41362328 || Val it_count: 1107 || Current Learning Rate: 1e-05 || Time: 09:28:16.58
Epoch :: 70 || Loss: 0.41108353 || it_count: 8344 || Val Loss: 0.41361337 || Val it_count: 1107 || Current Learning Rate: 1e-05 || Time: 09:36:31.17
Epoch :: 71 || Loss: 0.41099411 || it_count: 8344 || Val Loss: 0.41357754 || Val it_count: 1107 || Current Learning Rate: 1e-05 || Time: 09:44:46.42
Epoch :: 72 || Loss: 0.41097843 || it_count: 8344 || Val Loss: 0.41355510 || Val it_count: 1107 || Current Learning Rate: 1e-05 || Time: 09:53:3.20
Epoch :: 73 || Loss: 0.41103448 || it_count: 8344 || Val Loss: 0.41355841 || Val it_count: 1107 || Current Learning Rate: 1e-05 || Time: 10:01:17.98
Epoch :: 74 || Loss: 0.41100899 || it_count: 8344 || Val Loss: 0.41351327 || Val it_count: 1107 || Current Learning Rate: 1e-05 || Time: 10:09:32.66
Epoch :: 75 || Loss: 0.41098308 || it_count: 8344 || Val Loss: 0.41351311 || Val it_count: 1107 || Current Learning Rate: 1e-05 || Time: 10:17:48.53
Epoch :: 76 || Loss: 0.41101609 || it_count: 8344 || Val Loss: 0.41348272 || Val it_count: 1107 || Current Learning Rate: 1e-05 || Time: 10:26:1.52
Epoch :: 77 || Loss: 0.41103024 || it_count: 8344 || Val Loss: 0.41348619 || Val it_count: 1107 || Current Learning Rate: 1e-05 || Time: 10:34:16.05
Epoch :: 78 || Loss: 0.41100821 || it_count: 8344 || Val Loss: 0.41344220 || Val it_count: 1107 || Current Learning Rate: 1e-05 || Time: 10:42:30.30
Epoch :: 79 || Loss: 0.41097034 || it_count: 8344 || Val Loss: 0.41345277 || Val it_count: 1107 || Current Learning Rate: 1e-05 || Time: 10:50:42.88
Epoch :: 80 || Loss: 0.41088509 || it_count: 8344 || Val Loss: 0.41341721 || Val it_count: 1107 || Current Learning Rate: 1e-05 || Time: 10:58:56.05
Epoch :: 81 || Loss: 0.41092000 || it_count: 8344 || Val Loss: 0.41342071 || Val it_count: 1107 || Current Learning Rate: 1e-05 || Time: 11:07:9.01
Epoch :: 82 || Loss: 0.41085648 || it_count: 8344 || Val Loss: 0.41344037 || Val it_count: 1107 || Current Learning Rate: 1e-05 || Time: 11:15:21.86
Epoch :: 83 || Loss: 0.41083511 || it_count: 8344 || Val Loss: 0.41342760 || Val it_count: 1107 || Current Learning Rate: 1e-05 || Time: 11:23:36.46
Epoch 00068: reducing learning rate of group 0 to 1.0000e-06.
Epoch :: 84 || Loss: 0.41087174 || it_count: 8344 || Val Loss: 0.41341259 || Val it_count: 1107 || Current Learning Rate: 1.0000000000000002e-06 || Time: 11:31:50.23
Epoch :: 85 || Loss: 0.41105937 || it_count: 8344 || Val Loss: 0.41312956 || Val it_count: 1107 || Current Learning Rate: 1.0000000000000002e-06 || Time: 11:40:3.54
Epoch :: 86 || Loss: 0.41096083 || it_count: 8344 || Val Loss: 0.41306886 || Val it_count: 1107 || Current Learning Rate: 1.0000000000000002e-06 || Time: 11:48:18.15
Epoch :: 87 || Loss: 0.41098586 || it_count: 8344 || Val Loss: 0.41304802 || Val it_count: 1107 || Current Learning Rate: 1.0000000000000002e-06 || Time: 11:56:32.95
Epoch :: 88 || Loss: 0.41096405 || it_count: 8344 || Val Loss: 0.41304177 || Val it_count: 1107 || Current Learning Rate: 1.0000000000000002e-06 || Time: 12:04:49.74
Epoch :: 89 || Loss: 0.41099930 || it_count: 8344 || Val Loss: 0.41303683 || Val it_count: 1107 || Current Learning Rate: 1.0000000000000002e-06 || Time: 12:13:4.61
Epoch :: 90 || Loss: 0.41098476 || it_count: 8344 || Val Loss: 0.41303173 || Val it_count: 1107 || Current Learning Rate: 1.0000000000000002e-06 || Time: 12:21:18.54
Epoch :: 91 || Loss: 0.41097111 || it_count: 8344 || Val Loss: 0.41303129 || Val it_count: 1107 || Current Learning Rate: 1.0000000000000002e-06 || Time: 12:29:34.04
Epoch 00076: reducing learning rate of group 0 to 1.0000e-07.
Early stopping triggered due to learning rate below threshold.
Done Total time: 12:37:48.48
best_loss: 0.41303129080525036

--------------------Testing--------------------

total_samples :: test_dataset = 139200, test_dataloader = 139200
Epoch ::  1 || Loss: 0.23663211 || it_count: 544 || Time: 00:00:22.19
MAE:  0.2534544
MSE:  0.23664916
RMSE:  0.44213784

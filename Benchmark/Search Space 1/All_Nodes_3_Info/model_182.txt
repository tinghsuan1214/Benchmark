--------------------Training--------------------
arch_str :: |lstm_2~0|+|lstm_1~0|none~1|[dropout->linear]
model :: 3B
InferCell(
  info :: nodes=3, inC=1, outC=64, [1<-(I0-L0) | 2<-(I0-L1,I1-L2)], genotype_str: lstm_2~0|lstm_1~0|none~1
  linear_layers: [dropout->linear]
  (layers): ModuleList(
    (0): LSTM(
      (lstm): LSTM(1, 64, num_layers=2, batch_first=True)
    )
    (1): LSTM(
      (lstm): LSTM(1, 64, batch_first=True)
    )
    (2): Zero(C_in=64, C_out=64, stride=1)
  )
  (linear_layers): ModuleList(
    (0): Dropout(p=0.1, inplace=False)
    (1): Linear(in_features=3072, out_features=1, bias=True)
  )
)
tr_params :: epochs = 100, patience = 20, batch_size = 256, window_size = 48, data_size = 100
Model FLOPs: 3.321M, Model Params: 70.657K
learning rate scheduling :: (optimizer, mode='min', factor=0.1, patience=5, verbose=True)
total_samples :: train_dataset = 2136000, train_dataloader = 2136000
total_samples :: valid_dataset = 283200, valid_dataloader = 283200
Epoch ::  1 || Loss: 0.42167712 || it_count: 8344 || Val Loss: 0.44742258 || Val it_count: 1107 || Current Learning Rate: 0.001 || Time: 00:07:2.00
Epoch ::  2 || Loss: 0.41994316 || it_count: 8344 || Val Loss: 0.44617489 || Val it_count: 1107 || Current Learning Rate: 0.001 || Time: 00:14:1.06
Epoch ::  3 || Loss: 0.41933820 || it_count: 8344 || Val Loss: 0.44451467 || Val it_count: 1107 || Current Learning Rate: 0.001 || Time: 00:21:0.73
Epoch ::  4 || Loss: 0.41881660 || it_count: 8344 || Val Loss: 0.44271344 || Val it_count: 1107 || Current Learning Rate: 0.001 || Time: 00:27:59.48
Epoch ::  5 || Loss: 0.41853520 || it_count: 8344 || Val Loss: 0.44166324 || Val it_count: 1107 || Current Learning Rate: 0.001 || Time: 00:34:58.31
Epoch ::  6 || Loss: 0.41853015 || it_count: 8344 || Val Loss: 0.44096831 || Val it_count: 1107 || Current Learning Rate: 0.001 || Time: 00:41:57.66
Epoch ::  7 || Loss: 0.41824573 || it_count: 8344 || Val Loss: 0.44086350 || Val it_count: 1107 || Current Learning Rate: 0.001 || Time: 00:48:56.44
Epoch ::  8 || Loss: 0.41814744 || it_count: 8344 || Val Loss: 0.44035059 || Val it_count: 1107 || Current Learning Rate: 0.001 || Time: 00:55:54.36
Epoch ::  9 || Loss: 0.41790538 || it_count: 8344 || Val Loss: 0.44143644 || Val it_count: 1107 || Current Learning Rate: 0.001 || Time: 01:02:53.18
Epoch :: 10 || Loss: 0.41786610 || it_count: 8344 || Val Loss: 0.44015632 || Val it_count: 1107 || Current Learning Rate: 0.001 || Time: 01:09:52.76
Epoch :: 11 || Loss: 0.41772135 || it_count: 8344 || Val Loss: 0.44008953 || Val it_count: 1107 || Current Learning Rate: 0.001 || Time: 01:16:52.39
Epoch :: 12 || Loss: 0.41769297 || it_count: 8344 || Val Loss: 0.44117699 || Val it_count: 1107 || Current Learning Rate: 0.001 || Time: 01:23:51.40
Epoch :: 13 || Loss: 0.41771598 || it_count: 8344 || Val Loss: 0.44017913 || Val it_count: 1107 || Current Learning Rate: 0.001 || Time: 01:30:49.99
Epoch :: 14 || Loss: 0.41761304 || it_count: 8344 || Val Loss: 0.44091619 || Val it_count: 1107 || Current Learning Rate: 0.001 || Time: 01:37:48.61
Epoch :: 15 || Loss: 0.41773671 || it_count: 8344 || Val Loss: 0.43966146 || Val it_count: 1107 || Current Learning Rate: 0.001 || Time: 01:44:49.29
Epoch :: 16 || Loss: 0.41755556 || it_count: 8344 || Val Loss: 0.43961889 || Val it_count: 1107 || Current Learning Rate: 0.001 || Time: 01:51:48.24
Epoch :: 17 || Loss: 0.41752027 || it_count: 8344 || Val Loss: 0.43986840 || Val it_count: 1107 || Current Learning Rate: 0.001 || Time: 01:58:49.05
Epoch :: 18 || Loss: 0.41733022 || it_count: 8344 || Val Loss: 0.43984295 || Val it_count: 1107 || Current Learning Rate: 0.001 || Time: 02:05:48.99
Epoch :: 19 || Loss: 0.41723897 || it_count: 8344 || Val Loss: 0.43963120 || Val it_count: 1107 || Current Learning Rate: 0.001 || Time: 02:12:48.75
Epoch :: 20 || Loss: 0.41709115 || it_count: 8344 || Val Loss: 0.43997771 || Val it_count: 1107 || Current Learning Rate: 0.001 || Time: 02:19:48.05
Epoch :: 21 || Loss: 0.41696804 || it_count: 8344 || Val Loss: 0.43885215 || Val it_count: 1107 || Current Learning Rate: 0.001 || Time: 02:26:46.78
Epoch :: 22 || Loss: 0.41679109 || it_count: 8344 || Val Loss: 0.43950900 || Val it_count: 1107 || Current Learning Rate: 0.001 || Time: 02:33:45.52
Epoch :: 23 || Loss: 0.41674526 || it_count: 8344 || Val Loss: 0.43990624 || Val it_count: 1107 || Current Learning Rate: 0.001 || Time: 02:40:45.14
Epoch :: 24 || Loss: 0.41679414 || it_count: 8344 || Val Loss: 0.44005846 || Val it_count: 1107 || Current Learning Rate: 0.001 || Time: 02:47:43.50
Epoch :: 25 || Loss: 0.41677085 || it_count: 8344 || Val Loss: 0.43920811 || Val it_count: 1107 || Current Learning Rate: 0.001 || Time: 02:54:42.72
Epoch :: 26 || Loss: 0.41674400 || it_count: 8344 || Val Loss: 0.43946064 || Val it_count: 1107 || Current Learning Rate: 0.001 || Time: 03:01:42.55
Epoch 00011: reducing learning rate of group 0 to 1.0000e-04.
Epoch :: 27 || Loss: 0.41675720 || it_count: 8344 || Val Loss: 0.43955744 || Val it_count: 1107 || Current Learning Rate: 0.0001 || Time: 03:08:41.01
Epoch :: 28 || Loss: 0.42177726 || it_count: 8344 || Val Loss: 0.42673574 || Val it_count: 1107 || Current Learning Rate: 0.0001 || Time: 03:15:40.47
Epoch :: 29 || Loss: 0.41829001 || it_count: 8344 || Val Loss: 0.42554426 || Val it_count: 1107 || Current Learning Rate: 0.0001 || Time: 03:22:40.90
Epoch :: 30 || Loss: 0.41748231 || it_count: 8344 || Val Loss: 0.42514318 || Val it_count: 1107 || Current Learning Rate: 0.0001 || Time: 03:29:41.94
Epoch :: 31 || Loss: 0.41709594 || it_count: 8344 || Val Loss: 0.42501296 || Val it_count: 1107 || Current Learning Rate: 0.0001 || Time: 03:36:41.22
Epoch :: 32 || Loss: 0.41695728 || it_count: 8344 || Val Loss: 0.42492190 || Val it_count: 1107 || Current Learning Rate: 0.0001 || Time: 03:43:40.69
Epoch :: 33 || Loss: 0.41684804 || it_count: 8344 || Val Loss: 0.42479671 || Val it_count: 1107 || Current Learning Rate: 0.0001 || Time: 03:50:41.18
Epoch :: 34 || Loss: 0.41676295 || it_count: 8344 || Val Loss: 0.42476817 || Val it_count: 1107 || Current Learning Rate: 0.0001 || Time: 03:57:39.73
Epoch :: 35 || Loss: 0.41668252 || it_count: 8344 || Val Loss: 0.42469135 || Val it_count: 1107 || Current Learning Rate: 0.0001 || Time: 04:04:38.50
Epoch :: 36 || Loss: 0.41661669 || it_count: 8344 || Val Loss: 0.42469877 || Val it_count: 1107 || Current Learning Rate: 0.0001 || Time: 04:11:38.49
Epoch :: 37 || Loss: 0.41655064 || it_count: 8344 || Val Loss: 0.42476094 || Val it_count: 1107 || Current Learning Rate: 0.0001 || Time: 04:18:36.70
Epoch :: 38 || Loss: 0.41657237 || it_count: 8344 || Val Loss: 0.42460526 || Val it_count: 1107 || Current Learning Rate: 0.0001 || Time: 04:25:34.98
Epoch :: 39 || Loss: 0.41648268 || it_count: 8344 || Val Loss: 0.42456614 || Val it_count: 1107 || Current Learning Rate: 0.0001 || Time: 04:32:34.43
Epoch :: 40 || Loss: 0.41639313 || it_count: 8344 || Val Loss: 0.42449879 || Val it_count: 1107 || Current Learning Rate: 0.0001 || Time: 04:39:33.33
Epoch :: 41 || Loss: 0.41635147 || it_count: 8344 || Val Loss: 0.42447745 || Val it_count: 1107 || Current Learning Rate: 0.0001 || Time: 04:46:32.73
Epoch :: 42 || Loss: 0.41627205 || it_count: 8344 || Val Loss: 0.42432964 || Val it_count: 1107 || Current Learning Rate: 0.0001 || Time: 04:53:31.13
Epoch :: 43 || Loss: 0.41624420 || it_count: 8344 || Val Loss: 0.42420974 || Val it_count: 1107 || Current Learning Rate: 0.0001 || Time: 05:00:31.16
Epoch :: 44 || Loss: 0.41615689 || it_count: 8344 || Val Loss: 0.42420113 || Val it_count: 1107 || Current Learning Rate: 0.0001 || Time: 05:07:30.25
Epoch :: 45 || Loss: 0.41607864 || it_count: 8344 || Val Loss: 0.42384543 || Val it_count: 1107 || Current Learning Rate: 0.0001 || Time: 05:14:29.92
Epoch :: 46 || Loss: 0.41600908 || it_count: 8344 || Val Loss: 0.42369707 || Val it_count: 1107 || Current Learning Rate: 0.0001 || Time: 05:21:28.42
Epoch :: 47 || Loss: 0.41595778 || it_count: 8344 || Val Loss: 0.42344888 || Val it_count: 1107 || Current Learning Rate: 0.0001 || Time: 05:28:28.72
Epoch :: 48 || Loss: 0.41589010 || it_count: 8344 || Val Loss: 0.42314019 || Val it_count: 1107 || Current Learning Rate: 0.0001 || Time: 05:35:28.26
Epoch :: 49 || Loss: 0.41580235 || it_count: 8344 || Val Loss: 0.42280465 || Val it_count: 1107 || Current Learning Rate: 0.0001 || Time: 05:42:28.00
Epoch :: 50 || Loss: 0.41574689 || it_count: 8344 || Val Loss: 0.42256582 || Val it_count: 1107 || Current Learning Rate: 0.0001 || Time: 05:49:27.32
Epoch :: 51 || Loss: 0.41560035 || it_count: 8344 || Val Loss: 0.42229668 || Val it_count: 1107 || Current Learning Rate: 0.0001 || Time: 05:56:25.13
Epoch :: 52 || Loss: 0.41550067 || it_count: 8344 || Val Loss: 0.42203116 || Val it_count: 1107 || Current Learning Rate: 0.0001 || Time: 06:03:24.39
Epoch :: 53 || Loss: 0.41542942 || it_count: 8344 || Val Loss: 0.42169574 || Val it_count: 1107 || Current Learning Rate: 0.0001 || Time: 06:10:24.31
Epoch :: 54 || Loss: 0.41533361 || it_count: 8344 || Val Loss: 0.42168387 || Val it_count: 1107 || Current Learning Rate: 0.0001 || Time: 06:17:24.06
Epoch :: 55 || Loss: 0.41525198 || it_count: 8344 || Val Loss: 0.42161860 || Val it_count: 1107 || Current Learning Rate: 0.0001 || Time: 06:24:24.38
Epoch :: 56 || Loss: 0.41517485 || it_count: 8344 || Val Loss: 0.42147227 || Val it_count: 1107 || Current Learning Rate: 0.0001 || Time: 06:31:22.53
Epoch :: 57 || Loss: 0.41512226 || it_count: 8344 || Val Loss: 0.42139494 || Val it_count: 1107 || Current Learning Rate: 0.0001 || Time: 06:38:23.44
Epoch :: 58 || Loss: 0.41504172 || it_count: 8344 || Val Loss: 0.42104565 || Val it_count: 1107 || Current Learning Rate: 0.0001 || Time: 06:45:22.92
Epoch :: 59 || Loss: 0.41500948 || it_count: 8344 || Val Loss: 0.42113807 || Val it_count: 1107 || Current Learning Rate: 0.0001 || Time: 06:52:21.21
Epoch :: 60 || Loss: 0.41489077 || it_count: 8344 || Val Loss: 0.42122689 || Val it_count: 1107 || Current Learning Rate: 0.0001 || Time: 06:59:20.93
Epoch :: 61 || Loss: 0.41486616 || it_count: 8344 || Val Loss: 0.42110697 || Val it_count: 1107 || Current Learning Rate: 0.0001 || Time: 07:06:20.61
Epoch :: 62 || Loss: 0.41479964 || it_count: 8344 || Val Loss: 0.42109331 || Val it_count: 1107 || Current Learning Rate: 0.0001 || Time: 07:13:21.33
Epoch :: 63 || Loss: 0.41477648 || it_count: 8344 || Val Loss: 0.42115778 || Val it_count: 1107 || Current Learning Rate: 0.0001 || Time: 07:20:19.90
Epoch 00048: reducing learning rate of group 0 to 1.0000e-05.
Epoch :: 64 || Loss: 0.41474846 || it_count: 8344 || Val Loss: 0.42110368 || Val it_count: 1107 || Current Learning Rate: 1e-05 || Time: 07:27:20.34
Epoch :: 65 || Loss: 0.41571144 || it_count: 8344 || Val Loss: 0.41883140 || Val it_count: 1107 || Current Learning Rate: 1e-05 || Time: 07:34:18.96
Epoch :: 66 || Loss: 0.41539424 || it_count: 8344 || Val Loss: 0.41869076 || Val it_count: 1107 || Current Learning Rate: 1e-05 || Time: 07:41:19.80
Epoch :: 67 || Loss: 0.41521620 || it_count: 8344 || Val Loss: 0.41857964 || Val it_count: 1107 || Current Learning Rate: 1e-05 || Time: 07:48:19.57
Epoch :: 68 || Loss: 0.41523075 || it_count: 8344 || Val Loss: 0.41854317 || Val it_count: 1107 || Current Learning Rate: 1e-05 || Time: 07:55:20.11
Epoch :: 69 || Loss: 0.41517607 || it_count: 8344 || Val Loss: 0.41854006 || Val it_count: 1107 || Current Learning Rate: 1e-05 || Time: 08:02:19.92
Epoch :: 70 || Loss: 0.41516105 || it_count: 8344 || Val Loss: 0.41852825 || Val it_count: 1107 || Current Learning Rate: 1e-05 || Time: 08:09:19.74
Epoch :: 71 || Loss: 0.41517905 || it_count: 8344 || Val Loss: 0.41848829 || Val it_count: 1107 || Current Learning Rate: 1e-05 || Time: 08:16:21.15
Epoch :: 72 || Loss: 0.41510595 || it_count: 8344 || Val Loss: 0.41846435 || Val it_count: 1107 || Current Learning Rate: 1e-05 || Time: 08:23:21.54
Epoch :: 73 || Loss: 0.41512499 || it_count: 8344 || Val Loss: 0.41845994 || Val it_count: 1107 || Current Learning Rate: 1e-05 || Time: 08:30:22.87
Epoch :: 74 || Loss: 0.41506661 || it_count: 8344 || Val Loss: 0.41846098 || Val it_count: 1107 || Current Learning Rate: 1e-05 || Time: 08:37:22.98
Epoch :: 75 || Loss: 0.41513148 || it_count: 8344 || Val Loss: 0.41848005 || Val it_count: 1107 || Current Learning Rate: 1e-05 || Time: 08:44:23.20
Epoch :: 76 || Loss: 0.41509461 || it_count: 8344 || Val Loss: 0.41849792 || Val it_count: 1107 || Current Learning Rate: 1e-05 || Time: 08:51:23.80
Epoch :: 77 || Loss: 0.41507207 || it_count: 8344 || Val Loss: 0.41847957 || Val it_count: 1107 || Current Learning Rate: 1e-05 || Time: 08:58:23.89
Epoch 00062: reducing learning rate of group 0 to 1.0000e-06.
Epoch :: 78 || Loss: 0.41507644 || it_count: 8344 || Val Loss: 0.41847047 || Val it_count: 1107 || Current Learning Rate: 1.0000000000000002e-06 || Time: 09:05:24.32
Epoch :: 79 || Loss: 0.41510574 || it_count: 8344 || Val Loss: 0.41834876 || Val it_count: 1107 || Current Learning Rate: 1.0000000000000002e-06 || Time: 09:12:25.37
Epoch :: 80 || Loss: 0.41503379 || it_count: 8344 || Val Loss: 0.41832501 || Val it_count: 1107 || Current Learning Rate: 1.0000000000000002e-06 || Time: 09:19:24.59
Epoch :: 81 || Loss: 0.41507592 || it_count: 8344 || Val Loss: 0.41830872 || Val it_count: 1107 || Current Learning Rate: 1.0000000000000002e-06 || Time: 09:26:24.62
Epoch :: 82 || Loss: 0.41509793 || it_count: 8344 || Val Loss: 0.41830041 || Val it_count: 1107 || Current Learning Rate: 1.0000000000000002e-06 || Time: 09:33:24.15
Epoch :: 83 || Loss: 0.41505055 || it_count: 8344 || Val Loss: 0.41829598 || Val it_count: 1107 || Current Learning Rate: 1.0000000000000002e-06 || Time: 09:40:22.86
Epoch :: 84 || Loss: 0.41510918 || it_count: 8344 || Val Loss: 0.41829526 || Val it_count: 1107 || Current Learning Rate: 1.0000000000000002e-06 || Time: 09:47:22.75
Epoch :: 85 || Loss: 0.41505339 || it_count: 8344 || Val Loss: 0.41829053 || Val it_count: 1107 || Current Learning Rate: 1.0000000000000002e-06 || Time: 09:54:23.99
Epoch :: 86 || Loss: 0.41505894 || it_count: 8344 || Val Loss: 0.41828642 || Val it_count: 1107 || Current Learning Rate: 1.0000000000000002e-06 || Time: 10:01:25.25
Epoch :: 87 || Loss: 0.41498501 || it_count: 8344 || Val Loss: 0.41827821 || Val it_count: 1107 || Current Learning Rate: 1.0000000000000002e-06 || Time: 10:08:25.33
Epoch 00072: reducing learning rate of group 0 to 1.0000e-07.
Early stopping triggered due to learning rate below threshold.
Done Total time: 10:15:26.87
best_loss: 0.418278212795941

--------------------Testing--------------------

total_samples :: test_dataset = 139200, test_dataloader = 139200
Epoch ::  1 || Loss: 0.23860597 || it_count: 544 || Time: 00:00:20.40
MAE:  0.25566256
MSE:  0.23862776
RMSE:  0.44450068

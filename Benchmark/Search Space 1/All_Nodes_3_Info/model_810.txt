--------------------Training--------------------
arch_str :: |lstm_1~0|+|lstm_3~0|lstm_3~1|[linear->relu->linear]
model :: 3G
InferCell(
  info :: nodes=3, inC=1, outC=64, [1<-(I0-L0) | 2<-(I0-L1,I1-L2)], genotype_str: lstm_1~0|lstm_3~0|lstm_3~1
  linear_layers: [linear->relu->linear]
  (layers): ModuleList(
    (0): LSTM(
      (lstm): LSTM(1, 64, batch_first=True)
    )
    (1): LSTM(
      (lstm): LSTM(1, 64, num_layers=3, batch_first=True)
    )
    (2): LSTM(
      (lstm): LSTM(64, 64, num_layers=3, batch_first=True)
    )
  )
  (linear_layers): ModuleList(
    (0): Linear(in_features=3072, out_features=1536, bias=True)
    (1): ReLU()
    (2): Linear(in_features=1536, out_features=1, bias=True)
  )
)
tr_params :: epochs = 100, patience = 20, batch_size = 256, window_size = 48, data_size = 100
Model FLOPs: 14.526M, Model Params: 4.922M
learning rate scheduling :: (optimizer, mode='min', factor=0.1, patience=5, verbose=True)
total_samples :: train_dataset = 2136000, train_dataloader = 2136000
total_samples :: valid_dataset = 283200, valid_dataloader = 283200
Epoch ::  1 || Loss: 0.42141844 || it_count: 8344 || Val Loss: 0.46934875 || Val it_count: 1107 || Current Learning Rate: 0.001 || Time: 00:16:10.26
Epoch ::  2 || Loss: 0.41444262 || it_count: 8344 || Val Loss: 0.45788823 || Val it_count: 1107 || Current Learning Rate: 0.001 || Time: 00:32:16.95
Epoch ::  3 || Loss: 0.41398291 || it_count: 8344 || Val Loss: 0.45441453 || Val it_count: 1107 || Current Learning Rate: 0.001 || Time: 00:48:25.16
Epoch ::  4 || Loss: 0.41217309 || it_count: 8344 || Val Loss: 0.45420565 || Val it_count: 1107 || Current Learning Rate: 0.001 || Time: 01:04:40.70
Epoch ::  5 || Loss: 0.41082076 || it_count: 8344 || Val Loss: 0.45189015 || Val it_count: 1107 || Current Learning Rate: 0.001 || Time: 01:20:58.96
Epoch ::  6 || Loss: 0.40963338 || it_count: 8344 || Val Loss: 0.45413508 || Val it_count: 1107 || Current Learning Rate: 0.001 || Time: 01:37:21.90
Epoch ::  7 || Loss: 0.40875753 || it_count: 8344 || Val Loss: 0.45719593 || Val it_count: 1107 || Current Learning Rate: 0.001 || Time: 01:53:44.78
Epoch ::  8 || Loss: 0.40749448 || it_count: 8344 || Val Loss: 0.45818186 || Val it_count: 1107 || Current Learning Rate: 0.001 || Time: 02:10:11.04
Epoch ::  9 || Loss: 0.40637134 || it_count: 8344 || Val Loss: 0.45754145 || Val it_count: 1107 || Current Learning Rate: 0.001 || Time: 02:26:40.72
Epoch :: 10 || Loss: 0.40492263 || it_count: 8344 || Val Loss: 0.45431956 || Val it_count: 1107 || Current Learning Rate: 0.001 || Time: 02:43:10.85
Epoch :: 11 || Loss: 0.40290223 || it_count: 8344 || Val Loss: 0.45396574 || Val it_count: 1107 || Current Learning Rate: 0.001 || Time: 02:59:41.59
Epoch :: 12 || Loss: 0.40059009 || it_count: 8344 || Val Loss: 0.45387819 || Val it_count: 1107 || Current Learning Rate: 0.001 || Time: 03:16:14.71
Epoch :: 13 || Loss: 0.39781141 || it_count: 8344 || Val Loss: 0.45444540 || Val it_count: 1107 || Current Learning Rate: 0.001 || Time: 03:32:48.81
Epoch :: 14 || Loss: 0.39428155 || it_count: 8344 || Val Loss: 0.45581013 || Val it_count: 1107 || Current Learning Rate: 0.001 || Time: 03:49:23.68
Epoch :: 15 || Loss: 0.38978302 || it_count: 8344 || Val Loss: 0.45904206 || Val it_count: 1107 || Current Learning Rate: 0.001 || Time: 04:05:59.64
Epoch :: 16 || Loss: 0.38479987 || it_count: 8344 || Val Loss: 0.46369633 || Val it_count: 1107 || Current Learning Rate: 0.001 || Time: 04:22:34.30
Epoch :: 17 || Loss: 0.37996295 || it_count: 8344 || Val Loss: 0.47313037 || Val it_count: 1107 || Current Learning Rate: 0.001 || Time: 04:39:11.01
Epoch :: 18 || Loss: 0.37393527 || it_count: 8344 || Val Loss: 0.47431638 || Val it_count: 1107 || Current Learning Rate: 0.001 || Time: 04:55:47.25
Epoch :: 19 || Loss: 0.36771716 || it_count: 8344 || Val Loss: 0.48580347 || Val it_count: 1107 || Current Learning Rate: 0.001 || Time: 05:12:24.83
Epoch :: 20 || Loss: 0.36234732 || it_count: 8344 || Val Loss: 0.48793035 || Val it_count: 1107 || Current Learning Rate: 0.001 || Time: 05:29:2.60
Epoch :: 21 || Loss: 0.35712611 || it_count: 8344 || Val Loss: 0.49307156 || Val it_count: 1107 || Current Learning Rate: 0.001 || Time: 05:45:40.88
Epoch :: 22 || Loss: 0.35325388 || it_count: 8344 || Val Loss: 0.50646992 || Val it_count: 1107 || Current Learning Rate: 0.001 || Time: 06:02:18.32
Epoch 00007: reducing learning rate of group 0 to 1.0000e-04.
Epoch :: 23 || Loss: 0.34853599 || it_count: 8344 || Val Loss: 0.51230496 || Val it_count: 1107 || Current Learning Rate: 0.0001 || Time: 06:18:57.20
Epoch :: 24 || Loss: 0.36919121 || it_count: 8344 || Val Loss: 0.45922346 || Val it_count: 1107 || Current Learning Rate: 0.0001 || Time: 06:35:34.71
Epoch :: 25 || Loss: 0.35920900 || it_count: 8344 || Val Loss: 0.46063283 || Val it_count: 1107 || Current Learning Rate: 0.0001 || Time: 06:52:13.67
Early stopping triggered due to patience exceeded.
Done Total time: 06:52:13.67
best_loss: 0.45189015076270345

--------------------Testing--------------------

total_samples :: test_dataset = 139200, test_dataloader = 139200
Epoch ::  1 || Loss: 0.34615225 || it_count: 544 || Time: 00:00:31.11
MAE:  0.29315713
MSE:  0.34622803
RMSE:  0.4942633

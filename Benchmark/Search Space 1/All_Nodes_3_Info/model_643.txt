--------------------Training--------------------
arch_str :: |skip_connect~0|+|lstm_1~0|none~1|[linear->dropout->linear]
model :: 3F
InferCell(
  info :: nodes=3, inC=1, outC=64, [1<-(I0-L0) | 2<-(I0-L1,I1-L2)], genotype_str: skip_connect~0|lstm_1~0|none~1
  linear_layers: [linear->dropout->linear]
  (layers): ModuleList(
    (0): FactorizedReduce(
      C_in=1, C_out=64, stride=1
      (relu): ReLU()
      (conv): Conv1d(1, 64, kernel_size=(1,), stride=(1,), bias=False)
      (bn): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (1): LSTM(
      (lstm): LSTM(1, 64, batch_first=True)
    )
    (2): Zero(C_in=64, C_out=64, stride=1)
  )
  (linear_layers): ModuleList(
    (0): Linear(in_features=3072, out_features=1536, bias=True)
    (1): Dropout(p=0.1, inplace=False)
    (2): Linear(in_features=1536, out_features=1, bias=True)
  )
)
tr_params :: epochs = 100, patience = 20, batch_size = 256, window_size = 48, data_size = 100
Model FLOPs: 5.583M, Model Params: 4.739M
learning rate scheduling :: (optimizer, mode='min', factor=0.1, patience=5, verbose=True)
total_samples :: train_dataset = 2136000, train_dataloader = 2136000
total_samples :: valid_dataset = 283200, valid_dataloader = 283200
Epoch ::  1 || Loss: 0.42126988 || it_count: 8344 || Val Loss: 0.45197328 || Val it_count: 1107 || Current Learning Rate: 0.001 || Time: 00:03:53.21
Epoch ::  2 || Loss: 0.41787545 || it_count: 8344 || Val Loss: 0.44925044 || Val it_count: 1107 || Current Learning Rate: 0.001 || Time: 00:07:36.65
Epoch ::  3 || Loss: 0.41749351 || it_count: 8344 || Val Loss: 0.44972741 || Val it_count: 1107 || Current Learning Rate: 0.001 || Time: 00:11:22.70
Epoch ::  4 || Loss: 0.41751760 || it_count: 8344 || Val Loss: 0.44865296 || Val it_count: 1107 || Current Learning Rate: 0.001 || Time: 00:15:9.34
Epoch ::  5 || Loss: 0.41754286 || it_count: 8344 || Val Loss: 0.44822176 || Val it_count: 1107 || Current Learning Rate: 0.001 || Time: 00:18:56.54
Epoch ::  6 || Loss: 0.41748428 || it_count: 8344 || Val Loss: 0.44812449 || Val it_count: 1107 || Current Learning Rate: 0.001 || Time: 00:22:43.12
Epoch ::  7 || Loss: 0.41744302 || it_count: 8344 || Val Loss: 0.44787799 || Val it_count: 1107 || Current Learning Rate: 0.001 || Time: 00:26:29.02
Epoch ::  8 || Loss: 0.41740067 || it_count: 8344 || Val Loss: 0.44756612 || Val it_count: 1107 || Current Learning Rate: 0.001 || Time: 00:30:16.74
Epoch ::  9 || Loss: 0.41716813 || it_count: 8344 || Val Loss: 0.44749467 || Val it_count: 1107 || Current Learning Rate: 0.001 || Time: 00:34:4.91
Epoch :: 10 || Loss: 0.41716353 || it_count: 8344 || Val Loss: 0.44693271 || Val it_count: 1107 || Current Learning Rate: 0.001 || Time: 00:37:52.22
Epoch :: 11 || Loss: 0.41696025 || it_count: 8344 || Val Loss: 0.44711071 || Val it_count: 1107 || Current Learning Rate: 0.001 || Time: 00:41:40.61
Epoch :: 12 || Loss: 0.41695332 || it_count: 8344 || Val Loss: 0.44740483 || Val it_count: 1107 || Current Learning Rate: 0.001 || Time: 00:45:26.10
Epoch :: 13 || Loss: 0.41694666 || it_count: 8344 || Val Loss: 0.44782095 || Val it_count: 1107 || Current Learning Rate: 0.001 || Time: 00:49:12.16
Epoch :: 14 || Loss: 0.41694486 || it_count: 8344 || Val Loss: 0.44768139 || Val it_count: 1107 || Current Learning Rate: 0.001 || Time: 00:52:58.14
Epoch :: 15 || Loss: 0.41685778 || it_count: 8344 || Val Loss: 0.44796834 || Val it_count: 1107 || Current Learning Rate: 0.001 || Time: 00:56:43.56
Epoch :: 16 || Loss: 0.41687059 || it_count: 8344 || Val Loss: 0.44754607 || Val it_count: 1107 || Current Learning Rate: 0.001 || Time: 01:00:30.41
Epoch :: 17 || Loss: 0.41680676 || it_count: 8344 || Val Loss: 0.44764529 || Val it_count: 1107 || Current Learning Rate: 0.001 || Time: 01:04:17.02
Epoch :: 18 || Loss: 0.41683627 || it_count: 8344 || Val Loss: 0.44791884 || Val it_count: 1107 || Current Learning Rate: 0.001 || Time: 01:08:3.36
Epoch :: 19 || Loss: 0.41691600 || it_count: 8344 || Val Loss: 0.44771933 || Val it_count: 1107 || Current Learning Rate: 0.001 || Time: 01:11:50.76
Epoch :: 20 || Loss: 0.41689161 || it_count: 8344 || Val Loss: 0.44740156 || Val it_count: 1107 || Current Learning Rate: 0.001 || Time: 01:15:36.63
Epoch :: 21 || Loss: 0.41692983 || it_count: 8344 || Val Loss: 0.44775575 || Val it_count: 1107 || Current Learning Rate: 0.001 || Time: 01:19:24.11
Epoch :: 22 || Loss: 0.41709606 || it_count: 8344 || Val Loss: 0.44724195 || Val it_count: 1107 || Current Learning Rate: 0.001 || Time: 01:23:10.65
Epoch :: 23 || Loss: 0.41702084 || it_count: 8344 || Val Loss: 0.44690017 || Val it_count: 1107 || Current Learning Rate: 0.001 || Time: 01:26:57.02
Epoch :: 24 || Loss: 0.41712192 || it_count: 8344 || Val Loss: 0.44695591 || Val it_count: 1107 || Current Learning Rate: 0.001 || Time: 01:30:45.03
Epoch :: 25 || Loss: 0.41718528 || it_count: 8344 || Val Loss: 0.44688981 || Val it_count: 1107 || Current Learning Rate: 0.001 || Time: 01:34:31.97
Epoch :: 26 || Loss: 0.41709899 || it_count: 8344 || Val Loss: 0.44682407 || Val it_count: 1107 || Current Learning Rate: 0.001 || Time: 01:38:18.84
Epoch :: 27 || Loss: 0.41705471 || it_count: 8344 || Val Loss: 0.44710963 || Val it_count: 1107 || Current Learning Rate: 0.001 || Time: 01:42:5.26
Epoch :: 28 || Loss: 0.41706273 || it_count: 8344 || Val Loss: 0.44707900 || Val it_count: 1107 || Current Learning Rate: 0.001 || Time: 01:45:53.15
Epoch :: 29 || Loss: 0.41681852 || it_count: 8344 || Val Loss: 0.44702876 || Val it_count: 1107 || Current Learning Rate: 0.001 || Time: 01:49:40.42
Epoch :: 30 || Loss: 0.41653405 || it_count: 8344 || Val Loss: 0.44642193 || Val it_count: 1107 || Current Learning Rate: 0.001 || Time: 01:53:27.57
Epoch :: 31 || Loss: 0.41627499 || it_count: 8344 || Val Loss: 0.44670499 || Val it_count: 1107 || Current Learning Rate: 0.001 || Time: 01:57:13.88
Epoch :: 32 || Loss: 0.41608046 || it_count: 8344 || Val Loss: 0.44580727 || Val it_count: 1107 || Current Learning Rate: 0.001 || Time: 02:00:59.16
Epoch :: 33 || Loss: 0.41595816 || it_count: 8344 || Val Loss: 0.44543466 || Val it_count: 1107 || Current Learning Rate: 0.001 || Time: 02:04:47.28
Epoch :: 34 || Loss: 0.41585445 || it_count: 8344 || Val Loss: 0.44511684 || Val it_count: 1107 || Current Learning Rate: 0.001 || Time: 02:08:35.04
Epoch :: 35 || Loss: 0.41569509 || it_count: 8344 || Val Loss: 0.44529194 || Val it_count: 1107 || Current Learning Rate: 0.001 || Time: 02:12:22.33
Epoch :: 36 || Loss: 0.41553278 || it_count: 8344 || Val Loss: 0.44545619 || Val it_count: 1107 || Current Learning Rate: 0.001 || Time: 02:16:10.40
Epoch :: 37 || Loss: 0.41557785 || it_count: 8344 || Val Loss: 0.44606073 || Val it_count: 1107 || Current Learning Rate: 0.001 || Time: 02:19:58.82
Epoch :: 38 || Loss: 0.41548529 || it_count: 8344 || Val Loss: 0.44582722 || Val it_count: 1107 || Current Learning Rate: 0.001 || Time: 02:23:46.15
Epoch :: 39 || Loss: 0.41551103 || it_count: 8344 || Val Loss: 0.44552218 || Val it_count: 1107 || Current Learning Rate: 0.001 || Time: 02:27:33.55
Epoch 00024: reducing learning rate of group 0 to 1.0000e-04.
Epoch :: 40 || Loss: 0.41543716 || it_count: 8344 || Val Loss: 0.44592832 || Val it_count: 1107 || Current Learning Rate: 0.0001 || Time: 02:31:23.03
Epoch :: 41 || Loss: 0.42141610 || it_count: 8344 || Val Loss: 0.43654938 || Val it_count: 1107 || Current Learning Rate: 0.0001 || Time: 02:35:12.75
Epoch :: 42 || Loss: 0.41948757 || it_count: 8344 || Val Loss: 0.43541313 || Val it_count: 1107 || Current Learning Rate: 0.0001 || Time: 02:39:0.33
Epoch :: 43 || Loss: 0.41914927 || it_count: 8344 || Val Loss: 0.43470440 || Val it_count: 1107 || Current Learning Rate: 0.0001 || Time: 02:42:45.55
Epoch :: 44 || Loss: 0.41893215 || it_count: 8344 || Val Loss: 0.43417535 || Val it_count: 1107 || Current Learning Rate: 0.0001 || Time: 02:46:32.17
Epoch :: 45 || Loss: 0.41872516 || it_count: 8344 || Val Loss: 0.43372334 || Val it_count: 1107 || Current Learning Rate: 0.0001 || Time: 02:50:19.38
Epoch :: 46 || Loss: 0.41851777 || it_count: 8344 || Val Loss: 0.43330535 || Val it_count: 1107 || Current Learning Rate: 0.0001 || Time: 02:54:6.43
Epoch :: 47 || Loss: 0.41832052 || it_count: 8344 || Val Loss: 0.43320723 || Val it_count: 1107 || Current Learning Rate: 0.0001 || Time: 02:57:53.61
Epoch :: 48 || Loss: 0.41815340 || it_count: 8344 || Val Loss: 0.43299993 || Val it_count: 1107 || Current Learning Rate: 0.0001 || Time: 03:01:41.47
Epoch :: 49 || Loss: 0.41797760 || it_count: 8344 || Val Loss: 0.43280249 || Val it_count: 1107 || Current Learning Rate: 0.0001 || Time: 03:05:30.01
Epoch :: 50 || Loss: 0.41791121 || it_count: 8344 || Val Loss: 0.43279346 || Val it_count: 1107 || Current Learning Rate: 0.0001 || Time: 03:09:16.89
Epoch :: 51 || Loss: 0.41776112 || it_count: 8344 || Val Loss: 0.43260656 || Val it_count: 1107 || Current Learning Rate: 0.0001 || Time: 03:13:4.79
Epoch :: 52 || Loss: 0.41764290 || it_count: 8344 || Val Loss: 0.43255557 || Val it_count: 1107 || Current Learning Rate: 0.0001 || Time: 03:16:53.10
Epoch :: 53 || Loss: 0.41755648 || it_count: 8344 || Val Loss: 0.43251195 || Val it_count: 1107 || Current Learning Rate: 0.0001 || Time: 03:20:40.49
Epoch :: 54 || Loss: 0.41747639 || it_count: 8344 || Val Loss: 0.43236659 || Val it_count: 1107 || Current Learning Rate: 0.0001 || Time: 03:24:27.59
Epoch :: 55 || Loss: 0.41735249 || it_count: 8344 || Val Loss: 0.43237609 || Val it_count: 1107 || Current Learning Rate: 0.0001 || Time: 03:28:14.79
Epoch :: 56 || Loss: 0.41731575 || it_count: 8344 || Val Loss: 0.43225339 || Val it_count: 1107 || Current Learning Rate: 0.0001 || Time: 03:32:1.77
Epoch :: 57 || Loss: 0.41721528 || it_count: 8344 || Val Loss: 0.43224113 || Val it_count: 1107 || Current Learning Rate: 0.0001 || Time: 03:35:52.91
Epoch :: 58 || Loss: 0.41716998 || it_count: 8344 || Val Loss: 0.43229940 || Val it_count: 1107 || Current Learning Rate: 0.0001 || Time: 03:39:40.33
Epoch :: 59 || Loss: 0.41713626 || it_count: 8344 || Val Loss: 0.43226481 || Val it_count: 1107 || Current Learning Rate: 0.0001 || Time: 03:43:28.11
Epoch :: 60 || Loss: 0.41702567 || it_count: 8344 || Val Loss: 0.43221916 || Val it_count: 1107 || Current Learning Rate: 0.0001 || Time: 03:47:17.40
Epoch :: 61 || Loss: 0.41700402 || it_count: 8344 || Val Loss: 0.43226589 || Val it_count: 1107 || Current Learning Rate: 0.0001 || Time: 03:51:6.59
Epoch 00046: reducing learning rate of group 0 to 1.0000e-05.
Epoch :: 62 || Loss: 0.41695952 || it_count: 8344 || Val Loss: 0.43230353 || Val it_count: 1107 || Current Learning Rate: 1e-05 || Time: 03:54:54.42
Epoch :: 63 || Loss: 0.41983890 || it_count: 8344 || Val Loss: 0.42263180 || Val it_count: 1107 || Current Learning Rate: 1e-05 || Time: 03:58:41.85
Epoch :: 64 || Loss: 0.41819154 || it_count: 8344 || Val Loss: 0.42209479 || Val it_count: 1107 || Current Learning Rate: 1e-05 || Time: 04:02:29.78
Epoch :: 65 || Loss: 0.41798633 || it_count: 8344 || Val Loss: 0.42197098 || Val it_count: 1107 || Current Learning Rate: 1e-05 || Time: 04:06:17.10
Epoch :: 66 || Loss: 0.41789099 || it_count: 8344 || Val Loss: 0.42188420 || Val it_count: 1107 || Current Learning Rate: 1e-05 || Time: 04:10:5.40
Epoch :: 67 || Loss: 0.41782956 || it_count: 8344 || Val Loss: 0.42184718 || Val it_count: 1107 || Current Learning Rate: 1e-05 || Time: 04:13:53.75
Epoch :: 68 || Loss: 0.41774523 || it_count: 8344 || Val Loss: 0.42182888 || Val it_count: 1107 || Current Learning Rate: 1e-05 || Time: 04:17:39.67
Epoch :: 69 || Loss: 0.41770901 || it_count: 8344 || Val Loss: 0.42179705 || Val it_count: 1107 || Current Learning Rate: 1e-05 || Time: 04:21:26.55
Epoch :: 70 || Loss: 0.41768968 || it_count: 8344 || Val Loss: 0.42179947 || Val it_count: 1107 || Current Learning Rate: 1e-05 || Time: 04:25:11.80
Epoch :: 71 || Loss: 0.41765919 || it_count: 8344 || Val Loss: 0.42178936 || Val it_count: 1107 || Current Learning Rate: 1e-05 || Time: 04:28:55.81
Epoch :: 72 || Loss: 0.41762560 || it_count: 8344 || Val Loss: 0.42179558 || Val it_count: 1107 || Current Learning Rate: 1e-05 || Time: 04:32:41.33
Epoch :: 73 || Loss: 0.41758534 || it_count: 8344 || Val Loss: 0.42179948 || Val it_count: 1107 || Current Learning Rate: 1e-05 || Time: 04:36:26.64
Epoch 00058: reducing learning rate of group 0 to 1.0000e-06.
Epoch :: 74 || Loss: 0.41757839 || it_count: 8344 || Val Loss: 0.42179499 || Val it_count: 1107 || Current Learning Rate: 1.0000000000000002e-06 || Time: 04:40:9.97
Epoch :: 75 || Loss: 0.41775764 || it_count: 8344 || Val Loss: 0.42103571 || Val it_count: 1107 || Current Learning Rate: 1.0000000000000002e-06 || Time: 04:43:54.56
Epoch :: 76 || Loss: 0.41769196 || it_count: 8344 || Val Loss: 0.42098925 || Val it_count: 1107 || Current Learning Rate: 1.0000000000000002e-06 || Time: 04:47:40.49
Epoch :: 77 || Loss: 0.41766805 || it_count: 8344 || Val Loss: 0.42096429 || Val it_count: 1107 || Current Learning Rate: 1.0000000000000002e-06 || Time: 04:51:26.87
Epoch :: 78 || Loss: 0.41762582 || it_count: 8344 || Val Loss: 0.42094457 || Val it_count: 1107 || Current Learning Rate: 1.0000000000000002e-06 || Time: 04:55:11.65
Epoch :: 79 || Loss: 0.41764940 || it_count: 8344 || Val Loss: 0.42093341 || Val it_count: 1107 || Current Learning Rate: 1.0000000000000002e-06 || Time: 04:58:58.28
Epoch :: 80 || Loss: 0.41762070 || it_count: 8344 || Val Loss: 0.42092432 || Val it_count: 1107 || Current Learning Rate: 1.0000000000000002e-06 || Time: 05:02:43.13
Epoch :: 81 || Loss: 0.41760950 || it_count: 8344 || Val Loss: 0.42091319 || Val it_count: 1107 || Current Learning Rate: 1.0000000000000002e-06 || Time: 05:06:37.51
Epoch :: 82 || Loss: 0.41760600 || it_count: 8344 || Val Loss: 0.42090520 || Val it_count: 1107 || Current Learning Rate: 1.0000000000000002e-06 || Time: 05:11:8.53
Epoch :: 83 || Loss: 0.41764677 || it_count: 8344 || Val Loss: 0.42090331 || Val it_count: 1107 || Current Learning Rate: 1.0000000000000002e-06 || Time: 05:14:55.22
Epoch :: 84 || Loss: 0.41761306 || it_count: 8344 || Val Loss: 0.42089456 || Val it_count: 1107 || Current Learning Rate: 1.0000000000000002e-06 || Time: 05:18:41.35
Epoch :: 85 || Loss: 0.41755534 || it_count: 8344 || Val Loss: 0.42088661 || Val it_count: 1107 || Current Learning Rate: 1.0000000000000002e-06 || Time: 05:22:27.38
Epoch :: 86 || Loss: 0.41757868 || it_count: 8344 || Val Loss: 0.42088349 || Val it_count: 1107 || Current Learning Rate: 1.0000000000000002e-06 || Time: 05:26:12.62
Epoch :: 87 || Loss: 0.41759188 || it_count: 8344 || Val Loss: 0.42087845 || Val it_count: 1107 || Current Learning Rate: 1.0000000000000002e-06 || Time: 05:30:1.59
Epoch :: 88 || Loss: 0.41756434 || it_count: 8344 || Val Loss: 0.42087186 || Val it_count: 1107 || Current Learning Rate: 1.0000000000000002e-06 || Time: 05:33:55.96
Epoch :: 89 || Loss: 0.41756515 || it_count: 8344 || Val Loss: 0.42086669 || Val it_count: 1107 || Current Learning Rate: 1.0000000000000002e-06 || Time: 05:37:50.92
Epoch 00074: reducing learning rate of group 0 to 1.0000e-07.
Early stopping triggered due to learning rate below threshold.
Done Total time: 05:41:43.67
best_loss: 0.4208666914440163

--------------------Testing--------------------

total_samples :: test_dataset = 139200, test_dataloader = 139200
Epoch ::  1 || Loss: 0.24861235 || it_count: 544 || Time: 00:00:13.06
MAE:  0.2618308
MSE:  0.24863711
RMSE:  0.4511497

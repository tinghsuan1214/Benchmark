--------------------Training--------------------
arch_str :: |skip_connect~0|+|none~0|lstm_3~1|[dropout->linear]
model :: 3B
InferCell(
  info :: nodes=3, inC=1, outC=64, [1<-(I0-L0) | 2<-(I0-L1,I1-L2)], genotype_str: skip_connect~0|none~0|lstm_3~1
  linear_layers: [dropout->linear]
  (layers): ModuleList(
    (0): FactorizedReduce(
      C_in=1, C_out=64, stride=1
      (relu): ReLU()
      (conv): Conv1d(1, 64, kernel_size=(1,), stride=(1,), bias=False)
      (bn): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (1): Zero(C_in=1, C_out=64, stride=1)
    (2): LSTM(
      (lstm): LSTM(64, 64, num_layers=3, batch_first=True)
    )
  )
  (linear_layers): ModuleList(
    (0): Dropout(p=0.1, inplace=False)
    (1): Linear(in_features=3072, out_features=1, bias=True)
  )
)
tr_params :: epochs = 100, patience = 20, batch_size = 256, window_size = 48, data_size = 100
Model FLOPs: 4.884M, Model Params: 103.105K
learning rate scheduling :: (optimizer, mode='min', factor=0.1, patience=5, verbose=True)
total_samples :: train_dataset = 2136000, train_dataloader = 2136000
total_samples :: valid_dataset = 283200, valid_dataloader = 283200
Epoch ::  1 || Loss: 0.46885363 || it_count: 8344 || Val Loss: 0.49596205 || Val it_count: 1107 || Current Learning Rate: 0.001 || Time: 00:06:51.93
Epoch ::  2 || Loss: 0.47211790 || it_count: 8344 || Val Loss: 0.49086072 || Val it_count: 1107 || Current Learning Rate: 0.001 || Time: 00:13:40.21
Epoch ::  3 || Loss: 0.45859191 || it_count: 8344 || Val Loss: 0.48918930 || Val it_count: 1107 || Current Learning Rate: 0.001 || Time: 00:20:30.00
Epoch ::  4 || Loss: 0.45462798 || it_count: 8344 || Val Loss: 0.49445574 || Val it_count: 1107 || Current Learning Rate: 0.001 || Time: 00:27:20.28
Epoch ::  5 || Loss: 0.45240496 || it_count: 8344 || Val Loss: 0.48866159 || Val it_count: 1107 || Current Learning Rate: 0.001 || Time: 00:34:10.20
Epoch ::  6 || Loss: 0.46920179 || it_count: 8344 || Val Loss: 0.49479197 || Val it_count: 1107 || Current Learning Rate: 0.001 || Time: 00:41:1.17
Epoch ::  7 || Loss: 0.45942052 || it_count: 8344 || Val Loss: 0.49746079 || Val it_count: 1107 || Current Learning Rate: 0.001 || Time: 00:47:51.12
Epoch ::  8 || Loss: 0.45751726 || it_count: 8344 || Val Loss: 0.49808917 || Val it_count: 1107 || Current Learning Rate: 0.001 || Time: 00:54:40.30
Epoch ::  9 || Loss: 0.45655578 || it_count: 8344 || Val Loss: 0.49871987 || Val it_count: 1107 || Current Learning Rate: 0.001 || Time: 01:01:29.51
Epoch :: 10 || Loss: 0.45259388 || it_count: 8344 || Val Loss: 0.49790305 || Val it_count: 1107 || Current Learning Rate: 0.001 || Time: 01:08:19.47
Epoch :: 11 || Loss: 0.46238414 || it_count: 8344 || Val Loss: 0.49526074 || Val it_count: 1107 || Current Learning Rate: 0.001 || Time: 01:15:10.41
Epoch :: 12 || Loss: 0.45413669 || it_count: 8344 || Val Loss: 0.49377387 || Val it_count: 1107 || Current Learning Rate: 0.001 || Time: 01:22:0.36
Epoch :: 13 || Loss: 0.45071893 || it_count: 8344 || Val Loss: 0.49353248 || Val it_count: 1107 || Current Learning Rate: 0.001 || Time: 01:28:50.15
Epoch :: 14 || Loss: 0.45403236 || it_count: 8344 || Val Loss: 0.49213434 || Val it_count: 1107 || Current Learning Rate: 0.001 || Time: 01:35:40.13
Epoch :: 15 || Loss: 0.45081337 || it_count: 8344 || Val Loss: 0.49399084 || Val it_count: 1107 || Current Learning Rate: 0.001 || Time: 01:42:30.68
Epoch :: 16 || Loss: 0.45384608 || it_count: 8344 || Val Loss: 0.49969542 || Val it_count: 1107 || Current Learning Rate: 0.001 || Time: 01:49:19.27
Epoch :: 17 || Loss: 0.45111762 || it_count: 8344 || Val Loss: 0.49724512 || Val it_count: 1107 || Current Learning Rate: 0.001 || Time: 01:56:8.64
Epoch :: 18 || Loss: 0.45734344 || it_count: 8344 || Val Loss: 0.49515171 || Val it_count: 1107 || Current Learning Rate: 0.001 || Time: 02:02:58.64
Epoch :: 19 || Loss: 0.45852802 || it_count: 8344 || Val Loss: 0.50468118 || Val it_count: 1107 || Current Learning Rate: 0.001 || Time: 02:09:47.14
Epoch :: 20 || Loss: 0.45715062 || it_count: 8344 || Val Loss: 0.49790652 || Val it_count: 1107 || Current Learning Rate: 0.001 || Time: 02:16:35.89
Epoch :: 21 || Loss: 0.45142359 || it_count: 8344 || Val Loss: 0.49781850 || Val it_count: 1107 || Current Learning Rate: 0.001 || Time: 02:23:24.45
Epoch :: 22 || Loss: 0.45012877 || it_count: 8344 || Val Loss: 0.50941851 || Val it_count: 1107 || Current Learning Rate: 0.001 || Time: 02:30:12.61
Epoch :: 23 || Loss: 0.45681861 || it_count: 8344 || Val Loss: 0.48938924 || Val it_count: 1107 || Current Learning Rate: 0.001 || Time: 02:37:0.90
Epoch :: 24 || Loss: 0.45800246 || it_count: 8344 || Val Loss: 0.48785367 || Val it_count: 1107 || Current Learning Rate: 0.001 || Time: 02:43:49.37
Epoch :: 25 || Loss: 0.45794348 || it_count: 8344 || Val Loss: 0.48638133 || Val it_count: 1107 || Current Learning Rate: 0.001 || Time: 02:50:38.18
Epoch :: 26 || Loss: 0.45704834 || it_count: 8344 || Val Loss: 0.49191094 || Val it_count: 1107 || Current Learning Rate: 0.001 || Time: 02:57:27.01
Epoch :: 27 || Loss: 0.45412115 || it_count: 8344 || Val Loss: 0.49965733 || Val it_count: 1107 || Current Learning Rate: 0.001 || Time: 03:04:16.29
Epoch :: 28 || Loss: 0.44840529 || it_count: 8344 || Val Loss: 0.49292751 || Val it_count: 1107 || Current Learning Rate: 0.001 || Time: 03:11:5.13
Epoch :: 29 || Loss: 0.44909793 || it_count: 8344 || Val Loss: 0.49242585 || Val it_count: 1107 || Current Learning Rate: 0.001 || Time: 03:17:54.01
Epoch :: 30 || Loss: 0.44941563 || it_count: 8344 || Val Loss: 0.48643119 || Val it_count: 1107 || Current Learning Rate: 0.001 || Time: 03:24:43.33
Epoch 00015: reducing learning rate of group 0 to 1.0000e-04.
Epoch :: 31 || Loss: 0.45207402 || it_count: 8344 || Val Loss: 0.48799448 || Val it_count: 1107 || Current Learning Rate: 0.0001 || Time: 03:31:32.47
Epoch :: 32 || Loss: 0.44432684 || it_count: 8344 || Val Loss: 0.48198943 || Val it_count: 1107 || Current Learning Rate: 0.0001 || Time: 03:38:22.46
Epoch :: 33 || Loss: 0.43389130 || it_count: 8344 || Val Loss: 0.48213686 || Val it_count: 1107 || Current Learning Rate: 0.0001 || Time: 03:45:11.01
Epoch :: 34 || Loss: 0.43017120 || it_count: 8344 || Val Loss: 0.48202857 || Val it_count: 1107 || Current Learning Rate: 0.0001 || Time: 03:52:0.92
Epoch :: 35 || Loss: 0.42808423 || it_count: 8344 || Val Loss: 0.48488044 || Val it_count: 1107 || Current Learning Rate: 0.0001 || Time: 03:58:50.16
Epoch :: 36 || Loss: 0.42662572 || it_count: 8344 || Val Loss: 0.48411135 || Val it_count: 1107 || Current Learning Rate: 0.0001 || Time: 04:05:40.48
Epoch :: 37 || Loss: 0.42548970 || it_count: 8344 || Val Loss: 0.48580017 || Val it_count: 1107 || Current Learning Rate: 0.0001 || Time: 04:12:29.76
Epoch 00022: reducing learning rate of group 0 to 1.0000e-05.
Epoch :: 38 || Loss: 0.42461258 || it_count: 8344 || Val Loss: 0.48739602 || Val it_count: 1107 || Current Learning Rate: 1e-05 || Time: 04:19:17.81
Epoch :: 39 || Loss: 0.42979443 || it_count: 8344 || Val Loss: 0.46706950 || Val it_count: 1107 || Current Learning Rate: 1e-05 || Time: 04:26:7.74
Epoch :: 40 || Loss: 0.42640385 || it_count: 8344 || Val Loss: 0.46599974 || Val it_count: 1107 || Current Learning Rate: 1e-05 || Time: 04:32:57.06
Epoch :: 41 || Loss: 0.42511593 || it_count: 8344 || Val Loss: 0.46589724 || Val it_count: 1107 || Current Learning Rate: 1e-05 || Time: 04:39:46.41
Epoch :: 42 || Loss: 0.42436504 || it_count: 8344 || Val Loss: 0.46578159 || Val it_count: 1107 || Current Learning Rate: 1e-05 || Time: 04:46:35.82
Epoch :: 43 || Loss: 0.42377560 || it_count: 8344 || Val Loss: 0.46604169 || Val it_count: 1107 || Current Learning Rate: 1e-05 || Time: 04:53:26.40
Epoch :: 44 || Loss: 0.42331527 || it_count: 8344 || Val Loss: 0.46632928 || Val it_count: 1107 || Current Learning Rate: 1e-05 || Time: 05:00:14.98
Epoch :: 45 || Loss: 0.42295592 || it_count: 8344 || Val Loss: 0.46671421 || Val it_count: 1107 || Current Learning Rate: 1e-05 || Time: 05:07:2.67
Epoch :: 46 || Loss: 0.42262255 || it_count: 8344 || Val Loss: 0.46732313 || Val it_count: 1107 || Current Learning Rate: 1e-05 || Time: 05:13:52.98
Epoch :: 47 || Loss: 0.42230530 || it_count: 8344 || Val Loss: 0.46814862 || Val it_count: 1107 || Current Learning Rate: 1e-05 || Time: 05:20:44.20
Epoch 00032: reducing learning rate of group 0 to 1.0000e-06.
Epoch :: 48 || Loss: 0.42193964 || it_count: 8344 || Val Loss: 0.46869739 || Val it_count: 1107 || Current Learning Rate: 1.0000000000000002e-06 || Time: 05:27:34.23
Epoch :: 49 || Loss: 0.42406891 || it_count: 8344 || Val Loss: 0.47683251 || Val it_count: 1107 || Current Learning Rate: 1.0000000000000002e-06 || Time: 05:34:24.67
Epoch :: 50 || Loss: 0.42359580 || it_count: 8344 || Val Loss: 0.47674146 || Val it_count: 1107 || Current Learning Rate: 1.0000000000000002e-06 || Time: 05:41:14.90
Epoch :: 51 || Loss: 0.42341444 || it_count: 8344 || Val Loss: 0.47653844 || Val it_count: 1107 || Current Learning Rate: 1.0000000000000002e-06 || Time: 05:48:3.93
Epoch :: 52 || Loss: 0.42330902 || it_count: 8344 || Val Loss: 0.47637291 || Val it_count: 1107 || Current Learning Rate: 1.0000000000000002e-06 || Time: 05:54:53.52
Epoch :: 53 || Loss: 0.42326134 || it_count: 8344 || Val Loss: 0.47616206 || Val it_count: 1107 || Current Learning Rate: 1.0000000000000002e-06 || Time: 06:01:42.06
Epoch 00038: reducing learning rate of group 0 to 1.0000e-07.
Early stopping triggered due to learning rate below threshold.
Done Total time: 06:08:31.19
best_loss: 0.4657815911514595

--------------------Testing--------------------

total_samples :: test_dataset = 139200, test_dataloader = 139200
Epoch ::  1 || Loss: 0.45744838 || it_count: 544 || Time: 00:00:20.23
MAE:  0.31968036
MSE:  0.45756063
RMSE:  0.5156553

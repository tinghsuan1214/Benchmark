--------------------Training--------------------
arch_str :: |lstm_3~0|[relu->dropout->linear->linear]
model :: 2Q
InferCell(
  info :: nodes=2, inC=1, outC=64, [1<-(I0-L0)], genotype_str: lstm_3~0
  linear_layers: [relu->dropout->linear->linear]
  (layers): ModuleList(
    (0): LSTM(
      (lstm): LSTM(1, 64, num_layers=3, batch_first=True)
    )
  )
  (linear_layers): ModuleList(
    (0): ReLU()
    (1): Dropout(p=0.1, inplace=False)
    (2): Linear(in_features=3072, out_features=1536, bias=True)
    (3): Linear(in_features=1536, out_features=1, bias=True)
  )
)
tr_params :: epochs = 100, patience = 20, batch_size = 256, window_size = 48, data_size = 100
Model FLOPs: 8.812M, Model Params: 4.805M
learning rate scheduling :: (optimizer, mode='min', factor=0.1, patience=5, verbose=True)
total_samples :: train_dataset = 2136000, train_dataloader = 2136000
total_samples :: valid_dataset = 283200, valid_dataloader = 283200
Epoch ::  1 || Loss: 0.42767881 || it_count: 8344 || Val Loss: 0.46640740 || Val it_count: 1107 || Current Learning Rate: 0.001 || Time: 00:04:14.09
Epoch ::  2 || Loss: 0.42038785 || it_count: 8344 || Val Loss: 0.45156358 || Val it_count: 1107 || Current Learning Rate: 0.001 || Time: 00:08:22.83
Epoch ::  3 || Loss: 0.41931495 || it_count: 8344 || Val Loss: 0.44973461 || Val it_count: 1107 || Current Learning Rate: 0.001 || Time: 00:12:35.41
Epoch ::  4 || Loss: 0.41898438 || it_count: 8344 || Val Loss: 0.44872073 || Val it_count: 1107 || Current Learning Rate: 0.001 || Time: 00:16:48.93
Epoch ::  5 || Loss: 0.41841781 || it_count: 8344 || Val Loss: 0.44924884 || Val it_count: 1107 || Current Learning Rate: 0.001 || Time: 00:21:1.95
Epoch ::  6 || Loss: 0.41790514 || it_count: 8344 || Val Loss: 0.45077324 || Val it_count: 1107 || Current Learning Rate: 0.001 || Time: 00:25:14.08
Epoch ::  7 || Loss: 0.41761630 || it_count: 8344 || Val Loss: 0.44946236 || Val it_count: 1107 || Current Learning Rate: 0.001 || Time: 00:29:25.27
Epoch ::  8 || Loss: 0.41732610 || it_count: 8344 || Val Loss: 0.45042826 || Val it_count: 1107 || Current Learning Rate: 0.001 || Time: 00:33:36.94
Epoch ::  9 || Loss: 0.41696167 || it_count: 8344 || Val Loss: 0.45056849 || Val it_count: 1107 || Current Learning Rate: 0.001 || Time: 00:37:49.30
Epoch :: 10 || Loss: 0.41657923 || it_count: 8344 || Val Loss: 0.44870149 || Val it_count: 1107 || Current Learning Rate: 0.001 || Time: 00:42:2.05
Epoch :: 11 || Loss: 0.41622301 || it_count: 8344 || Val Loss: 0.45000182 || Val it_count: 1107 || Current Learning Rate: 0.001 || Time: 00:46:16.56
Epoch :: 12 || Loss: 0.41630734 || it_count: 8344 || Val Loss: 0.45056500 || Val it_count: 1107 || Current Learning Rate: 0.001 || Time: 00:50:29.75
Epoch :: 13 || Loss: 0.41588264 || it_count: 8344 || Val Loss: 0.45098870 || Val it_count: 1107 || Current Learning Rate: 0.001 || Time: 00:54:43.58
Epoch :: 14 || Loss: 0.41581476 || it_count: 8344 || Val Loss: 0.44997397 || Val it_count: 1107 || Current Learning Rate: 0.001 || Time: 00:58:58.11
Epoch :: 15 || Loss: 0.41534990 || it_count: 8344 || Val Loss: 0.44781187 || Val it_count: 1107 || Current Learning Rate: 0.001 || Time: 01:03:10.42
Epoch :: 16 || Loss: 0.41536352 || it_count: 8344 || Val Loss: 0.45097326 || Val it_count: 1107 || Current Learning Rate: 0.001 || Time: 01:07:23.24
Epoch :: 17 || Loss: 0.41470429 || it_count: 8344 || Val Loss: 0.45201149 || Val it_count: 1107 || Current Learning Rate: 0.001 || Time: 01:11:34.00
Epoch :: 18 || Loss: 0.41394998 || it_count: 8344 || Val Loss: 0.45067284 || Val it_count: 1107 || Current Learning Rate: 0.001 || Time: 01:15:47.22
Epoch :: 19 || Loss: 0.41444900 || it_count: 8344 || Val Loss: 0.45458969 || Val it_count: 1107 || Current Learning Rate: 0.001 || Time: 01:20:0.61
Epoch :: 20 || Loss: 0.41485229 || it_count: 8344 || Val Loss: 0.45339466 || Val it_count: 1107 || Current Learning Rate: 0.001 || Time: 01:24:12.15
Epoch :: 21 || Loss: 0.41413255 || it_count: 8344 || Val Loss: 0.45007546 || Val it_count: 1107 || Current Learning Rate: 0.001 || Time: 01:28:26.56
Epoch :: 22 || Loss: 0.41432532 || it_count: 8344 || Val Loss: 0.45144888 || Val it_count: 1107 || Current Learning Rate: 0.001 || Time: 01:32:39.73
Epoch :: 23 || Loss: 0.41291497 || it_count: 8344 || Val Loss: 0.44998744 || Val it_count: 1107 || Current Learning Rate: 0.001 || Time: 01:36:50.03
Epoch :: 24 || Loss: 0.41245085 || it_count: 8344 || Val Loss: 0.45240004 || Val it_count: 1107 || Current Learning Rate: 0.001 || Time: 01:41:2.02
Epoch :: 25 || Loss: 0.41301422 || it_count: 8344 || Val Loss: 0.45260137 || Val it_count: 1107 || Current Learning Rate: 0.001 || Time: 01:45:13.80
Epoch :: 26 || Loss: 0.41223576 || it_count: 8344 || Val Loss: 0.44722072 || Val it_count: 1107 || Current Learning Rate: 0.001 || Time: 01:49:26.14
Epoch :: 27 || Loss: 0.41155055 || it_count: 8344 || Val Loss: 0.44952671 || Val it_count: 1107 || Current Learning Rate: 0.001 || Time: 01:53:40.08
Epoch :: 28 || Loss: 0.41140219 || it_count: 8344 || Val Loss: 0.45211691 || Val it_count: 1107 || Current Learning Rate: 0.001 || Time: 01:57:54.02
Epoch :: 29 || Loss: 0.41268062 || it_count: 8344 || Val Loss: 0.46496272 || Val it_count: 1107 || Current Learning Rate: 0.001 || Time: 02:02:8.88
Epoch :: 30 || Loss: 0.41084480 || it_count: 8344 || Val Loss: 0.45196957 || Val it_count: 1107 || Current Learning Rate: 0.001 || Time: 02:06:23.09
Epoch :: 31 || Loss: 0.41018210 || it_count: 8344 || Val Loss: 0.45243148 || Val it_count: 1107 || Current Learning Rate: 0.001 || Time: 02:10:35.22
Epoch 00016: reducing learning rate of group 0 to 1.0000e-04.
Epoch :: 32 || Loss: 0.41008446 || it_count: 8344 || Val Loss: 0.45007888 || Val it_count: 1107 || Current Learning Rate: 0.0001 || Time: 02:14:49.09
Epoch :: 33 || Loss: 0.41740257 || it_count: 8344 || Val Loss: 0.43313888 || Val it_count: 1107 || Current Learning Rate: 0.0001 || Time: 02:19:3.36
Epoch :: 34 || Loss: 0.41293078 || it_count: 8344 || Val Loss: 0.43121099 || Val it_count: 1107 || Current Learning Rate: 0.0001 || Time: 02:23:17.81
Epoch :: 35 || Loss: 0.41187929 || it_count: 8344 || Val Loss: 0.42940352 || Val it_count: 1107 || Current Learning Rate: 0.0001 || Time: 02:27:31.56
Epoch :: 36 || Loss: 0.41118016 || it_count: 8344 || Val Loss: 0.42871628 || Val it_count: 1107 || Current Learning Rate: 0.0001 || Time: 02:31:44.40
Epoch :: 37 || Loss: 0.41065806 || it_count: 8344 || Val Loss: 0.42846932 || Val it_count: 1107 || Current Learning Rate: 0.0001 || Time: 02:35:57.86
Epoch :: 38 || Loss: 0.41019244 || it_count: 8344 || Val Loss: 0.42844854 || Val it_count: 1107 || Current Learning Rate: 0.0001 || Time: 02:40:10.82
Epoch :: 39 || Loss: 0.40994183 || it_count: 8344 || Val Loss: 0.42809671 || Val it_count: 1107 || Current Learning Rate: 0.0001 || Time: 02:44:25.07
Epoch :: 40 || Loss: 0.40958474 || it_count: 8344 || Val Loss: 0.42833676 || Val it_count: 1107 || Current Learning Rate: 0.0001 || Time: 02:48:37.50
Epoch :: 41 || Loss: 0.40933899 || it_count: 8344 || Val Loss: 0.42884825 || Val it_count: 1107 || Current Learning Rate: 0.0001 || Time: 02:52:51.27
Epoch :: 42 || Loss: 0.40918072 || it_count: 8344 || Val Loss: 0.42768878 || Val it_count: 1107 || Current Learning Rate: 0.0001 || Time: 02:57:5.66
Epoch :: 43 || Loss: 0.40885226 || it_count: 8344 || Val Loss: 0.42860924 || Val it_count: 1107 || Current Learning Rate: 0.0001 || Time: 03:01:20.81
Epoch :: 44 || Loss: 0.40875297 || it_count: 8344 || Val Loss: 0.42797455 || Val it_count: 1107 || Current Learning Rate: 0.0001 || Time: 03:05:34.51
Epoch :: 45 || Loss: 0.40847975 || it_count: 8344 || Val Loss: 0.42777821 || Val it_count: 1107 || Current Learning Rate: 0.0001 || Time: 03:09:48.93
Epoch :: 46 || Loss: 0.40820999 || it_count: 8344 || Val Loss: 0.42780720 || Val it_count: 1107 || Current Learning Rate: 0.0001 || Time: 03:14:1.21
Epoch :: 47 || Loss: 0.40787321 || it_count: 8344 || Val Loss: 0.42753513 || Val it_count: 1107 || Current Learning Rate: 0.0001 || Time: 03:18:13.77
Epoch :: 48 || Loss: 0.40772710 || it_count: 8344 || Val Loss: 0.42716726 || Val it_count: 1107 || Current Learning Rate: 0.0001 || Time: 03:22:26.64
Epoch :: 49 || Loss: 0.40751654 || it_count: 8344 || Val Loss: 0.42799469 || Val it_count: 1107 || Current Learning Rate: 0.0001 || Time: 03:26:41.79
Epoch :: 50 || Loss: 0.40747913 || it_count: 8344 || Val Loss: 0.42761651 || Val it_count: 1107 || Current Learning Rate: 0.0001 || Time: 03:30:56.78
Epoch :: 51 || Loss: 0.40735431 || it_count: 8344 || Val Loss: 0.42827994 || Val it_count: 1107 || Current Learning Rate: 0.0001 || Time: 03:35:9.52
Epoch :: 52 || Loss: 0.40732672 || it_count: 8344 || Val Loss: 0.42807114 || Val it_count: 1107 || Current Learning Rate: 0.0001 || Time: 03:39:24.43
Epoch :: 53 || Loss: 0.40683639 || it_count: 8344 || Val Loss: 0.42845921 || Val it_count: 1107 || Current Learning Rate: 0.0001 || Time: 03:43:37.17
Epoch 00038: reducing learning rate of group 0 to 1.0000e-05.
Epoch :: 54 || Loss: 0.40669735 || it_count: 8344 || Val Loss: 0.42755862 || Val it_count: 1107 || Current Learning Rate: 1e-05 || Time: 03:47:50.45
Epoch :: 55 || Loss: 0.41130797 || it_count: 8344 || Val Loss: 0.41337886 || Val it_count: 1107 || Current Learning Rate: 1e-05 || Time: 03:52:3.43
Epoch :: 56 || Loss: 0.40903180 || it_count: 8344 || Val Loss: 0.41322473 || Val it_count: 1107 || Current Learning Rate: 1e-05 || Time: 03:56:15.93
Epoch :: 57 || Loss: 0.40885710 || it_count: 8344 || Val Loss: 0.41317637 || Val it_count: 1107 || Current Learning Rate: 1e-05 || Time: 04:00:29.20
Epoch :: 58 || Loss: 0.40881881 || it_count: 8344 || Val Loss: 0.41312042 || Val it_count: 1107 || Current Learning Rate: 1e-05 || Time: 04:04:41.00
Epoch :: 59 || Loss: 0.40867927 || it_count: 8344 || Val Loss: 0.41315846 || Val it_count: 1107 || Current Learning Rate: 1e-05 || Time: 04:08:54.13
Epoch :: 60 || Loss: 0.40860876 || it_count: 8344 || Val Loss: 0.41312795 || Val it_count: 1107 || Current Learning Rate: 1e-05 || Time: 04:13:7.51
Epoch :: 61 || Loss: 0.40850917 || it_count: 8344 || Val Loss: 0.41317212 || Val it_count: 1107 || Current Learning Rate: 1e-05 || Time: 04:17:21.53
Epoch :: 62 || Loss: 0.40843202 || it_count: 8344 || Val Loss: 0.41318064 || Val it_count: 1107 || Current Learning Rate: 1e-05 || Time: 04:21:34.44
Epoch :: 63 || Loss: 0.40834923 || it_count: 8344 || Val Loss: 0.41319912 || Val it_count: 1107 || Current Learning Rate: 1e-05 || Time: 04:25:46.41
Epoch 00048: reducing learning rate of group 0 to 1.0000e-06.
Epoch :: 64 || Loss: 0.40832762 || it_count: 8344 || Val Loss: 0.41326013 || Val it_count: 1107 || Current Learning Rate: 1.0000000000000002e-06 || Time: 04:29:58.97
Epoch :: 65 || Loss: 0.40893171 || it_count: 8344 || Val Loss: 0.41199535 || Val it_count: 1107 || Current Learning Rate: 1.0000000000000002e-06 || Time: 04:34:10.22
Epoch :: 66 || Loss: 0.40863354 || it_count: 8344 || Val Loss: 0.41183990 || Val it_count: 1107 || Current Learning Rate: 1.0000000000000002e-06 || Time: 04:38:22.07
Epoch :: 67 || Loss: 0.40856842 || it_count: 8344 || Val Loss: 0.41178508 || Val it_count: 1107 || Current Learning Rate: 1.0000000000000002e-06 || Time: 04:42:36.58
Epoch :: 68 || Loss: 0.40845824 || it_count: 8344 || Val Loss: 0.41176280 || Val it_count: 1107 || Current Learning Rate: 1.0000000000000002e-06 || Time: 04:46:48.78
Epoch :: 69 || Loss: 0.40843972 || it_count: 8344 || Val Loss: 0.41175274 || Val it_count: 1107 || Current Learning Rate: 1.0000000000000002e-06 || Time: 04:51:2.29
Epoch :: 70 || Loss: 0.40844546 || it_count: 8344 || Val Loss: 0.41173290 || Val it_count: 1107 || Current Learning Rate: 1.0000000000000002e-06 || Time: 04:55:17.78
Epoch :: 71 || Loss: 0.40839997 || it_count: 8344 || Val Loss: 0.41172325 || Val it_count: 1107 || Current Learning Rate: 1.0000000000000002e-06 || Time: 04:59:36.46
Epoch :: 72 || Loss: 0.40841274 || it_count: 8344 || Val Loss: 0.41171345 || Val it_count: 1107 || Current Learning Rate: 1.0000000000000002e-06 || Time: 05:03:52.16
Epoch :: 73 || Loss: 0.40835421 || it_count: 8344 || Val Loss: 0.41169509 || Val it_count: 1107 || Current Learning Rate: 1.0000000000000002e-06 || Time: 05:08:4.65
Epoch :: 74 || Loss: 0.40837029 || it_count: 8344 || Val Loss: 0.41169722 || Val it_count: 1107 || Current Learning Rate: 1.0000000000000002e-06 || Time: 05:12:17.48
Epoch :: 75 || Loss: 0.40834641 || it_count: 8344 || Val Loss: 0.41169392 || Val it_count: 1107 || Current Learning Rate: 1.0000000000000002e-06 || Time: 05:16:31.57
Epoch :: 76 || Loss: 0.40829760 || it_count: 8344 || Val Loss: 0.41168666 || Val it_count: 1107 || Current Learning Rate: 1.0000000000000002e-06 || Time: 05:20:46.06
Epoch :: 77 || Loss: 0.40834643 || it_count: 8344 || Val Loss: 0.41168234 || Val it_count: 1107 || Current Learning Rate: 1.0000000000000002e-06 || Time: 05:24:59.45
Epoch :: 78 || Loss: 0.40834658 || it_count: 8344 || Val Loss: 0.41168215 || Val it_count: 1107 || Current Learning Rate: 1.0000000000000002e-06 || Time: 05:29:13.18
Epoch :: 79 || Loss: 0.40828395 || it_count: 8344 || Val Loss: 0.41166909 || Val it_count: 1107 || Current Learning Rate: 1.0000000000000002e-06 || Time: 05:33:26.53
Epoch :: 80 || Loss: 0.40829522 || it_count: 8344 || Val Loss: 0.41166894 || Val it_count: 1107 || Current Learning Rate: 1.0000000000000002e-06 || Time: 05:37:41.86
Epoch :: 81 || Loss: 0.40831326 || it_count: 8344 || Val Loss: 0.41166520 || Val it_count: 1107 || Current Learning Rate: 1.0000000000000002e-06 || Time: 05:41:55.15
Epoch 00066: reducing learning rate of group 0 to 1.0000e-07.
Early stopping triggered due to learning rate below threshold.
Done Total time: 05:46:8.75
best_loss: 0.411665195822064

--------------------Testing--------------------

total_samples :: test_dataset = 139200, test_dataloader = 139200
Epoch ::  1 || Loss: 0.23550268 || it_count: 544 || Time: 00:00:13.62
MAE:  0.25209594
MSE:  0.23552196
RMSE:  0.44111514

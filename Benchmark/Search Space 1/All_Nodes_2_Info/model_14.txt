--------------------Training--------------------
arch_str :: |lstm_1~0|[relu->linear]
model :: 2C
InferCell(
  info :: nodes=2, inC=1, outC=64, [1<-(I0-L0)], genotype_str: lstm_1~0
  linear_layers: [relu->linear]
  (layers): ModuleList(
    (0): LSTM(
      (lstm): LSTM(1, 64, batch_first=True)
    )
  )
  (linear_layers): ModuleList(
    (0): ReLU()
    (1): Linear(in_features=3072, out_features=1, bias=True)
  )
)
tr_params :: epochs = 100, patience = 20, batch_size = 256, window_size = 48, data_size = 100
Model FLOPs: 850.944K, Model Params: 20.225K
learning rate scheduling :: (optimizer, mode='min', factor=0.1, patience=5, verbose=True)
total_samples :: train_dataset = 2136000, train_dataloader = 2136000
total_samples :: valid_dataset = 283200, valid_dataloader = 283200
Epoch ::  1 || Loss: 0.42127171 || it_count: 8344 || Val Loss: 0.44833824 || Val it_count: 1107 || Current Learning Rate: 0.001 || Time: 00:05:19.75
Epoch ::  2 || Loss: 0.41876066 || it_count: 8344 || Val Loss: 0.44706970 || Val it_count: 1107 || Current Learning Rate: 0.001 || Time: 00:10:36.45
Epoch ::  3 || Loss: 0.41872384 || it_count: 8344 || Val Loss: 0.44656963 || Val it_count: 1107 || Current Learning Rate: 0.001 || Time: 00:15:52.70
Epoch ::  4 || Loss: 0.41829271 || it_count: 8344 || Val Loss: 0.44726426 || Val it_count: 1107 || Current Learning Rate: 0.001 || Time: 00:21:7.34
Epoch ::  5 || Loss: 0.41783377 || it_count: 8344 || Val Loss: 0.44624989 || Val it_count: 1107 || Current Learning Rate: 0.001 || Time: 00:26:22.04
Epoch ::  6 || Loss: 0.41726135 || it_count: 8344 || Val Loss: 0.44559981 || Val it_count: 1107 || Current Learning Rate: 0.001 || Time: 00:31:38.56
Epoch ::  7 || Loss: 0.41684502 || it_count: 8344 || Val Loss: 0.44412666 || Val it_count: 1107 || Current Learning Rate: 0.001 || Time: 00:36:53.88
Epoch ::  8 || Loss: 0.41645741 || it_count: 8344 || Val Loss: 0.44410794 || Val it_count: 1107 || Current Learning Rate: 0.001 || Time: 00:42:9.17
Epoch ::  9 || Loss: 0.41625840 || it_count: 8344 || Val Loss: 0.44654623 || Val it_count: 1107 || Current Learning Rate: 0.001 || Time: 00:47:24.80
Epoch :: 10 || Loss: 0.41635166 || it_count: 8344 || Val Loss: 0.44554232 || Val it_count: 1107 || Current Learning Rate: 0.001 || Time: 00:52:41.76
Epoch :: 11 || Loss: 0.41613577 || it_count: 8344 || Val Loss: 0.44527574 || Val it_count: 1107 || Current Learning Rate: 0.001 || Time: 00:57:57.39
Epoch :: 12 || Loss: 0.41588811 || it_count: 8344 || Val Loss: 0.44429112 || Val it_count: 1107 || Current Learning Rate: 0.001 || Time: 01:03:13.40
Epoch :: 13 || Loss: 0.41564902 || it_count: 8344 || Val Loss: 0.44452547 || Val it_count: 1107 || Current Learning Rate: 0.001 || Time: 01:08:29.05
Epoch :: 14 || Loss: 0.41553871 || it_count: 8344 || Val Loss: 0.44351002 || Val it_count: 1107 || Current Learning Rate: 0.001 || Time: 01:13:44.85
Epoch :: 15 || Loss: 0.41525713 || it_count: 8344 || Val Loss: 0.44348440 || Val it_count: 1107 || Current Learning Rate: 0.001 || Time: 01:19:0.23
Epoch :: 16 || Loss: 0.41510532 || it_count: 8344 || Val Loss: 0.44323554 || Val it_count: 1107 || Current Learning Rate: 0.001 || Time: 01:24:15.67
Epoch :: 17 || Loss: 0.41483078 || it_count: 8344 || Val Loss: 0.44291616 || Val it_count: 1107 || Current Learning Rate: 0.001 || Time: 01:29:31.48
Epoch :: 18 || Loss: 0.41461288 || it_count: 8344 || Val Loss: 0.44250223 || Val it_count: 1107 || Current Learning Rate: 0.001 || Time: 01:34:47.77
Epoch :: 19 || Loss: 0.41450096 || it_count: 8344 || Val Loss: 0.44199458 || Val it_count: 1107 || Current Learning Rate: 0.001 || Time: 01:40:2.51
Epoch :: 20 || Loss: 0.41452227 || it_count: 8344 || Val Loss: 0.44342641 || Val it_count: 1107 || Current Learning Rate: 0.001 || Time: 01:45:18.24
Epoch :: 21 || Loss: 0.41439385 || it_count: 8344 || Val Loss: 0.44241576 || Val it_count: 1107 || Current Learning Rate: 0.001 || Time: 01:50:33.22
Epoch :: 22 || Loss: 0.41404090 || it_count: 8344 || Val Loss: 0.44029987 || Val it_count: 1107 || Current Learning Rate: 0.001 || Time: 01:55:48.65
Epoch :: 23 || Loss: 0.42201941 || it_count: 8344 || Val Loss: 0.44133937 || Val it_count: 1107 || Current Learning Rate: 0.001 || Time: 02:01:4.82
Epoch :: 24 || Loss: 0.41536288 || it_count: 8344 || Val Loss: 0.44346206 || Val it_count: 1107 || Current Learning Rate: 0.001 || Time: 02:06:20.08
Epoch :: 25 || Loss: 0.41510592 || it_count: 8344 || Val Loss: 0.44382172 || Val it_count: 1107 || Current Learning Rate: 0.001 || Time: 02:11:37.33
Epoch :: 26 || Loss: 0.41511592 || it_count: 8344 || Val Loss: 0.44065121 || Val it_count: 1107 || Current Learning Rate: 0.001 || Time: 02:16:53.62
Epoch :: 27 || Loss: 0.41405105 || it_count: 8344 || Val Loss: 0.44378667 || Val it_count: 1107 || Current Learning Rate: 0.001 || Time: 02:22:10.34
Epoch 00012: reducing learning rate of group 0 to 1.0000e-04.
Epoch :: 28 || Loss: 0.41474319 || it_count: 8344 || Val Loss: 0.44116943 || Val it_count: 1107 || Current Learning Rate: 0.0001 || Time: 02:27:26.05
Epoch :: 29 || Loss: 0.41858980 || it_count: 8344 || Val Loss: 0.42217520 || Val it_count: 1107 || Current Learning Rate: 0.0001 || Time: 02:32:42.28
Epoch :: 30 || Loss: 0.41544794 || it_count: 8344 || Val Loss: 0.42147133 || Val it_count: 1107 || Current Learning Rate: 0.0001 || Time: 02:37:57.45
Epoch :: 31 || Loss: 0.41499860 || it_count: 8344 || Val Loss: 0.42160371 || Val it_count: 1107 || Current Learning Rate: 0.0001 || Time: 02:43:13.91
Epoch :: 32 || Loss: 0.41477207 || it_count: 8344 || Val Loss: 0.42171593 || Val it_count: 1107 || Current Learning Rate: 0.0001 || Time: 02:48:30.59
Epoch :: 33 || Loss: 0.41454195 || it_count: 8344 || Val Loss: 0.42144435 || Val it_count: 1107 || Current Learning Rate: 0.0001 || Time: 02:53:45.20
Epoch :: 34 || Loss: 0.41436877 || it_count: 8344 || Val Loss: 0.42018068 || Val it_count: 1107 || Current Learning Rate: 0.0001 || Time: 02:59:2.20
Epoch :: 35 || Loss: 0.41390901 || it_count: 8344 || Val Loss: 0.42062535 || Val it_count: 1107 || Current Learning Rate: 0.0001 || Time: 03:04:17.96
Epoch :: 36 || Loss: 0.41364781 || it_count: 8344 || Val Loss: 0.41989061 || Val it_count: 1107 || Current Learning Rate: 0.0001 || Time: 03:09:33.34
Epoch :: 37 || Loss: 0.41333279 || it_count: 8344 || Val Loss: 0.41961491 || Val it_count: 1107 || Current Learning Rate: 0.0001 || Time: 03:14:48.73
Epoch :: 38 || Loss: 0.41311975 || it_count: 8344 || Val Loss: 0.41942506 || Val it_count: 1107 || Current Learning Rate: 0.0001 || Time: 03:20:4.60
Epoch :: 39 || Loss: 0.41288769 || it_count: 8344 || Val Loss: 0.42025718 || Val it_count: 1107 || Current Learning Rate: 0.0001 || Time: 03:25:20.27
Epoch :: 40 || Loss: 0.41274121 || it_count: 8344 || Val Loss: 0.42018226 || Val it_count: 1107 || Current Learning Rate: 0.0001 || Time: 03:30:37.13
Epoch :: 41 || Loss: 0.41250467 || it_count: 8344 || Val Loss: 0.42062302 || Val it_count: 1107 || Current Learning Rate: 0.0001 || Time: 03:35:54.20
Epoch :: 42 || Loss: 0.41231178 || it_count: 8344 || Val Loss: 0.42025668 || Val it_count: 1107 || Current Learning Rate: 0.0001 || Time: 03:41:10.93
Epoch :: 43 || Loss: 0.41221504 || it_count: 8344 || Val Loss: 0.42053236 || Val it_count: 1107 || Current Learning Rate: 0.0001 || Time: 03:46:28.10
Epoch 00028: reducing learning rate of group 0 to 1.0000e-05.
Epoch :: 44 || Loss: 0.41206215 || it_count: 8344 || Val Loss: 0.42000587 || Val it_count: 1107 || Current Learning Rate: 1e-05 || Time: 03:51:44.71
Epoch :: 45 || Loss: 0.41310282 || it_count: 8344 || Val Loss: 0.41528215 || Val it_count: 1107 || Current Learning Rate: 1e-05 || Time: 03:57:0.43
Epoch :: 46 || Loss: 0.41244376 || it_count: 8344 || Val Loss: 0.41518284 || Val it_count: 1107 || Current Learning Rate: 1e-05 || Time: 04:02:15.82
Epoch :: 47 || Loss: 0.41235823 || it_count: 8344 || Val Loss: 0.41520003 || Val it_count: 1107 || Current Learning Rate: 1e-05 || Time: 04:07:31.83
Epoch :: 48 || Loss: 0.41228194 || it_count: 8344 || Val Loss: 0.41518009 || Val it_count: 1107 || Current Learning Rate: 1e-05 || Time: 04:12:48.03
Epoch :: 49 || Loss: 0.41223707 || it_count: 8344 || Val Loss: 0.41514696 || Val it_count: 1107 || Current Learning Rate: 1e-05 || Time: 04:18:4.00
Epoch :: 50 || Loss: 0.41221965 || it_count: 8344 || Val Loss: 0.41509264 || Val it_count: 1107 || Current Learning Rate: 1e-05 || Time: 04:23:19.90
Epoch :: 51 || Loss: 0.41218972 || it_count: 8344 || Val Loss: 0.41502410 || Val it_count: 1107 || Current Learning Rate: 1e-05 || Time: 04:28:36.99
Epoch :: 52 || Loss: 0.41216968 || it_count: 8344 || Val Loss: 0.41509157 || Val it_count: 1107 || Current Learning Rate: 1e-05 || Time: 04:33:52.98
Epoch :: 53 || Loss: 0.41214867 || it_count: 8344 || Val Loss: 0.41506078 || Val it_count: 1107 || Current Learning Rate: 1e-05 || Time: 04:39:8.82
Epoch :: 54 || Loss: 0.41212528 || it_count: 8344 || Val Loss: 0.41504475 || Val it_count: 1107 || Current Learning Rate: 1e-05 || Time: 04:44:24.99
Epoch :: 55 || Loss: 0.41210497 || it_count: 8344 || Val Loss: 0.41503302 || Val it_count: 1107 || Current Learning Rate: 1e-05 || Time: 04:49:40.26
Epoch :: 56 || Loss: 0.41208841 || it_count: 8344 || Val Loss: 0.41502490 || Val it_count: 1107 || Current Learning Rate: 1e-05 || Time: 04:54:55.74
Epoch 00041: reducing learning rate of group 0 to 1.0000e-06.
Epoch :: 57 || Loss: 0.41206815 || it_count: 8344 || Val Loss: 0.41501343 || Val it_count: 1107 || Current Learning Rate: 1.0000000000000002e-06 || Time: 05:00:12.41
Epoch :: 58 || Loss: 0.41211616 || it_count: 8344 || Val Loss: 0.41479984 || Val it_count: 1107 || Current Learning Rate: 1.0000000000000002e-06 || Time: 05:05:28.91
Epoch :: 59 || Loss: 0.41209147 || it_count: 8344 || Val Loss: 0.41477592 || Val it_count: 1107 || Current Learning Rate: 1.0000000000000002e-06 || Time: 05:10:44.61
Epoch :: 60 || Loss: 0.41208093 || it_count: 8344 || Val Loss: 0.41475858 || Val it_count: 1107 || Current Learning Rate: 1.0000000000000002e-06 || Time: 05:16:0.08
Epoch :: 61 || Loss: 0.41207425 || it_count: 8344 || Val Loss: 0.41474812 || Val it_count: 1107 || Current Learning Rate: 1.0000000000000002e-06 || Time: 05:21:15.99
Epoch :: 62 || Loss: 0.41206916 || it_count: 8344 || Val Loss: 0.41474075 || Val it_count: 1107 || Current Learning Rate: 1.0000000000000002e-06 || Time: 05:26:32.24
Epoch :: 63 || Loss: 0.41206564 || it_count: 8344 || Val Loss: 0.41473633 || Val it_count: 1107 || Current Learning Rate: 1.0000000000000002e-06 || Time: 05:31:48.78
Epoch :: 64 || Loss: 0.41206231 || it_count: 8344 || Val Loss: 0.41473388 || Val it_count: 1107 || Current Learning Rate: 1.0000000000000002e-06 || Time: 05:37:4.33
Epoch :: 65 || Loss: 0.41205932 || it_count: 8344 || Val Loss: 0.41473108 || Val it_count: 1107 || Current Learning Rate: 1.0000000000000002e-06 || Time: 05:42:20.87
Epoch :: 66 || Loss: 0.41205714 || it_count: 8344 || Val Loss: 0.41473024 || Val it_count: 1107 || Current Learning Rate: 1.0000000000000002e-06 || Time: 05:47:38.96
Epoch 00051: reducing learning rate of group 0 to 1.0000e-07.
Early stopping triggered due to learning rate below threshold.
Done Total time: 05:52:54.55
best_loss: 0.41473023986177476

--------------------Testing--------------------

total_samples :: test_dataset = 139200, test_dataloader = 139200
Epoch ::  1 || Loss: 0.23975934 || it_count: 544 || Time: 00:00:16.25
MAE:  0.2569644
MSE:  0.23977618
RMSE:  0.44472337
